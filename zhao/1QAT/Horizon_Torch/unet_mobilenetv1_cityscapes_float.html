<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>unet_mobilenetv1_cityscapes_float</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型配置</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">float_trainer = dict(\n    type="distributed_data_parallel_trainer",\n    model=<span style=\'color: green;font-weight: bold;\'>model</span>,\n    data_loader=<span style=\'color: green;font-weight: bold;\'>data_loader</span>,\n    optimizer=dict(\n        type=torch.optim.SGD,\n        params={"weight": dict(weight_decay=weight_decay)},\n        lr=start_lr,\n        momentum=0.9,\n    ),\n    batch_processor=<span style=\'color: green;font-weight: bold;\'>batch_processor</span>,       <span style=\'color: red\'>hat_tool.profiler.profilers.SimpleProfiler</span>\n    device=None,\n    num_epochs=train_epochs,\n    callbacks=[\n        <span style=\'color: green;font-weight: bold;\'>stat_callback</span>,\n        dict(\n            type="StepDecayLrUpdater",\n            lr_decay_id=[200, 240, 280],\n            lr_decay_factor=0.1,\n        ),\n        <span style=\'color: green;font-weight: bold;\'>metric_updater</span>,\n        <span style=\'color: green;font-weight: bold;\'>tb_callback</span>,\n        <span style=\'color: green;font-weight: bold;\'>aidi_tb_callback</span>,\n        <span style=\'color: green;font-weight: bold;\'>tb_loss_callback</span>,\n        <span style=\'color: green;font-weight: bold;\'>aidi_tb_loss_callback</span>,\n        <span style=\'color: green;font-weight: bold;\'>float_val_callback</span>,\n        <span style=\'color: green;font-weight: bold;\'>ckpt_callback</span>,\n    ],\n    sync_bn=True,\n)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">model</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">model = dict(\n    type="Segmentor",\n    backbone=dict(\n        type="MobileNetV1",\n        num_classes=-1,\n        bn_kwargs=bn_kwargs,\n        alpha=alpha,\n        dw_with_relu=True,\n        include_top=False,\n        flat_output=False,\n    ),\n    neck=dict(\n        type="DwUnet",\n        base_channels=int(32 * alpha),\n        bn_kwargs=bn_kwargs,\n        act_type=nn.ReLU,\n        use_deconv=False,\n        dw_with_act=True,\n        output_scales=train_scales,\n    ),\n    head=dict(\n        type="SegHead",\n        num_classes=num_classes,\n        in_strides=train_scales,\n        out_strides=train_scales,\n        stride2channels={\n            stride: int(stride * 32 * alpha) for stride in train_scales\n        },\n        feat_channels=tuple(np.array(train_scales) * int(32 * alpha)),\n        stacked_convs=0,\n        argmax_output=False,\n        dequant_output=True,              <span style=\'color: red\'># 表示输出是经过量化处理的 Int8 数据，适用于边缘设备推理优化。</span>\n        int8_output=True,\n        upscale=False,                    <span style=\'color: red\'># 是否对输出进行上采样到原图大小。</span>\n        output_with_bn=output_with_bn,    <span style=\'color: red\'># 输出层是否使用 BatchNorm。   True</span>\n        bn_kwargs=bn_kwargs, \n    ),\n    losses=dict(\n        type="SoftmaxFocalLoss",\n        loss_name="Focal",\n        num_classes=num_classes,\n        weight=tuple(np.array((256, 128, 64, 32, 16)) / 19),\n        reduction="mean",\n    ),\n)\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">data_loader</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">data_loader = dict(\n    type=torch.utils.data.DataLoader,\n    dataset=dict(\n        type="Cityscapes",\n        data_path=os.path.join(data_rootdir, "train_lmdb"),\n        transforms=[\n            dict(type="PILToTensor"),        <span style=\'color: red\'># 图像裁剪、翻转、颜色增强等</span>\n        ],\n    ),\n    sampler=dict(type=torch.utils.data.DistributedSampler),\n    batch_size=batch_size_per_gpu,\n    shuffle=True,\n    num_workers=dataloader_workers,\n    pin_memory=True,\n    collate_fn=collate_2d,\n)\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">batch_processor</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">batch_processor = dict(\n    type="BasicBatchProcessor",\n    need_grad_update=True,           <span style=\'color: red\'># 表示这个 batch processor 会参与梯度更新（即用于训练阶段）。</span>\n    batch_transforms=[               <span style=\'color: red\'># 这是一个在 batch 层面进行的数据增强与预处理流程，在数据加载后、模型输入前进行处理。 批量归一化、缩放、one-hot、损失计算等</span>\n        dict(type="LabelRemap", mapping=CITYSCAPES_LABLE_MAPPINGS),      <span style=\'color: red\'># 将原始标签（例如 Cityscapes 中的 34 类）映射为训练使用的类别（如 19 类）。</span>\n        dict(type="SegOneHot", num_classes=num_classes),         <span style=\'color: red\'># 将语义分割标签转换为 one-hot 编码格式。输出形状为 (batch_size, num_classes, H, W)，方便后续损失计算。</span>\n        dict(type="SegResize", size=data_shape[1:]),             <span style=\'color: red\'># 将图像和标签统一缩放到指定大小（如 (512, 1024)）。</span>\n        dict(\n            type="SegRandomAffine",   <span style=\'color: red\'># 将图像和标签统一缩放到指定大小（如 (512, 1024)）。</span>\n            degrees=0,\n            scale=(0.5, 2.0),\n            interpolation=InterpolationMode.BILINEAR,\n            label_fill_value=0,\n        ),\n        dict(type="BgrToYuv444", rgb_input=True),     <span style=\'color: red\'># 将 RGB 图像转换为 YUV 格式。</span>\n        dict(\n            type="TorchVisionAdapter",                <span style=\'color: red\'># 图像归一化操作：img = (img - mean) / std</span>\n            interface="Normalize",\n            mean=128.0,\n            std=128.0,\n        ),\n        dict(                              <span style=\'color: red\'># 对输入图像进行缩放，缩放比例为 1 / train_scales。 例如：如果 train_scales = [8, 16, 32]，则 scales = [1/8, 1/16, 1/32]</span>\n            type="Scale",\n            scales=tuple(1 / np.array(train_scales)),\n            mode="bilinear",\n        ),\n    ],\n    loss_collector=<span style=\'color: green;font-weight: bold;\'>loss_collector</span>,\n    enable_amp=enable_amp,                 <span style=\'color: red\'># False</span>\n)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">loss_collector</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def loss_collector(model_outs):\n    losses = model_outs[1]["Focal"]\n    return losses\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">stat_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">stat_callback = dict(    <span style=\'color: red\'># 使用的是一个名为 StatsMonitor 的回调（callback）类。损失值（loss）\\准确率（accuracy）\\学习率（learning rate）\\每一步的耗时\\GPU 内存使用情况\\梯度幅值等</span>\n    type="StatsMonitor",\n    log_freq=1000,\n)\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">MetricUpdater</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">metric_updater = dict(                <span style=\'color: red\'># 用于在训练或验证过程中动态更新评估指标（如 mIoU）的模块</span>\n    type="MetricUpdater",\n    metrics=[miou_metric],            <span style=\'color: red\'># miou_metric = MeanIOU(seg_class=[str(i) for i in range(num_classes)])</span>\n    metric_update_func=update_metric, <span style=\'color: red\'># 每次需要更新指标时调用的函数。这个函数负责从 batch 数据中提取真实标签和预测结果，并更新到指标对象中</span>\n    step_log_freq=100,                <span style=\'color: red\'># 每隔 100 步输出一次当前指标值（例如 mIoU）</span>\n    epoch_log_freq=1,                 <span style=\'color: red\'># 每个 epoch 结束后都会输出一次指标值</span>\n    log_prefix=task_name,             <span style=\'color: red\'># 日志前缀，用于标识不同任务 "unet_mobilenetv1_cityscapes"</span>\n)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">update_metric</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def update_metric(metrics, batch, model_outs):\n    <span style=\'color: red\'># 将每个 batch 的真实标签 target 和预测结果 preds 输入到 metric 对象中，进行内部统计（如 TP / FP / FN 等），后续可用于计算 mIoU、准确率等</span>\n    target: Tensor = batch["gt_seg"][0]\n    ignore_points = target.sum(dim=1) == 0    <span style=\'color: red\'># # 找出所有类别都为 0 的像素点（即忽略区域）</span>\n    target = target.argmax(dim=1)\n    target[ignore_points] = 255\n    preds = model_outs[0][0]\n    preds = torch.argmax(preds, dim=1, keepdim=False)\n    for metric in metrics:\n        metric.update(target, preds)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">tb_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">tb_callback = dict(\n    type="TensorBoard",\n    save_dir=os.path.join(tensorboard_log_path, training_step, "train"),\n    update_freq=1,         <span style=\'color: red\'># 每隔多少次执行一次更新（这里是每 1 次）</span>\n    update_by="epoch",     <span style=\'color: red\'># 更新频率基于“epoch”而不是“iteration”，即每个 epoch 结束后触发一次更新。</span>\n    tb_update_funcs=[tb_update_func],  <span style=\'color: red\'># 提供一个或多个函数，这些函数会在每次更新时被调用。这些函数负责向 TensorBoard 中写入具体的指标数据</span>\n)\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">aidi_tb_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">aidi_tb_callback = dict(     <span style=\'color: red\'># 可能是为了支持在 AI 平台（如 AIDI）上运行时的日志上传机制</span>\n    type="TensorBoard",\n    save_dir=os.path.join(\n        os.getenv("TENSORBOARD_LOG_PATH")\n        or os.path.join(tensorboard_log_path, ".aidi"),\n        training_step,\n        "train",\n    ),\n    update_freq=1,\n    update_by="epoch",\n    tb_update_funcs=[<span style=\'color: green;font-weight: bold;\'>tb_update_func</span>],\n)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">tb_update_func</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">miou_metric = MeanIOU(seg_class=[str(i) for i in range(num_classes)])\ndef tb_update_func(writer, epoch_id, **kwargs):\n    name, value = miou_metric.get()\n    if isinstance(name, str):\n        writer.add_scalar(name, value, global_step=epoch_id)\n    else:\n        for k, v in zip(name, value):\n            writer.add_scalar(k, v, global_step=epoch_id)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">tb_loss_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">tb_loss_callback = dict(\n    type="TensorBoard",\n    save_dir=os.path.join(tensorboard_log_path, training_step, "loss"),\n    loss_name_reg="^.*Focal.*",\n    update_freq=100,\n    update_by="step",\n)\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">aidi_tb_loss_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">aidi_tb_callback = dict(\n    type="TensorBoard",\n    save_dir=os.path.join(\n        os.getenv("TENSORBOARD_LOG_PATH")\n        or os.path.join(tensorboard_log_path, ".aidi"),\n        training_step,\n        "train",\n    ),\n    update_freq=1,\n    update_by="epoch",\n    tb_update_funcs=[<span style=\'color: green;font-weight: bold;\'>tb_update_func</span>],\n)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">tb_update_func</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def tb_update_func(writer, epoch_id, **kwargs):\n    name, value = miou_metric.get()\n    if isinstance(name, str):\n        writer.add_scalar(name, value, global_step=epoch_id)\n    else:\n        for k, v in zip(name, value):\n            writer.add_scalar(k, v, global_step=epoch_id)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">float_val_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">float_val_callback = dict(\n    type="Validation",\n    data_loader=val_data_loader,\n    batch_processor=val_batch_processor,\n    callbacks=[val_metric_updater, val_tb_callback, val_aidi_tb_callback],\n    val_model=deploy_model,\n)\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ckpt_callback</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">ckpt_callback = dict(\n    type="Checkpoint",\n    save_dir=ckpt_dir,\n    name_prefix=training_step + "-",\n    save_interval=1,\n    strict_match=True,\n    mode="max",\n    best_refer_metric=val_miou_metric,\n)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练train.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def train_entrance():\n    <span style=\'color: red\'>4. build and run trainer</span>\n    with DisableLogger(disable_logger, level), RegistryContext():\n        trainer = getattr(cfg, f"{stage}_trainer")      <span style=\'color: red\'>{\'type\': \'distributed_data_par...el_trainer\', \'model\': {\'type\': \'Segmentor\', \'backbone\':</span>\n        trainer["device"] = device                      <span style=\'color: red\'>2</span>\n        trainer = build_from_registry(trainer)          <span style=\'color: red\'><span style=\'color: green;font-weight: bold;\'><</span>hat_tool.engine.ddp_trainer.DistributedDataParallelTrainer<span style=\'color: green;font-weight: bold;\'>></span></span>\n        trainer.<span style=\'color: green;font-weight: bold;\'>fit</span>()\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">hat_tool/engine/loop_base.py</p>DistributedDataParallelTrainer-->Trainer-->LoopBase<br>\n<font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class LoopBase(PipeBase):  <span style=\'color: red\'># noqa: D205,D400</span>\n</code></pre></font>'}]}]})</script></body>
</html>
