<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>crnn_trian</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">train.py</p><span class=\'hidden-code\' data-code=\'train_dataset = dataset.lmdbDataset(root=opt.trainRoot)                  &amp;#39;./data/crnn_gt_test_lmdb&amp;#39;\nassert train_dataset\nif not opt.random_sample:\n    sampler = dataset.randomSequentialSampler(train_dataset, opt.batchSize,idx_list)\nelse:\n    sampler = dataset.randomSequentialSampler(train_dataset, opt.batchSize,idx_list)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batchSize,shuffle=False, sampler=sampler,\n    num_workers=int(opt.workers),collate_fn = dataset.padCollate())      原论文训练测试都统一成32x100.\ntest_dataset = dataset.lmdbDataset(root=opt.valRoot)\nnclass = len(alphabet) + 1\nnc = 1                                                                   输入图像的channel,1表示灰度图。\nconverter = utils.`strLabelConverter`(alphabet)\ncriterion = CTCLoss(blank=0, reduction=&amp;#39;mean&amp;#39;)\ncrnn = crnn.CRNN(opt.imgH, nc, nclass, opt.nh)                         32, 1, 6153, 256\ncrnn.apply(weights_init)\nimage = torch.FloatTensor(opt.batchSize, 3, opt.imgH, opt.imgH)        B,3,32,32\ntext = torch.IntTensor(opt.batchSize * 5)                              40\nlength = torch.IntTensor(opt.batchSize)                                8\nif opt.cuda:\n    crnn.cuda()\n    crnn = torch.nn.DataParallel(crnn, device_ids=range(opt.ngpu))\n    image = image.cuda()\n    criterion = criterion.cuda()\nimage = Variable(image)\ntext = Variable(text)\nlength = Variable(length)\nloss_avg = utils.`averager`()                     loss averager\n......\nfor epoch in range(begin_epoch,opt.nepoch):       0-100\n    train_iter = iter(train_loader)\n    i = 0\n    train_step = epoch*(len(train_loader))\n    while i < len(train_loader):                  i永远到不了15000,所以无法保存模型 这里的len是指所有的数据除以batch_size，也就是一个epoch的step数,已验证过。\n        for p in crnn.parameters():\n            p.requires_grad = True\n        crnn.train()\n        cost = `trainBatch`(crnn, criterion, optimizer)\n        print(&amp;#39;cost&amp;#39;,cost.item())\n        loss_avg.add(cost)\n        i += 1\n        \n        train_step = init_step+((epoch-begin_epoch)*(len(train_loader))+i)\n        if i % opt.displayInterval == 0:\n            lr = scheduler.get_last_lr()[0]\n            print(&amp;#39;lr:%f [epoch:%d/nepoch:%d] [step:%d/nstep:%d] [train_step:%d] Loss: %f&amp;#39; %\n                  (lr,epoch, opt.nepoch, i, len(train_loader), train_step, loss_avg.val()))\n            loss_avg.reset()\n        if train_step % opt.valInterval == 0:\n            val(crnn, test_dataset, criterion)\n        do checkpointing\n        if train_step % opt.saveInterval == 0:\n            save_dict = {\n                &amp;#39;epoch&amp;#39;: epoch+1,  after training one epoch, the start_epoch should be epoch+1\n                &amp;#39;step&amp;#39;: train_step,\n                &amp;#39;optimizer_state_dict&amp;#39;: optimizer.state_dict(),\n                &amp;#39;scheduler_state_dict&amp;#39;: scheduler.state_dict()}\n            save_dict[&amp;#39;model_state_dict&amp;#39;] = crnn.module.state_dict()\n            torch.save(save_dict, &amp;#39;{0}/netCRNN_{1}_{2}.pth&amp;#39;.format(opt.expr_dir, epoch, train_step))\n    scheduler.step() 这里会根据调度器step()函数调整学习率。初始化调整过一次了，必须放optimizer.step()的后面。\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><span class=\'hidden-code\' data-code=\'class strLabelConverter(object):\n    def __init__(self, alphabet, ignore_case=False):\n        self._ignore_case = ignore_case\n        if self._ignore_case:\n            alphabet = alphabet.lower()\n        self.alphabet = alphabet + &amp;#39;-&amp;#39;  # for `-1` index\n        self.dict = {}                  # {&amp;#39;(&amp;#39;: 1, &amp;#39;)&amp;#39;: 2, &amp;#39; &amp;#39;: 3, &amp;#39;#&amp;#39;: 4, ............}\n        for i, char in enumerate(alphabet):\n            self.dict[char] = i + 1\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><span class=\'hidden-code\' data-code=\'class averager(object):\n    def __init__(self):\n        self.reset()\n    def add(self, v):\n        if isinstance(v, Variable):\n            count = v.data.numel()\n            v = v.data.sum()\n        elif isinstance(v, torch.Tensor):\n            count = v.numel()\n            v = v.sum()\n        self.n_count += count\n        self.sum += v\n    def reset(self):\n        self.n_count = 0\n        self.sum = 0\n    def val(self):\n        res = 0\n        if self.n_count != 0:\n            res = self.sum / float(self.n_count)\n        return res\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">train.py</p><span class=\'hidden-code\' data-code=\'def trainBatch(net, criterion, optimizer):\n    data = train_iter.`next`()\n    cpu_images, cpu_texts = data          # torch.Size([8, 1, 32, 170]),  (&amp;#39;听海大道&amp;#39;, &amp;#39;沙河西路(北)&amp;#39;, &amp;#39;滨海大道(东)&amp;#39;, &amp;#39;月亮湾大道&amp;#39;, &amp;#39;深南大道(东)&amp;#39;, &amp;#39;高新南六道&amp;#39;, &amp;#39;铁仔...\n    batch_size = cpu_images.size(0)       # [40,1,32,100]\n    utils.loadData(image, cpu_images)     # 将image resize到(torch.Size([8, 1, 32, 170]),再把cpu_images拷贝给他)\n    t, l = converter.`encode`(cpu_texts)  # torch.Size([48])  , tensor([4, 7, 7, 5, 7, 5, 5, 8], dtype=torch.int32)\n    # t是cpu_texts对应的每个字符下标列表,l是下表列表中对应的文本长度tensor([ 4,  4,  2,  9,  5,  4,  3, 12, 14,  4]\n    utils.loadData(text, t)\n    utils.loadData(length, l)\n    preds = `crnn`(image)                                                # torch.Size([8, 44, 6153])->torch.Size([44, 8, 6153])\n    preds = preds.permute(1,0,2).contiguous()+1e-6                       # [b,t,c]->[t,b,c] 多GPU训练batch汇总是在第一维汇总的,所以确保模型出来的第一维是Batch_size\n    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size)) # Batch_size个T  tensor([44, 44, 44, 44, 44, 44, 44, 44], dtype=torch.int32) => torch.Size([8])\n    cost = criterion(preds.log_softmax(2),text,preds_size,length)        # torch.Size([44, 8, 6153]),torch.Size([48]),torch.Size([8]),torch.Size([8])\n    crnn.zero_grad()\n    cost.backward()\n    optimizer.step()\n    return cost\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">dataset.py</p><span class=\'hidden-code\' data-code=\'\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><span class=\'hidden-code\' data-code=\'class strLabelConverter(object):\n    def encode(self, text):\n        if isinstance(text, str):\n            text = [\n                self.dict[char.lower() if self._ignore_case else char]\n                for char in text\n            ]\n            length = [len(text)]\n        elif isinstance(text, collections.Iterable):\n            length = [len(s) for s in text]                       # [4, 7, 7, 5, 7, 5, 5, 8]  sum(length)=48\n            text = &amp;#39;&amp;#39;.join(text)\n            text, _ = self.`encode`(text)                           # &amp;#39;听海大道沙河西路(北)滨海大道(东)月亮湾大道深南大道(东)高新南六道铁仔山公园Xinhu Rd&amp;#39;\n        return (torch.IntTensor(text), torch.IntTensor(length))   # 返回所有字符的下标的一维Tensor torch.Size([48])，以及每个batch中sample的一维长度Tensor\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><span class=\'hidden-code\' data-code=\'class strLabelConverter(object):\n    def encode(self, text):\n        if isinstance(text, str):           # &amp;#39;听海大道沙河西路(北)滨海大道(东)月亮湾大道深南大道(东)高新南六道铁仔山公园Xinhu Rd&amp;#39;  -- len=48\n            text = [                        # 得到txt=[722, 2936, 1173, 5422, 2804, 2820, 4967, 5245, ......, 38, 49, 54, 48, 61, 3, 32, 44]\n                self.dict[char.lower() if self._ignore_case else char]\n                for char in text\n            ]\n            length = [len(text)]\n        elif isinstance(text, collections.Iterable):\n            length = [len(s) for s in text]                      \n            text = &amp;#39;&amp;#39;.join(text)\n            text, _ = self.encode(text)                           \n        return (torch.IntTensor(text), torch.IntTensor(length))     # torch.Size([48]),\n\'> </span>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/crnn.py</p><span class=\'hidden-code\' data-code=\'class CRNN(nn.Module):\n    def forward(self, input):\n        output = self.layer0(input)       # torch.Size([8, 1, 32, 170])-->torch.Size([8, 64, 16, 85])\n        output = self.layer1(output)      # torch.Size([8, 64, 16, 85])-->torch.Size([8, 128, 8, 43])\n        output = self.layer2(output)      # torch.Size([8, 128, 8, 43])-->torch.Size([8, 256, 4, 44])\n        output = self.layer3(output)      # --->torch.Size([8, 512, 2, 45])\n        conv = self.layer4(output)        # --->torch.Size([8, 512, 1, 44])\n        b, c, h, w = conv.size()          # torch.Size([8, 512, 1, 44])\n        assert h == 1, &amp;#39;the height of conv must be 1&amp;#39;\n        conv = conv.view([b,c,w])\n        conv = conv.permute((2, 0, 1))    # <[26,1,512]?  torch.Size([44, 8, 512])\n        # conv = conv.contiguous() \n        # 第一个LSTM层\n        self.rnn1.flatten_parameters() \n        recurrent, _ = self.rnn1(conv)    # torch.Size([44, 8, 256])\n        T, b, h = recurrent.size()        # `<`26,1,256  所有时刻的输出都拿到,而不是只拿某一个时刻。`>`\n        t_rec = recurrent.view([T*b, h])  # torch.Size([352, 256])\n        output = self.embedding1(t_rec)   # [T * b, nOut]  torch.Size([352, 256])\n        output = output.view([T, b, -1])  # torch.Size([44, 8, 256])\n        # 第二个LSTM层\n        self.rnn2.flatten_parameters()\n        recurrent, _ = self.rnn2(output)\n        T, b, h = recurrent.size()\n        t_rec = recurrent.view([T * b, h])\n        output = self.embedding2(t_rec)   # [T * b, nOut] ---> \n        output = output.view([T, b, -1])  # torch.Size([44, 8, 6153])\n        output = output.permute((1,0,2))  # [b,w,c] --->  torch.Size([8, 44, 6153])\n        return output\n\'> </span>'}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
