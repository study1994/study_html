<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>crnn_trian</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">train.py</p><font size="0"><pre class="language-python"><code class="language-python">train_dataset = dataset.lmdbDataset(root=opt.trainRoot)                  <span style=\'color: red\'>\'./data/crnn_gt_test_lmdb\'</span>\nassert train_dataset\nif not opt.random_sample:\n    sampler = dataset.randomSequentialSampler(train_dataset, opt.batchSize,idx_list)\nelse:\n    sampler = dataset.randomSequentialSampler(train_dataset, opt.batchSize,idx_list)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batchSize,shuffle=False, sampler=sampler,\n    num_workers=int(opt.workers),collate_fn = dataset.padCollate())      <span style=\'color: red\'>原论文训练测试都统一成32x100.</span>\ntest_dataset = dataset.lmdbDataset(root=opt.valRoot)\nnclass = len(alphabet) + 1\nnc = 1                                                                   <span style=\'color: red\'>输入图像的channel,1表示灰度图。</span>\nconverter = utils.<span style=\'color: green;font-weight: bold;\'>strLabelConverter</span>(alphabet)\ncriterion = CTCLoss(blank=0, reduction=\'mean\')\ncrnn = crnn.CRNN(opt.imgH, nc, nclass, opt.nh)      <span style=\'color: red\'>32, 1, 6153, 256</span>\ncrnn.apply(weights_init)\nimage = torch.FloatTensor(opt.batchSize, 3, opt.imgH, opt.imgH)        <span style=\'color: red\'>B,3,32,32</span>\ntext = torch.IntTensor(opt.batchSize * 5)                              <span style=\'color: red\'>40</span>\nlength = torch.IntTensor(opt.batchSize)                                <span style=\'color: red\'>8</span>\nif opt.cuda:\n    crnn.cuda()\n    crnn = torch.nn.DataParallel(crnn, device_ids=range(opt.ngpu))\n    image = image.cuda()\n    criterion = criterion.cuda()\nimage = Variable(image)\ntext = Variable(text)\nlength = Variable(length)\nloss_avg = utils.<span style=\'color: green;font-weight: bold;\'>averager</span>()                     <span style=\'color: red\'>loss averager</span>\n......\nfor epoch in range(begin_epoch,opt.nepoch):       <span style=\'color: red\'>0-100</span>\n    train_iter = iter(train_loader)\n    i = 0\n    train_step = epoch*(len(train_loader))\n    while i < len(train_loader):                  <span style=\'color: red\'>i永远到不了15000,所以无法保存模型 这里的len是指所有的数据除以batch_size，也就是一个epoch的step数,已验证过。</span>\n        for p in crnn.parameters():\n            p.requires_grad = True\n        crnn.train()\n        cost = <span style=\'color: green;font-weight: bold;\'>trainBatch</span>(crnn, criterion, optimizer)\n        #print(\'cost\',cost.item())\n        loss_avg.add(cost)\n        i += 1\n        \n        train_step = init_step+((epoch-begin_epoch)*(len(train_loader))+i)\n        if i % opt.displayInterval == 0:\n            lr = scheduler.get_last_lr()[0]\n            print(\'lr:%f [epoch:%d/nepoch:%d] [step:%d/nstep:%d] [train_step:%d] Loss: %f\' %\n                  (lr,epoch, opt.nepoch, i, len(train_loader), train_step, loss_avg.val()))\n            loss_avg.reset()\n        if train_step % opt.valInterval == 0:\n            val(crnn, test_dataset, criterion)\n        <span style=\'color: red\'>do checkpointing</span>\n        if train_step % opt.saveInterval == 0:\n            save_dict = {\n                \'epoch\': epoch+1,  <span style=\'color: red\'>after training one epoch, the start_epoch should be epoch+1</span>\n                \'step\': train_step,\n                \'optimizer_state_dict\': optimizer.state_dict(),\n                \'scheduler_state_dict\': scheduler.state_dict()}\n            save_dict[\'model_state_dict\'] = crnn.module.state_dict()\n            torch.save(save_dict, \'{0}/netCRNN_{1}_{2}.pth\'.format(opt.expr_dir, epoch, train_step))\n    scheduler.step() #这里会根据调度器step()函数调整学习率。初始化调整过一次了，必须放optimizer.step()的后面。\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class strLabelConverter(object):\n    def __init__(self, alphabet, ignore_case=False):\n        self._ignore_case = ignore_case\n        if self._ignore_case:\n            alphabet = alphabet.lower()\n        self.alphabet = alphabet + \'-\'  <span style=\'color: red\'># for <span style=\'color: green;font-weight: bold;\'>-1</span> index</span>\n        self.dict = {}                  <span style=\'color: red\'># {\'(\': 1, \')\': 2, \' \': 3, \'#\': 4, ............}</span>\n        for i, char in enumerate(alphabet):\n            self.dict[char] = i + 1\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class averager(object):\n    def __init__(self):\n        self.reset()\n    def add(self, v):\n        if isinstance(v, Variable):\n            count = v.data.numel()\n            v = v.data.sum()\n        elif isinstance(v, torch.Tensor):\n            count = v.numel()\n            v = v.sum()\n        self.n_count += count\n        self.sum += v\n    def reset(self):\n        self.n_count = 0\n        self.sum = 0\n    def val(self):\n        res = 0\n        if self.n_count != 0:\n            res = self.sum / float(self.n_count)\n        return res\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">train.py</p><font size="0"><pre class="language-python"><code class="language-python">def trainBatch(net, criterion, optimizer):\n    data = train_iter.next()\n    cpu_images, cpu_texts = data          <span style=\'color: red\'># torch.Size([8, 1, 32, 170]),  (\'听海大道\', \'沙河西路(北)\', \'滨海大道(东)\', \'月亮湾大道\', \'深南大道(东)\', \'高新南六道\', \'铁仔...</span>\n    batch_size = cpu_images.size(0)       <span style=\'color: red\'># [40,1,32,100]</span>\n    utils.loadData(image, cpu_images)     <span style=\'color: red\'># 将image resize到(torch.Size([8, 1, 32, 170]),再把cpu_images拷贝给他)</span>\n    t, l = converter.<span style=\'color: green;font-weight: bold;\'>encode</span>(cpu_texts)  <span style=\'color: red\'># torch.Size([48])  , tensor([4, 7, 7, 5, 7, 5, 5, 8], dtype=torch.int32)</span>\n    <span style=\'color: red\'># t是cpu_texts对应的每个字符下标列表,l是下表列表中对应的文本长度tensor([ 4,  4,  2,  9,  5,  4,  3, 12, 14,  4]</span>\n    utils.loadData(text, t)\n    utils.loadData(length, l)\n    preds = <span style=\'color: green;font-weight: bold;\'>crnn</span>(image)                                                <span style=\'color: red\'># torch.Size([8, 44, 6153])->torch.Size([44, 8, 6153])</span>\n    preds = preds.permute(1,0,2).contiguous()+1e-6                       <span style=\'color: red\'># [b,t,c]->[t,b,c] 多GPU训练batch汇总是在第一维汇总的,所以确保模型出来的第一维是Batch_size</span>\n    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size)) <span style=\'color: red\'># Batch_size个T  tensor([44, 44, 44, 44, 44, 44, 44, 44], dtype=torch.int32) => torch.Size([8])</span>\n    cost = criterion(preds.log_softmax(2),text,preds_size,length)        <span style=\'color: red\'># torch.Size([44, 8, 6153]),torch.Size([48]),torch.Size([8]),torch.Size([8])</span>\n    crnn.zero_grad()\n    cost.backward()\n    optimizer.step()\n    return cost\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class strLabelConverter(object):\n    def encode(self, text):\n        if isinstance(text, str):\n            text = [\n                self.dict[char.lower() if self._ignore_case else char]\n                for char in text\n            ]\n            length = [len(text)]\n        elif isinstance(text, collections.Iterable):\n            length = [len(s) for s in text]                       <span style=\'color: red\'># [4, 7, 7, 5, 7, 5, 5, 8]  sum(length)=48</span>\n            text = \'\'.join(text)\n            text, _ = self.<span style=\'color: green;font-weight: bold;\'>encode</span>(text)                           <span style=\'color: red\'># \'听海大道沙河西路(北)滨海大道(东)月亮湾大道深南大道(东)高新南六道铁仔山公园Xinhu Rd\'</span>\n        return (torch.IntTensor(text), torch.IntTensor(length))   <span style=\'color: red\'># 返回所有字符的下标的一维Tensor torch.Size([48])，以及每个batch中sample的一维长度Tensor</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class strLabelConverter(object):\n    def encode(self, text):\n        if isinstance(text, str):           <span style=\'color: red\'># \'听海大道沙河西路(北)滨海大道(东)月亮湾大道深南大道(东)高新南六道铁仔山公园Xinhu Rd\'  -- len=48</span>\n            text = [                        <span style=\'color: red\'># 得到txt=[722, 2936, 1173, 5422, 2804, 2820, 4967, 5245, ......, 38, 49, 54, 48, 61, 3, 32, 44]</span>\n                self.dict[char.lower() if self._ignore_case else char]\n                for char in text\n            ]\n            length = [len(text)]\n        elif isinstance(text, collections.Iterable):\n            length = [len(s) for s in text]                      \n            text = \'\'.join(text)\n            text, _ = self.encode(text)                           \n        return (torch.IntTensor(text), torch.IntTensor(length))     <span style=\'color: red\'># torch.Size([48]),</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/crnn.py</p><font size="0"><pre class="language-python"><code class="language-python">class CRNN(nn.Module):\n    def forward(self, input):\n        output = self.layer0(input)       <span style=\'color: red\'># torch.Size([8, 1, 32, 170])-->torch.Size([8, 64, 16, 85])</span>\n        output = self.layer1(output)      <span style=\'color: red\'># torch.Size([8, 64, 16, 85])-->torch.Size([8, 128, 8, 43])</span>\n        output = self.layer2(output)      <span style=\'color: red\'># torch.Size([8, 128, 8, 43])-->torch.Size([8, 256, 4, 44])</span>\n        output = self.layer3(output)      <span style=\'color: red\'># --->torch.Size([8, 512, 2, 45])</span>\n        conv = self.layer4(output)        <span style=\'color: red\'># --->torch.Size([8, 512, 1, 44])</span>\n        b, c, h, w = conv.size()          <span style=\'color: red\'># torch.Size([8, 512, 1, 44])</span>\n        assert h == 1, "the height of conv must be 1"\n        conv = conv.view([b,c,w])\n        conv = conv.permute((2, 0, 1))    <span style=\'color: red\'># <[26,1,512]?  torch.Size([44, 8, 512])</span>\n        <span style=\'color: red\'># conv = conv.contiguous() </span>\n        <span style=\'color: red\'># 第一个LSTM层</span>\n        self.rnn1.flatten_parameters() \n        recurrent, _ = self.rnn1(conv)    <span style=\'color: red\'># torch.Size([44, 8, 256])</span>\n        T, b, h = recurrent.size()        <span style=\'color: red\'># <span style=\'color: green;font-weight: bold;\'><</span>26,1,256  所有时刻的输出都拿到,而不是只拿某一个时刻。<span style=\'color: green;font-weight: bold;\'>></span></span>\n        t_rec = recurrent.view([T*b, h])  <span style=\'color: red\'># torch.Size([352, 256])</span>\n        output = self.embedding1(t_rec)   <span style=\'color: red\'># [T * b, nOut]  torch.Size([352, 256])</span>\n        output = output.view([T, b, -1])  <span style=\'color: red\'># torch.Size([44, 8, 256])</span>\n        <span style=\'color: red\'># 第二个LSTM层</span>\n        self.rnn2.flatten_parameters()\n        recurrent, _ = self.rnn2(output)\n        T, b, h = recurrent.size()\n        t_rec = recurrent.view([T * b, h])\n        output = self.embedding2(t_rec)   <span style=\'color: red\'># [T * b, nOut] ---> </span>\n        output = output.view([T, b, -1])  <span style=\'color: red\'># torch.Size([44, 8, 6153])</span>\n        output = output.permute((1,0,2))  <span style=\'color: red\'># [b,w,c] --->  torch.Size([8, 44, 6153])</span>\n        return output\n</code></pre></font>'}]}]}]})</script></body>
</html>
