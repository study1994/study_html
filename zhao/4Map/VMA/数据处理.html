<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>数据处理</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">nyc(projects/configs/vma_icurb.py)</p><font size="0"><pre class="language-python"><code class="language-python">map_classes = [\'curb\']\nfixed_ptsnum_per_gt_line = 50 <span style=\'color: red\'>now only support fixed_pts > 0</span>\nfixed_ptsnum_per_pred_line = 50\neval_use_same_gt_sample_num_flag=True\nnum_map_classes = len(map_classes)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/icurb_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">@DATASETS.register_module()\nclass iCurb_Dataset(Dataset):\n    CLASSES = (\'curb\')\n    def __init__(self, split_file,seq_dir, image_dir, mask_dir, points_nums, map_classes=None, pipeline=None,mode="valid", test_mode=False):\n        assert mode in {"train", "valid", "test"}\n        self.MAPCLASSES = self.get_map_classes(map_classes)                            <span style=\'color: red\'># [\'curb\']</span>\n        annotation_dict = self.<span style=\'color: green;font-weight: bold;\'>load_datadir</span>(split_file, seq_dir, image_dir, mode)\n        self.annotation_dict = annotation_dict\n        self.seq_len = len(annotation_dict)                                            <span style=\'color: red\'># 20236</span>\n        self.points_nums = points_nums                                                 <span style=\'color: red\'># 50</span>\n        self.padding_value = -10000                                                    \n        self.mask_dir = mask_dir                        <span style=\'color: red\'># \'./data/nyc/labels/binary_map\'     </span>\n        self.total_acc = 0\n        self.total_recall = 0\n        self.total_r_f = 0\n        self.NUM_MAPCLASSES = len(self.MAPCLASSES)      <span style=\'color: red\'># 1</span>\n        if pipeline is not None:\n            self.pipeline = Compose(pipeline)           <span style=\'color: red\'># {\'type\': \'LoadImageFromFiles\', \'to_float32\': True}   {\'type\': \'Collect\', \'keys\': [\'img\'], \'meta_keys\': </span>\n        if not test_mode:\n            self._set_group_flag()                      <span style=\'color: red\'># self.flag,长度为(20236,)的全0 numpy</span>\n    def load_datadir(self, split_file, seq_path, image_path, mode):\n        with open(split_file,\'r\') as jf:                             <span style=\'color: red\'># \'./data/nyc/data_split.json\'</span>\n            json_list = json.load(jf)                                <span style=\'color: red\'># {\'train\':[\'917137_12\',...], \'valid\':[\'042247_00\',...], \'test\':, \'pretrain\':}</span>\n        train_list = json_list[\'train\'] + json_list[\'pretrain\']      <span style=\'color: red\'># 20236</span>\n        test_list = json_list[\'valid\']                               <span style=\'color: red\'># 1770</span>\n        val_list = json_list[\'valid\']\n        if mode == \'valid\':\n            json_list = [x+\'.json\' for x in val_list]\n        elif mode == \'test\':\n            json_list = [x+\'.json\' for x in test_list]\n        else:\n            json_list = [x+\'.json\' for x in train_list]\n        annotation_dict={}\n        for jsonf in json_list[:20]:\n            with open(osp.join(seq_path, jsonf), \'r\') as f:\n                seq_list = json.load(f)                               <span style=\'color: red\'># 见readme.md  </span>\n            instances= []\n            for area in seq_list: \n                instances.append(area[\'seq\'])                         <span style=\'color: red\'># [[[512,0],...,[999,597]],[[543,0],...,[999,540]]]</span>\n            annotation_dict.update({jsonf:{\'image_path\':osp.join(image_path, jsonf[:-4]+\'tiff\'),\'instances\':instances}})      <span style=\'color: red\'># 轨迹路线</span>\n        return annotation_dict   \n    def __getitem__(self, idx):\n        example = self.<span style=\'color: green;font-weight: bold;\'>load_data</span>(**list(self.annotation_dict.values())[idx])      <span style=\'color: red\'># {\'image_path\': \'./data/nyc/cropped_t...37_12.tiff\', \'instances\': [[...], [...]]}</span>\n        return example                                                            <span style=\'color: red\'># <projects.mmdet3d_plugin.datasets.icurb_dataset.InstanceLines</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/icurb_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">@DATASETS.register_module()\nclass iCurb_Dataset(Dataset):\n    def load_data(self, image_path, instances):\n        <span style=\'color: red\'># load image    LoadImageFromFiles:  projects/mmdet3d_plugin/datasets/pipelines/load.py  Collect:                                             </span>\n        example = self.<span style=\'color: green;font-weight: bold;\'>pipeline</span>({\'img_filename\':image_path})          <span style=\'color: red\'># \'./data/nyc/cropped_tiff/917137_12.tiff\'  --->example-{\'img_metas\':,\'img\':(4, 1000, 1000)}</span>\n        <span style=\'color: red\'># load vectormap</span>\n        example = self.<span style=\'color: green;font-weight: bold;\'>vectormap_pipeline</span>(example, instances)         <span style=\'color: red\'># iCurb_Dataset.vectormap_pipeline</span>\n        return example\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/pipelines/load.py</p><font size="0"><pre class="language-python"><code class="language-python">class LoadImageFromFiles(object):\n    def __call__(self, results):\n        filename = results[\'img_filename\']            <span style=\'color: red\'># \'./data/nyc/cropped_tiff/917137_12.tiff\'</span>\n        img = Image.open(filename)                    <span style=\'color: red\'># (1000, 1000)</span>\n        img = F.to_tensor(img).numpy()                <span style=\'color: red\'># (4, 1000, 1000)</span>\n        img_shape = img.shape\n        h = img_shape[1]\n        w = img_shape[2]\n        size = (h, w)\n        if self.to_float32:\n            img = img.astype(np.float32)\n        results[\'filename\'] = filename\n        results[\'img\'] = img\n        results[\'img_shape\'] = size\n        results[\'ori_shape\'] = size\n        results[\'pad_shape\'] = size\n        results[\'scale_factor\'] = 1.0\n        num_channels = 1 if len(img.shape) < 3 else img.shape[0]\n        results[\'img_norm_cfg\'] = dict(mean=np.zeros(num_channels, dtype=np.float32),std=np.ones(num_channels, dtype=np.float32),to_rgb=False)\n        return results\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/icurb_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class iCurb_Dataset(Dataset):\n    def vectormap_pipeline(self, example, instances):\n        vectormap = <span style=\'color: green;font-weight: bold;\'>VectorizedLocalMap</span>(patch_size=example[\'img_metas\'].data[\'img_shape\'],map_classes=self.MAPCLASSES,fixed_ptsnum_per_line=self.points_nums,padding_value=self.padding_value,)\n        anns_results = vectormap.<span style=\'color: green;font-weight: bold;\'>gen_vectorized_samples</span>(instances=instances)  <span style=\'color: red\'># anns_results, type: dict</span>\n                                                                                <span style=\'color: red\'># \'gt_vecs_pts_loc\': list[num_vecs], vec with num_points*2 coordinates</span>\n                                                                                <span style=\'color: red\'># \'gt_vecs_pts_num\': list[num_vecs], vec with num_points</span>\n                                                                                <span style=\'color: red\'># \'gt_vecs_label\': list[num_vecs], vec with cls index</span>\n        gt_vecs_label = to_tensor(anns_results[\'gt_vecs_label\'])                <span style=\'color: red\'># tensor([0, 0])</span>\n        if isinstance(anns_results[\'gt_vecs_pts_loc\'], InstanceLines):          <span style=\'color: red\'># True</span>\n            gt_vecs_pts_loc = anns_results[\'gt_vecs_pts_loc\']                   <span style=\'color: red\'># <span style=\'color: green;font-weight: bold;\'><</span>projects.mmdet3d_plugin.datasets.icurb_dataset.InstanceLines object at 0x7fe49b278130<span style=\'color: green;font-weight: bold;\'>></span></span>\n        else:\n            ......\n        example[\'gt_labels\'] = DC(gt_vecs_label, cpu_only=False)\n        example[\'gt_bboxes\'] = DC(gt_vecs_pts_loc, cpu_only=True)\n        return example\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/icurb_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class VectorizedLocalMap(object):\n    def __init__(self,patch_size,map_classes=[\'divider\',\'ped_crossing\',\'boundary\'],sample_dist=1,num_samples=250,padding=False,fixed_ptsnum_per_line=-1,padding_value=-10000):\n        super().__init__()\n        self.vec_classes = map_classes                <span style=\'color: red\'># [\'curb\']</span>\n        self.sample_dist = sample_dist                <span style=\'color: red\'># 1</span>\n        self.num_samples = num_samples                <span style=\'color: red\'># 250</span>\n        self.padding = padding                        <span style=\'color: red\'># False</span>\n        self.fixed_num = fixed_ptsnum_per_line        <span style=\'color: red\'># 50</span>\n        self.padding_value = padding_value            <span style=\'color: red\'># -10000</span>\n        self.patch_size = patch_size                  <span style=\'color: red\'># (1000, 1000)</span>\n    def gen_vectorized_samples(self, instances):      <span style=\'color: red\'># [[[[512, 0]],...,[999, 597]],[[[543, 0],...,[999, 540]]]]</span>\n        vectors = []\n        for instance in instances:                    <span style=\'color: red\'># [[[512, 0]],...,[999, 597]]</span>\n            vectors.append((LineString(np.array(instance)), 0)) \n        gt_labels = []\n        gt_instance = []\n        for instance, instance_type in vectors:\n            if instance_type != -1:\n                gt_instance.append(instance)\n                gt_labels.append(instance_type)\n        gt_instance = InstanceLines(gt_instance, gt_labels, self.sample_dist, self.num_samples, self.padding, self.fixed_num,self.padding_value, patch_size=self.patch_size)\n        <span style=\'color: red\'># ----------------自己加的测试代码-----------------------</span>\n        _ = gt_instance.start_end_points\n        _ = gt_instance.bbox\n        <span style=\'color: red\'># _ = gt_instance.origin_points</span>\n        _ = gt_instance.shift_fixed_num_sampled_points_v2\n        <span style=\'color: red\'># ------------------------------------------------------</span>\n        anns_results = dict(\n            gt_vecs_pts_loc=gt_instance,\n            gt_vecs_label=gt_labels,\n        )\n        return anns_results\n</code></pre></font>'}]}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">sd_data_line(projects/configs/vma_res152_e80_line.py)</p><font size="0"><pre class="language-python"><code class="language-python">lane_direction = [\'unidirectional\', \'bidirectional\', \'unknown\']                             <span style=\'color: red\'>“单向”、“双向”、“未知”</span>\nlane_type = [\'solid\', \'dotted\', \'solid_fishbone\', \'ldotted_fishbone\', \'unknown\', \'no\']      <span style=\'color: red\'>“实心”、“虚线”</span>\nlane_properties = [\'general\', \'stay\', \'tide\', \'bus\', \'three_color\', \'unknown\']\nlane_flag = [\'single\', \'double\', \'triple\', \'unknown\']                                       <span style=\'color: red\'>“单”、“双”、“三”、“未知”</span>\nlane_width = [\'normal\', \'wide\', \'unknown\']\ncurb_type = [\'groundside\', \'roadside\', \'cone\', \'water_horse\', \'guardrail\',\'unknown\']        <span style=\'color: red\'>“圆形边”、“路边”、“锥形”、“水_霍斯”、“护栏”、“未知”</span>\nattrs_dict = {\'lane_direction\':lane_direction, \'lane_type\':lane_type, \'lane_properties\':lane_properties, \'lane_flag\':lane_flag,\'lane_width\':lane_width, \'curb_type\':curb_type}\nfixed_ptsnum_per_gt_line = 50                              <span style=\'color: red\'>now only support fixed_pts > 0</span>\nfixed_ptsnum_per_pred_line = 50\neval_use_same_gt_sample_num_flag=True\nnum_map_classes = len(map_classes)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/sd_driving_line_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">@DATASETS.register_module()\nclass SD_Driving_Line_Dataset(Dataset):\n    def __init__(......):\n        assert mode in {"train", "test", "valid"}\n        self.MAPCLASSES = self.CLASSES = self.get_map_classes(map_classes)  <span style=\'color: red\'># [\'lane\', \'curb\', \'stopline\']-->[\'lane\', \'curb\', \'stopline\']</span>\n        self.attrs_dict = attrs_dict               <span style=\'color: red\'># {\'lane_direction\': [\'unidirectional\', \'bidirectional\', \'unknown\'], \'lane_type\': [...],...}</span>\n        self.data_root = data_root                 <span style=\'color: red\'># \'data/sd_data/line/cropped_data\'       这里面图片被切成了1000*1000大小的图片，</span>\n        self.sub_dir = sub_dir                     <span style=\'color: red\'># \'trajectory_cropped_images\'</span>\n        annotation_dict = self.<span style=\'color: green;font-weight: bold;\'>load_datadir</span>(annotation_file, mode)\n        self.annotation_dict = annotation_dict\n        self.mask_dir = mask_dir                   <span style=\'color: red\'># \'data/sd_data/line/cropped_data/mask_map\'</span>\n        self.seq_len = len(annotation_dict)        <span style=\'color: red\'># 35</span>\n        self.points_nums = points_nums             <span style=\'color: red\'># 50</span>\n        self.padding_value = -10000   \n        self.NUM_MAPCLASSES = len(self.MAPCLASSES)  <span style=\'color: red\'># 3</span>\n        self.eval_use_same_gt_sample_num_flag=eval_use_same_gt_sample_num_flag   <span style=\'color: red\'># True</span>\n        self.test_mode = test_mode\n        if pipeline is not None:\n            self.pipeline = Compose(pipeline)   <span style=\'color: red\'># \'LoadImageFromFiles\',\'NormalizeImage\',\'Collect\'</span>\n        if not test_mode:\n            self.<span style=\'color: green;font-weight: bold;\'>_set_group_flag</span>()              <span style=\'color: red\'># self.flag = np.zeros(len(self), dtype=np.uint8)</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/sd_driving_line_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class SD_Driving_Line_Dataset(Dataset):\n    def load_datadir(self, annotation_file, mode):\n        annotation_file = os.path.join(self.data_root, annotation_file)   <span style=\'color: red\'># \'data/sd_data/line/cropped_data/sd_data_line_dict.json\'</span>\n        with open(annotation_file,\'r\') as jf:\n            json_dict = json.load(jf)         <span style=\'color: red\'># {"train":[{\'image_name\':\'sample_1_0.jpg\', \'left_top\': [2415, 0],\'instances\' =:[{\'class\':\'lane\',\'data\':[[],...,],"attr":{}}]}</span>\n        if mode == \'valid\':\n            json_list = json_dict[\'valid\']\n        elif mode == \'test\':\n            json_list = json_dict[\'valid\']\n        else:\n            json_list = json_dict[\'train\']\n        annotation_dict={}\n        for img_ann in json_list:\n            annotation_dict.update({img_ann[\'image_name\']:{\'image_path\':osp.join(self.data_root, self.sub_dir, img_ann[\'image_name\']),\'instances\':img_ann[\'instances\']}})\n        return annotation_dict    <span style=\'color: red\'># {\'sample_1_0.jpg\':{"iamge_path":"","instances":[{},{}]}}</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/sd_driving_line_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class SD_Driving_Line_Dataset(Dataset):\n    def __getitem__(self, idx):\n        if self.test_mode:\n            return self.prepare_test_data(idx)\n        while True:\n            data = self.<span style=\'color: green;font-weight: bold;\'>prepare_train_data</span>(idx)\n            if data is None:\n                idx = self._rand_another(idx)\n                continue\n            return data\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/sd_driving_line_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class SD_Driving_Line_Dataset(Dataset):\n    def prepare_train_data(self,idx):\n        return self.<span style=\'color: green;font-weight: bold;\'>load_train_data</span>(**list(self.annotation_dict.values())[idx])\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/sd_driving_line_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class SD_Driving_Line_Dataset(Dataset):\n    def load_train_data(self, image_path, instances):\n        example = self.<span style=\'color: green;font-weight: bold;\'>pipeline</span>({\'img_filename\':image_path})  <span style=\'color: red\'># load image    \'data/....../sample_1_0.jpg\'</span>\n        example = self.<span style=\'color: green;font-weight: bold;\'>vectormap_pipeline</span>(example, instances) <span style=\'color: red\'># load vectormap [{\'class\': \'lane\', \'data\':[],\'attrs\':{}},{},......]</span>\n        return example\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/pipelines/load.py</p><font size="0"><pre class="language-python"><code class="language-python">class LoadImageFromFiles(object):\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/pipelines/load.py</p><font size="0"><pre class="language-python"><code class="language-python">class NormalizeImage(object):\n    def __call__(self, results):\n        img = results[\'img\'].transpose(1, 2, 0)     <span style=\'color: red\'># C,H,W -> H,W,C</span>\n        results[\'img\'] = mmcv.imnormalize(img, self.mean, self.std, self.to_rgb).transpose(2, 0, 1)\n        results[\'img_norm_cfg\'] = dict(\n            mean=self.mean, std=self.std, to_rgb=self.to_rgb)\n        return results\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">projects/mmdet3d_plugin/datasets/sd_driving_line_dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class SD_Driving_Line_Dataset(Dataset):\n    def vectormap_pipeline(self, example, instances):\n        vectormap = <span style=\'color: green;font-weight: bold;\'>VectorizedLocalMap</span>(patch_size=example[\'img_metas\'].data[\'img_shape\'], \n                                        map_classes=self.MAPCLASSES, \n                                        fixed_ptsnum_per_line=self.points_nums,\n                                        padding_value=self.padding_value,)\n        anns_results = vectormap.<span style=\'color: green;font-weight: bold;\'>gen_vectorized_samples</span>(instances, self.attrs_dict)\n        \n        \'\'\'\n        anns_results, type: dict\n            \'gt_vecs_pts_loc\': list[num_vecs], vec with num_points*2 coordinates\n            \'gt_vecs_pts_num\': list[num_vecs], vec with num_points\n            \'gt_vecs_label\': list[num_vecs], vec with cls index\n        \'\'\'\n        gt_vecs_label = to_tensor(anns_results[\'gt_vecs_label\'])\n        gt_vecs_attr = to_tensor(anns_results[\'gt_vecs_attr\']).permute(1, 0)\n        if isinstance(anns_results[\'gt_vecs_pts_loc\'], InstanceLines):\n            gt_vecs_pts_loc = anns_results[\'gt_vecs_pts_loc\']\n        else:\n            gt_vecs_pts_loc = to_tensor(anns_results[\'gt_vecs_pts_loc\'])\n            try:\n                gt_vecs_pts_loc = gt_vecs_pts_loc.flatten(1).to(dtype=torch.float32)\n            except:\n                <span style=\'color: red\'># empty tensor, will be passed in train,  but we preserve it for test</span>\n                gt_vecs_pts_loc = gt_vecs_pts_loc\n        example[\'gt_labels\'] = DC(gt_vecs_label, cpu_only=False)\n        example[\'gt_bboxes\'] = DC(gt_vecs_pts_loc, cpu_only=True)\n        example[\'gt_attrs\'] = DC(gt_vecs_attr, cpu_only=False)\n        return example\n</code></pre></font>'}]}]}]}]}]})</script></body>
</html>
