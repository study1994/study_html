<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>vectornet_bilibili</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">制作特征compute_feature_module.py</p><span class=\'hidden-code\' data-code=\'if __name__ == &amp;#39;__main__&amp;#39;:\n    am = ArgoverseMap()\n    for folder in os.listdir(DATA_DIR):   遍历train，val，test\n        print(f&amp;#39;folder: {folder}&amp;#39;)\n        afl = ArgoverseForecastingLoader(os.path.join(DATA_DIR, folder))\n        norm_center_dict = {}\n        for name in tqdm(afl.seq_list):          读取csv文件,&amp;#39;38439\n            afl_ = afl.get(name)\n            path, name = os.path.split(name)\n            name, ext = os.path.splitext(name)   .csv\n            agent_feature, obj_feature_ls, lane_feature_ls, norm_center = `compute_feature_for_one_seq`(\n                afl_.seq_df, am, OBS_LEN, LANE_RADIUS, OBJ_RADIUS, viz=False, mode=&amp;#39;nearby&amp;#39;)  DataFrame,工具包，20【个点预测30个点】，30，30\n            df = encoding_features(agent_feature, obj_feature_ls, lane_feature_ls)\n            save_features(df, name, os.path.join(INTERMEDIATE_DATA_DIR, f&amp;#39;{folder}_intermediate&amp;#39;))\n            norm_center_dict[name] = norm_center\n        \n        with open(os.path.join(INTERMEDIATE_DATA_DIR, f&amp;#39;{folder}-norm_center_dict.pkl&amp;#39;), &amp;#39;wb&amp;#39;) as f:\n            pickle.dump(norm_center_dict, f, pickle.HIGHEST_PROTOCOL)\n            print(pd.DataFrame(df[&amp;#39;POLYLINE_FEATURES&amp;#39;].values[0]).describe())\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/feature_utils.py</p><span class=\'hidden-code\' data-code=\'def compute_feature_for_one_seq(traj_df: pd.DataFrame, am: ArgoverseMap, obs_len: int = 20, lane_radius: int = 5, obj_radius: int = 10, viz: bool = False, mode=&amp;#39;rect&amp;#39;, query_bbox=[-100, 100, -100, 100]):\n    # return lane &amp; track features\n    # args:\n    #     mode: &amp;#39;rect&amp;#39; or &amp;#39;nearby&amp;#39;\n    # returns:\n    #     agent_feature_ls: list of (doubeld_track, object_type, timetamp, track_id, not_doubled_groudtruth_feature_trajectory)\n    #     obj_feature_ls:   list of list of (doubled_track, object_type, timestamp, track_id)\n    #     lane_feature_ls:  list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]\n    #     norm_center np.ndarray: (2, )\n    # normalize timestamps  标准化操作\n    traj_df[&amp;#39;TIMESTAMP&amp;#39;] -= np.min(traj_df[&amp;#39;TIMESTAMP&amp;#39;].values)\n    seq_ts = np.unique(traj_df[&amp;#39;TIMESTAMP&amp;#39;].values)\n    seq_len = seq_ts.shape[0]                            # 50【每0.1秒采样，总共5秒】\n    city_name = traj_df[&amp;#39;CITY_NAME&amp;#39;].iloc[0]             # &amp;#39;MIA\n    agent_df = None\n    agent_x_end, agent_y_end, start_x, start_y, query_x, query_y, norm_center = [ None] * 7 # 车终止位置，起始位置，第20个点x,y值\n    # agent traj &amp; its start/end point\n    for obj_type, remain_df in traj_df.groupby(&amp;#39;OBJECT_TYPE&amp;#39;):               \n        if obj_type == &amp;#39;AGENT&amp;#39;:\n            agent_df = remain_df                                            # (50,6)大小的DataFrame\n            start_x, start_y = agent_df[[&amp;#39;X&amp;#39;, &amp;#39;Y&amp;#39;]].values[0]               # 第0个数(x,y)\n            agent_x_end, agent_y_end = agent_df[[&amp;#39;X&amp;#39;, &amp;#39;Y&amp;#39;]].values[-1]      # 最后那个数-第49个数据(x,y)\n            query_x, query_y = agent_df[[&amp;#39;X&amp;#39;, &amp;#39;Y&amp;#39;]].values[obs_len-1]       # 第20-1=19个数的(x,y)\n            norm_center = np.array([query_x, query_y])\n            break\n        else:\n            raise ValueError(f&amp;#39;cannot find &amp;#39;agent&amp;#39; object type&amp;#39;)\n    # prune points after &amp;#39;obs_len&amp;#39; timestamp [FIXED] test set length is only `obs_len`\n    traj_df = traj_df[traj_df[&amp;#39;TIMESTAMP&amp;#39;] <= agent_df[&amp;#39;TIMESTAMP&amp;#39;].values[obs_len-1]]    # 时间轴做个刷选\n    assert (np.unique(traj_df[&amp;#39;TIMESTAMP&amp;#39;].values).shape[0] == obs_len), &amp;#39;Obs len mismatch&amp;#39;\n    lane_feature_ls = `get_nearby_lane_feature_ls`(am, agent_df, obs_len, city_name, lane_radius, norm_center, mode=mode, query_bbox=query_bbox)\n    # pdb.set_trace()\n    # search nearby moving objects from the last observed point of agent\n    obj_feature_ls = `get_nearby_moving_obj_feature_ls`(agent_df, traj_df, obs_len, seq_ts, norm_center)\n    # get agent features\n    agent_feature = `get_agent_feature_ls`(agent_df, obs_len, norm_center)\n    return [agent_feature, obj_feature_ls, lane_feature_ls, norm_center]\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/lane_utils.py</p><span class=\'hidden-code\' data-code=\'def get_nearby_lane_feature_ls(am, agent_df, obs_len, city_name, lane_radius, norm_center, has_attr=False, mode=&amp;#39;nearby&amp;#39;, query_bbox=None):\n    # compute lane features\n    # args:\n    #     norm_center: np.ndarray\n    #     mode:        &amp;#39;nearby&amp;#39; return nearby lanes within the radius; &amp;#39;rect&amp;#39; return lanes within the query bbox\n    #     **kwargs:     query_bbox= List[int, int, int, int]\n    # returns:\n    #     list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]\n    lane_feature_ls = []\n    if mode == &amp;#39;nearby&amp;#39;:\n        query_x, query_y = agent_df[[&amp;#39;X&amp;#39;, &amp;#39;Y&amp;#39;]].values[obs_len-1]                               # 383.07,168  第19个点的值\n        nearby_lane_ids = am.get_lane_ids_in_xy_bbox(query_x, query_y, city_name, lane_radius)  # 根据当前点拿到旁边车道线信息 [9618965,9619203,...]-list长度为19\n        for lane_id in nearby_lane_ids:                                                # lane_id=9618965\n            traffic_control = am.lane_has_traffic_control_measure(lane_id, city_name)  # True 是否交通管制\n            is_intersection = am.lane_is_in_intersection(lane_id, city_name)           # True\n            centerlane = am.get_lane_segment_centerline(lane_id, city_name)            # [[x,y,z],[x1,y1,z1],.....]  (10,3)的numpy 车道线的值\n            # normalize to last observed timestamp point of agent\n            centerlane[:, :2] -= norm_center\n            halluc_lane_1, halluc_lane_2 = get_halluc_lane(centerlane, city_name)\n            if has_attr:\n                raise NotImplementedError()\n            lane_feature_ls.append([halluc_lane_1, halluc_lane_2, traffic_control, is_intersection, lane_id])\n    elif mode == &amp;#39;rect&amp;#39;:\n        pass\n    else:\n        raise ValueError(f&amp;#39;{mode} is not in {&amp;#39;rect&amp;#39;, &amp;#39;nearby&amp;#39;}&amp;#39;)\n    return lane_feature_ls\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">DataLoader构建图结构 train.py</p><span class=\'hidden-code\' data-code=\'if __name__ == &amp;#39;__main__&amp;#39;:\n    training envs\n    device = torch.device(f&amp;#39;cuda:{gpus[0]}&amp;#39; if torch.cuda.is_available() else &amp;#39;cpu&amp;#39;)\n    prepare dara\n    train_data = `GraphDataset`(TRAIN_DIR).shuffle()\n    val_data = GraphDataset(VAL_DIR)\n    if small_dataset:\n        train_loader = DataListLoader(train_data[:1000], batch_size=batch_size, shuffle=True)\n        val_loader = DataListLoader(val_data[:200], batch_size=batch_size)\n    else:\n        train_loader = DataListLoader(train_data, batch_size=batch_size, shuffle=True)\n        val_loader = DataListLoader(val_data, batch_size=batch_size)\n    model = `HGNN`(in_channels, out_channels)\n    model = nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])\n    model = model.to(device=device)\n    \n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = optim.lr_scheduler.StepLR(\n        optimizer, step_size=decay_lr_every, gamma=decay_lr_factor)\n    training loop\n    model.train()\n    for epoch in range(epochs):\n        acc_loss = .0\n        num_samples = 0\n        start_tic = time.time()\n        for data in train_loader:\n            if epoch < end_epoch: break\n            y = torch.cat([i.y for i in data], 0).view(-1, out_channels).to(device)\n            optimizer.zero_grad()\n            out = model(data)\n            loss = F.mse_loss(out, y)\n            loss.backward()\n            acc_loss += batch_size * loss.item()\n            num_samples += y.shape[0]\n            optimizer.step()\n            global_step += 1\n            if (global_step + 1) % show_every == 0:\n                print( f&amp;#39;loss at epoch {epoch} step {global_step}:{loss.item():3f}, lr:{optimizer.state_dict()[&amp;#39;param_groups&amp;#39;][0][&amp;#39;lr&amp;#39;]: .6f}, time:{time.time() - start_tic: 4f}sec&amp;#39;)\n        scheduler.step()\n        print(\n            f&amp;#39;loss at epoch {epoch}:{acc_loss / num_samples:.3f}, lr:{optimizer.state_dict()[&amp;#39;param_groups&amp;#39;][0][&amp;#39;lr&amp;#39;]: .6f}, time:{time.time() - start_tic: 4f}sec&amp;#39;)\n        \n        if (epoch+1) % val_every == 0 and (not epoch < end_epoch):\n            print(&amp;#39;eval as epoch:{epoch}&amp;#39;)\n            metrics = get_eval_metric_results(model, val_loader, device, out_channels, max_n_guesses, horizon, miss_threshold)\n            curr_minade = metrics[&amp;#39;minADE&amp;#39;]\n            print(f&amp;#39;minADE:{metrics[&amp;#39;minADE&amp;#39;]:3f}, minFDE:{metrics[&amp;#39;minFDE&amp;#39;]:3f}, MissRate:{metrics[&amp;#39;MR&amp;#39;]:3f}&amp;#39;)\n            if curr_minade < best_minade:\n                best_minade = curr_minade\n                save_checkpoint(save_dir, model, optimizer, epoch, best_minade, date)\n                \n    eval result on the identity dataset\n    metrics = get_eval_metric_results(model, val_loader, device, out_channels, max_n_guesses, horizon, miss_threshold)\n    curr_minade = metrics[&amp;#39;minADE&amp;#39;]\n    if curr_minade < best_minade:\n        best_minade = curr_minade\n        save_checkpoint(save_dir, model, optimizer, -1, best_minade, date)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">dataset.py</p><span class=\'hidden-code\' data-code=\'class GraphDataset(InMemoryDataset):\n    def __init__(self, root, transform=None, pre_transform=None):\n        super(GraphDataset, self).__init__(root, transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0])\n    def process(self):\n        def get_data_path_ls(dir_):\n            return [os.path.join(dir_, data_path) for data_path in os.listdir(dir_)]\n        # make sure deterministic results\n        data_path_ls = sorted(get_data_path_ls(self.root))\n        valid_len_ls = []\n        valid_len_ls = []\n        data_ls = []\n        for data_p in tqdm(data_path_ls):     # data_p-保存的特征路径   `interm_data/train_intermediate/features_11800.pkl`\n            if not data_p.endswith(&amp;#39;pkl&amp;#39;):\n                continue\n            x_ls = []\n            y = None\n            cluster = None\n            edge_index_ls = []\n            data = pd.read_pickle(data_p)                                 # (1,6)的DataFrame\n            all_in_features = data[&amp;#39;POLYLINE_FEATURES&amp;#39;].values[0]         # 很多个点（757,8）的numpy\n            add_len = data[&amp;#39;TARJ_LEN&amp;#39;].values[0]                          # 19\n            cluster = all_in_features[:, -1].reshape(-1).astype(np.int32) # numpy[0,0,0,...,9,9,9,9]，shape为757 哪些点会放到一个子图当中,注意最大值为82\n            valid_len_ls.append(cluster.max())                            # [82]\n            y = data[&amp;#39;GT&amp;#39;].values[0].reshape(-1).astype(np.float32)       # (60,) min(-0.07),max(4.43) 是预测的30个点(x,y)\n            traj_mask, lane_mask = data[&amp;#39;TRAJ_ID_TO_MASK&amp;#39;].values[0], data[&amp;#39;LANE_ID_TO_MASK&amp;#39;].values[0]\n            agent_id = 0\n            edge_index_start = 0\n            assert all_in_features[agent_id][-1] == 0, f&amp;#39;agent id is wrong. id {agent_id}: type {all_in_features[agent_id][4]}&amp;#39;\n            for id_, mask_ in traj_mask.items():                         # 0,(0,19)\n                data_ = all_in_features[mask_[0]:mask_[1]]               # shape=(19,8)=(点的个数*特征)\n                edge_index_, edge_index_start = get_fc_edge_index(data_.shape[0], start=edge_index_start)  # 边的索引，shape=(2,242),19\n                x_ls.append(data_)\n                edge_index_ls.append(edge_index_)                        # 构建索引\n            # 和上面一样，构架图\n            for id_, mask_ in lane_mask.items():\n                data_ = all_in_features[mask_[0]+add_len: mask_[1]+add_len]\n                edge_index_, edge_index_start = get_fc_edge_index(data_.shape[0], edge_index_start)\n                x_ls.append(data_)\n                edge_index_ls.append(edge_index_)\n            edge_index = np.hstack(edge_index_ls)\n            x = np.vstack(x_ls)\n            data_ls.append([x, y, cluster, edge_index])\n        # [x, y, cluster, edge_index, valid_len]\n        g_ls = []\n        padd_to_index = np.max(valid_len_ls)\n        feature_len = data_ls[0][0].shape[1]\n        for ind, tup in enumerate(data_ls):\n            tup[0] = np.vstack([tup[0], np.zeros((padd_to_index - tup[-2].max(), feature_len), dtype=tup[0].dtype)])\n            tup[-2] = np.hstack([tup[2], np.arange(tup[-2].max()+1, padd_to_index+1)])\n            g_data = GraphData(\n                x=torch.from_numpy(tup[0]),\n                y=torch.from_numpy(tup[1]),\n                cluster=torch.from_numpy(tup[2]),\n                edge_index=torch.from_numpy(tup[3]),\n                valid_len=torch.tensor([valid_len_ls[ind]]),\n                time_step_len=torch.tensor([padd_to_index + 1])\n            )\n            g_ls.append(g_data)\n        data, slices = self.collate(g_ls)\n        torch.save((data, slices), self.processed_paths[0])\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">modeling/vectornet.py</p><span class=\'hidden-code\' data-code=\'class HGNN(nn.Module):\n    &amp;#39;&amp;#39;&amp;#39;hierarchical GNN with trajectory prediction MLP&amp;#39;&amp;#39;&amp;#39;\n    def __init__(self, in_channels, out_channels, num_subgraph_layers=3, num_global_graph_layer=1, subgraph_width=64, global_graph_width=64, traj_pred_mlp_width=64):\n        super(HGNN, self).__init__()\n        self.polyline_vec_shape = in_channels * (2 ** num_subgraph_layers)\n        self.subgraph = SubGraph(in_channels, num_subgraph_layers, subgraph_width)\n        self.self_atten_layer = SelfAttentionLayer(self.polyline_vec_shape, global_graph_width, need_scale=False)\n        self.traj_pred_mlp = TrajPredMLP(global_graph_width, out_channels, traj_pred_mlp_width)\n    def forward(self, data):\n        # data (Data): [x=(8310,8)8130个点,每个点带8个特征, y==[840], cluster=[8310], edge_index=(2,66852)索引矩阵, valid_len=[14],time_step_len=[14]batch=[8310],ptr=[15]] 这里15是指15个值\n        time_step_len = int(data.time_step_len[0])              # 83\n        valid_lens = data.valid_len                             # tensor([78])\n        sub_graph_out = self.`subgraph`(data)                   # DataBatch([x=1162,64],edge_index=[2,0],batch=[1162])\n        x = sub_graph_out.x.view(-1, time_step_len, self.polyline_vec_shape)  # (14,83,64) 14个图，每个图83个点，每个点64特征向量？\n        out = self.`self_atten_layer`(x, valid_lens)            # (14,83,64)-torch.tensor\n        pred = self.traj_pred_mlp(out[:, [0]].squeeze(1))       # liner64-64；layernorm(64)relu() linear64-60\n        return pred\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">modeling/subgraph.py</p><span class=\'hidden-code\' data-code=\'class SubGraph(nn.Module):\n    # Subgraph that computes all vectors in a polyline, and get a polyline-level feature\n    def __init__(self, in_channels, num_subgraph_layres=3, hidden_unit=64):\n        super(SubGraph, self).__init__()\n        self.num_subgraph_layres = num_subgraph_layres\n        self.layer_seq = nn.Sequential()\n        for i in range(num_subgraph_layres):\n            self.layer_seq.add_module(f&amp;#39;glp_{i}&amp;#39;, GraphLayerProp(in_channels, hidden_unit))   # from torch_geometric.nn import MessagePassing, max_pool\n            in_channels *= 2\n    def forward(self, sub_data):\n        # polyline vector set in torch_geometric.data.Data format\n        # args:sub_data (Data): [x, y, cluster, edge_index, valid_len]\n        x, edge_index = sub_data.x, sub_data.edge_index           # (8310,8);(2,66852)\n        for name, layer in self.layer_seq.named_modules():\n            if isinstance(layer, GraphLayerProp):\n                x = layer(x, edge_index)\n        sub_data.x = x                                    # sub_data=graphDataBatch(x=(8310,64), y==[840], cluster=[8310], edge_index=(2,66852)索引矩阵, valid_len=[14],time_step_len=[14],batch=[8310],ptr=[15])\n        out_data = max_pool(sub_data.cluster, sub_data)   # DataBatch([x=1162,64],edge_index=[2,0],batch=[1162])\n        assert out_data.x.shape[0] % int(sub_data.time_step_len[0]) == 0\n        out_data.x = out_data.x / out_data.x.norm(dim=0)\n        return out_data\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">modeling/selfatten.py</p><span class=\'hidden-code\' data-code=\'class SelfAttentionLayer(nn.Module):\n    # Self-attention layer. no scale_factor d_k\n    def __init__(self, in_channels, global_graph_width, need_scale=False):\n        super(SelfAttentionLayer, self).__init__()\n        self.in_channels = in_channels\n        self.q_lin = nn.Linear(in_channels, global_graph_width)\n        self.k_lin = nn.Linear(in_channels, global_graph_width)\n        self.v_lin = nn.Linear(in_channels, global_graph_width)\n        self.scale_factor_d = 1 + int(np.sqrt(self.in_channels)) if need_scale else 1\n    def forward(self, x, valid_len):\n        # print(x.shape)\n        # print(self.q_lin)\n        query = self.q_lin(x)     # (14,83,64)x有多少个就构建多少个Q\n        key = self.k_lin(x)       # (14,83,64)\n        value = self.v_lin(x)     # (14,83,64)\n        scores = torch.bmm(query, key.transpose(1, 2))         # (14,83,83)\n        attention_weights = masked_softmax(scores, valid_len)  # (14,83,83)\n        return torch.bmm(attention_weights, value)\n\'> </span>'}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
