<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>vectornet_bilibili</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">制作特征compute_feature_module.py</p><font size="0"><pre class="language-python"><code class="language-python">if __name__ == "__main__":\n    am = ArgoverseMap()\n    for folder in os.listdir(DATA_DIR):   <span style=\'color: red\'>遍历train，val，test</span>\n        print(f"folder: {folder}")\n        afl = ArgoverseForecastingLoader(os.path.join(DATA_DIR, folder))\n        norm_center_dict = {}\n        for name in tqdm(afl.seq_list):       <span style=\'color: red\'>读取csv文件,\'38439</span>\n            afl_ = afl.get(name)\n            path, name = os.path.split(name)\n            name, ext = os.path.splitext(name)   <span style=\'color: red\'>.csv</span>\n            agent_feature, obj_feature_ls, lane_feature_ls, norm_center = <span style=\'color: green;font-weight: bold;\'>compute_feature_for_one_seq</span>(\n                afl_.seq_df, am, OBS_LEN, LANE_RADIUS, OBJ_RADIUS, viz=False, mode=\'nearby\')  <span style=\'color: red\'>DataFrame,工具包，20【个点预测30个点】，30，30</span>\n            df = encoding_features(agent_feature, obj_feature_ls, lane_feature_ls)\n            save_features(df, name, os.path.join(INTERMEDIATE_DATA_DIR, f"{folder}_intermediate"))\n            norm_center_dict[name] = norm_center\n        \n        with open(os.path.join(INTERMEDIATE_DATA_DIR, f"{folder}-norm_center_dict.pkl"), \'wb\') as f:\n            pickle.dump(norm_center_dict, f, pickle.HIGHEST_PROTOCOL)\n            <span style=\'color: red\'>print(pd.DataFrame(df[\'POLYLINE_FEATURES\'].values[0]).describe())</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/feature_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def compute_feature_for_one_seq(traj_df: pd.DataFrame, am: ArgoverseMap, obs_len: int = 20, lane_radius: int = 5, obj_radius: int = 10, viz: bool = False, mode=\'rect\', query_bbox=[-100, 100, -100, 100]):\n    <span style=\'color: red\'># return lane & track features</span>\n    <span style=\'color: red\'># args:</span>\n    <span style=\'color: red\'>#     mode: \'rect\' or \'nearby\'</span>\n    <span style=\'color: red\'># returns:</span>\n    <span style=\'color: red\'>#     agent_feature_ls: list of (doubeld_track, object_type, timetamp, track_id, not_doubled_groudtruth_feature_trajectory)</span>\n    <span style=\'color: red\'>#     obj_feature_ls:   list of list of (doubled_track, object_type, timestamp, track_id)</span>\n    <span style=\'color: red\'>#     lane_feature_ls:  list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]</span>\n    <span style=\'color: red\'>#     norm_center np.ndarray: (2, )</span>\n    <span style=\'color: red\'># normalize timestamps  标准化操作</span>\n    traj_df[\'TIMESTAMP\'] -= np.min(traj_df[\'TIMESTAMP\'].values)\n    seq_ts = np.unique(traj_df[\'TIMESTAMP\'].values)\n    seq_len = seq_ts.shape[0]                            <span style=\'color: red\'># 50【每0.1秒采样，总共5秒】前</span>\n    city_name = traj_df[\'CITY_NAME\'].iloc[0]\n    agent_df = None\n    agent_x_end, agent_y_end, start_x, start_y, query_x, query_y, norm_center = [ None] * 7 <span style=\'color: red\'># 车终止位置，起始位置，前20个点x,y值</span>\n    <span style=\'color: red\'># agent traj & its start/end point</span>\n    for obj_type, remain_df in traj_df.groupby(\'OBJECT_TYPE\'):\n        if obj_type == \'AGENT\':\n            agent_df = remain_df\n            start_x, start_y = agent_df[[\'X\', \'Y\']].values[0]               <span style=\'color: red\'># 第0个数</span>\n            agent_x_end, agent_y_end = agent_df[[\'X\', \'Y\']].values[-1]      <span style=\'color: red\'># 最后那个数</span>\n            query_x, query_y = agent_df[[\'X\', \'Y\']].values[obs_len-1]       <span style=\'color: red\'># 20-1</span>\n            norm_center = np.array([query_x, query_y])\n            break\n        else:\n            raise ValueError(f"cannot find \'agent\' object type")\n    <span style=\'color: red\'># prune points after "obs_len" timestamp [FIXED] test set length is only <span style=\'color: green;font-weight: bold;\'>obs_len</span></span>\n    traj_df = traj_df[traj_df[\'TIMESTAMP\'] <= agent_df[\'TIMESTAMP\'].values[obs_len-1]]    <span style=\'color: red\'># 时间轴做个刷选</span>\n    assert (np.unique(traj_df["TIMESTAMP"].values).shape[0] == obs_len), "Obs len mismatch"\n    lane_feature_ls = <span style=\'color: green;font-weight: bold;\'>get_nearby_lane_feature_ls</span>(am, agent_df, obs_len, city_name, lane_radius, norm_center, mode=mode, query_bbox=query_bbox)\n    <span style=\'color: red\'># pdb.set_trace()</span>\n    <span style=\'color: red\'># search nearby moving objects from the last observed point of agent</span>\n    obj_feature_ls = <span style=\'color: green;font-weight: bold;\'>get_nearby_moving_obj_feature_ls</span>(agent_df, traj_df, obs_len, seq_ts, norm_center)\n    <span style=\'color: red\'># get agent features</span>\n    agent_feature = <span style=\'color: green;font-weight: bold;\'>get_agent_feature_ls</span>(agent_df, obs_len, norm_center)\n    return [agent_feature, obj_feature_ls, lane_feature_ls, norm_center]\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/lane_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_nearby_lane_feature_ls(am, agent_df, obs_len, city_name, lane_radius, norm_center, has_attr=False, mode=\'nearby\', query_bbox=None):\n    <span style=\'color: red\'># compute lane features</span>\n    <span style=\'color: red\'># args:</span>\n    <span style=\'color: red\'>#     norm_center: np.ndarray</span>\n    <span style=\'color: red\'>#     mode:        \'nearby\' return nearby lanes within the radius; \'rect\' return lanes within the query bbox</span>\n    <span style=\'color: red\'>#     **kwargs:     query_bbox= List[int, int, int, int]</span>\n    <span style=\'color: red\'># returns:</span>\n    <span style=\'color: red\'>#     list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]</span>\n    lane_feature_ls = []\n    if mode == \'nearby\':\n        query_x, query_y = agent_df[[\'X\', \'Y\']].values[obs_len-1]       <span style=\'color: red\'># 383.07,168</span>\n        nearby_lane_ids = am.get_lane_ids_in_xy_bbox(query_x, query_y, city_name, lane_radius)  <span style=\'color: red\'># 根据当前点拿到旁边车道线信息 [9618965,9619203,...]</span>\n        for lane_id in nearby_lane_ids:                                <span style=\'color: red\'># 9618965</span>\n            traffic_control = am.lane_has_traffic_control_measure(lane_id, city_name)  <span style=\'color: red\'># True</span>\n            is_intersection = am.lane_is_in_intersection(lane_id, city_name)           <span style=\'color: red\'># True</span>\n            centerlane = am.get_lane_segment_centerline(lane_id, city_name)            <span style=\'color: red\'># [[x,y,z],[x1,y1,z1],.....]</span>\n            <span style=\'color: red\'># normalize to last observed timestamp point of agent</span>\n            centerlane[:, :2] -= norm_center\n            halluc_lane_1, halluc_lane_2 = get_halluc_lane(centerlane, city_name)\n            if has_attr:\n                raise NotImplementedError()\n            lane_feature_ls.append(\n                [halluc_lane_1, halluc_lane_2, traffic_control, is_intersection, lane_id])\n    elif mode == \'rect\':\n        pass\n    else:\n        raise ValueError(f"{mode} is not in {\'rect\', \'nearby\'}")\n    return lane_feature_ls\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">DataLoader构建图结构 train.py</p><font size="0"><pre class="language-python"><code class="language-python">if __name__ == "__main__":\n    <span style=\'color: red\'>training envs</span>\n    device = torch.device(f\'cuda:{gpus[0]}\' if torch.cuda.is_available() else \'cpu\')\n    <span style=\'color: red\'>prepare dara</span>\n    train_data = <span style=\'color: green;font-weight: bold;\'>GraphDataset</span>(TRAIN_DIR).shuffle()\n    val_data = GraphDataset(VAL_DIR)\n    if small_dataset:\n        train_loader = DataListLoader(train_data[:1000], batch_size=batch_size, shuffle=True)\n        val_loader = DataListLoader(val_data[:200], batch_size=batch_size)\n    else:\n        train_loader = DataListLoader(train_data, batch_size=batch_size, shuffle=True)\n        val_loader = DataListLoader(val_data, batch_size=batch_size)\n    model = <span style=\'color: green;font-weight: bold;\'>HGNN</span>(in_channels, out_channels)\n    model = nn.DataParallel(model, device_ids=gpus, output_device=gpus[0])\n    model = model.to(device=device)\n    \n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = optim.lr_scheduler.StepLR(\n        optimizer, step_size=decay_lr_every, gamma=decay_lr_factor)\n    <span style=\'color: red\'>training loop</span>\n    model.train()\n    for epoch in range(epochs):\n        acc_loss = .0\n        num_samples = 0\n        start_tic = time.time()\n        for data in train_loader:\n            if epoch < end_epoch: break\n            y = torch.cat([i.y for i in data], 0).view(-1, out_channels).to(device)\n            optimizer.zero_grad()\n            out = model(data)\n            loss = F.mse_loss(out, y)\n            loss.backward()\n            acc_loss += batch_size * loss.item()\n            num_samples += y.shape[0]\n            optimizer.step()\n            global_step += 1\n            if (global_step + 1) % show_every == 0:\n                print( f"loss at epoch {epoch} step {global_step}:{loss.item():3f}, lr:{optimizer.state_dict()[\'param_groups\'][0][\'lr\']: .6f}, time:{time.time() - start_tic: 4f}sec")\n        scheduler.step()\n        print(\n            f"loss at epoch {epoch}:{acc_loss / num_samples:.3f}, lr:{optimizer.state_dict()[\'param_groups\'][0][\'lr\']: .6f}, time:{time.time() - start_tic: 4f}sec")\n        \n        if (epoch+1) % val_every == 0 and (not epoch < end_epoch):\n            print("eval as epoch:{epoch}")\n            metrics = get_eval_metric_results(model, val_loader, device, out_channels, max_n_guesses, horizon, miss_threshold)\n            curr_minade = metrics["minADE"]\n            print(f"minADE:{metrics[\'minADE\']:3f}, minFDE:{metrics[\'minFDE\']:3f}, MissRate:{metrics[\'MR\']:3f}")\n            if curr_minade < best_minade:\n                best_minade = curr_minade\n                save_checkpoint(save_dir, model, optimizer, epoch, best_minade, date)\n                \n    <span style=\'color: red\'>eval result on the identity dataset</span>\n    metrics = get_eval_metric_results(model, val_loader, device, out_channels, max_n_guesses, horizon, miss_threshold)\n    curr_minade = metrics["minADE"]\n    if curr_minade < best_minade:\n        best_minade = curr_minade\n        save_checkpoint(save_dir, model, optimizer, -1, best_minade, date)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">dataset.py</p><font size="0"><pre class="language-python"><code class="language-python">class GraphDataset(InMemoryDataset):\n    def __init__(self, root, transform=None, pre_transform=None):\n        super(GraphDataset, self).__init__(root, transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0])\n    def process(self):\n        def get_data_path_ls(dir_):\n            return [os.path.join(dir_, data_path) for data_path in os.listdir(dir_)]\n        <span style=\'color: red\'># make sure deterministic results</span>\n        data_path_ls = sorted(get_data_path_ls(self.root))\n        valid_len_ls = []\n        valid_len_ls = []\n        data_ls = []\n        for data_p in tqdm(data_path_ls):     <span style=\'color: red\'># data_p-保存的特征路径   <span style=\'color: green;font-weight: bold;\'>interm_data/train_intermediate/features_11800.pkl</span></span>\n            if not data_p.endswith(\'pkl\'):\n                continue\n            x_ls = []\n            y = None\n            cluster = None\n            edge_index_ls = []\n            data = pd.read_pickle(data_p)                                 <span style=\'color: red\'># DataFrame</span>\n            all_in_features = data[\'POLYLINE_FEATURES\'].values[0]         <span style=\'color: red\'># 很多个点</span>\n            add_len = data[\'TARJ_LEN\'].values[0]                          <span style=\'color: red\'># 19</span>\n            cluster = all_in_features[:, -1].reshape(-1).astype(np.int32) <span style=\'color: red\'># numpy[0,0,0,...,9,9,9,9] 哪些点会放到一个子图当中</span>\n            valid_len_ls.append(cluster.max())\n            y = data[\'GT\'].values[0].reshape(-1).astype(np.float32)       <span style=\'color: red\'># (60) min(-0.07),max(4.43) 是预测的30个点(x,y)</span>\n            traj_mask, lane_mask = data["TRAJ_ID_TO_MASK"].values[0], data[\'LANE_ID_TO_MASK\'].values[0]\n            agent_id = 0\n            edge_index_start = 0\n            assert all_in_features[agent_id][-1] == 0, f"agent id is wrong. id {agent_id}: type {all_in_features[agent_id][4]}"\n            for id_, mask_ in traj_mask.items():                         <span style=\'color: red\'># 0,(0,19)</span>\n                data_ = all_in_features[mask_[0]:mask_[1]]               <span style=\'color: red\'># shape=(19,8)=(点的个数x特征)</span>\n                edge_index_, edge_index_start = get_fc_edge_index(data_.shape[0], start=edge_index_start)  <span style=\'color: red\'># shape=(2,2342)</span>\n                x_ls.append(data_)\n                edge_index_ls.append(edge_index_)                        <span style=\'color: red\'># 构建索引</span>\n            for id_, mask_ in lane_mask.items():\n                data_ = all_in_features[mask_[0]+add_len: mask_[1]+add_len]\n                edge_index_, edge_index_start = get_fc_edge_index(data_.shape[0], edge_index_start)\n                x_ls.append(data_)\n                edge_index_ls.append(edge_index_)\n            edge_index = np.hstack(edge_index_ls)\n            x = np.vstack(x_ls)\n            data_ls.append([x, y, cluster, edge_index])\n        <span style=\'color: red\'># [x, y, cluster, edge_index, valid_len]</span>\n        g_ls = []\n        padd_to_index = np.max(valid_len_ls)\n        feature_len = data_ls[0][0].shape[1]\n        for ind, tup in enumerate(data_ls):\n            tup[0] = np.vstack([tup[0], np.zeros((padd_to_index - tup[-2].max(), feature_len), dtype=tup[0].dtype)])\n            tup[-2] = np.hstack([tup[2], np.arange(tup[-2].max()+1, padd_to_index+1)])\n            g_data = GraphData(\n                x=torch.from_numpy(tup[0]),\n                y=torch.from_numpy(tup[1]),\n                cluster=torch.from_numpy(tup[2]),\n                edge_index=torch.from_numpy(tup[3]),\n                valid_len=torch.tensor([valid_len_ls[ind]]),\n                time_step_len=torch.tensor([padd_to_index + 1])\n            )\n            g_ls.append(g_data)\n        data, slices = self.collate(g_ls)\n        torch.save((data, slices), self.processed_paths[0])\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">modeling/vectornet.py</p><font size="0"><pre class="language-python"><code class="language-python">class HGNN(nn.Module):\n    """hierarchical GNN with trajectory prediction MLP"""\n    def __init__(self, in_channels, out_channels, num_subgraph_layers=3, num_global_graph_layer=1, subgraph_width=64, global_graph_width=64, traj_pred_mlp_width=64):\n        super(HGNN, self).__init__()\n        self.polyline_vec_shape = in_channels * (2 ** num_subgraph_layers)\n        self.subgraph = SubGraph(in_channels, num_subgraph_layers, subgraph_width)\n        self.self_atten_layer = SelfAttentionLayer(self.polyline_vec_shape, global_graph_width, need_scale=False)\n        self.traj_pred_mlp = TrajPredMLP(global_graph_width, out_channels, traj_pred_mlp_width)\n    def forward(self, data):\n        <span style=\'color: red\'># data (Data): [x=(8310,8)8130个点,每个带你8个特征；, y, cluster, edge_index=(2,66852)索引矩阵, valid_len]</span>\n        time_step_len = int(data.time_step_len[0])              <span style=\'color: red\'># 83</span>\n        valid_lens = data.valid_len                             <span style=\'color: red\'># tensor([78])</span>\n        sub_graph_out = self.<span style=\'color: green;font-weight: bold;\'>subgraph</span>(data)                   <span style=\'color: red\'># DataBatch([x=1162,64],edge_index=[2,0],batch=[1162])</span>\n        x = sub_graph_out.x.view(-1, time_step_len, self.polyline_vec_shape)  <span style=\'color: red\'># (14,83,64) 14个图，每个图83个点，每个点64特征向量？</span>\n        out = self.<span style=\'color: green;font-weight: bold;\'>self_atten_layer</span>(x, valid_lens)            <span style=\'color: red\'># (14,83,64)</span>\n        pred = self.traj_pred_mlp(out[:, [0]].squeeze(1))       <span style=\'color: red\'># liner64-64；layernorm(64)relu() linear64-60</span>\n        return pred\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">modeling/subgraph.py</p><font size="0"><pre class="language-python"><code class="language-python">class SubGraph(nn.Module):\n    <span style=\'color: red\'># Subgraph that computes all vectors in a polyline, and get a polyline-level feature</span>\n    def __init__(self, in_channels, num_subgraph_layres=3, hidden_unit=64):\n        super(SubGraph, self).__init__()\n        self.num_subgraph_layres = num_subgraph_layres\n        self.layer_seq = nn.Sequential()\n        for i in range(num_subgraph_layres):\n            self.layer_seq.add_module(f\'glp_{i}\', GraphLayerProp(in_channels, hidden_unit))   <span style=\'color: red\'># from torch_geometric.nn import MessagePassing, max_pool</span>\n            in_channels *= 2\n    def forward(self, sub_data):\n        <span style=\'color: red\'># polyline vector set in torch_geometric.data.Data format</span>\n        <span style=\'color: red\'># args:sub_data (Data): [x, y, cluster, edge_index, valid_len]</span>\n        x, edge_index = sub_data.x, sub_data.edge_index           <span style=\'color: red\'># (8310,8);(2,66852)</span>\n        for name, layer in self.layer_seq.named_modules():\n            if isinstance(layer, GraphLayerProp):\n                x = layer(x, edge_index)\n        sub_data.x = x\n        out_data = max_pool(sub_data.cluster, sub_data)           <span style=\'color: red\'># DataBatch([x=1162,64],edge_index=[2,0],batch=[1162])</span>\n        assert out_data.x.shape[0] % int(sub_data.time_step_len[0]) == 0\n        out_data.x = out_data.x / out_data.x.norm(dim=0)\n        return out_data\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">modeling/selfatten.py</p><font size="0"><pre class="language-python"><code class="language-python">class SelfAttentionLayer(nn.Module):\n    <span style=\'color: red\'># Self-attention layer. no scale_factor d_k</span>\n    def __init__(self, in_channels, global_graph_width, need_scale=False):\n        super(SelfAttentionLayer, self).__init__()\n        self.in_channels = in_channels\n        self.q_lin = nn.Linear(in_channels, global_graph_width)\n        self.k_lin = nn.Linear(in_channels, global_graph_width)\n        self.v_lin = nn.Linear(in_channels, global_graph_width)\n        self.scale_factor_d = 1 + int(np.sqrt(self.in_channels)) if need_scale else 1\n    def forward(self, x, valid_len):\n        <span style=\'color: red\'># print(x.shape)</span>\n        <span style=\'color: red\'># print(self.q_lin)</span>\n        query = self.q_lin(x)     <span style=\'color: red\'># (14,83,64)x有多少个就构建多少个Q</span>\n        key = self.k_lin(x)       <span style=\'color: red\'># (14,83,64)</span>\n        value = self.v_lin(x)     <span style=\'color: red\'># (14,83,64)</span>\n        scores = torch.bmm(query, key.transpose(1, 2))         <span style=\'color: red\'># (14,83,83)</span>\n        attention_weights = masked_softmax(scores, valid_len)  <span style=\'color: red\'># (14,83,83)</span>\n        return torch.bmm(attention_weights, value)\n</code></pre></font>'}]}]}]})</script></body>
</html>
