<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>bevdet_sttiny</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def forward_train</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def extract_feat</p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def extract_img_feat</p>[i.shape for i in img]=[(1, 6, 3,,256, 704]),(1, 6, 3, 3),(1, 6, 3), (1, 6, 3, 3), (1, 6, 3, 3),(1, 6, 3)]<br>\n900x1600下采样，后面分别为rots, trans, intrins, post_rots, post_trans<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def image_encoder</p>imgs=（6, 3,,256, 704）<br>\nx->[(6, 384, 16, 44),(6, 768, 8, 22)]->(6, 512, 16, 44)->(1, 6, 512, 16, 44)<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def extract_img_feat</p>输入self.img_view_transformer为[(1, 6, 512, 16, 44),(1, 6, 3, 3),(1, 6, 3), (1, 6, 3, 3), (1, 6, 3, 3),(1, 6, 3)]<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/view_transformer.py：class ViewTransformerLiftSplatShoot：def forward</p>\n<p>x-&gt;(1, 6, 512, 16, 44)-&gt;(6, 512, 16, 44)-<code>self.depthnet</code>&gt;(6, 123, 16, 44)<br>\nself.D=59,self.numC_Trans=64相加得到123<br>\ndepth=（6, 59, 16, 44)<br>\nimg_feat=(6, 64, 16, 44)<br>\nvolume=(6, 64, 59, 16, 44)-&gt;(6, 64, 59, 16, 44)-&gt;(1,6,59,16,44,64)<br>\n输入self.voxel_pooling_accelerated：rots, trans, intrins, post_rots, post_trans, volume<br></p>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/view_transformer.py：class ViewTransformerLiftSplatShoot：def voxel_pooling_accelerated</p>B, N, D, H, W, C=1,6,59,16,44,64，去掉特征Nprime=249216<br>\nnx=tensor（128，128，1）在点云的范围x坐标在0-128,y坐标在0-128,z坐标在0-1<br>\nx=(249216,64),代表249216个点，每个点的特征维度为64<br>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/view_transformer.py：class ViewTransformerLiftSplatShoot：def get_geometry</p>self.frustum=（59, 16, 44, 3）<br>'}]}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/view_transformer.py：class ViewTransformerLiftSplatShoot：def voxel_pooling_accelerated</p>geom_feats=（1, 6, 59, 16, 44, 3）这里相对于x没有64维特征，加了x,y,z，3个特征,<br>\nself.bx=（-50.8000, -50.8000,   0.0000）；self.dx=（0.8000,  0.8000, 20.0000），<br>\n(self.bx - self.dx / 2.)=-51.2000, -51.2000, -10.0000，也就是x,y,z为0时对应到了前面这个值<br>\nx范围0-128，0-128*0.8=102.4,-51.2-51.2,<br>\n将x, geom_feats, ranks, idx按照坐标排序<br>\nfinal-（1, 64, 128, 128）<br>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def extract_img_feat</p>输入self.bev_encoder为（1, 64, 128, 128）<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def bev_encoder</p>输入self.img_bev_encoder_backbone为（1, 64, 128, 128）<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/backbones/resnet.py</p>\n<p>len(self.layers)=3,self.backbone_output_ids=(0,1,2)<br>\n<code>==========================lid=0=================================</code><br>\nx_tmp = layer(x_tmp):（1, 64, 128, 128）-&gt;(1, 128, 64, 64)<br>\n<code>==========================lid=1=================================</code><br>\nx_tmp = layer(x_tmp):(1, 128, 64, 64)-&gt;(1, 128, 32, 32)<br>\n<code>==========================lid=2=================================</code><br>\nx_tmp = layer(x_tmp):(1, 128, 32, 32)-&gt;(1, 128, 16, 16)<br>\n<code>----------------------------------------------------------------</code><br>\n[(1, 128, 64, 64),(1, 128, 32, 32),(1, 128, 16, 16)]<br></p>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def bev_encoder</p>输入self.img_bev_encoder_neck为[(1, 128, 64, 64),(1, 128, 32, 32),(1, 128, 16, 16)]<br>\n输出：[1, 256, 128, 128]<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/lss_fpn.py</p>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def extract_feat</p>返回：(img_feats, pts_feats)=（1, 256, 128, 128），None<br>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevdet.py:def forward_train</p>输入self.forward_pts_train:[（1, 256, 128, 128）]，[LiDARInstance3DBoxes()],[tensor([5, 8, ...,]]<br>'}]})</script></body>
</html>
