<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>parking_fs_cb</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">数据处理</p>'}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型结构</p>'}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p>'}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型推理</p><span class=\'hidden-code\' data-code=\'def float_infer_jpgs(float_model,jpg_list,save_path,num_deal=12,cam_name=’’,car_name=’’,modeltype = ’float’):\n    num_jpg = len(jpg_list)\n    for idx in range(int(num_jpg/num_deal)+1):\n        if idx==int(num_jpg/num_deal):\n            jpg_paths = jpg_list[idx*num_deal:]\n            `infer_jpg`(jpg_paths,float_model,save_path,cam_name,car_name,modeltype)\n        else:\n            jpg_paths = jpg_list[idx*num_deal:(idx+1)*num_deal]\n            `infer_jpg`(jpg_paths,float_model,save_path,cam_name,car_name,modeltype)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">infer_jpg</p><span class=\'hidden-code\' data-code=\'def infer_jpg(output):\n    K = 30    #  最大检测30个目标出来\n    detections, seg_fs = `decode_segdet`(output, None, K, visible_mask=visible_mask)\n    dbox_cls = `decode_yolodet`(float_model.yolo_heads, [output[’arm_yolo_det’][0]], xywh=False)  # torch.Size([20, 6, 11520])\n    det_yolos = `postprocess_numpy`(dbox_cls.detach().cpu().numpy(), nc, conf_thres = 0.1)\n    for idx_i,image in enumerate(image_list):\n        image1 = deepcopy(image)\n        jpg_path,jpg_name = jpg_paths[idx_i],jpg_names[idx_i]\n        pillar_points0 = detections[’pillar_points0’][idx_i,...].detach().cpu().numpy()\n        pillar_points1 = detections[’pillar_points1’][idx_i,...].detach().cpu().numpy()     \n        pillar_cls_prob0 = detections[’pillar_cls_prob0’][idx_i,...].detach().cpu().numpy()\n        pillar_cls_prob1 = detections[’pillar_cls_prob1’][idx_i,...].detach().cpu().numpy()\n        det_points = detections[’det_points’][idx_i,...].detach().cpu().numpy()\n        pillar_xs = detections[’pillar_xs’][idx_i,...].detach().cpu().numpy()\n        pillar_ys = detections[’pillar_ys’][idx_i,...].detach().cpu().numpy()\n        det_xs = detections[’det_xs’][idx_i,...].detach().cpu().numpy()\n        det_ys = detections[’det_ys’][idx_i,...].detach().cpu().numpy()\n        det_cls_prob = detections[’det_cls_probs’][idx_i,...].detach().cpu().numpy()\n        seg_probs_fs = seg_fs[’seg_probs’][idx_i,...].detach().cpu().numpy().squeeze(0)\n        seg_class_fs = seg_fs[’seg_cls’][idx_i,...].detach().cpu().numpy()\n        mask = np.zeros((img_size[1],img_size[0]),dtype=np.uint8)\n        class_num_list = []\n        # process segmentation\n        seg_rows = np.argmax(seg_probs_fs, axis=0).astype(np.int32)\n        seg_values  = np.max(seg_probs_fs, axis=0)\n        for col in range(seg_probs_fs.shape[1]):\n            row = seg_rows[col]\n            if seg_values[col] > 0.9:\n                cls = seg_class_fs[row, col]\n                if cls not in class_num_list:\n                    class_num_list.append(int(cls))\n                mask[row,col] = cls\n                # color = colormap[cls+4]\n                # cv2.circle(image1, [col, row], color=color, radius=1, thickness=-1)\n        det_stride = 4       # 下采样4倍；\n        for i in range(K):\n            conf_pillar = detections[’pillar_probs’][idx_i, i].item()\n            center_pillar = np.array([pillar_xs[i]*det_stride, pillar_ys[i]*det_stride])\n            pillar_cls0 = np.argmax(pillar_cls_prob0[i])\n            pillar_cls1 = np.argmax(pillar_cls_prob1[i])\n            pillar_pts0 = pillar_points0[i, :].reshape(10, 2)\n            pillar_pts0 = pillar_pts0 * det_stride + center_pillar\n            pillar_pts1 = pillar_points1[i, :].reshape(10, 2)\n            pillar_pts1 = pillar_pts1 * det_stride + center_pillar\n            conf_det = detections[’det_probs’][idx_i, i].item()\n            center_det  = np.array([det_xs[i]*det_stride, det_ys[i]*det_stride])\n            pts_det = det_points[i, :].reshape(10, 2)\n            pts_det = pts_det * det_stride + center_det\n            det_cls = np.argmax(det_cls_prob[i])\n            if conf_pillar > 0.9:\n                cv2.circle(image1, tuple(map(int, center_pillar)), radius=1, color=(128, 0, 128), thickness=-1)\n                cv2.polylines(image1, [pillar_pts0.astype(np.int32)], color=colormap[pillar_cls0], thickness=1, isClosed=False)\n                cv2.polylines(image1, [pillar_pts1.astype(np.int32)], color=colormap[pillar_cls1], thickness=1, isClosed=False)\n                # cv2.polylines(mask, [pillar_pts0.astype(np.int32)], color=pillar_cls0, thickness=1, isClosed=False)\n                # cv2.polylines(mask, [pillar_pts1.astype(np.int32)], color=pillar_cls1, thickness=1, isClosed=False)\n            if conf_det > 0.9:\n                cv2.circle(image1, tuple(map(int, center_det)), radius=1, color=(0, 255, 0), thickness=-1)\n                cv2.polylines(image1, [pts_det.astype(np.int32)], color=colormap[det_cls], thickness=1, isClosed=False)\n                # cv2.polylines(mask, [pts_det.astype(np.int32)], color=int(det_cls), thickness=1, isClosed=False)\n        # 怎么可视化类别--------------------------------------------------\n        sw = int((bx2-bx1)/(len(class_num_list)+1))\n        by1 = int(0.05*img_size[1])\n        for idx,cls in enumerate(class_num_list):\n            if cls!=0:\n                image1[by1-int(0.05*img_size[1]):by1,idx*sw+bx1:(idx+1)*sw+bx1] = colormap[cls]\n                # cv2.putText(image, idx_data[cls], (idx*sw+1+bx1,by1-int(0.025*img_size[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0), thickness=1)\n                image1[mask==cls] = colormap[cls]\n        image_zh = deepcopy(image1)\n        img_pil = Image.fromarray(cv2.cvtColor(image_zh, cv2.COLOR_BGR2RGB))\n        draw = ImageDraw.Draw(img_pil)\n        for idx,cls in enumerate(class_num_list):\n            if cls!=0:\n                draw.text((idx*sw+1+bx1, 0), idx_data[cls], font=font, fill=(0, 0, 0))\n        image_zh = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n        image1[by1-int(0.05*img_size[1]):by1] = image_zh[by1-int(0.05*img_size[1]):by1]\n        # ------------------------------------------------------------------\n        # visualize vehicle and pedestrian\n        seg_vp = `decode_seg`(output, None, visible_mask)\n        seg_probs_vp = seg_vp[’seg_probs’][0,...].detach().cpu().numpy().squeeze(0)\n        seg_class_vp = seg_vp[’seg_cls’][0,...].detach().cpu().numpy()\n        seg_rows    = np.argmax(seg_probs_vp, axis=0)\n        seg_values  = np.max(seg_probs_vp, axis=0)\n        for col in range(seg_probs_vp.shape[1]):\n            row = seg_rows[col]\n            if seg_values[col] > 0.9:\n                cls = seg_class_vp[row, col]\n                color = colormap[cls]\n                # cv2.circle(image1, [col, row], color=color, radius=1, thickness=-1)\n                image1[row,col] = color\n        for pcls,pobjects in det_yolos[idx_i].items():\n            for pobject in pobjects:\n                score, box = pobject\n                plot_one_box(box, image1, label=’%.2f’%score, color=colormap[int(pcls)], line_thickness=1)\n        print(’保存图片’,os.path.join(save_path,’%s’%jpg_name))\n        cv2.imwrite(os.path.join(save_path,’%s’%jpg_name),image1)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">decode_segdet</p><span class=\'hidden-code\' data-code=\'def decode_segdet(outputs, gt=None, K=30, visible_mask=None):\n    if visible_mask is not None:\n        det_visible_mask = torch.nn.functional.upsample_bilinear(visible_mask, scale_factor=1/4)\n    # decode pillar   柱子实例预测,柱子用拐点\n    hm_center = torch.sigmoid(outputs[’hm_pillar’])  # torch.Size([20, 1, 96, 120])\n    if gt is not None:\n        hm_center *= gt[’ignore_det_mask’].unsqueeze(1)\n    elif visible_mask is not None:\n        hm_center *= det_visible_mask\n    batch, cat, height, width = hm_center.size()\n    heat = `_nms`(hm_center)\n    probs, inds, clses, ys, xs = `_topk`(heat, K=K)  # torch.Size([20, 30])；torch.Size([20, 30])\n    reg_pointsets = `_transpose_and_gather_feat`(outputs[’pillar_points’], inds) # torch.Size([20, 40, 96, 120])-->torch.Size([20, 30, 40])\n    reg_pointsets = reg_pointsets.reshape(batch, K, 2, 20)                     # torch.Size([20, 30, 2, 20])左右分别回归10个点\n    pillar_point0 = reg_pointsets[:, :, 0, :]\n    pillar_point1 = reg_pointsets[:, :, 1, :]\n    pillar_scores = _transpose_and_gather_feat(outputs[’pillar_cls’], inds) # torch.Size([20, 12, 96, 120]) 10个点，每个点6个类别\n    pillar_scores0 = pillar_scores[:, :, :6]       # torch.Size([20, 30, 6])\n    pillar_cls_prob0 = torch.softmax(pillar_scores0, dim=2)  # torch.Size([20, 30, 6])\n    pillar_scores1 = pillar_scores[:, :, 6:]\n    pillar_cls_prob1 = torch.softmax(pillar_scores1, dim=2)\n    detections = {}\n    detections[’hm_pillar’] = hm_center  # torch.Size([20, 1, 96, 120])\n    detections[’pillar_probs’] = probs   # torch.Size([20, 30])\n    detections[’pillar_xs’] = xs         # torch.Size([20, 30])\n    detections[’pillar_ys’] = ys         # torch.Size([20, 30])\n    detections[’pillar_points0’] = pillar_point0   # torch.Size([20, 30, 20])\n    detections[’pillar_points1’] = pillar_point1\n    detections[’pillar_cls_prob0’] = pillar_cls_prob0  # torch.Size([20, 30, 6])\n    detections[’pillar_cls_prob1’] = pillar_cls_prob1\n    # decode object  其它障碍物用中心点，回归10个点\n    hm_center = torch.sigmoid(outputs[’hm_det’])    # torch.Size([20, 1, 96, 120])\n    if gt is not None:\n        hm_center *= gt[’ignore_det_mask’].unsqueeze(1)\n    elif visible_mask is not None:\n        hm_center *= det_visible_mask\n    batch, cat, height, width = hm_center.size()\n    heat = _nms(hm_center)\n    probs, inds, clses, ys, xs = _topk(heat, K=K)\n    reg_pointsets = _transpose_and_gather_feat(outputs[’det_points’], inds)  # torch.Size([20, 40, 96, 120])-->torch.Size([20, 30, 20])\n    reg_pointsets = reg_pointsets.reshape(batch, K, 1, 20)    # torch.Size([20, 30, 1, 20])\n    pointset0 = reg_pointsets[:, :, 0, :]                     # torch.Size([20, 30, 20])\n    det_scores = _transpose_and_gather_feat(outputs[’det_cls’], inds)  # torch.Size([20, 30, 18])障碍物18个类别\n    det_cls_probs  = torch.softmax(det_scores, dim=2)\n    detections[’hm_det’] = hm_center   # torch.Size([20, 1, 96, 120])\n    detections[’det_probs’] = probs    # torch.Size([20, 30])\n    detections[’det_xs’] = xs          # torch.Size([20, 30])\n    detections[’det_ys’] = ys          # torch.Size([20, 30])\n    detections[’det_points’] = pointset0         # torch.Size([20, 30, 20])\n    detections[’det_cls_probs’] = det_cls_probs  # torch.Size([20, 30, 18])\n    segmentation = dict()\n    segmentation[’seg_probs’] = torch.sigmoid(outputs[’seg_fs’][:, 0:1, :, :])  # torch.Size([20, 28, 384, 480]) 1+27个类别\n    if gt is not None:\n        segmentation[’seg_probs’] *= gt[’ignore_seg_mask’].unsqueeze(1)\n    elif visible_mask is not None:\n        segmentation[’seg_probs’] *= visible_mask\n    segmentation[’seg_cls’]  = torch.argmax(torch.softmax(outputs[’seg_fs’][:, 1:, :, :], dim=1), dim=1)  # torch.Size([20, 27, 384, 480])->torch.Size([20, 384, 480])\n    return detections, segmentation\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">_nms</p><span class=\'hidden-code\' data-code=\'def _nms(heat, kernel=3):\n    pad = (kernel - 1) // 2\n    hmax = nn.functional.max_pool2d(heat, (kernel, kernel), stride=1, padding=pad)\n    keep = (hmax == heat).float()\n    return heat * keep\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">_topk</p><span class=\'hidden-code\' data-code=\'def _topk(scores, K=40): \n    batch, cat, height, width = scores.size()        # torch.Size([20, 1, 96, 120])\n    topk_scores, topk_inds = torch.topk(scores.view(batch, cat, -1), K)  # torch.Size([20, 1, 30])；torch.Size([20, 1, 30])\n    topk_inds = topk_inds % (height * width)        # torch.Size([20, 1, 30])\n    topk_ys = (topk_inds / width).int().float()     # torch.Size([20, 1, 30])\n    topk_xs = (topk_inds % width).int().float()\n    topk_score, topk_ind = torch.topk(topk_scores.view(batch, -1), K)\n    topk_clses = (topk_ind / K).int()\n    topk_inds = `_gather_feat`(topk_inds.view(batch, -1, 1), topk_ind).view(batch, K)\n    topk_ys = _gather_feat(topk_ys.view(batch, -1, 1), topk_ind).view(batch, K)\n    topk_xs = _gather_feat(topk_xs.view(batch, -1, 1), topk_ind).view(batch, K)\n    return topk_score, topk_inds, topk_clses, topk_ys, topk_xs\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">_gather_feat</p><span class=\'hidden-code\' data-code=\'def _gather_feat(feat, ind, mask=None):\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat\n\'> </span>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">_transpose_and_gather_feat</p><span class=\'hidden-code\' data-code=\'def _transpose_and_gather_feat(feat, ind):\n    feat = feat.permute(0, 2, 3, 1).contiguous()\n    feat = feat.view(feat.size(0), -1, feat.size(3))\n    feat = _gather_feat(feat, ind)\n    return feat\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">_gather_feat</p><span class=\'hidden-code\' data-code=\'def _gather_feat(feat, ind, mask=None):\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">decode_yolodet</p><span class=\'hidden-code\' data-code=\'def decode_yolodet(model, x, xywh=False):\n    shape = x[0].shape  # BCHW     # torch.Size([20, 66, 96, 120])  64+2=16x4+2\n    x_cat = torch.cat([xi.view(shape[0], model.no, -1) for xi in x], 2)  # torch.Size([20, 66, 11520])\n    model.anchors, model.strides = (x.transpose(0, 1) for x in make_anchors(x, model.stride, 0.5))\n    box, cls = x_cat.split((model.reg_max * 4, model.nc), 1)  # torch.Size([20, 64, 11520]);torch.Size([20, 2, 11520])\n    dbox = `decode_bboxes`(model.dfl(box), model.anchors.unsqueeze(0), xywh) * model.strides    # torch.Size([1, 4, 2880])\n    return torch.cat((dbox, cls.sigmoid()), 1)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">decode_bboxes</p><span class=\'hidden-code\' data-code=\'def decode_bboxes(bboxes: torch.Tensor, anchors: torch.Tensor, xywh: bool = True) -> torch.Tensor:\n    ’’’Decode bounding boxes from predictions.’’’\n    return `dist2bbox`(bboxes,anchors,xywh=xywh,dim=1,)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">dist2bbox</p><span class=\'hidden-code\' data-code=\'def dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n    ’’’Transform distance(ltrb) to box(xywh or xyxy).’’’\n    lt, rb = distance.chunk(2, dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat([c_xy, wh], dim)  # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">postprocess_numpy</p><span class=\'hidden-code\' data-code=\'def postprocess_numpy(preds: np.ndarray, nc: int = 80, conf_thres: float = 0.25, iou_thres: float = 0.45, xywh: bool = False) -> list:\n    batch_size, ch, num_anchors = preds.shape\n    assert ch == 4 + nc, f’Expected channel dim = 4 + {nc}, got {ch}’\n    results = []\n    for b in range(batch_size):\n        # Transpose to (num_anchors, 4 + nc)\n        pred = preds[b].T  # (N, 4+nc)\n        boxes = pred[:, :4]          # (N, 4)\n        cls_probs = pred[:, 4:]           # (N, nc)\n        # Compute max class score and class index\n        max_scores = np.max(cls_probs, axis=1)   # (N,)\n        class_ids = np.argmax(cls_probs, axis=1) # (N,)\n        # Filter by confidence threshold\n        valid_mask = max_scores > conf_thres\n        boxes = boxes[valid_mask]\n        scores = max_scores[valid_mask]\n        classes = class_ids[valid_mask]\n        class_dict = {}\n        if boxes.shape[0]>0:\n            # Convert to xyxy for NMS\n            if xywh:\n                boxes = `xywh2xyxy`(boxes)\n            # Group detections by class: {class_id: [(score, xyxy_box), ...]}\n            for score, box, cls in zip(scores, boxes, classes):\n                if cls not in class_dict:\n                    class_dict[cls] = []\n                class_dict[cls].append((float(score), box.tolist()))\n            for cls_id, obj_list in class_dict.items():\n                # obj_list: List[(score, [x1,y1,x2,y2])]\n                kept_objs = `nms`(obj_list, iou_threshold=iou_thres)  # ← 调用你的 nms\n                class_dict[cls_id] = kept_objs\n        results.append(class_dict)\n    return results\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">xywh2xyxy</p><span class=\'hidden-code\' data-code=\'def xywh2xyxy(x):\n    assert x.shape[-1] == 4, f’input shape last dimension expected 4 but input shape is {x.shape}’\n    y = empty_like(x)  # faster than clone/copy\n    xy = x[..., :2]  # centers\n    wh = x[..., 2:] / 2  # half width-height\n    y[..., :2] = xy - wh  # top left xy\n    y[..., 2:] = xy + wh  # bottom right xy\n    return y\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">nms</p><span class=\'hidden-code\' data-code=\'def nms(objects, iou_threshold=0.2):  # 注意：你原始代码中硬编码了 0.2，这里改为参数\n    objects = sorted(objects, key=lambda ob: ob[0], reverse=True)\n    obj_len = len(objects)\n    merge = np.ones((obj_len,), dtype=np.int32) * (-1)\n    for i in range(obj_len):\n        if merge[i] >= 0:\n            continue\n        ibox = objects[i][1]\n        for j in range(i + 1, obj_len):\n            if merge[j] >= 0:\n                continue\n            jbox = objects[j][1]\n            if iou_func(ibox, jbox) > iou_threshold:\n                merge[j] = i\n    new_objs = [objects[i] for i in range(obj_len) if merge[i] < 0]\n    return new_objs\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">iou_func</p><span class=\'hidden-code\' data-code=\'def iou_func(box1, box2):\n    inter_x1 = max(box1[0], box2[0])\n    inter_y1 = max(box1[1], box2[1])\n    inter_x2 = min(box1[2], box2[2])\n    inter_y2 = min(box1[3], box2[3])\n    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n    union_area = box1_area + box2_area - inter_area\n    return inter_area / union_area if union_area != 0 else 0.0\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">decode_seg</p><span class=\'hidden-code\' data-code=\'def decode_seg(outputs, gt=None, visible_mask=None):\n    # decode segmentation\n    segmentation = dict()\n    segmentation[’seg_probs’] = torch.sigmoid(outputs[’seg_vehped’][:, 0:1, :, :])\n    if gt is not None:\n        segmentation[’seg_probs’] *= gt[’ignore_seg_mask’].unsqueeze(1)\n    elif visible_mask is not None:\n        segmentation[’seg_probs’] *= visible_mask\n    segmentation[’seg_cls’]  = torch.argmax(torch.softmax(outputs[’seg_vehped’][:, 1:, :, :], dim=1), dim=1)\n    return segmentation\n\'> </span>'}]}]}]})</script>
    <script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
  </body>
</html>
