<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>pnp_det损失计算过程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">损失计算过程</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">epropnp_det/models/dense_heads/deform_pnp_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class DeformPnPHead(BaseDenseHead):\n        def forward_train(self,\n                      mlvl_feats,                <span style=\'color: red\'># [i.shape for i in mlvl_feats](1600, 900) = [torch.Size([6, 256, 84, 200])x8, torch.Size([6, 256, 42, 100])x16, torch.Size([6, 256, 21, 50])x32, torch.Size([6, 256, 11, 25])x64, torch.Size([6, 256, 6, 13])x128]</span>\n                      img_metas,                 <span style=\'color: red\'># 6张图片[,,...],img_metas[0][\'ori_shape\']=(900, 1600, 3);img_metas[0][\'img_shape\']=(672, 1600, 3);img_metas[0][\'pad_shape\']=(672, 1600, 3);img_metas[0][\'flip\']=True;img_metas[0][\'flip_direction\']=\'horizontal\'</span>\n                      gt_bboxes,                 <span style=\'color: red\'># 6个2D box[,,...],gt_bboxes[0].shape=torch.Size([3, 4])</span>\n                      gt_labels=None,            <span style=\'color: red\'># 6个2D box[,,...],gt_labels[0].shape=torch.Size([3])</span>\n                      gt_bboxes_ignore=None,     \n                      gt_bboxes_3d=None,         <span style=\'color: red\'># 6个3D box[,,...],gt_bboxes_3d[0].shape=torch.Size([3, 7])-->对着的是原始图片</span>\n                      gt_x3d=None,               <span style=\'color: red\'># 6个 box第一个box有n个值，gt_x3d[0][0].shape=torch.Size([2, 3])；gt_x3d[0][1].shape=torch.Size([1, 3])；...；gt_x3d[0][n].shape=torch.Size([433, 3])；</span>\n                      gt_x2d=None,               <span style=\'color: red\'># 6个 box第一个box有n个值，gt_x2d[0][0].shape=torch.Size([2, 2])；gt_x2d[0][1].shape=torch.Size([1, 2])；...；gt_x2d[0][n].shape=torch.Size([433, 2])；</span>\n                      gt_attr=None,\n                      gt_velo=None,\n                      img_dense_x2d=None,        <span style=\'color: red\'># img_dense_x2d.shape=torch.Size([6, 2, 672, 1600])      </span>\n                      img_dense_x2d_mask=None,   <span style=\'color: red\'># img_dense_x2d_mask.shape=torch.Size([6, 1, 672, 1600])</span>\n                      cam_intrinsic=None):       <span style=\'color: red\'># cam_intrinsic[0].shape=torch.Size([3, 3])</span>\n        <span style=\'color: red\'># ===== prepare img metas and g.t. =====</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">epropnp_det/core/bbox_3d/center_target.py</p><font size="0"><pre class="language-python"><code class="language-python">class VolumeCenter(object):               <span style=\'color: red\'># 体积中心</span>\n    def get_centers_2d(self, bboxes_2d, bboxes_3d, obj_img_inds, img_dense_x2d_small, img_dense_x2d_mask_small,cam_intrinsic, max_shape)\n        num_obj = bboxes_3d.size(0)                    <span style=\'color: red\'># 22</span>\n        num_img = cam_intrinsic.size(0)                <span style=\'color: red\'># 6</span>\n        pad_shape = torch.ceil(max_shape / self.output_stride) * self.output_stride           <span style=\'color: red\'># tensor([ 900., 1600.], device=\'cuda:0\')->tensor([ 904., 1600.], device=\'cuda:0\')8的倍数</span>\n        verts = self.base_mesh.verts_list()[0].to(device) * 0.5  <span style=\'color: red\'># (vn, 3)     torch.Size([8, 3])值为-0.5或0.5，中心点为原点的长宽高为1的3D box</span>\n        faces = self.base_mesh.faces_list()[0].to(device)        <span style=\'color: red\'># (fn, 3)     torch.Size([12, 3])</span>\n        vn = verts.size(0)\n        fn = faces.size(0)\n        verts = verts[None].expand(num_obj, -1, -1)  <span style=\'color: red\'># (num_obj, vn, 3)  torch.Size([22, 8, 3])</span>\n        verts_oc = verts * bboxes_3d[:, None, :3]    <span style=\'color: red\'># torch.Size([22, 8, 3]),长宽高乘以那8个顶点</span>\n        <span style=\'color: red\'># =====transform to opencv camera space=====</span>\n        rot_mats = yaw_to_rot_mat(bboxes_3d[:, 6])  <span style=\'color: red\'># (num_obj, 3, 3)          得到旋转矩阵</span>\n        <span style=\'color: red\'># (num_obj, vn, 3) = ((num_obj, 3, 3) @ (num_obj, 3, vn)) -> (num_obj, vn, 3) + (num_obj, 1, 3)</span>\n        verts_cam = (rot_mats @ verts_oc.transpose(-1, -2)).transpose(-1, -2) + bboxes_3d[:, None, 3:6]    <span style=\'color: red\'># torch.Size([22, 8, 3])得到22个3Dbox的8个顶点</span>\n        <span style=\'color: red\'># =====join meshes as scenes=====</span>\n        verts_list = []  <span style=\'color: red\'># list of scenes</span>\n        faces_list = []\n        num_obj_per_img_list = []\n        img_has_object_list = []\n        for i in range(num_img):                        <span style=\'color: red\'># 6张图片</span>\n            verts_scene = verts_cam[obj_img_inds == i]  <span style=\'color: red\'># (num_obj_per_img, vn, 3)      </span>\n            num_obj_per_img = verts_scene.size(0)\n            img_has_object = num_obj_per_img > 0\n            if img_has_object:                                                           <span style=\'color: red\'># 该张图片有3D box</span>\n                faces_scene = faces.unsqueeze(0).expand(num_obj_per_img, -1, -1)         <span style=\'color: red\'># (num_obj_per_img, fn, 3)  torch.Size([4, 12, 3])</span>\n                faces_scene = faces_scene + torch.arange(0, num_obj_per_img * vn, step=vn, device=device)[:, None, None]      <span style=\'color: red\'># reindex  torch.Size([4, 12, 3]) / vn=8    tensor([[[ 0]],[[ 8]],[[16]],[[24]]], device=\'cuda:0\')</span>\n                verts_list.append(verts_scene.reshape(num_obj_per_img * vn, 3))          <span style=\'color: red\'># 顶点          第一个值的shape=torch.Size([32, 3])</span>\n                faces_list.append(faces_scene.reshape(num_obj_per_img * fn, 3))          <span style=\'color: red\'># 对应顶点索引   第一个值的shape=torch.Size([48, 3])</span>\n            num_obj_per_img_list.append(num_obj_per_img)                                 <span style=\'color: red\'># [4, 5, 2, 2, 3, 6]</span>\n            img_has_object_list.append(img_has_object)                                   <span style=\'color: red\'># [True, True, True, True, True, True]</span>\n        scene_meshes = Meshes(verts=verts_list, faces=faces_list)      \n        <span style=\'color: red\'># =====select images with objects=====</span>\n        img_has_object_list = torch.tensor(img_has_object_list, dtype=torch.bool, device=device)    <span style=\'color: red\'># tensor([True, True, True, True, True, True], device=\'cuda:0\')</span>\n        img_dense_x2d_small = img_dense_x2d_small[img_has_object_list]                              <span style=\'color: red\'># torch.Size([6, 2, 84, 200])</span>\n        img_dense_x2d_mask_small = img_dense_x2d_mask_small[img_has_object_list]                    <span style=\'color: red\'># torch.Size([6, 1, 84, 200])</span>\n        cam_intrinsic = cam_intrinsic[img_has_object_list]\n        obj_img_inds_new = (img_has_object_list.cumsum(dim=0) - 1)[obj_img_inds]                    <span style=\'color: red\'># img_has_object_list.cumsum(dim=0) - 1--》 torch.Size([22])</span>\n        <span style=\'color: red\'># =====camera conversion=====</span>\n        f = cam_intrinsic[:, [0, 1], [0, 1]]   <span style=\'color: red\'># (num_img, 2) [fx, fy]    torch.Size([6, 2])</span>\n        p = cam_intrinsic[:, :2, 2]            <span style=\'color: red\'># (num_img, 2) [px, py]</span>\n        half_shape = pad_shape / 2             <span style=\'color: red\'># (2, ) [h, w]     tensor([ 904., 1600.], device=\'cuda:0\')->tensor([452., 800.], device=\'cuda:0\')</span>\n        denom = torch.min(half_shape)          <span style=\'color: red\'># 452</span>\n        cameras = PerspectiveCameras(focal_length=-f / denom,principal_point=(half_shape[[1, 0]] - (p + 0.5)) / denom,device=device)\n        <span style=\'color: red\'># =====rasterize=====</span>\n        h_rend, w_rend = int(pad_shape[0]) // self.render_stride, int(pad_shape[1]) // self.render_stride    <span style=\'color: red\'># self.render_stride=4 --->226,400</span>\n        raster_settings = RasterizationSettings(image_size=(h_rend, w_rend),blur_radius=0.0, faces_per_pixel=self.faces_per_pixel,z_clip_value=1e-2)\n        frags = self.rasterizer(scene_meshes, cameras=cameras, raster_settings=raster_settings)\n        pix_to_face = frags.pix_to_face  <span style=\'color: red\'># (num_img, h_rend, w_rend, faces_per_pixel)     </span>\n        zbuf = frags.zbuf                <span style=\'color: red\'># (num_img, h_rend, w_rend, faces_per_pixel)     </span>\n        <span style=\'color: red\'># =====post proc=====</span>\n        if num_obj > self.max_gpu_obj > 0:      <span style=\'color: red\'># num_obj > False > 0</span>\n            bboxes_2d = bboxes_2d.cpu()\n            zbuf = zbuf.cpu()\n            pix_to_face = pix_to_face.cpu()\n            img_dense_x2d_small = img_dense_x2d_small.cpu()\n            img_dense_x2d_mask_small = img_dense_x2d_mask_small.cpu()\n            pad_shape = pad_shape.cpu()\n            obj_img_inds_new = obj_img_inds_new.cpu()\n        centers_2d, bboxes_2d, valid_mask = self.post_proc(zbuf, pix_to_face, img_dense_x2d_small, img_dense_x2d_mask_small,pad_shape, num_obj, obj_img_inds_new, bboxes_2d, fn)        \n</code></pre></font>\nverts<br>\n<font size="0"><pre class="language-python"><code class="language-python">tensor([[-0.5000, -0.5000,  0.5000],\n        [ 0.5000, -0.5000,  0.5000],\n        [-0.5000,  0.5000,  0.5000],\n        [ 0.5000,  0.5000,  0.5000],\n        [-0.5000, -0.5000, -0.5000],\n        [ 0.5000, -0.5000, -0.5000],\n        [-0.5000,  0.5000, -0.5000],\n        [ 0.5000,  0.5000, -0.5000]], device=\'cuda:0\')\n</code></pre></font>\nfaces<br>\n<font size="0"><pre class="language-python"><code class="language-python">tensor([[0, 1, 2],\n        [1, 3, 2],\n        [2, 3, 7],\n        [2, 7, 6],\n        [1, 7, 3],\n        [1, 5, 7],\n        [6, 7, 4],\n        [7, 5, 4],\n        [0, 4, 1],\n        [1, 4, 5],\n        [2, 6, 4],\n        [0, 2, 4]], device=\'cuda:0\')\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">epropnp_det/core/bbox_3d/center_target.py</p><font size="0"><pre class="language-python"><code class="language-python">class VolumeCenter(object):               <span style=\'color: red\'># 体积中心</span>\n    def post_proc(self, zbuf, pix_to_face, img_dense_x2d_small, img_dense_x2d_mask_small,pad_shape, num_obj, obj_img_inds, bboxes_2d, fn)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">epropnp_det/core/bbox_3d/center_target.py</p><font size="0"><pre class="language-python"><code class="language-python">class VolumeCenter(object):               <span style=\'color: red\'># 体积中心</span>\n    def get_centers_2d(self, bboxes_2d, bboxes_3d, obj_img_inds, img_dense_x2d_small, img_dense_x2d_mask_small,cam_intrinsic, max_shape)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">epropnp_det/models/dense_heads/deform_pnp_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class DeformPnPHead(BaseDenseHead):\n        def forward_train()\n</code></pre></font>'}]}]})</script></body>
</html>
