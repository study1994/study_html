<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>VIT代码流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/modeling.py</p><font size="0"><pre class="language-python"><code class="language-python">class VisionTransformer(nn.Module):\n    def __init__(self, config, img_size=224, num_classes=21843, zero_head=False, vis=False):\n        super(VisionTransformer, self).__init__()\n        self.num_classes = num_classes\n        self.zero_head = zero_head\n        self.classifier = config.classifier\n        self.transformer = Transformer(config, img_size, vis)\n        self.head = Linear(config.hidden_size, num_classes)\n    def forward(self, x, labels=None):\n        x, attn_weights = self.<span style=\'color: green;font-weight: bold;\'>transformer</span>(x) <span style=\'color: red\'>(16,197,768)</span>\n        logits = self.<span style=\'color: green;font-weight: bold;\'>head</span>(x[:, 0])           <span style=\'color: red\'>(16,768)->(16,10)用于计算分类计算</span>\n        if labels is not None:\n            loss_fct = CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n            return loss\n        else:\n            return logits, attn_weights\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/modeling.py</p><font size="0"><pre class="language-python"><code class="language-python">class Transformer(nn.Module):\n    def __init__(self, config, img_size, vis):\n        super(Transformer, self).__init__()\n        self.embeddings = Embeddings(config, img_size=img_size)\n        self.encoder = Encoder(config, vis)\n    def forward(self, input_ids):\n        embedding_output = self.<span style=\'color: green;font-weight: bold;\'>embeddings</span>(input_ids)        <span style=\'color: red\'># (16,197,768)</span>\n        encoded, attn_weights = self.<span style=\'color: green;font-weight: bold;\'>encoder</span>(embedding_output)\n        return encoded, attn_weights\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/modeling.py</p><font size="0"><pre class="language-python"><code class="language-python">class Embeddings(nn.Module):\n    """Construct the embeddings from patch, position embeddings.\n    """\n    def __init__(self, config, img_size, in_channels=3):\n        super(Embeddings, self).__init__()\n        self.hybrid = None\n        img_size = _pair(img_size)\n        if config.patches.get("grid") is not None:\n            grid_size = config.patches["grid"]\n            patch_size = (img_size[0] <span style=\'color: red\'>// 16</span>\n            n_patches = (img_size[0] <span style=\'color: red\'>// 16) * (img_size[1]</span>\n            self.hybrid = True\n        else:\n            patch_size = _pair(config.patches["size"])\n            n_patches = (img_size[0] <span style=\'color: red\'>// patch_size[0]) * (img_size[1]</span>\n            self.hybrid = False\n        if self.hybrid:\n            self.hybrid_model = ResNetV2(block_units=config.resnet.num_layers,width_factor=config.resnet.width_factor)\n            in_channels = self.hybrid_model.width * 16\n        self.patch_embeddings = Conv2d(in_channels=in_channels,out_channels=config.hidden_size,kernel_size=patch_size,stride=patch_size)\n        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches+1, config.hidden_size))     <span style=\'color: red\'># (1,196+1,768)</span>\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, config.hidden_size))     <span style=\'color: red\'># config.hidden_size=768</span>\n        self.dropout = Dropout(config.transformer["dropout_rate"])\n    def forward(self, x):    <span style=\'color: red\'># (16,3,224,224)</span>\n        B = x.shape[0]\n        cls_tokens = self.cls_token.expand(B, -1, -1)  <span style=\'color: red\'># (16,1,768)</span>\n        if self.hybrid:\n            x = self.hybrid_model(x)\n        x = self.patch_embeddings(x)      <span style=\'color: red\'># 卷积操作->(16,768,14,14)</span>\n        x = x.flatten(2)                  <span style=\'color: red\'># (16,768,196)</span>\n        x = x.transpose(-1, -2)           <span style=\'color: red\'># (16,196,768)</span>\n        x = torch.cat((cls_tokens, x), dim=1)      <span style=\'color: red\'># (16,197,768)</span>\n        embeddings = x + self.position_embeddings  <span style=\'color: red\'># (16,197,768)</span>\n        embeddings = self.dropout(embeddings)      <span style=\'color: red\'># (16,197,768)</span>\n        return embeddings\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/modeling.py</p><font size="0"><pre class="language-python"><code class="language-python">class Encoder(nn.Module):\n    def __init__(self, config, vis):\n        super(Encoder, self).__init__()\n        self.vis = vis\n        self.layer = nn.ModuleList()\n        self.encoder_norm = LayerNorm(config.hidden_size, eps=1e-6)\n        for _ in range(config.transformer["num_layers"]):\n            layer = Block(config, vis)\n            self.layer.append(copy.deepcopy(layer))\n    def forward(self, hidden_states):         <span style=\'color: red\'># (16,197,768)</span>\n        attn_weights = []\n        for layer_block in self.layer:\n            hidden_states, weights = <span style=\'color: green;font-weight: bold;\'>layer_block</span>(hidden_states)\n            if self.vis:\n                attn_weights.append(weights)\n        encoded = self.<span style=\'color: green;font-weight: bold;\'>encoder_norm</span>(hidden_states)\n        return encoded, attn_weights\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/modeling.py</p><font size="0"><pre class="language-python"><code class="language-python">class Block(nn.Module):\n    def __init__(self, config, vis):\n        super(Block, self).__init__()\n        self.hidden_size = config.hidden_size\n        self.attention_norm = LayerNorm(config.hidden_size, eps=1e-6)\n        self.ffn_norm = LayerNorm(config.hidden_size, eps=1e-6)\n        self.ffn = Mlp(config)\n        self.attn = Attention(config, vis)\n    def forward(self, x):\n        h = x\n        x = self.<span style=\'color: green;font-weight: bold;\'>attention_norm</span>(x)  <span style=\'color: red\'># (16,197,768)</span>\n        x, weights = self.<span style=\'color: green;font-weight: bold;\'>attn</span>(x)   <span style=\'color: red\'># (16,197,768) (16,12，197，64)</span>\n        x = x + h\n        h = x\n        x = self.ffn_norm(x)          <span style=\'color: red\'># (16,197,768)</span>\n        x = self.ffn(x)\n        x = x + h\n        return x, weights             <span style=\'color: red\'># (16,197,768)</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">attention_norm</p>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">Attention</p><font size="0"><pre class="language-python"><code class="language-python">class Attention(nn.Module):\n    def __init__(self, config, vis):\n        super(Attention, self).__init__()\n        self.vis = vis\n        self.num_attention_heads = config.transformer["num_heads"]\n        self.attention_head_size = int(config.hidden_size / self.num_attention_heads)\n        self.all_head_size = self.num_attention_heads * self.attention_head_size\n        self.query = Linear(config.hidden_size, self.all_head_size)\n        self.key = Linear(config.hidden_size, self.all_head_size)\n        self.value = Linear(config.hidden_size, self.all_head_size)\n        self.out = Linear(config.hidden_size, config.hidden_size)\n        self.attn_dropout = Dropout(config.transformer["attention_dropout_rate"])\n        self.proj_dropout = Dropout(config.transformer["attention_dropout_rate"])\n        self.softmax = Softmax(dim=-1)\n    def transpose_for_scores(self, x): <span style=\'color: red\'># (16,197,768)</span>\n        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n        x = x.view(*new_x_shape)       <span style=\'color: red\'># (16,197,12，64)   分成12个头</span>\n        return x.permute(0, 2, 1, 3)   <span style=\'color: red\'># (16,12，197，64)</span>\n    def forward(self, hidden_states):      <span style=\'color: red\'># (16,197,768)</span>\n        mixed_query_layer = self.query(hidden_states)  <span style=\'color: red\'># 全连接得到(16,197,768)</span>\n        mixed_key_layer = self.key(hidden_states)      <span style=\'color: red\'># (16,197,768)</span>\n        mixed_value_layer = self.value(hidden_states)  <span style=\'color: red\'># (16,197,768)</span>\n        query_layer = self.transpose_for_scores(mixed_query_layer)  <span style=\'color: red\'># (16,12，197，64)</span>\n        key_layer = self.transpose_for_scores(mixed_key_layer)      <span style=\'color: red\'># (16,12，197，64)</span>\n        value_layer = self.transpose_for_scores(mixed_value_layer)  <span style=\'color: red\'># (16,12，197，64)</span>\n        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))  <span style=\'color: red\'># # (16,12，197，197)  197之间的关系</span>\n        attention_scores = attention_scores / math.sqrt(self.attention_head_size)  <span style=\'color: red\'># 排除64长度的影响</span>\n        attention_probs = self.softmax(attention_scores)                           <span style=\'color: red\'># 分值->权重值</span>\n        weights = attention_probs if self.vis else None\n        attention_probs = self.attn_dropout(attention_probs)                       <span style=\'color: red\'># (16,12，197，64)</span>\n        context_layer = torch.matmul(attention_probs, value_layer)                 <span style=\'color: red\'># 将得分值作用到value上面--》重构特征</span>\n        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()             <span style=\'color: red\'># (16,12，197，64)</span>\n        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n        context_layer = context_layer.view(*new_context_layer_shape)               <span style=\'color: red\'># (16, 197，768)</span>\n        attention_output = self.out(context_layer)                                 <span style=\'color: red\'># 全连接</span>\n        attention_output = self.proj_dropout(attention_output)\n        return attention_output, weights\n</code></pre></font>'}]}]}]}]}]})</script></body>
</html>
