<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov10训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p><span class=\'hidden-code\' data-code=\'from ultralytics import YOLOv10\nmodel_yaml_path = &amp;#39;ultralytics/cfg/models/v10/yolov10s.yaml&amp;#39;\ndata_yaml_path = &amp;#39;datasets/side_all/data.yaml&amp;#39;\npre_model_name = &amp;#39;yolov10s.pt&amp;#39;\nif __name__ == &amp;#39;__main__&amp;#39;:\n    model = `YOLOv10`(model_yaml_path).`load`(pre_model_name)\n    results = model.`train`(data=data_yaml_path,epochs=150,batch=4,name=&amp;#39;train_v10&amp;#39;)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolov10/model.py</p><span class=\'hidden-code\' data-code=\'class YOLOv10(`Model`, PyTorchModelHubMixin, model_card_template=card_template_text):\n    def __init__(self, model=&amp;#39;yolov10n.pt&amp;#39;, task=None, verbose=False, names=None):\n        super().__init__(model=model, task=task, verbose=verbose)\n        if names is not None:\n            setattr(self.model, &amp;#39;names&amp;#39;, names)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def __init__(self,model,task,verbose):\n        super().__init__()\n        self.callbacks = callbacks.get_default_callbacks()  # defaultdict={},长度25，， &amp;#39;on_pretrain_routine_start&amp;#39;；\n        self.predictor = None  # reuse predictor\n        self.model = None      # model object\n        self.trainer = None    # trainer object\n        self.ckpt = None       # if loaded from *.pt\n        self.cfg = None        # if loaded from *.yaml\n        self.ckpt_path = None\n        self.overrides = {}    # overrides for trainer object\n        self.metrics = None    # validation/training metrics\n        self.session = None    # HUB session\n        self.task = task       # task type\n        model = str(model).strip()\n        # Load or create new YOLO model\n        if Path(model).suffix in (&amp;#39;.yaml&amp;#39;, &amp;#39;.yml&amp;#39;):         # &amp;#39;ultralytics/cfg/models/v10/yolov10s.yaml&amp;#39;\n            self.`_new`(model, task=task, verbose=verbose)\n        else:\n            self._load(model, task=task)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def _new(self, cfg: str, task=None, model=None, verbose=False) -> None:\n        cfg_dict = yaml_model_load(cfg)                     # dict_keys([&amp;#39;nc&amp;#39;, &amp;#39;scales&amp;#39;, &amp;#39;backbone&amp;#39;, &amp;#39;head&amp;#39;, &amp;#39;scale&amp;#39;, &amp;#39;yaml_file&amp;#39;])\n        self.cfg = cfg                                      # &amp;#39;ultralytics/cfg/models/v10/yolov10s.yaml&amp;#39;\n        self.task = task or guess_model_task(cfg_dict)      # &amp;#39;detect&amp;#39;\n        self.model = (model or self.`_smart_load`(&amp;#39;model&amp;#39;))(cfg_dict, verbose=verbose and RANK == -1)  # build model\n        self.overrides[&amp;#39;model&amp;#39;] = self.cfg\n        self.overrides[&amp;#39;task&amp;#39;] = self.task\n        # Below added to allow export from YAMLs   # ultralytics/utils/__init__.py设置了默认的参数路径==》ultralytics/cfg/default.yaml\n        self.model.args = {**DEFAULT_CFG_DICT, **self.overrides}  # combine default and model args (prefer model args)\n        self.model.task = self.task\n        self.model_name = cfg\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class v10Detect(Detect):\n    max_det = 300\n    def __init__(self, nc=80, ch=()):\n        `super`().__init__(nc, ch)\n        c3 = max(ch[0], min(self.nc, 100))  # channels  ch=[128, 256, 512],128\n        self.cv3 = nn.ModuleList(nn.Sequential(nn.Sequential(Conv(x, x, 3, g=x), Conv(x, c3, 1)), \n               nn.Sequential(Conv(c3, c3, 3, g=c3), Conv(c3, c3, 1)),\n               nn.Conv2d(c3, self.nc, 1)) for i, x in enumerate(ch))          # 替换掉了Class Detect里面的卷积\n        self.one2one_cv2 = copy.deepcopy(self.cv2)\n        self.one2one_cv3 = copy.deepcopy(self.cv3)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class Detect(nn.Module):           # YOLOv8 Detect head for detection models\n    dynamic = False           # force grid reconstruction\n    export = False            # export mode\n    shape = None\n    anchors = torch.empty(0)  # init\n    strides = torch.empty(0)  # init\n    def __init__(self, nc=80, ch=()):              # Initializes the YOLOv8 detection layer with specified number of classes and channels\n        super().__init__()\n        self.nc = nc       # number of classes          6\n        self.nl = len(ch)  # number of detection layers  [128, 256, 512]->3\n        self.reg_max = 16  # DFL channels (ch[0] // 16 to scale 4/8/12/16/20 for n/s/m/l/x)\n        self.no = nc + self.reg_max * 4  # number of outputs per anchor   6+16*4=70\n        self.stride = torch.zeros(self.nl)  # strides computed during build\n        c2, c3 = max((16, ch[0] // 4, self.reg_max * 4)), max(ch[0], min(self.nc, 100))  # channels     64,128\n        self.cv2 = nn.ModuleList(nn.Sequential(Conv(x, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch)  # 通道变为16\n        self.cv3 = nn.ModuleList(nn.Sequential(Conv(x, c3, 3), Conv(c3, c3, 3), nn.Conv2d(c3, self.nc, 1)) for x in ch)           # 通道变为类别6\n        self.dfl = DFL(self.reg_max) if self.reg_max > 1 else nn.Identity()\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/block.py</p><span class=\'hidden-code\' data-code=\'class DFL(nn.Module):\n    def __init__(self, c1=16):    # Initialize a convolutional layer with a given number of input channels\n        super().__init__()\n        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n        x = torch.arange(c1, dtype=torch.float)           # tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.])\n        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))   # (1,16,1,1)\n        self.c1 = c1              # 16\n\'> </span>'}]}]}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def load(self, weights: Union[str, Path] = &amp;#39;yolov8n.pt&amp;#39;) -> &amp;#39;Model&amp;#39;:\n        self._check_is_pytorch_model()\n        if isinstance(weights, (str, Path)):\n            weights, self.ckpt = attempt_load_one_weight(weights)    # &amp;#39;yolov10s.pt&amp;#39;\n        self.model.load(weights)\n        return self\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def train(self, trainer=None, **kwargs):\n        self._check_is_pytorch_model()\n        if hasattr(self.session, &amp;#39;model&amp;#39;) and self.session.model.id:  # Ultralytics HUB session with loaded model\n            if any(kwargs):\n                LOGGER.warning(&amp;#39;WARNING ⚠️ using HUB training arguments, ignoring local training arguments.&amp;#39;)\n            kwargs = self.session.train_args                          # overwrite kwargs\n        checks.check_pip_update_available()\n        overrides = yaml_load(checks.check_yaml(kwargs[&amp;#39;cfg&amp;#39;])) if kwargs.get(&amp;#39;cfg&amp;#39;) else self.overrides  # {&amp;#39;model&amp;#39;: &amp;#39;ultralytics/....../v10/yolov10s.yaml&amp;#39;, &amp;#39;task&amp;#39;: &amp;#39;detect&amp;#39;}\n        custom = {&amp;#39;data&amp;#39;: DEFAULT_CFG_DICT[&amp;#39;data&amp;#39;] or TASK2DATA[self.task]}  # method defaults  从默认的ultralytics/utils/__init__.py里面的DEFAULT_CFG_PATH=ultralytics/cfg/default.yaml--{&amp;#39;data&amp;#39;: &amp;#39;coco8.yaml&amp;#39;}\n        args = {**overrides, **custom, **kwargs, &amp;#39;mode&amp;#39;: &amp;#39;train&amp;#39;}            # highest priority args on the right\n        if args.get(&amp;#39;resume&amp;#39;):\n            args[&amp;#39;resume&amp;#39;] = self.ckpt_path\n        self.trainer = (trainer or self.`_smart_load`(&amp;#39;trainer&amp;#39;))(overrides=args, _callbacks=self.callbacks)   # ultralytics.models.yolov10.train.YOLOv10DetectionTrainer\n        if not args.get(&amp;#39;resume&amp;#39;):                                    # manually set model only if not resuming\n            self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)\n            self.model = self.trainer.model\n            ......\n        self.trainer.hub_session = self.session                       # attach optional HUB session\n        self.trainer.`train`()\n        if RANK in (-1, 0):                                           # Update model and cfg after training\n            ckpt = self.trainer.best if self.trainer.best.exists() else self.trainer.last\n            self.model, _ = attempt_load_one_weight(ckpt)\n            self.overrides = self.model.args\n            self.metrics = getattr(self.trainer.validator, &amp;#39;metrics&amp;#39;, None)  # TODO: no metrics returned by DDP\n        return self.metrics\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolov10/train.py</p><span class=\'hidden-code\' data-code=\'class YOLOv10DetectionTrainer(DetectionTrainer):\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/train.py</p><span class=\'hidden-code\' data-code=\'class DetectionTrainer(BaseTrainer):\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><span class=\'hidden-code\' data-code=\'class BaseTrainer:\n    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):\n        self.args = get_cfg(cfg, overrides)\n        self.check_resume(overrides)\n        self.device = select_device(self.args.device, self.args.batch)    # device(type=&amp;#39;cuda&amp;#39;, index=0)\n        self.validator = None\n        self.metrics = None\n        self.plots = {}\n        init_seeds(self.args.seed + 1 + RANK, deterministic=self.args.deterministic)\n        # Dirs\n        self.save_dir = get_save_dir(self.args)                 # PosixPath(&amp;#39;/sdb/zzhu/code_study/yolov10/runs/detect/train_v103&amp;#39;)\n        self.args.name = self.save_dir.name                     # update name for loggers   &amp;#39;train_v103&amp;#39;\n        self.wdir = self.save_dir / &amp;#39;weights&amp;#39;                   # weights dir\n        if RANK in (-1, 0):\n            self.wdir.mkdir(parents=True, exist_ok=True)        # make dir\n            self.args.save_dir = str(self.save_dir)\n            yaml_save(self.save_dir / &amp;#39;args.yaml&amp;#39;, vars(self.args))          # save run args\n        self.last, self.best = self.wdir / &amp;#39;last.pt&amp;#39;, self.wdir / &amp;#39;best.pt&amp;#39;  # checkpoint paths\n        self.save_period = self.args.save_period                # -1\n        self.batch_size = self.args.batch                       # 4\n        self.epochs = self.args.epochs\n        self.start_epoch = 0\n        if RANK == -1:\n            print_args(vars(self.args))\n        # Device\n        if self.device.type in (&amp;#39;cpu&amp;#39;, &amp;#39;mps&amp;#39;):\n            self.args.workers = 0  # faster CPU training as time dominated by inference, not dataloading\n        # Model and Dataset\n        self.model = check_model_file_from_stem(self.args.model)  # add suffix, i.e. yolov8n -> yolov8n.pt  &amp;#39;ultralytics/cfg/models/v10/yolov10s.yaml&amp;#39;\n        try:\n            if self.args.task == &amp;#39;classify&amp;#39;:\n                self.data = check_cls_dataset(self.args.data)\n            elif self.args.data.split(&amp;#39;.&amp;#39;)[-1] in (&amp;#39;yaml&amp;#39;, &amp;#39;yml&amp;#39;) or self.args.task in (&amp;#39;detect&amp;#39;,&amp;#39;segment&amp;#39;,&amp;#39;pose&amp;#39;,&amp;#39;obb&amp;#39;):\n                self.data = check_det_dataset(self.args.data)\n                if &amp;#39;yaml_file&amp;#39; in self.data:\n                    self.args.data = self.data[&amp;#39;yaml_file&amp;#39;]  # for validating &amp;#39;yolo train data=url.zip&amp;#39; usage\n        except Exception as e:\n            raise RuntimeError(emojis(f&amp;#39;Dataset &amp;#39;{clean_url(self.args.data)}&amp;#39; error ❌ {e}&amp;#39;)) from e\n        # &amp;#39;/sdb/.../img_2d/images/train2017&amp;#39;, &amp;#39;/sdb/.../img_2d/images/val2017&amp;#39;\n        self.trainset, self.testset = self.get_dataset(self.data)    # &amp;#39;/sdb/zzhu/code_study/yolov10/datasets/side_all/images/train2017&amp;#39;\n        self.ema = None\n        # Optimization utils init\n        self.lf = None\n        self.scheduler = None\n        # Epoch level metrics\n        self.best_fitness = None\n        self.fitness = None\n        self.loss = None\n        self.tloss = None\n        self.loss_names = [&amp;#39;Loss&amp;#39;]\n        self.csv = self.save_dir / &amp;#39;results.csv&amp;#39;\n        self.plot_idx = [0, 1, 2]\n        # Callbacks\n        self.callbacks = _callbacks or callbacks.get_default_callbacks()      # `<`defaultdict, len() = 25`>`\n        if RANK in (-1, 0):\n            callbacks.add_integration_callbacks(self)\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><span class=\'hidden-code\' data-code=\'class BaseTrainer:\n    def train(self):\n        if world_size > 1 and &amp;#39;LOCAL_RANK&amp;#39; not in os.environ:\n            ......\n        else:\n            self.`_do_train`(world_size)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><span class=\'hidden-code\' data-code=\'class BaseTrainer:\n    def _do_train(self, world_size=1):\n        self.`_setup_train`(world_size)\n        nb = len(self.train_loader)                           # number of batches   250\n        nw = max(round(self.args.warmup_epochs * nb), 100) if self.args.warmup_epochs > 0 else -1  # warmup iterations  max(3*250,100)=750\n        last_opt_step = -1\n        self.epoch_time = None\n        self.epoch_time_start = time.time()\n        self.train_time_start = time.time()\n        self.run_callbacks(&amp;#39;on_train_start&amp;#39;)\n        if self.args.close_mosaic:\n            base_idx = (self.epochs - self.args.close_mosaic) * nb    # (150-10)*250\n            self.plot_idx.extend([base_idx, base_idx + 1, base_idx + 2])\n        epoch = self.start_epoch                           # 0\n        while True:\n            self.epoch = epoch\n            self.run_callbacks(&amp;#39;on_train_epoch_start&amp;#39;)\n            self.model.train()\n            if RANK != -1:\n                self.train_loader.sampler.set_epoch(epoch)\n            pbar = enumerate(self.train_loader)\n            # Update dataloader attributes (optional)\n            if epoch == (self.epochs - self.args.close_mosaic):         # 关掉mosaic\n                self._close_dataloader_mosaic()\n                self.train_loader.reset()\n            if RANK in (-1, 0):\n                LOGGER.info(self.progress_string())\n                pbar = TQDM(enumerate(self.train_loader), total=nb)\n            self.tloss = None\n            self.optimizer.zero_grad()\n            for i, batch in pbar:\n                self.run_callbacks(&amp;#39;on_train_batch_start&amp;#39;)\n                # Warmup\n                ni = i + nb * epoch\n                if ni <= nw:\n                    xi = [0, nw]                                        # x interp\n                    self.accumulate = max(1, int(np.interp(ni, xi, [1, self.args.nbs / self.batch_size]).round()))\n                    for j, x in enumerate(self.optimizer.param_groups):\n                        # Bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n                        x[&amp;#39;lr&amp;#39;] = np.interp(ni, xi, [self.args.warmup_bias_lr if j == 0 else 0.0, x[&amp;#39;initial_lr&amp;#39;] * self.lf(epoch)])\n                        if &amp;#39;momentum&amp;#39; in x:\n                            x[&amp;#39;momentum&amp;#39;] = np.interp(ni, xi, [self.args.warmup_momentum, self.args.momentum])\n                # Forward\n                with torch.cuda.amp.autocast(self.amp):\n                    batch = self.preprocess_batch(batch)        # {&amp;#39;im_file&amp;#39;:[,,,], &amp;#39;ori_shape&amp;#39;:[[1080, 1920],...], &amp;#39;resized_shape&amp;#39;:[[640, 640],...], &amp;#39;img&amp;#39;:torch.Size([4, 3, 640, 640]), &amp;#39;cls&amp;#39;:, &amp;#39;bboxes&amp;#39;:, &amp;#39;batch_idx&amp;#39;:}\n                    self.loss, self.loss_items = self.`model`(batch)\n                    if RANK != -1:\n                        self.loss *= world_size\n                    self.tloss = ((self.tloss * i + self.loss_items) / (i + 1) if self.tloss is not None else self.loss_items)\n                # Backward\n                self.scaler.scale(self.loss).backward()\n                # Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\n                if ni - last_opt_step >= self.accumulate:\n                    self.optimizer_step()\n                    last_opt_step = ni\n                    # Timed stopping\n                    if self.args.time:\n                        self.stop = (time.time() - self.train_time_start) > (self.args.time * 3600)\n                        if RANK != -1:  # if DDP training\n                            broadcast_list = [self.stop if RANK == 0 else None]\n                            dist.broadcast_object_list(broadcast_list, 0)  # broadcast &amp;#39;stop&amp;#39; to all ranks\n                            self.stop = broadcast_list[0]\n                        if self.stop:  # training time exceeded\n                            break\n                # Log\n                mem = f&amp;#39;{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}G&amp;#39;  # (GB)\n                loss_len = self.tloss.shape[0] if len(self.tloss.shape) else 1\n                losses = self.tloss if loss_len > 1 else torch.unsqueeze(self.tloss, 0)\n                if RANK in (-1, 0):\n                    pbar.set_description((&amp;#39;%11s&amp;#39; * 2 + &amp;#39;%11.4g&amp;#39; * (2 + loss_len))% (f&amp;#39;{epoch + 1}/{self.epochs}&amp;#39;, mem, *losses, batch[&amp;#39;cls&amp;#39;].shape[0], batch[&amp;#39;img&amp;#39;].shape[-1]))\n                    self.run_callbacks(&amp;#39;on_batch_end&amp;#39;)\n                    if self.args.plots and ni in self.plot_idx:\n                        self.plot_training_samples(batch, ni)\n                self.run_callbacks(&amp;#39;on_train_batch_end&amp;#39;)\n            self.lr = {f&amp;#39;lr/pg{ir}&amp;#39;: x[&amp;#39;lr&amp;#39;] for ir, x in enumerate(self.optimizer.param_groups)}  # for loggers\n            self.run_callbacks(&amp;#39;on_train_epoch_end&amp;#39;)\n            if RANK in (-1, 0):\n                final_epoch = epoch + 1 == self.epochs\n                self.ema.update_attr(self.model, include=[&amp;#39;yaml&amp;#39;, &amp;#39;nc&amp;#39;, &amp;#39;args&amp;#39;, &amp;#39;names&amp;#39;, &amp;#39;stride&amp;#39;, &amp;#39;class_weights&amp;#39;])\n                # Validation\n                if (self.args.val and (((epoch+1) % self.args.val_period == 0) or (self.epochs - epoch) <= 10)) or final_epoch or self.stopper.possible_stop or self.stop:\n                    self.metrics, self.fitness = self.validate()\n                self.save_metrics(metrics={**self.label_loss_items(self.tloss), **self.metrics, **self.lr})\n                self.stop |= self.stopper(epoch + 1, self.fitness) or final_epoch\n                if self.args.time:\n                    self.stop |= (time.time() - self.train_time_start) > (self.args.time * 3600)\n                # Save model\n                if self.args.save or final_epoch:\n                    self.save_model()\n                    self.run_callbacks(&amp;#39;on_model_save&amp;#39;)\n            # Scheduler\n            t = time.time()\n            self.epoch_time = t - self.epoch_time_start\n            self.epoch_time_start = t\n            with warnings.catch_warnings():\n                warnings.simplefilter(&amp;#39;ignore&amp;#39;)  # suppress &amp;#39;Detected lr_scheduler.step() before optimizer.step()&amp;#39;\n                if self.args.time:\n                    mean_epoch_time = (t - self.train_time_start) / (epoch - self.start_epoch + 1)\n                    self.epochs = self.args.epochs = math.ceil(self.args.time * 3600 / mean_epoch_time)\n                    self._setup_scheduler()\n                    self.scheduler.last_epoch = self.epoch  # do not move\n                    self.stop |= epoch >= self.epochs  # stop if exceeded epochs\n                self.scheduler.step()\n            self.run_callbacks(&amp;#39;on_fit_epoch_end&amp;#39;)\n            torch.cuda.empty_cache()  # clear GPU memory at end of epoch, may help reduce CUDA out of memory errors\n            # Early Stopping\n            if RANK != -1:  # if DDP training\n                broadcast_list = [self.stop if RANK == 0 else None]\n                dist.broadcast_object_list(broadcast_list, 0)  # broadcast &amp;#39;stop&amp;#39; to all ranks\n                self.stop = broadcast_list[0]\n            if self.stop:\n                break  # must break all DDP ranks\n            epoch += 1\n        if RANK in (-1, 0):\n            # Do final val with best.pt\n            LOGGER.info(f&amp;#39;\\n{epoch - self.start_epoch + 1} epochs completed in {(time.time() - self.train_time_start) / 3600:.3f} hours.&amp;#39;)\n            self.final_eval()\n            if self.args.plots:\n                self.plot_metrics()\n            self.run_callbacks(&amp;#39;on_train_end&amp;#39;)\n        torch.cuda.empty_cache()\n        self.run_callbacks(&amp;#39;teardown&amp;#39;)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><span class=\'hidden-code\' data-code=\'class BaseTrainer:\n    def _setup_train(self, world_size):              # Builds dataloaders and optimizer on correct rank process.\n        # Model\n        self.run_callbacks(&amp;#39;on_pretrain_routine_start&amp;#39;)\n        ckpt = self.setup_model()                    # None\n        self.model = self.model.to(self.device)      # YOLOv10DetectionModel\n        self.set_model_attributes()\n        # Freeze layers\n        freeze_list = (self.args.freeze if isinstance(self.args.freeze, list) else range(self.args.freeze) if isinstance(self.args.freeze, int) else []) # []\n        always_freeze_names = [&amp;#39;.dfl&amp;#39;]                                                       # always freeze these layers\n        freeze_layer_names = [f&amp;#39;model.{x}.&amp;#39; for x in freeze_list] + always_freeze_names      # [&amp;#39;.dfl&amp;#39;]\n        for k, v in self.model.named_parameters():  # v.register_hook(lambda x: torch.nan_to_num(x))  # NaN to 0 (commented for erratic training results)\n            if any(x in k for x in freeze_layer_names):\n                LOGGER.info(f&amp;#39;Freezing layer &amp;#39;{k}&amp;#39;&amp;#39;)\n                v.requires_grad = False\n            elif not v.requires_grad and v.dtype.is_floating_point:  # only floating point Tensor can require gradients\n                LOGGER.info(f&amp;#39;WARNING ⚠️ setting &amp;#39;requires_grad=True&amp;#39; for frozen layer &amp;#39;{k}&amp;#39;. See ultralytics.engine.trainer for customization of frozen layers.&amp;#39;)\n                v.requires_grad = True\n        # Check AMP\n        self.amp = torch.tensor(self.args.amp).to(self.device)     # True or False  # True\n        if self.amp and RANK in (-1, 0):  # Single-GPU and DDP\n            callbacks_backup = callbacks.default_callbacks.copy()  # backup callbacks as check_amp() resets them\n            self.amp = torch.tensor(check_amp(self.model), device=self.device)      # tensor(True, device=&amp;#39;cuda:0&amp;#39;)\n            callbacks.default_callbacks = callbacks_backup  # restore callbacks\n        if RANK > -1 and world_size > 1:  # DDP\n            dist.broadcast(self.amp, src=0)  # broadcast the tensor from rank 0 to all other ranks (returns None)\n        self.amp = bool(self.amp)         # as boolean  ---- True\n        self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)                   # `<`torch.cuda.amp.grad_scaler.GradScaler object at 0x7f04c80d6520`>`\n        if world_size > 1:\n            self.model = nn.parallel.DistributedDataParallel(self.model, device_ids=[RANK])\n        # Check imgsz\n        gs = max(int(self.model.stride.max() if hasattr(self.model, &amp;#39;stride&amp;#39;) else 32), 32)  # grid size (max stride)   32\n        self.args.imgsz = check_imgsz(self.args.imgsz, stride=gs, floor=gs, max_dim=1)       # 640\n        self.stride = gs  # for multiscale training     32\n        # Batch size\n        if self.batch_size == -1 and RANK == -1:  # single-GPU only, estimate best batch size\n            self.args.batch = self.batch_size = check_train_batch_size(self.model, self.args.imgsz, self.amp)\n        # Dataloaders\n        batch_size = self.batch_size // max(world_size, 1)    # 4//1=4\n        self.train_loader = self.`get_dataloader`(self.trainset, batch_size=batch_size, rank=RANK, mode=&amp;#39;train&amp;#39;)\n        if RANK in (-1, 0):                       # Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\n            self.test_loader = self.get_dataloader(self.testset, batch_size=batch_size if self.args.task == &amp;#39;obb&amp;#39; else batch_size * 2, rank=-1, mode=&amp;#39;val&amp;#39;)\n            self.validator = self.get_validator()             # ultralytics.models.yolov10.val.YOLOv10DetectionValidator\n            metric_keys = self.validator.metrics.keys + self.label_loss_items(prefix=&amp;#39;val&amp;#39;)\n            self.metrics = dict(zip(metric_keys, [0] * len(metric_keys)))\n            self.ema = ModelEMA(self.model)\n            if self.args.plots:\n                self.plot_training_labels()\n        # Optimizer\n        self.accumulate = max(round(self.args.nbs / self.batch_size), 1)                           # accumulate loss before optimizing  16=max(64/4,1)\n        weight_decay = self.args.weight_decay * self.batch_size * self.accumulate / self.args.nbs  # scale weight_decay 0.0005*4*16/64 = 0.0005\n        iterations = math.ceil(len(self.train_loader.dataset) / max(self.batch_size, self.args.nbs)) * self.epochs    # 1000/max(4,64)*150=2400\n        self.optimizer = self.build_optimizer(model=self.model,name=self.args.optimizer,lr=self.args.lr0,momentum=self.args.momentum,decay=weight_decay,iterations=iterations)\n        # Scheduler\n        self._setup_scheduler()\n        self.stopper, self.stop = EarlyStopping(patience=self.args.patience), False  # self.args.patience=100\n        self.resume_training(ckpt)                        # None\n        self.scheduler.last_epoch = self.start_epoch - 1  # do not move\n        self.run_callbacks(&amp;#39;on_pretrain_routine_end&amp;#39;)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/train.py</p><span class=\'hidden-code\' data-code=\'class DetectionTrainer(BaseTrainer):\n    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode=&amp;#39;train&amp;#39;):          # Construct and return dataloader\n        assert mode in [&amp;#39;train&amp;#39;, &amp;#39;val&amp;#39;]\n        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP\n            dataset = self.`build_dataset`(dataset_path, mode, batch_size)\n        shuffle = mode == &amp;#39;train&amp;#39;\n        if getattr(dataset, &amp;#39;rect&amp;#39;, False) and shuffle:\n            LOGGER.warning(&amp;#39;WARNING ⚠️ &amp;#39;rect=True&amp;#39; is incompatible with DataLoader shuffle, setting shuffle=False&amp;#39;)\n            shuffle = False\n        workers = self.args.workers if mode == &amp;#39;train&amp;#39; else self.args.workers * 2\n        return `build_dataloader`(dataset, batch_size, workers, shuffle, rank)  # return dataloader\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/train.py</p><span class=\'hidden-code\' data-code=\'class DetectionTrainer(BaseTrainer):\n    def build_dataset(self, img_path, mode=&amp;#39;train&amp;#39;, batch=None):\n        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)     # 32\n        return `build_yolo_dataset`(self.args, img_path, batch, self.data, mode=mode, rect=mode == &amp;#39;val&amp;#39;, stride=gs)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><span class=\'hidden-code\' data-code=\'def build_yolo_dataset(cfg, img_path, batch, data, mode=&amp;#39;train&amp;#39;, rect=False, stride=32):\n    save_path=&amp;#39;/sdb/zzhu/code_study/yolov10/build_yolo_dataset.npy&amp;#39;\n    if not os.path.exists(save_path):\n        a = {&amp;#39;cfg&amp;#39;:cfg, &amp;#39;img_path&amp;#39;:img_path, &amp;#39;batch&amp;#39;:batch, &amp;#39;data&amp;#39;:data, &amp;#39;mode&amp;#39;:mode, &amp;#39;rect&amp;#39;:rect, &amp;#39;stride&amp;#39;:stride}\n        np.save(save_path,a)\n    return `YOLODataset`(\n        img_path=img_path,        # &amp;#39;/sdb/zzhu/data/data_fisheye_all/img_2d/images/train2017&amp;#39;\n        imgsz=cfg.imgsz,          # 960\n        batch_size=batch,         # 4\n        augment=mode == &amp;#39;train&amp;#39;,  # augmentation         True\n        hyp=cfg,                  # TODO: probably add a get_hyps_from_cfg function\n        rect=cfg.rect or rect,    # rectangular batches  False or False\n        cache=cfg.cache or None,               # False\n        single_cls=cfg.single_cls or False,    # False\n        stride=int(stride),                    # 32\n        pad=0.0 if mode == &amp;#39;train&amp;#39; else 0.5,\n        prefix=colorstr(f&amp;#39;{mode}: &amp;#39;),\n        task=cfg.task,            # &amp;#39;detect&amp;#39;\n        classes=cfg.classes,      # None\n        data=data,\n        fraction=cfg.fraction if mode == &amp;#39;train&amp;#39; else 1.0,   # 1\n    )\n\'> </span>'}]}, {'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><span class=\'hidden-code\' data-code=\'def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):\n    &amp;#39;&amp;#39;&amp;#39;Return an InfiniteDataLoader or DataLoader for training or validation set.&amp;#39;&amp;#39;&amp;#39;\n    batch = min(batch, len(dataset))\n    nd = torch.cuda.device_count()  # number of CUDA devices\n    nw = min([os.cpu_count() // max(nd, 1), workers])  # number of workers\n    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)\n    generator = torch.Generator()\n    generator.manual_seed(6148914691236517205 + RANK)\n    return InfiniteDataLoader(dataset=dataset,batch_size=batch,shuffle=shuffle and sampler is None,\n        num_workers=nw,sampler=sampler,pin_memory=PIN_MEMORY,collate_fn=getattr(dataset, &amp;#39;collate_fn&amp;#39;, None),\n        worker_init_fn=seed_worker,generator=generator)\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><span class=\'hidden-code\' data-code=\'YOLOv10DetectionModel-->DetectionModel\nclass BaseModel(nn.Module):\n    def forward(self, x, *args, **kwargs):\n        if isinstance(x, dict):  # for cases of training and validating while training.\n            return self.`loss`(x, *args, **kwargs)\n        return self.predict(x, *args, **kwargs)\n    def loss(self, batch, preds=None):\n        if not hasattr(self, &amp;#39;criterion&amp;#39;):\n            self.criterion = self.`init_criterion`()\n        preds = self.`forward`(batch[&amp;#39;img&amp;#39;]) if preds is None else preds\n        return self.`criterion`(preds, batch)    # `<`ultralytics.utils.loss.v10DetectLoss object at 0x7f04c01985e0`>`\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><span class=\'hidden-code\' data-code=\'class BaseModel(nn.Module):\n    def forward(self, x, *args, **kwargs):\n        if isinstance(x, dict):  # for cases of training and validating while training.\n            return self.loss(x, *args, **kwargs)\n        return self.`predict`(x, *args, **kwargs)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><span class=\'hidden-code\' data-code=\'class BaseModel(nn.Module):\n    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):\n        if augment:\n            return self._predict_augment(x)\n        return self.`_predict_once`(x, profile, visualize, embed)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><span class=\'hidden-code\' data-code=\'def _predict_once(self, x, profile=False, visualize=False, embed=None):\n    y, dt, embeddings = [], [], []  # outputs\n    for m in self.model:\n        if m.f != -1:  # if not from previous layer\n            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n        if profile:\n            self._profile_one_layer(m, x, dt)\n        x = m(x)  # run\n        y.append(x if m.i in self.save else None)  # save output\n        if visualize:\n            feature_visualization(x, m.type, m.i, save_dir=visualize)\n        if embed and m.i in embed:\n            embeddings.append(nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1))  # flatten\n            if m.i == max(embed):\n                return torch.unbind(torch.cat(embeddings, 1), dim=0)    # 类别6，4+1+6\n    return x     # {&amp;#39;one2many&amp;#39;:[torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]],&amp;#39;one2one&amp;#39;:[torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]]}\n\'> </span>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class v10Detect(Detect):       # self.one2one_cv2=copy.deepcopy(self.cv2) / self.one2one_cv3=copy.deepcopy(self.cv3)\n    def forward(self, x):      # [torch.Size([4, 128, 80, 80]),[4, 256, 40, 40],[4, 512, 20, 20]] \n        one2one = self.`forward_feat`([xi.detach() for xi in x], self.one2one_cv2, self.one2one_cv3)   # Tensor与原始Tensor共享数据但不需要梯度计算。\n        if not self.export:    # 训练走\n            one2many = super().`forward`(x)\n        if not self.training:           # 训练是不走\n            one2one = self.inference(one2one)\n            if not self.export:\n                return {&amp;#39;one2many&amp;#39;: one2many, &amp;#39;one2one&amp;#39;: one2one}\n            else:\n                assert(self.max_det != -1)\n                boxes, scores, labels = ops.v10postprocess(one2one.permute(0, 2, 1), self.max_det, self.nc)\n                return torch.cat([boxes, scores.unsqueeze(-1), labels.unsqueeze(-1).to(boxes.dtype)], dim=-1)\n        else:\n            return {&amp;#39;one2many&amp;#39;: one2many, &amp;#39;one2one&amp;#39;: one2one}\n\'> </span>', 'children': [{'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class Detect(nn.Module):\n    def forward_feat(self, x, cv2, cv3):\n        y = []\n        for i in range(self.nl):   # 3\n            y.append(torch.cat((cv2[i](x[i]), cv3[i](x[i])), 1))\n        return y                   # [torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]]\n\'> </span>'}, {'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class Detect(nn.Module):\n    def forward(self, x):\n        y = self.forward_feat(x, self.cv2, self.cv3)\n        if self.training:\n            return y               # [torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]]\n        return self.inference(y)\n\'> </span>'}]}]}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><span class=\'hidden-code\' data-code=\'class v10DetectLoss:\n    def __init__(self, model):\n        self.one2many = v8DetectionLoss(model, tal_topk=10)\n        self.one2one = v8DetectionLoss(model, tal_topk=1)\n    \n    def __call__(self, preds, batch):\n        one2many = preds[&amp;#39;one2many&amp;#39;]                          # torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]\n        loss_one2many = self.`one2many`(one2many, batch)      # (tensor(31.1620),tensor([1.4539, 5.2442, 1.0923]))\n        one2one = preds[&amp;#39;one2one&amp;#39;]                            # torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]\n        loss_one2one = self.`one2one`(one2one, batch)         # (tensor(44.8558),tensor([1.8921, 8.2079, 1.1140]))\n        return loss_one2many[0] + loss_one2one[0], torch.cat((loss_one2many[1], loss_one2one[1]))\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><span class=\'hidden-code\' data-code=\'class v8DetectionLoss:\n    def __call__(self, preds, batch):                  # Calculate the sum of the loss for box, cls and dfl multiplied by batch size\n        loss = torch.zeros(3, device=self.device)  # box, cls, dfl\n        feats = preds[1] if isinstance(preds, tuple) else preds\n        # torch.Size([4, 70, 8400])-->70=4*16+6   --->   torch.Size([4, 64, 8400])+torch.Size([4, 6, 8400])\n        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split((self.reg_max * 4, self.nc), 1)\n        pred_scores = pred_scores.permute(0, 2, 1).contiguous()   # torch.Size([4, 8400, 6])\n        pred_distri = pred_distri.permute(0, 2, 1).contiguous()   # torch.Size([4, 8400, 64])\n        dtype = pred_scores.dtype\n        batch_size = pred_scores.shape[0]\n        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)  tensor([640., 640.])\n        anchor_points, stride_tensor = `make_anchors`(feats, self.stride, 0.5)                      # torch.Size([8400, 2])   torch.Size([8400, 1])\n        # Targets\n        targets = torch.cat((batch[&amp;#39;batch_idx&amp;#39;].view(-1, 1), batch[&amp;#39;cls&amp;#39;].view(-1, 1), batch[&amp;#39;bboxes&amp;#39;]), 1)  # torch.Size([63, 6]) 6=1+1+4,batch_id,cls,bbox,\n        targets = self.`preprocess`(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n        gt_labels, gt_bboxes = targets.split((1, 4), 2)             # cls, xyxy   torch.Size([4, 20, 1])  torch.Size([4, 20, 4])\n        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)             # torch.Size([4, 20, 1]) 是gt的话为1，否则为0\n        # Pboxes\n        pred_bboxes = self.`bbox_decode`(anchor_points, pred_distri)  # xyxy, (b, h*w, 4)  torch.Size([4, 8400, 4])\n        _, target_bboxes, target_scores, fg_mask, _ = self.`assigner`(\n            pred_scores.detach().sigmoid(),                                     # torch.Size([4, 8400, 6])  到-1之间  6为类别数量\n            (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),       # 乘以下采样倍数对应原图像   torch.Size([4, 8400, 4])\n            anchor_points * stride_tensor,                                      # torch.Size([8400, 2]) 对应输入图片上的点\n            gt_labels,                                                          # torch.Size([4, 20, 1])  4个图片，某个图片的框最多为20\n            gt_bboxes,                                                          # torch.Size([4, 20, 4])\n            mask_gt,                                                            # torch.Size([4, 20, 1])\n        )\n        target_scores_sum = max(target_scores.sum(), 1)                         # torch.Size([4, 8400, 6]) -> tensor(103.7702, device=&amp;#39;cuda:0&amp;#39;)\n        # Cls loss          self.bce(pred_scores, target_scores.to(dtype)).shape--->(4, 8400, 6)\n        # loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\n        loss[1] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum  # BCEWithLogitsLoss()  torch.Size([4, 8400, 6])-\n        # Bbox loss\n        if fg_mask.sum():                           # torch.Size([4, 8400])  -->True or False \n            target_bboxes /= stride_tensor          # torch.Size([4, 8400, 4])在对应的feature map上面计算\n            loss[0], loss[2] = self.`bbox_loss`(pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask)\n        loss[0] *= self.hyp.box  # box gain\n        loss[1] *= self.hyp.cls  # cls gain\n        loss[2] *= self.hyp.dfl  # dfl gain\n        return loss.sum() * batch_size, loss.detach()  # loss(box, cls, dfl)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'def make_anchors(feats, strides, grid_cell_offset=0.5):     # Generate anchors from features  strides-->[ 8., 16., 32.]\n    anchor_points, stride_tensor = [], []\n    assert feats is not None                                # feats->([4, 70, 80, 80],[4, 70, 40, 40],[4, 70, 20, 20])  \n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape    # (80,80)\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x   torch.Size([80]) -(0.5->79.5)\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx, indexing=&amp;#39;ij&amp;#39;) if TORCH_1_10 else torch.meshgrid(sy, sx)\n        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))              # torch.Size([6400, 2])  tensor([[0.5000, 0.5000], [1.5000, 0.5000], [2.5000, 0.5000]])\n        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n    return torch.cat(anchor_points), torch.cat(stride_tensor)\n\'> </span>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><span class=\'hidden-code\' data-code=\'class v8DetectionLoss:\n    def preprocess(self, targets, batch_size, scale_tensor):  # Preprocesses the target counts and matches with the input batch size to output a tensor\n        if targets.shape[0] == 0:\n            out = torch.zeros(batch_size, 0, 5, device=self.device)\n        else:\n            i = targets[:, 0]                         # image index\n            _, counts = i.unique(return_counts=True)  # tensor([16,  7, 20, 20])  属于第一张图片有16个box，第二张图片7个box\n            counts = counts.to(dtype=torch.int32)\n            out = torch.zeros(batch_size, counts.max(), 5, device=self.device)\n            for j in range(batch_size):\n                matches = i == j\n                n = matches.sum()\n                if n:\n                    out[j, :n] = targets[matches, 1:]\n            out[..., 1:5] = xywh2xyxy(out[..., 1:5].mul_(scale_tensor))         # 恢复到输入到神经网络的图片大小--x1,y1,x2,y2\n        return out\n\'> </span>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><span class=\'hidden-code\' data-code=\'class v8DetectionLoss:\n    def bbox_decode(self, anchor_points, pred_dist):      # Decode predicted object bounding box coordinates from anchor points and distribution\n        if self.use_dfl:\n            b, a, c = pred_dist.shape                     # torch.Size([4, 8400, 64])  batch, anchors, channels   self.proj范围0-15  15*(0-1的数)+14*(0-1的数)+...+0*(0-1的数)\n            pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))    # 也就是  torch.Size([4, 8400, 4, 16])\n            # pred_dist = pred_dist.view(b, a, c // 4, 4).transpose(2,3).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n            # pred_dist = (pred_dist.view(b, a, c // 4, 4).softmax(2) * self.proj.type(pred_dist.dtype).view(1, 1, -1, 1)).sum(2)\n        return `dist2bbox`(pred_dist, anchor_points, xywh=False)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'def dist2bbox(distance, anchor_points, xywh=True, dim=-1):     # Transform distance(ltrb) to box(xywh or xyxy)\n    assert(distance.shape[dim] == 4)               # torch.Size([4, 8400, 4])  + torch.Size([8400, 2])\n    lt, rb = distance.split([2, 2], dim)           # torch.Size([4, 8400, 2])  torch.Size([4, 8400, 2])\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)         # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)           # xyxy bbox\n\'> </span>'}]}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    @torch.no_grad()             # 在输入模型图片上的尺度上操作  \n    def forward(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt):\n        self.bs = pd_scores.shape[0]                # 4\n        self.n_max_boxes = gt_bboxes.shape[1]       # 20\n        if self.n_max_boxes == 0:\n            device = gt_bboxes.device\n            return ......                                # [4, 8400, 6],[4, 8400, 4],[4, 20, 1],[4, 20, 4],[8400, 2],[4, 20, 1]\n        mask_pos, align_metric, overlaps = self.`get_pos_mask`(pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt)  # (4, 20, 8400)匹配上为1=点在box里面+iou达标+box在里面，[4, 20, 8400]-分数+iou计算得到的值，(4,20,8400)-iou值\n        target_gt_idx, fg_mask, mask_pos = self.`select_highest_overlaps`(mask_pos, overlaps, self.n_max_boxes)\n        # Assigned target   输入[4, 20, 1]->4个图片，某个图片的框最多为20; torch.Size([4, 20, 4]); [4, 8400]-该anchor最大的gt索引; [4, 8400]-该anchor有多少个gt进行匹配\n        target_labels, target_bboxes, target_scores = self.`get_targets`(gt_labels, gt_bboxes, target_gt_idx, fg_mask) # torch.Size([4, 8400]), torch.Size([4, 8400, 4]), torch.Size([4, 8400, 6])\n        # Normalize\n        align_metric *= mask_pos                                           # torch.Size([4, 20, 8400])\n        pos_align_metrics = align_metric.amax(dim=-1, keepdim=True)        # b, max_num_obj   torch.Size([4, 20, 1])\n        pos_overlaps = (overlaps * mask_pos).amax(dim=-1, keepdim=True)    # b, max_num_obj   torch.Size([4, 20, 1])\n        norm_align_metric = (align_metric * pos_overlaps / (pos_align_metrics + self.eps)).amax(-2).unsqueeze(-1)   # torch.Size([4, 20, 8400])/torch.Size([4, 20, 1])-->torch.Size([4, 8400, 1])\n        target_scores = target_scores * norm_align_metric\n        return target_labels, target_bboxes, target_scores, fg_mask.bool(), target_gt_idx  # [4, 8400],[4, 8400, 4],[4, 8400, 6],[4, 8400],[4, 8400]\n\'> </span>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    def get_pos_mask(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt):         # Get in_gts mask, (b, max_num_obj, h*w)\n        mask_in_gts = self.`select_candidates_in_gts`(anc_points, gt_bboxes)                         # 得到torch.Size([4, 20, 8400])\n        # Get anchor_align metric, (b, max_num_obj, h*w)\n        align_metric, overlaps = self.`get_box_metrics`(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n        # Get topk_metric mask, (b, max_num_obj, h*w)           topk_mask: [4, 20, 1] -> [4, 20, self.topk]\n        mask_topk = self.`select_topk_candidates`(align_metric, topk_mask=mask_gt.expand(-1, -1, self.topk).bool())\n        # Merge all mask to a final mask, (b, max_num_obj, h*w)\n        mask_pos = mask_topk * mask_in_gts * mask_gt\n        return mask_pos, align_metric, overlaps   # torch.Size([4, 20, 8400])匹配上为1，torch.Size([4, 20, 8400])，torch.Size([4, 20, 8400])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    @staticmethod\n    def select_candidates_in_gts(xy_centers, gt_bboxes, eps=1e-9):\n        n_anchors = xy_centers.shape[0]\n        bs, n_boxes, _ = gt_bboxes.shape\n        lt, rb = gt_bboxes.view(-1, 1, 4).chunk(2, 2)                # left-top, right-bottom\n        bbox_deltas = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]), dim=2).view(bs, n_boxes, n_anchors, -1)\n        # return (bbox_deltas.min(3)[0] > eps).to(gt_bboxes.dtype)\n        return bbox_deltas.amin(3).gt_(eps)\n\'> </span>'}, {'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    def get_box_metrics(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_gt):       # Compute alignment metric given predicted and ground truth bounding boxes\n        na = pd_bboxes.shape[-2]                                                          # torch.Size([4, 8400, 4])  -- 8400\n        mask_gt = mask_gt.bool()                                                          # b, max_num_obj, h*w   torch.Size([4, 20, 8400])\n        overlaps = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_bboxes.dtype, device=pd_bboxes.device)     # torch.Size([4, 20, 8400])\n        bbox_scores = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_scores.dtype, device=pd_scores.device)  # torch.Size([4, 20, 8400])\n        ind = torch.zeros([2, self.bs, self.n_max_boxes], dtype=torch.long)               # 2, b, max_num_obj  --- torch.Size([2, 4, 20])\n        ind[0] = torch.arange(end=self.bs).view(-1, 1).expand(-1, self.n_max_boxes)       # b, max_num_obj     --- torch.Size([4, 20])  第0行全为0，第1行全为1，第b-1行全为b-1\n        ind[1] = gt_labels.squeeze(-1)                                                    # b, max_num_obj      torch.Size([4, 20, 1]) --> torch.Size([4, 20])\n        # Get the scores of each grid for each gt cls \n        bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w  torch.Size([4, 8400, 6])赋值到 torch.Size([4, 20, 8400])\n        # (b, max_num_obj, 1, 4), (b, 1, h*w, 4)\n        pd_boxes = pd_bboxes.unsqueeze(1).expand(-1, self.n_max_boxes, -1, -1)[mask_gt]   # torch.Size([4, 8400, 4])->(4, 20, 8400, 4)-->(1368, 4)\n        gt_boxes = gt_bboxes.unsqueeze(2).expand(-1, -1, na, -1)[mask_gt]                 # torch.Size([4, 20, 4])-> torch.Size([4, 20,8400, 4])-->(1368, 4)\n        overlaps[mask_gt] = self.iou_calculation(gt_boxes, pd_boxes)                      # return bbox_iou(gt_bboxes, pd_bboxes, xywh=False, CIoU=True).squeeze(-1).clamp_(0)\n        align_metric = bbox_scores.pow(self.alpha) * overlaps.pow(self.beta)\n        return align_metric, overlaps               # torch.Size([4, 20, 8400])  torch.Size([4, 20, 8400]),,4张图片，里面20个GT与8400个点之间的对应值     \n\'> </span>'}, {'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    def select_topk_candidates(self, metrics, largest=True, topk_mask=None):\n        # (b, max_num_obj, topk)   # torch.Size([4, 20, 8400])20个对应的box选topk个 -> torch.Size([4, 20, 10]) + torch.Size([4, 20, 10])\n        topk_metrics, topk_idxs = torch.topk(metrics, self.topk, dim=-1, largest=largest)   \n        if topk_mask is None:\n            topk_mask = (topk_metrics.max(-1, keepdim=True)[0] > self.eps).expand_as(topk_idxs)\n        # (b, max_num_obj, topk)\n        topk_idxs.masked_fill_(~topk_mask, 0)      # 不满足条件的top id置0\n        # (b, max_num_obj, topk, h*w) -> (b, max_num_obj, h*w)\n        count_tensor = torch.zeros(metrics.shape, dtype=torch.int8, device=topk_idxs.device)     # torch.Size([4, 20, 8400])  用于计数每个锚点被选为前k个的次数\n        ones = torch.ones_like(topk_idxs[:, :, :1], dtype=torch.int8, device=topk_idxs.device)   # torch.Size([4, 20, 1])\n        for k in range(self.topk):\n            # Expand topk_idxs for each value of k and add 1 at the specified positions【这里不明白 (count_tensor>1).sum()=17；(count_tensor==1).sum()=630；(topk_idxs>0).sum()=585】\n            count_tensor.scatter_add_(-1, topk_idxs[:, :, k : k + 1], ones)        # 在最后一个维度，的那个位置+1  统计每个位置被选中的次数\n        # count_tensor.scatter_add_(-1, topk_idxs, torch.ones_like(topk_idxs, dtype=torch.int8, device=topk_idxs.device))\n        # Filter invalid bboxes\n        count_tensor.masked_fill_(count_tensor > 1, 0)                             # 为了过滤掉那些由于某种原因被重复选中的候选项\n        return count_tensor.to(metrics.dtype)\n\'> </span>'}]}, {'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    @staticmethod                                  # If an anchor box is assigned to multiple gts, the one with the highest IoU will be selected.\n    def select_highest_overlaps(mask_pos, overlaps, n_max_boxes):       # torch.Size([4, 20, 8400]),torch.Size([4, 20, 8400]),20\n        fg_mask = mask_pos.sum(-2)                 # (b, n_max_boxes, h*w) -> (b, h*w)  torch.Size([4, 8400])  值为8400个点有多少个gt匹配，值得范围为0-20\n        if fg_mask.max() > 1:                      # one anchor is assigned to multiple gt_bboxes  一个anchor都多个gt box\n            mask_multi_gts = (fg_mask.unsqueeze(1) > 1).expand(-1, n_max_boxes, -1)  # (b, n_max_boxes, h*w)  torch.Size([4, 20, 8400])  大于1的那个anchor都为True,比如第1张图片一个anchor， mask_multi_gts[1,:,1]=True\n            max_overlaps_idx = overlaps.argmax(1)  # (b, h*w)  torch.Size([4, 8400])  每个anchor最大的iou值\n            is_max_overlaps = torch.zeros(mask_pos.shape, dtype=mask_pos.dtype, device=mask_pos.device)  # torch.Size([4, 20, 8400])\n            is_max_overlaps.scatter_(1, max_overlaps_idx.unsqueeze(1), 1)     # 在第1维度根据索引。。。进行填充\n            mask_pos = torch.where(mask_multi_gts, is_max_overlaps, mask_pos).float()  # (b, n_max_boxes, h*w)  第i个box匹配到了第j个anchor，则mask_pose[0,i,j]=1\n            fg_mask = mask_pos.sum(-2)             # torch.Size([4, 8400])  值为8400个点有多少个gt匹配，值得范围为0-1  现在保证了一个anchor对应一个gt\n        # Find each grid serve which gt(index)\n        target_gt_idx = mask_pos.argmax(-2)  # (b, h*w) 该anchor最大的gt索引，索引值范围0-19，该anchor有多少个gt进行匹配，值得范围为0-1 ，20个GT和8400个anchor是否匹配，匹配为1\n        return target_gt_idx, fg_mask, mask_pos    # torch.Size([4, 8400])，torch.Size([4, 8400])，torch.Size([4, 20, 8400])\n\'> </span>'}, {'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'class TaskAlignedAssigner(nn.Module):\n    def get_targets(self, gt_labels, gt_bboxes, target_gt_idx, fg_mask):   # 该anchor最大的gt索引，该anchor有多少个gt进行匹配  \n        batch_ind = torch.arange(end=self.bs, dtype=torch.int64, device=gt_labels.device)[..., None]  # Assigned target labels, (b, 1) ---> tensor([[0], [1], [2], [3]], device=&amp;#39;cuda:0&amp;#39;)\n        target_gt_idx = target_gt_idx + batch_ind * self.n_max_boxes                                  # (b, h*w) torch.Size([4, 8400]) + tensor([[0], [1*20], [2*20], [3*20]], device=&amp;#39;cuda:0&amp;#39;) = torch.Size([4, 8400])\n        target_labels = gt_labels.long().flatten()[target_gt_idx]                                     # (b, h*w)  torch.Size([4, 8400])\n        # Assigned target boxes, (b, max_num_obj, 4) -> (b, h*w, 4)\n        target_bboxes = gt_bboxes.view(-1, gt_bboxes.shape[-1])[target_gt_idx]                        # torch.Size([4, 8400, 4])\n        # Assigned target scores\n        target_labels.clamp_(0)\n        # 10x faster than F.one_hot()\n        target_scores = torch.zeros(\n            (target_labels.shape[0], target_labels.shape[1], self.num_classes),\n            dtype=torch.int64,\n            device=target_labels.device,\n        )  # (b, h*w, 80)\n        target_scores.scatter_(2, target_labels.unsqueeze(-1), 1)            # torch.Size([4, 8400, 6])\n        fg_scores_mask = fg_mask[:, :, None].repeat(1, 1, self.num_classes)  # (b, h*w, 80)  torch.Size([4, 8400, 6])\n        target_scores = torch.where(fg_scores_mask > 0, target_scores, 0)    # 设置背景的label为0\n        return target_labels, target_bboxes, target_scores         # torch.Size([4, 8400]) + torch.Size([4, 8400, 4]) + torch.Size([4, 8400, 6])\n\'> </span>'}]}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><span class=\'hidden-code\' data-code=\'class BboxLoss(nn.Module):\n    def __init__(self, reg_max, use_dfl=False):\n        super().__init__()\n        self.reg_max = reg_max\n        self.use_dfl = use_dfl\n                # [4,8400,64],  [4,8400,4],   [8400,2],       [4,8400,4]     [4,8400,6]    62.0619\n    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):  # IoU loss\n        weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)                                       # torch.Size([245, 1])\n        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)         # torch.Size([245, 1])\n        loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum\n        if self.use_dfl:               # DFL loss\n            target_ltrb = `bbox2dist`(anchor_points, target_bboxes, self.reg_max)                     # self.reg_max=15\n            loss_dfl = self.`_df_loss`(pred_dist[fg_mask].view(-1, self.reg_max + 1), target_ltrb[fg_mask]) * weight\n            loss_dfl = loss_dfl.sum() / target_scores_sum\n        else:\n            loss_dfl = torch.tensor(0.0).to(pred_dist.device)\n        return loss_iou, loss_dfl\n    @staticmethod\n    def _df_loss(pred_dist, target):\n        tl = target.long()  # target left   torch.Size([245, 4])\n        tr = tl + 1         # target right  torch.Size([245, 4])\n        wl = tr - target    # weight left\n        wr = 1 - wl         # weight right\n        return (\n            F.cross_entropy(pred_dist, tl.view(-1), reduction=&amp;#39;none&amp;#39;).view(tl.shape) * wl\n            + F.cross_entropy(pred_dist, tr.view(-1), reduction=&amp;#39;none&amp;#39;).view(tl.shape) * wr\n        ).mean(-1, keepdim=True)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'def bbox2dist(anchor_points, bbox, reg_max):         # Transform bbox(xyxy) to dist(ltrb)\n    x1y1, x2y2 = bbox.chunk(2, -1)                   # torch.Size([4, 8400, 2]),torch.Size([4, 8400, 2])\n    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp_(0, reg_max - 0.01)  # dist (lt, rb)\n\'> </span>'}]}]}]}]}]}]}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
