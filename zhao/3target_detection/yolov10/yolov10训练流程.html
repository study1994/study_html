<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov10训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p><font size="0"><pre class="language-python"><code class="language-python">from ultralytics import YOLOv10\nmodel_yaml_path = "ultralytics/cfg/models/v10/yolov10s.yaml"\ndata_yaml_path = \'datasets/side_all/data.yaml\'\npre_model_name = \'yolov10s.pt\'\nif __name__ == \'__main__\':\n    model = <span style=\'color: green;font-weight: bold;\'>YOLOv10</span>(model_yaml_path).<span style=\'color: green;font-weight: bold;\'>load</span>(pre_model_name)\n    results = model.<span style=\'color: green;font-weight: bold;\'>train</span>(data=data_yaml_path,epochs=150,batch=4,name=\'train_v10\')\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolov10/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class YOLOv10(<span style=\'color: green;font-weight: bold;\'>Model</span>, PyTorchModelHubMixin, model_card_template=card_template_text):\n    def __init__(self, model="yolov10n.pt", task=None, verbose=False, names=None):\n        super().__init__(model=model, task=task, verbose=verbose)\n        if names is not None:\n            setattr(self.model, \'names\', names)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def __init__(self,model,task,verbose):\n        super().__init__()\n        self.callbacks = callbacks.get_default_callbacks()  <span style=\'color: red\'># defaultdict={},长度25，， \'on_pretrain_routine_start\'；</span>\n        self.predictor = None  <span style=\'color: red\'># reuse predictor</span>\n        self.model = None      <span style=\'color: red\'># model object</span>\n        self.trainer = None    <span style=\'color: red\'># trainer object</span>\n        self.ckpt = None       <span style=\'color: red\'># if loaded from *.pt</span>\n        self.cfg = None        <span style=\'color: red\'># if loaded from *.yaml</span>\n        self.ckpt_path = None\n        self.overrides = {}    <span style=\'color: red\'># overrides for trainer object</span>\n        self.metrics = None    <span style=\'color: red\'># validation/training metrics</span>\n        self.session = None    <span style=\'color: red\'># HUB session</span>\n        self.task = task       <span style=\'color: red\'># task type</span>\n        model = str(model).strip()\n        <span style=\'color: red\'># Load or create new YOLO model</span>\n        if Path(model).suffix in (".yaml", ".yml"):         <span style=\'color: red\'># \'ultralytics/cfg/models/v10/yolov10s.yaml\'</span>\n            self.<span style=\'color: green;font-weight: bold;\'>_new</span>(model, task=task, verbose=verbose)\n        else:\n            self._load(model, task=task)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def _new(self, cfg: str, task=None, model=None, verbose=False) -> None:\n        cfg_dict = yaml_model_load(cfg)                     <span style=\'color: red\'># dict_keys([\'nc\', \'scales\', \'backbone\', \'head\', \'scale\', \'yaml_file\'])</span>\n        self.cfg = cfg                                      <span style=\'color: red\'># \'ultralytics/cfg/models/v10/yolov10s.yaml\'</span>\n        self.task = task or guess_model_task(cfg_dict)      <span style=\'color: red\'># "detect"</span>\n        self.model = (model or self.<span style=\'color: green;font-weight: bold;\'>_smart_load</span>("model"))(cfg_dict, verbose=verbose and RANK == -1)  <span style=\'color: red\'># build model</span>\n        self.overrides["model"] = self.cfg\n        self.overrides["task"] = self.task\n        <span style=\'color: red\'># Below added to allow export from YAMLs  </span>\n        self.model.args = {**DEFAULT_CFG_DICT, **self.overrides}  <span style=\'color: red\'># combine default and model args (prefer model args)</span>\n        self.model.task = self.task\n        self.model_name = cfg\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class v10Detect(Detect):\n    max_det = 300\n    def __init__(self, nc=80, ch=()):\n        <span style=\'color: green;font-weight: bold;\'>super</span>().__init__(nc, ch)\n        c3 = max(ch[0], min(self.nc, 100))  <span style=\'color: red\'># channels  ch=[128, 256, 512],128</span>\n        self.cv3 = nn.ModuleList(nn.Sequential(nn.Sequential(Conv(x, x, 3, g=x), Conv(x, c3, 1)), \n               nn.Sequential(Conv(c3, c3, 3, g=c3), Conv(c3, c3, 1)),\n               nn.Conv2d(c3, self.nc, 1)) for i, x in enumerate(ch))          <span style=\'color: red\'># 替换掉了Class Detect里面的卷积</span>\n        self.one2one_cv2 = copy.deepcopy(self.cv2)\n        self.one2one_cv3 = copy.deepcopy(self.cv3)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):           <span style=\'color: red\'># YOLOv8 Detect head for detection models</span>\n    dynamic = False           <span style=\'color: red\'># force grid reconstruction</span>\n    export = False            <span style=\'color: red\'># export mode</span>\n    shape = None\n    anchors = torch.empty(0)  <span style=\'color: red\'># init</span>\n    strides = torch.empty(0)  <span style=\'color: red\'># init</span>\n    def __init__(self, nc=80, ch=()):              <span style=\'color: red\'># Initializes the YOLOv8 detection layer with specified number of classes and channels</span>\n        super().__init__()\n        self.nc = nc       <span style=\'color: red\'># number of classes          6</span>\n        self.nl = len(ch)  <span style=\'color: red\'># number of detection layers  [128, 256, 512]->3</span>\n        self.reg_max = 16  <span style=\'color: red\'># DFL channels (ch[0] // 16 to scale 4/8/12/16/20 for n/s/m/l/x)</span>\n        self.no = nc + self.reg_max * 4  <span style=\'color: red\'># number of outputs per anchor   6+16*4=70</span>\n        self.stride = torch.zeros(self.nl)  <span style=\'color: red\'># strides computed during build</span>\n        c2, c3 = max((16, ch[0] // 4, self.reg_max * 4)), max(ch[0], min(self.nc, 100))  <span style=\'color: red\'># channels     64,128</span>\n        self.cv2 = nn.ModuleList(nn.Sequential(Conv(x, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch)  <span style=\'color: red\'># 通道变为16</span>\n        self.cv3 = nn.ModuleList(nn.Sequential(Conv(x, c3, 3), Conv(c3, c3, 3), nn.Conv2d(c3, self.nc, 1)) for x in ch)           <span style=\'color: red\'># 通道变为类别6</span>\n        self.dfl = DFL(self.reg_max) if self.reg_max > 1 else nn.Identity()\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/block.py</p><font size="0"><pre class="language-python"><code class="language-python">class DFL(nn.Module):\n    def __init__(self, c1=16):    <span style=\'color: red\'># Initialize a convolutional layer with a given number of input channels</span>\n        super().__init__()\n        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n        x = torch.arange(c1, dtype=torch.float)           <span style=\'color: red\'># tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.])</span>\n        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))   <span style=\'color: red\'># (1,16,1,1)</span>\n        self.c1 = c1              <span style=\'color: red\'># 16</span>\n</code></pre></font>'}]}]}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def load(self, weights: Union[str, Path] = "yolov8n.pt") -> "Model":\n        self._check_is_pytorch_model()\n        if isinstance(weights, (str, Path)):\n            weights, self.ckpt = attempt_load_one_weight(weights)    <span style=\'color: red\'># \'yolov10s.pt\'</span>\n        self.model.load(weights)\n        return self\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def train(self, trainer=None, **kwargs):\n        self._check_is_pytorch_model()\n        if hasattr(self.session, "model") and self.session.model.id:  <span style=\'color: red\'># Ultralytics HUB session with loaded model</span>\n            if any(kwargs):\n                LOGGER.warning("WARNING ⚠️ using HUB training arguments, ignoring local training arguments.")\n            kwargs = self.session.train_args                          <span style=\'color: red\'># overwrite kwargs</span>\n        checks.check_pip_update_available()\n        overrides = yaml_load(checks.check_yaml(kwargs["cfg"])) if kwargs.get("cfg") else self.overrides  <span style=\'color: red\'># {\'model\': \'ultralytics/....../v10/yolov10s.yaml\', \'task\': \'detect\'}</span>\n        custom = {"data": DEFAULT_CFG_DICT["data"] or TASK2DATA[self.task]}  <span style=\'color: red\'># method defaults  从默认的ultralytics/utils/__init__.py里面的DEFAULT_CFG_PATH=ultralytics/cfg/default.yaml--{\'data\': \'coco8.yaml\'}</span>\n        args = {**overrides, **custom, **kwargs, "mode": "train"}            <span style=\'color: red\'># highest priority args on the right</span>\n        if args.get("resume"):\n            args["resume"] = self.ckpt_path\n        self.trainer = (trainer or self.<span style=\'color: green;font-weight: bold;\'>_smart_load</span>("trainer"))(overrides=args, _callbacks=self.callbacks)   <span style=\'color: red\'># ultralytics.models.yolov10.train.YOLOv10DetectionTrainer</span>\n        if not args.get("resume"):                                    <span style=\'color: red\'># manually set model only if not resuming</span>\n            self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)\n            self.model = self.trainer.model\n            ......\n        self.trainer.hub_session = self.session                       <span style=\'color: red\'># attach optional HUB session</span>\n        self.trainer.<span style=\'color: green;font-weight: bold;\'>train</span>()\n        if RANK in (-1, 0):                                           <span style=\'color: red\'># Update model and cfg after training</span>\n            ckpt = self.trainer.best if self.trainer.best.exists() else self.trainer.last\n            self.model, _ = attempt_load_one_weight(ckpt)\n            self.overrides = self.model.args\n            self.metrics = getattr(self.trainer.validator, "metrics", None)  <span style=\'color: red\'># TODO: no metrics returned by DDP</span>\n        return self.metrics\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolov10/train.py</p><font size="0"><pre class="language-python"><code class="language-python">class YOLOv10DetectionTrainer(DetectionTrainer):\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/train.py</p><font size="0"><pre class="language-python"><code class="language-python">class DetectionTrainer(BaseTrainer):\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><font size="0"><pre class="language-python"><code class="language-python">class BaseTrainer:\n    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):\n        self.args = get_cfg(cfg, overrides)\n        self.check_resume(overrides)\n        self.device = select_device(self.args.device, self.args.batch)    <span style=\'color: red\'># device(type=\'cuda\', index=0)</span>\n        self.validator = None\n        self.metrics = None\n        self.plots = {}\n        init_seeds(self.args.seed + 1 + RANK, deterministic=self.args.deterministic)\n        <span style=\'color: red\'># Dirs</span>\n        self.save_dir = get_save_dir(self.args)                 <span style=\'color: red\'># PosixPath(\'/sdb/zzhu/code_study/yolov10/runs/detect/train_v103\')</span>\n        self.args.name = self.save_dir.name                     <span style=\'color: red\'># update name for loggers   \'train_v103\'</span>\n        self.wdir = self.save_dir / "weights"                   <span style=\'color: red\'># weights dir</span>\n        if RANK in (-1, 0):\n            self.wdir.mkdir(parents=True, exist_ok=True)        <span style=\'color: red\'># make dir</span>\n            self.args.save_dir = str(self.save_dir)\n            yaml_save(self.save_dir / "args.yaml", vars(self.args))          <span style=\'color: red\'># save run args</span>\n        self.last, self.best = self.wdir / "last.pt", self.wdir / "best.pt"  <span style=\'color: red\'># checkpoint paths</span>\n        self.save_period = self.args.save_period                <span style=\'color: red\'># -1</span>\n        self.batch_size = self.args.batch                       <span style=\'color: red\'># 4</span>\n        self.epochs = self.args.epochs\n        self.start_epoch = 0\n        if RANK == -1:\n            print_args(vars(self.args))\n        <span style=\'color: red\'># Device</span>\n        if self.device.type in ("cpu", "mps"):\n            self.args.workers = 0  <span style=\'color: red\'># faster CPU training as time dominated by inference, not dataloading</span>\n        <span style=\'color: red\'># Model and Dataset</span>\n        self.model = check_model_file_from_stem(self.args.model)  <span style=\'color: red\'># add suffix, i.e. yolov8n -> yolov8n.pt  \'ultralytics/cfg/models/v10/yolov10s.yaml\'</span>\n        try:\n            if self.args.task == "classify":\n                self.data = check_cls_dataset(self.args.data)\n            elif self.args.data.split(".")[-1] in ("yaml", "yml") or self.args.task in ("detect","segment","pose","obb"):\n                self.data = check_det_dataset(self.args.data)\n                if "yaml_file" in self.data:\n                    self.args.data = self.data["yaml_file"]  <span style=\'color: red\'># for validating \'yolo train data=url.zip\' usage</span>\n        except Exception as e:\n            raise RuntimeError(emojis(f"Dataset \'{clean_url(self.args.data)}\' error ❌ {e}")) from e\n        <span style=\'color: red\'># \'/sdb/.../img_2d/images/train2017\', \'/sdb/.../img_2d/images/val2017\'</span>\n        self.trainset, self.testset = self.get_dataset(self.data)    <span style=\'color: red\'># \'/sdb/zzhu/code_study/yolov10/datasets/side_all/images/train2017\'</span>\n        self.ema = None\n        <span style=\'color: red\'># Optimization utils init</span>\n        self.lf = None\n        self.scheduler = None\n        <span style=\'color: red\'># Epoch level metrics</span>\n        self.best_fitness = None\n        self.fitness = None\n        self.loss = None\n        self.tloss = None\n        self.loss_names = ["Loss"]\n        self.csv = self.save_dir / "results.csv"\n        self.plot_idx = [0, 1, 2]\n        <span style=\'color: red\'># Callbacks</span>\n        self.callbacks = _callbacks or callbacks.get_default_callbacks()      <span style=\'color: red\'># <span style=\'color: green;font-weight: bold;\'><</span>defaultdict, len() = 25<span style=\'color: green;font-weight: bold;\'>></span></span>\n        if RANK in (-1, 0):\n            callbacks.add_integration_callbacks(self)\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><font size="0"><pre class="language-python"><code class="language-python">class BaseTrainer:\n    def train(self):\n        if world_size > 1 and "LOCAL_RANK" not in os.environ:\n            ......\n        else:\n            self.<span style=\'color: green;font-weight: bold;\'>_do_train</span>(world_size)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><font size="0"><pre class="language-python"><code class="language-python">class BaseTrainer:\n    def _do_train(self, world_size=1):\n        self.<span style=\'color: green;font-weight: bold;\'>_setup_train</span>(world_size)\n        nb = len(self.train_loader)                           <span style=\'color: red\'># number of batches   250</span>\n        nw = max(round(self.args.warmup_epochs * nb), 100) if self.args.warmup_epochs > 0 else -1  <span style=\'color: red\'># warmup iterations  max(3*250,100)=750</span>\n        last_opt_step = -1\n        self.epoch_time = None\n        self.epoch_time_start = time.time()\n        self.train_time_start = time.time()\n        self.run_callbacks("on_train_start")\n        if self.args.close_mosaic:\n            base_idx = (self.epochs - self.args.close_mosaic) * nb    <span style=\'color: red\'># (150-10)*250</span>\n            self.plot_idx.extend([base_idx, base_idx + 1, base_idx + 2])\n        epoch = self.start_epoch                           <span style=\'color: red\'># 0</span>\n        while True:\n            self.epoch = epoch\n            self.run_callbacks("on_train_epoch_start")\n            self.model.train()\n            if RANK != -1:\n                self.train_loader.sampler.set_epoch(epoch)\n            pbar = enumerate(self.train_loader)\n            <span style=\'color: red\'># Update dataloader attributes (optional)</span>\n            if epoch == (self.epochs - self.args.close_mosaic):         <span style=\'color: red\'># 关掉mosaic</span>\n                self._close_dataloader_mosaic()\n                self.train_loader.reset()\n            if RANK in (-1, 0):\n                LOGGER.info(self.progress_string())\n                pbar = TQDM(enumerate(self.train_loader), total=nb)\n            self.tloss = None\n            self.optimizer.zero_grad()\n            for i, batch in pbar:\n                self.run_callbacks("on_train_batch_start")\n                <span style=\'color: red\'># Warmup</span>\n                ni = i + nb * epoch\n                if ni <= nw:\n                    xi = [0, nw]                                        <span style=\'color: red\'># x interp</span>\n                    self.accumulate = max(1, int(np.interp(ni, xi, [1, self.args.nbs / self.batch_size]).round()))\n                    for j, x in enumerate(self.optimizer.param_groups):\n                        <span style=\'color: red\'># Bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0</span>\n                        x["lr"] = np.interp(ni, xi, [self.args.warmup_bias_lr if j == 0 else 0.0, x["initial_lr"] * self.lf(epoch)])\n                        if "momentum" in x:\n                            x["momentum"] = np.interp(ni, xi, [self.args.warmup_momentum, self.args.momentum])\n                <span style=\'color: red\'># Forward</span>\n                with torch.cuda.amp.autocast(self.amp):\n                    batch = self.preprocess_batch(batch)        <span style=\'color: red\'># {\'im_file\':[,,,], \'ori_shape\':[[1080, 1920],...], \'resized_shape\':[[640, 640],...], \'img\':torch.Size([4, 3, 640, 640]), \'cls\':, \'bboxes\':, \'batch_idx\':}</span>\n                    self.loss, self.loss_items = self.<span style=\'color: green;font-weight: bold;\'>model</span>(batch)\n                    if RANK != -1:\n                        self.loss *= world_size\n                    self.tloss = ((self.tloss * i + self.loss_items) / (i + 1) if self.tloss is not None else self.loss_items)\n                <span style=\'color: red\'># Backward</span>\n                self.scaler.scale(self.loss).backward()\n                <span style=\'color: red\'># Optimize - https://pytorch.org/docs/master/notes/amp_examples.html</span>\n                if ni - last_opt_step >= self.accumulate:\n                    self.optimizer_step()\n                    last_opt_step = ni\n                    <span style=\'color: red\'># Timed stopping</span>\n                    if self.args.time:\n                        self.stop = (time.time() - self.train_time_start) > (self.args.time * 3600)\n                        if RANK != -1:  <span style=\'color: red\'># if DDP training</span>\n                            broadcast_list = [self.stop if RANK == 0 else None]\n                            dist.broadcast_object_list(broadcast_list, 0)  <span style=\'color: red\'># broadcast \'stop\' to all ranks</span>\n                            self.stop = broadcast_list[0]\n                        if self.stop:  <span style=\'color: red\'># training time exceeded</span>\n                            break\n                <span style=\'color: red\'># Log</span>\n                mem = f"{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}G"  <span style=\'color: red\'># (GB)</span>\n                loss_len = self.tloss.shape[0] if len(self.tloss.shape) else 1\n                losses = self.tloss if loss_len > 1 else torch.unsqueeze(self.tloss, 0)\n                if RANK in (-1, 0):\n                    pbar.set_description(("%11s" * 2 + "%11.4g" * (2 + loss_len))% (f"{epoch + 1}/{self.epochs}", mem, *losses, batch["cls"].shape[0], batch["img"].shape[-1]))\n                    self.run_callbacks("on_batch_end")\n                    if self.args.plots and ni in self.plot_idx:\n                        self.plot_training_samples(batch, ni)\n                self.run_callbacks("on_train_batch_end")\n            self.lr = {f"lr/pg{ir}": x["lr"] for ir, x in enumerate(self.optimizer.param_groups)}  <span style=\'color: red\'># for loggers</span>\n            self.run_callbacks("on_train_epoch_end")\n            if RANK in (-1, 0):\n                final_epoch = epoch + 1 == self.epochs\n                self.ema.update_attr(self.model, include=["yaml", "nc", "args", "names", "stride", "class_weights"])\n                <span style=\'color: red\'># Validation</span>\n                if (self.args.val and (((epoch+1) % self.args.val_period == 0) or (self.epochs - epoch) <= 10)) or final_epoch or self.stopper.possible_stop or self.stop:\n                    self.metrics, self.fitness = self.validate()\n                self.save_metrics(metrics={**self.label_loss_items(self.tloss), **self.metrics, **self.lr})\n                self.stop |= self.stopper(epoch + 1, self.fitness) or final_epoch\n                if self.args.time:\n                    self.stop |= (time.time() - self.train_time_start) > (self.args.time * 3600)\n                <span style=\'color: red\'># Save model</span>\n                if self.args.save or final_epoch:\n                    self.save_model()\n                    self.run_callbacks("on_model_save")\n            <span style=\'color: red\'># Scheduler</span>\n            t = time.time()\n            self.epoch_time = t - self.epoch_time_start\n            self.epoch_time_start = t\n            with warnings.catch_warnings():\n                warnings.simplefilter("ignore")  <span style=\'color: red\'># suppress \'Detected lr_scheduler.step() before optimizer.step()\'</span>\n                if self.args.time:\n                    mean_epoch_time = (t - self.train_time_start) / (epoch - self.start_epoch + 1)\n                    self.epochs = self.args.epochs = math.ceil(self.args.time * 3600 / mean_epoch_time)\n                    self._setup_scheduler()\n                    self.scheduler.last_epoch = self.epoch  <span style=\'color: red\'># do not move</span>\n                    self.stop |= epoch >= self.epochs  <span style=\'color: red\'># stop if exceeded epochs</span>\n                self.scheduler.step()\n            self.run_callbacks("on_fit_epoch_end")\n            torch.cuda.empty_cache()  <span style=\'color: red\'># clear GPU memory at end of epoch, may help reduce CUDA out of memory errors</span>\n            <span style=\'color: red\'># Early Stopping</span>\n            if RANK != -1:  <span style=\'color: red\'># if DDP training</span>\n                broadcast_list = [self.stop if RANK == 0 else None]\n                dist.broadcast_object_list(broadcast_list, 0)  <span style=\'color: red\'># broadcast \'stop\' to all ranks</span>\n                self.stop = broadcast_list[0]\n            if self.stop:\n                break  <span style=\'color: red\'># must break all DDP ranks</span>\n            epoch += 1\n        if RANK in (-1, 0):\n            <span style=\'color: red\'># Do final val with best.pt</span>\n            LOGGER.info(f"\\n{epoch - self.start_epoch + 1} epochs completed in {(time.time() - self.train_time_start) / 3600:.3f} hours.")\n            self.final_eval()\n            if self.args.plots:\n                self.plot_metrics()\n            self.run_callbacks("on_train_end")\n        torch.cuda.empty_cache()\n        self.run_callbacks("teardown")\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/trainer.py</p><font size="0"><pre class="language-python"><code class="language-python">class BaseTrainer:\n    def _setup_train(self, world_size):              <span style=\'color: red\'># Builds dataloaders and optimizer on correct rank process.</span>\n        <span style=\'color: red\'># Model</span>\n        self.run_callbacks("on_pretrain_routine_start")\n        ckpt = self.setup_model()                    <span style=\'color: red\'># None</span>\n        self.model = self.model.to(self.device)      <span style=\'color: red\'># YOLOv10DetectionModel</span>\n        self.set_model_attributes()\n        <span style=\'color: red\'># Freeze layers</span>\n        freeze_list = (self.args.freeze if isinstance(self.args.freeze, list) else range(self.args.freeze) if isinstance(self.args.freeze, int) else []) <span style=\'color: red\'># []</span>\n        always_freeze_names = [".dfl"]                                                       <span style=\'color: red\'># always freeze these layers</span>\n        freeze_layer_names = [f"model.{x}." for x in freeze_list] + always_freeze_names      <span style=\'color: red\'># [\'.dfl\']</span>\n        for k, v in self.model.named_parameters():  <span style=\'color: red\'># v.register_hook(lambda x: torch.nan_to_num(x)) </span>\n            if any(x in k for x in freeze_layer_names):\n                LOGGER.info(f"Freezing layer \'{k}\'")\n                v.requires_grad = False\n            elif not v.requires_grad and v.dtype.is_floating_point:  <span style=\'color: red\'># only floating point Tensor can require gradients</span>\n                LOGGER.info(f"WARNING ⚠️ setting \'requires_grad=True\' for frozen layer \'{k}\'. See ultralytics.engine.trainer for customization of frozen layers.")\n                v.requires_grad = True\n        <span style=\'color: red\'># Check AMP</span>\n        self.amp = torch.tensor(self.args.amp).to(self.device)     <span style=\'color: red\'># True or False </span>\n        if self.amp and RANK in (-1, 0):  <span style=\'color: red\'># Single-GPU and DDP</span>\n            callbacks_backup = callbacks.default_callbacks.copy()  <span style=\'color: red\'># backup callbacks as check_amp() resets them</span>\n            self.amp = torch.tensor(check_amp(self.model), device=self.device)      <span style=\'color: red\'># tensor(True, device=\'cuda:0\')</span>\n            callbacks.default_callbacks = callbacks_backup  <span style=\'color: red\'># restore callbacks</span>\n        if RANK > -1 and world_size > 1:  <span style=\'color: red\'># DDP</span>\n            dist.broadcast(self.amp, src=0)  <span style=\'color: red\'># broadcast the tensor from rank 0 to all other ranks (returns None)</span>\n        self.amp = bool(self.amp)         <span style=\'color: red\'># as boolean  ---- True</span>\n        self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)                   <span style=\'color: red\'># <span style=\'color: green;font-weight: bold;\'><</span>torch.cuda.amp.grad_scaler.GradScaler object at 0x7f04c80d6520<span style=\'color: green;font-weight: bold;\'>></span></span>\n        if world_size > 1:\n            self.model = nn.parallel.DistributedDataParallel(self.model, device_ids=[RANK])\n        <span style=\'color: red\'># Check imgsz</span>\n        gs = max(int(self.model.stride.max() if hasattr(self.model, "stride") else 32), 32)  <span style=\'color: red\'># grid size (max stride)   32</span>\n        self.args.imgsz = check_imgsz(self.args.imgsz, stride=gs, floor=gs, max_dim=1)       <span style=\'color: red\'># 640</span>\n        self.stride = gs  <span style=\'color: red\'># for multiscale training     32</span>\n        <span style=\'color: red\'># Batch size</span>\n        if self.batch_size == -1 and RANK == -1:  <span style=\'color: red\'># single-GPU only, estimate best batch size</span>\n            self.args.batch = self.batch_size = check_train_batch_size(self.model, self.args.imgsz, self.amp)\n        <span style=\'color: red\'># Dataloaders</span>\n        batch_size = self.batch_size // max(world_size, 1)    <span style=\'color: red\'># 4//1=4</span>\n        self.train_loader = self.<span style=\'color: green;font-weight: bold;\'>get_dataloader</span>(self.trainset, batch_size=batch_size, rank=RANK, mode="train")\n        if RANK in (-1, 0):                       <span style=\'color: red\'># Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.</span>\n            self.test_loader = self.get_dataloader(self.testset, batch_size=batch_size if self.args.task == "obb" else batch_size * 2, rank=-1, mode="val")\n            self.validator = self.get_validator()             <span style=\'color: red\'># ultralytics.models.yolov10.val.YOLOv10DetectionValidator</span>\n            metric_keys = self.validator.metrics.keys + self.label_loss_items(prefix="val")\n            self.metrics = dict(zip(metric_keys, [0] * len(metric_keys)))\n            self.ema = ModelEMA(self.model)\n            if self.args.plots:\n                self.plot_training_labels()\n        <span style=\'color: red\'># Optimizer</span>\n        self.accumulate = max(round(self.args.nbs / self.batch_size), 1)                           <span style=\'color: red\'># accumulate loss before optimizing  16=max(64/4,1)</span>\n        weight_decay = self.args.weight_decay * self.batch_size * self.accumulate / self.args.nbs  <span style=\'color: red\'># scale weight_decay 0.0005*4*16/64 = 0.0005</span>\n        iterations = math.ceil(len(self.train_loader.dataset) / max(self.batch_size, self.args.nbs)) * self.epochs    <span style=\'color: red\'># 1000/max(4,64)*150=2400</span>\n        self.optimizer = self.build_optimizer(model=self.model,name=self.args.optimizer,lr=self.args.lr0,momentum=self.args.momentum,decay=weight_decay,iterations=iterations)\n        <span style=\'color: red\'># Scheduler</span>\n        self._setup_scheduler()\n        self.stopper, self.stop = EarlyStopping(patience=self.args.patience), False  <span style=\'color: red\'># self.args.patience=100</span>\n        self.resume_training(ckpt)                        <span style=\'color: red\'># None</span>\n        self.scheduler.last_epoch = self.start_epoch - 1  <span style=\'color: red\'># do not move</span>\n        self.run_callbacks("on_pretrain_routine_end")\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/train.py</p><font size="0"><pre class="language-python"><code class="language-python">class DetectionTrainer(BaseTrainer):\n    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):          <span style=\'color: red\'># Construct and return dataloader</span>\n        assert mode in ["train", "val"]\n        with torch_distributed_zero_first(rank):  <span style=\'color: red\'># init dataset *.cache only once if DDP</span>\n            dataset = self.<span style=\'color: green;font-weight: bold;\'>build_dataset</span>(dataset_path, mode, batch_size)\n        shuffle = mode == "train"\n        if getattr(dataset, "rect", False) and shuffle:\n            LOGGER.warning("WARNING ⚠️ \'rect=True\' is incompatible with DataLoader shuffle, setting shuffle=False")\n            shuffle = False\n        workers = self.args.workers if mode == "train" else self.args.workers * 2\n        return <span style=\'color: green;font-weight: bold;\'>build_dataloader</span>(dataset, batch_size, workers, shuffle, rank)  <span style=\'color: red\'># return dataloader</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/train.py</p><font size="0"><pre class="language-python"><code class="language-python">class DetectionTrainer(BaseTrainer):\n    def build_dataset(self, img_path, mode="train", batch=None):\n        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)     <span style=\'color: red\'># 32</span>\n        return <span style=\'color: green;font-weight: bold;\'>build_yolo_dataset</span>(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><font size="0"><pre class="language-python"><code class="language-python">def build_yolo_dataset(cfg, img_path, batch, data, mode="train", rect=False, stride=32):\n    save_path="/sdb/zzhu/code_study/yolov10/build_yolo_dataset.npy"\n    if not os.path.exists(save_path):\n        a = {"cfg":cfg, "img_path":img_path, "batch":batch, "data":data, "mode":mode, "rect":rect, "stride":stride}\n        np.save(save_path,a)\n    return <span style=\'color: green;font-weight: bold;\'>YOLODataset</span>(\n        img_path=img_path,        <span style=\'color: red\'># \'/sdb/zzhu/data/data_fisheye_all/img_2d/images/train2017\'</span>\n        imgsz=cfg.imgsz,          <span style=\'color: red\'># 960</span>\n        batch_size=batch,         <span style=\'color: red\'># 4</span>\n        augment=mode == "train",  <span style=\'color: red\'># augmentation         True</span>\n        hyp=cfg,                  <span style=\'color: red\'># TODO: probably add a get_hyps_from_cfg function</span>\n        rect=cfg.rect or rect,    <span style=\'color: red\'># rectangular batches  False or False</span>\n        cache=cfg.cache or None,               <span style=\'color: red\'># False</span>\n        single_cls=cfg.single_cls or False,    <span style=\'color: red\'># False</span>\n        stride=int(stride),                    <span style=\'color: red\'># 32</span>\n        pad=0.0 if mode == "train" else 0.5,\n        prefix=colorstr(f"{mode}: "),\n        task=cfg.task,            <span style=\'color: red\'># "detect"</span>\n        classes=cfg.classes,      <span style=\'color: red\'># None</span>\n        data=data,\n        fraction=cfg.fraction if mode == "train" else 1.0,   <span style=\'color: red\'># 1</span>\n    )\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><font size="0"><pre class="language-python"><code class="language-python">def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):\n    """Return an InfiniteDataLoader or DataLoader for training or validation set."""\n    batch = min(batch, len(dataset))\n    nd = torch.cuda.device_count()  <span style=\'color: red\'># number of CUDA devices</span>\n    nw = min([os.cpu_count() // max(nd, 1), workers])  <span style=\'color: red\'># number of workers</span>\n    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)\n    generator = torch.Generator()\n    generator.manual_seed(6148914691236517205 + RANK)\n    return InfiniteDataLoader(dataset=dataset,batch_size=batch,shuffle=shuffle and sampler is None,\n        num_workers=nw,sampler=sampler,pin_memory=PIN_MEMORY,collate_fn=getattr(dataset, "collate_fn", None),\n        worker_init_fn=seed_worker,generator=generator)\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python"><code class="language-python">YOLOv10DetectionModel-->DetectionModel\nclass BaseModel(nn.Module):\n    def forward(self, x, *args, **kwargs):\n        if isinstance(x, dict):  <span style=\'color: red\'># for cases of training and validating while training.</span>\n            return self.<span style=\'color: green;font-weight: bold;\'>loss</span>(x, *args, **kwargs)\n        return self.predict(x, *args, **kwargs)\n    def loss(self, batch, preds=None):\n        if not hasattr(self, "criterion"):\n            self.criterion = self.<span style=\'color: green;font-weight: bold;\'>init_criterion</span>()\n        preds = self.<span style=\'color: green;font-weight: bold;\'>forward</span>(batch["img"]) if preds is None else preds\n        return self.<span style=\'color: green;font-weight: bold;\'>criterion</span>(preds, batch)    <span style=\'color: red\'># <span style=\'color: green;font-weight: bold;\'><</span>ultralytics.utils.loss.v10DetectLoss object at 0x7f04c01985e0<span style=\'color: green;font-weight: bold;\'>></span></span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python"><code class="language-python">class BaseModel(nn.Module):\n    def forward(self, x, *args, **kwargs):\n        if isinstance(x, dict):  <span style=\'color: red\'># for cases of training and validating while training.</span>\n            return self.loss(x, *args, **kwargs)\n        return self.<span style=\'color: green;font-weight: bold;\'>predict</span>(x, *args, **kwargs)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python"><code class="language-python">class BaseModel(nn.Module):\n    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):\n        if augment:\n            return self._predict_augment(x)\n        return self.<span style=\'color: green;font-weight: bold;\'>_predict_once</span>(x, profile, visualize, embed)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python"><code class="language-python">def _predict_once(self, x, profile=False, visualize=False, embed=None):\n    y, dt, embeddings = [], [], []  <span style=\'color: red\'># outputs</span>\n    for m in self.model:\n        if m.f != -1:  <span style=\'color: red\'># if not from previous layer</span>\n            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  <span style=\'color: red\'># from earlier layers</span>\n        if profile:\n            self._profile_one_layer(m, x, dt)\n        x = m(x)  <span style=\'color: red\'># run</span>\n        y.append(x if m.i in self.save else None)  <span style=\'color: red\'># save output</span>\n        if visualize:\n            feature_visualization(x, m.type, m.i, save_dir=visualize)\n        if embed and m.i in embed:\n            embeddings.append(nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1))  <span style=\'color: red\'># flatten</span>\n            if m.i == max(embed):\n                return torch.unbind(torch.cat(embeddings, 1), dim=0)    <span style=\'color: red\'># 类别6，4+1+6</span>\n    return x     <span style=\'color: red\'># {\'one2many\':[torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]],\'one2one\':[torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]]}</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class v10Detect(Detect):\n    def forward(self, x):             <span style=\'color: red\'># [torch.Size([4, 128, 80, 80]),[4, 256, 40, 40],[4, 512, 20, 20]]</span>\n        one2one = self.<span style=\'color: green;font-weight: bold;\'>forward_feat</span>([xi.detach() for xi in x], self.one2one_cv2, self.one2one_cv3)   <span style=\'color: red\'># Tensor与原始Tensor共享数据但不需要梯度计算。</span>\n        if not self.export:             <span style=\'color: red\'># 训练走</span>\n            one2many = super().<span style=\'color: green;font-weight: bold;\'>forward</span>(x)\n        if not self.training:           <span style=\'color: red\'># 训练是不走</span>\n            one2one = self.inference(one2one)\n            if not self.export:\n                return {"one2many": one2many, "one2one": one2one}\n            else:\n                assert(self.max_det != -1)\n                boxes, scores, labels = ops.v10postprocess(one2one.permute(0, 2, 1), self.max_det, self.nc)\n                return torch.cat([boxes, scores.unsqueeze(-1), labels.unsqueeze(-1).to(boxes.dtype)], dim=-1)\n        else:\n            return {"one2many": one2many, "one2one": one2one}\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def forward_feat(self, x, cv2, cv3):\n        y = []\n        for i in range(self.nl):   <span style=\'color: red\'># 3</span>\n            y.append(torch.cat((cv2[i](x[i]), cv3[i](x[i])), 1))\n        return y                   <span style=\'color: red\'># [torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]]</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def forward(self, x):\n        y = self.forward_feat(x, self.cv2, self.cv3)\n        if self.training:\n            return y               <span style=\'color: red\'># [torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]]</span>\n        return self.inference(y)\n</code></pre></font>'}]}]}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class v10DetectLoss:\n    def __init__(self, model):\n        self.one2many = v8DetectionLoss(model, tal_topk=10)\n        self.one2one = v8DetectionLoss(model, tal_topk=1)\n    \n    def __call__(self, preds, batch):\n        one2many = preds["one2many"]                          <span style=\'color: red\'># torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]</span>\n        loss_one2many = self.<span style=\'color: green;font-weight: bold;\'>one2many</span>(one2many, batch)      <span style=\'color: red\'># (tensor(31.1620),tensor([1.4539, 5.2442, 1.0923]))</span>\n        one2one = preds["one2one"]                            <span style=\'color: red\'># torch.Size([4, 70, 80, 80]),[4, 70, 40, 40],[4, 70, 20, 20]</span>\n        loss_one2one = self.<span style=\'color: green;font-weight: bold;\'>one2one</span>(one2one, batch)         <span style=\'color: red\'># (tensor(44.8558),tensor([1.8921, 8.2079, 1.1140]))</span>\n        return loss_one2many[0] + loss_one2one[0], torch.cat((loss_one2many[1], loss_one2one[1]))\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class v8DetectionLoss:\n    def __call__(self, preds, batch):                  <span style=\'color: red\'># Calculate the sum of the loss for box, cls and dfl multiplied by batch size</span>\n        loss = torch.zeros(3, device=self.device)  <span style=\'color: red\'># box, cls, dfl</span>\n        feats = preds[1] if isinstance(preds, tuple) else preds\n        <span style=\'color: red\'># torch.Size([4, 70, 8400])-->70=4*16+6   --->   torch.Size([4, 64, 8400])+torch.Size([4, 6, 8400])</span>\n        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split((self.reg_max * 4, self.nc), 1)\n        pred_scores = pred_scores.permute(0, 2, 1).contiguous()   <span style=\'color: red\'># torch.Size([4, 8400, 6])</span>\n        pred_distri = pred_distri.permute(0, 2, 1).contiguous()   <span style=\'color: red\'># torch.Size([4, 8400, 64])</span>\n        dtype = pred_scores.dtype\n        batch_size = pred_scores.shape[0]\n        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  <span style=\'color: red\'># image size (h,w)  tensor([640., 640.])</span>\n        anchor_points, stride_tensor = <span style=\'color: green;font-weight: bold;\'>make_anchors</span>(feats, self.stride, 0.5)                      <span style=\'color: red\'># torch.Size([8400, 2])   torch.Size([8400, 1])</span>\n        <span style=\'color: red\'># Targets</span>\n        targets = torch.cat((batch["batch_idx"].view(-1, 1), batch["cls"].view(-1, 1), batch["bboxes"]), 1)  <span style=\'color: red\'># torch.Size([63, 6]) 6=1+1+4,batch_id,cls,bbox,</span>\n        targets = self.<span style=\'color: green;font-weight: bold;\'>preprocess</span>(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n        gt_labels, gt_bboxes = targets.split((1, 4), 2)             <span style=\'color: red\'># cls, xyxy   torch.Size([4, 20, 1])  torch.Size([4, 20, 4])</span>\n        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)             <span style=\'color: red\'># torch.Size([4, 20, 1]) 是gt的话为1，否则为0</span>\n        <span style=\'color: red\'># Pboxes</span>\n        pred_bboxes = self.<span style=\'color: green;font-weight: bold;\'>bbox_decode</span>(anchor_points, pred_distri)  <span style=\'color: red\'># xyxy, (b, h*w, 4)  torch.Size([4, 8400, 4])</span>\n        _, target_bboxes, target_scores, fg_mask, _ = self.<span style=\'color: green;font-weight: bold;\'>assigner</span>(\n            pred_scores.detach().sigmoid(),                                     <span style=\'color: red\'># torch.Size([4, 8400, 6])  到-1之间  6为类别数量</span>\n            (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),       <span style=\'color: red\'># 乘以下采样倍数对应原图像   torch.Size([4, 8400, 4])</span>\n            anchor_points * stride_tensor,                                      <span style=\'color: red\'># torch.Size([8400, 2]) 对应输入图片上的点</span>\n            gt_labels,                                                          <span style=\'color: red\'># torch.Size([4, 20, 1])  4个图片，某个图片的框最多为20</span>\n            gt_bboxes,                                                          <span style=\'color: red\'># torch.Size([4, 20, 4])</span>\n            mask_gt,                                                            <span style=\'color: red\'># torch.Size([4, 20, 1])</span>\n        )\n        target_scores_sum = max(target_scores.sum(), 1)                         <span style=\'color: red\'># tensor(103.7702, device=\'cuda:0\')</span>\n        <span style=\'color: red\'># Cls loss</span>\n        <span style=\'color: red\'># loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum </span>\n        loss[1] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum  <span style=\'color: red\'># BCEWithLogitsLoss()  torch.Size([4, 8400, 6])-</span>\n        <span style=\'color: red\'># Bbox loss</span>\n        if fg_mask.sum():\n            target_bboxes /= stride_tensor          <span style=\'color: red\'># torch.Size([4, 8400, 4])在对应的anchor上面计算</span>\n            loss[0], loss[2] = self.<span style=\'color: green;font-weight: bold;\'>bbox_loss</span>(pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask)\n        loss[0] *= self.hyp.box  <span style=\'color: red\'># box gain</span>\n        loss[1] *= self.hyp.cls  <span style=\'color: red\'># cls gain</span>\n        loss[2] *= self.hyp.dfl  <span style=\'color: red\'># dfl gain</span>\n        return loss.sum() * batch_size, loss.detach()  <span style=\'color: red\'># loss(box, cls, dfl)</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">def make_anchors(feats, strides, grid_cell_offset=0.5):     <span style=\'color: red\'># Generate anchors from features  strides-->[ 8., 16., 32.]</span>\n    anchor_points, stride_tensor = [], []\n    assert feats is not None                                <span style=\'color: red\'># feats->([4, 70, 80, 80],[4, 70, 40, 40],[4, 70, 20, 20])  </span>\n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape    <span style=\'color: red\'># (80,80)</span>\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  <span style=\'color: red\'># shift x   torch.Size([80]) -(0.5->79.5)</span>\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  <span style=\'color: red\'># shift y</span>\n        sy, sx = torch.meshgrid(sy, sx, indexing="ij") if TORCH_1_10 else torch.meshgrid(sy, sx)\n        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))              <span style=\'color: red\'># torch.Size([6400, 2])  tensor([[0.5000, 0.5000], [1.5000, 0.5000], [2.5000, 0.5000]])</span>\n        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n    return torch.cat(anchor_points), torch.cat(stride_tensor)\n</code></pre></font>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class v8DetectionLoss:\n    def preprocess(self, targets, batch_size, scale_tensor):  <span style=\'color: red\'># Preprocesses the target counts and matches with the input batch size to output a tensor</span>\n        if targets.shape[0] == 0:\n            out = torch.zeros(batch_size, 0, 5, device=self.device)\n        else:\n            i = targets[:, 0]                         <span style=\'color: red\'># image index</span>\n            _, counts = i.unique(return_counts=True)  <span style=\'color: red\'># tensor([16,  7, 20, 20])  属于第一张图片有16个box，第二张图片7个box</span>\n            counts = counts.to(dtype=torch.int32)\n            out = torch.zeros(batch_size, counts.max(), 5, device=self.device)\n            for j in range(batch_size):\n                matches = i == j\n                n = matches.sum()\n                if n:\n                    out[j, :n] = targets[matches, 1:]\n            out[..., 1:5] = xywh2xyxy(out[..., 1:5].mul_(scale_tensor))         <span style=\'color: red\'># 恢复到输入到神经网络的图片大小--x1,y1,x2,y2</span>\n        return out\n</code></pre></font>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class v8DetectionLoss:\n    def bbox_decode(self, anchor_points, pred_dist):      <span style=\'color: red\'># Decode predicted object bounding box coordinates from anchor points and distribution</span>\n        if self.use_dfl:\n            b, a, c = pred_dist.shape                     <span style=\'color: red\'># torch.Size([4, 8400, 64])  batch, anchors, channels   self.proj范围0-15  15*(0-1的数)+14*(0-1的数)+...+0*(0-1的数)</span>\n            pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))    <span style=\'color: red\'># 也就是  torch.Size([4, 8400, 4, 16])</span>\n            <span style=\'color: red\'># pred_dist = pred_dist.view(b, a, c // 4, 4).transpose(2,3).softmax(3).matmul(self.proj.type(pred_dist.dtype))</span>\n            <span style=\'color: red\'># pred_dist = (pred_dist.view(b, a, c // 4, 4).softmax(2) * self.proj.type(pred_dist.dtype).view(1, 1, -1, 1)).sum(2)</span>\n        return <span style=\'color: green;font-weight: bold;\'>dist2bbox</span>(pred_dist, anchor_points, xywh=False)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">def dist2bbox(distance, anchor_points, xywh=True, dim=-1):     <span style=\'color: red\'># Transform distance(ltrb) to box(xywh or xyxy)</span>\n    assert(distance.shape[dim] == 4)               <span style=\'color: red\'># torch.Size([4, 8400, 4])  + torch.Size([8400, 2])</span>\n    lt, rb = distance.split([2, 2], dim)           <span style=\'color: red\'># torch.Size([4, 8400, 2])  torch.Size([4, 8400, 2])</span>\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)         <span style=\'color: red\'># xywh bbox</span>\n    return torch.cat((x1y1, x2y2), dim)           <span style=\'color: red\'># xyxy bbox</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    @torch.no_grad()             <span style=\'color: red\'># 在输入模型图片上的尺度上操作  </span>\n    def forward(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt):\n        self.bs = pd_scores.shape[0]                <span style=\'color: red\'># 4</span>\n        self.n_max_boxes = gt_bboxes.shape[1]       <span style=\'color: red\'># 20</span>\n        if self.n_max_boxes == 0:\n            device = gt_bboxes.device\n            return ......                                <span style=\'color: red\'># [4, 8400, 6],[4, 8400, 4],[4, 20, 1],[4, 20, 4],[8400, 2],[4, 20, 1]</span>\n        mask_pos, align_metric, overlaps = self.<span style=\'color: green;font-weight: bold;\'>get_pos_mask</span>(pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt)\n        target_gt_idx, fg_mask, mask_pos = self.<span style=\'color: green;font-weight: bold;\'>select_highest_overlaps</span>(mask_pos, overlaps, self.n_max_boxes)\n        <span style=\'color: red\'># Assigned target   torch.Size([4, 8400]), torch.Size([4, 8400, 4]), torch.Size([4, 8400, 6])</span>\n        target_labels, target_bboxes, target_scores = self.<span style=\'color: green;font-weight: bold;\'>get_targets</span>(gt_labels, gt_bboxes, target_gt_idx, fg_mask)\n        <span style=\'color: red\'># Normalize</span>\n        align_metric *= mask_pos                                           <span style=\'color: red\'># torch.Size([4, 20, 8400])</span>\n        pos_align_metrics = align_metric.amax(dim=-1, keepdim=True)        <span style=\'color: red\'># b, max_num_obj   torch.Size([4, 20, 1])</span>\n        pos_overlaps = (overlaps * mask_pos).amax(dim=-1, keepdim=True)    <span style=\'color: red\'># b, max_num_obj   torch.Size([4, 20, 1])</span>\n        norm_align_metric = (align_metric * pos_overlaps / (pos_align_metrics + self.eps)).amax(-2).unsqueeze(-1)   <span style=\'color: red\'># torch.Size([4, 20, 8400])/torch.Size([4, 20, 1])-->torch.Size([4, 8400, 1])</span>\n        target_scores = target_scores * norm_align_metric\n        return target_labels, target_bboxes, target_scores, fg_mask.bool(), target_gt_idx  <span style=\'color: red\'># [4, 8400],[4, 8400, 4],[4, 8400, 6],[4, 8400],[4, 8400]</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    def get_pos_mask(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt):         <span style=\'color: red\'># Get in_gts mask, (b, max_num_obj, h*w)</span>\n        mask_in_gts = self.<span style=\'color: green;font-weight: bold;\'>select_candidates_in_gts</span>(anc_points, gt_bboxes)                         <span style=\'color: red\'># 得到torch.Size([4, 20, 8400])</span>\n        <span style=\'color: red\'># Get anchor_align metric, (b, max_num_obj, h*w)</span>\n        align_metric, overlaps = self.<span style=\'color: green;font-weight: bold;\'>get_box_metrics</span>(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n        <span style=\'color: red\'># Get topk_metric mask, (b, max_num_obj, h*w)</span>\n        mask_topk = self.<span style=\'color: green;font-weight: bold;\'>select_topk_candidates</span>(align_metric, topk_mask=mask_gt.expand(-1, -1, self.topk).bool())\n        <span style=\'color: red\'># Merge all mask to a final mask, (b, max_num_obj, h*w)</span>\n        mask_pos = mask_topk * mask_in_gts * mask_gt\n        return mask_pos, align_metric, overlaps   <span style=\'color: red\'># torch.Size([4, 20, 8400])匹配上为1，torch.Size([4, 20, 8400])，torch.Size([4, 20, 8400])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    @staticmethod\n    def select_candidates_in_gts(xy_centers, gt_bboxes, eps=1e-9):\n        n_anchors = xy_centers.shape[0]\n        bs, n_boxes, _ = gt_bboxes.shape\n        lt, rb = gt_bboxes.view(-1, 1, 4).chunk(2, 2)                <span style=\'color: red\'># left-top, right-bottom</span>\n        bbox_deltas = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]), dim=2).view(bs, n_boxes, n_anchors, -1)\n        <span style=\'color: red\'># return (bbox_deltas.min(3)[0] > eps).to(gt_bboxes.dtype)</span>\n        return bbox_deltas.amin(3).gt_(eps)\n</code></pre></font>'}, {'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    def get_box_metrics(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_gt):       <span style=\'color: red\'># Compute alignment metric given predicted and ground truth bounding boxes</span>\n        na = pd_bboxes.shape[-2]                                                          <span style=\'color: red\'># torch.Size([4, 8400, 4])  -- 8400</span>\n        mask_gt = mask_gt.bool()                                                          <span style=\'color: red\'># b, max_num_obj, h*w   torch.Size([4, 20, 8400])</span>\n        overlaps = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_bboxes.dtype, device=pd_bboxes.device)     <span style=\'color: red\'># torch.Size([4, 20, 8400])</span>\n        bbox_scores = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_scores.dtype, device=pd_scores.device)  <span style=\'color: red\'># torch.Size([4, 20, 8400])</span>\n        ind = torch.zeros([2, self.bs, self.n_max_boxes], dtype=torch.long)               <span style=\'color: red\'># 2, b, max_num_obj  --- torch.Size([2, 4, 20])</span>\n        ind[0] = torch.arange(end=self.bs).view(-1, 1).expand(-1, self.n_max_boxes)       <span style=\'color: red\'># b, max_num_obj     --- torch.Size([4, 20])  第0行全为0，第1行全为1，第b-1行全为b-1</span>\n        ind[1] = gt_labels.squeeze(-1)                                                    <span style=\'color: red\'># b, max_num_obj      torch.Size([4, 20, 1]) --> torch.Size([4, 20])</span>\n        <span style=\'color: red\'># Get the scores of each grid for each gt cls </span>\n        bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  <span style=\'color: red\'># b, max_num_obj, h*w  torch.Size([4, 8400, 6])赋值到 torch.Size([4, 20, 8400])</span>\n        <span style=\'color: red\'># (b, max_num_obj, 1, 4), (b, 1, h*w, 4)</span>\n        pd_boxes = pd_bboxes.unsqueeze(1).expand(-1, self.n_max_boxes, -1, -1)[mask_gt]   <span style=\'color: red\'># torch.Size([4, 8400, 4])->(4, 20, 8400, 4)-->(1368, 4)</span>\n        gt_boxes = gt_bboxes.unsqueeze(2).expand(-1, -1, na, -1)[mask_gt]                 <span style=\'color: red\'># torch.Size([4, 20, 4])-> torch.Size([4, 20,8400, 4])-->(1368, 4)</span>\n        overlaps[mask_gt] = self.iou_calculation(gt_boxes, pd_boxes)                      <span style=\'color: red\'># return bbox_iou(gt_bboxes, pd_bboxes, xywh=False, CIoU=True).squeeze(-1).clamp_(0)</span>\n        align_metric = bbox_scores.pow(self.alpha) * overlaps.pow(self.beta)\n        return align_metric, overlaps               <span style=\'color: red\'># torch.Size([4, 20, 8400])  torch.Size([4, 20, 8400]),,4张图片，里面20个GT与8400个点之间的对应值     </span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    def select_topk_candidates(self, metrics, largest=True, topk_mask=None):\n        <span style=\'color: red\'># (b, max_num_obj, topk)  </span>\n        topk_metrics, topk_idxs = torch.topk(metrics, self.topk, dim=-1, largest=largest)   \n        if topk_mask is None:\n            topk_mask = (topk_metrics.max(-1, keepdim=True)[0] > self.eps).expand_as(topk_idxs)\n        <span style=\'color: red\'># (b, max_num_obj, topk)</span>\n        topk_idxs.masked_fill_(~topk_mask, 0)      <span style=\'color: red\'># 不满足条件的top id置0</span>\n        <span style=\'color: red\'># (b, max_num_obj, topk, h*w) -> (b, max_num_obj, h*w)</span>\n        count_tensor = torch.zeros(metrics.shape, dtype=torch.int8, device=topk_idxs.device)     <span style=\'color: red\'># torch.Size([4, 20, 8400])  用于计数每个锚点被选为前k个的次数</span>\n        ones = torch.ones_like(topk_idxs[:, :, :1], dtype=torch.int8, device=topk_idxs.device)   <span style=\'color: red\'># torch.Size([4, 20, 1])</span>\n        for k in range(self.topk):\n            <span style=\'color: red\'># Expand topk_idxs for each value of k and add 1 at the specified positions【这里不明白 (count_tensor>1).sum()=17；(count_tensor==1).sum()=630；(topk_idxs>0).sum()=585】</span>\n            count_tensor.scatter_add_(-1, topk_idxs[:, :, k : k + 1], ones)        <span style=\'color: red\'># 在最后一个维度，的那个位置+1  统计每个位置被选中的次数</span>\n        <span style=\'color: red\'># count_tensor.scatter_add_(-1, topk_idxs, torch.ones_like(topk_idxs, dtype=torch.int8, device=topk_idxs.device))</span>\n        <span style=\'color: red\'># Filter invalid bboxes</span>\n        count_tensor.masked_fill_(count_tensor > 1, 0)                             <span style=\'color: red\'># 为了过滤掉那些由于某种原因被重复选中的候选项</span>\n        return count_tensor.to(metrics.dtype)\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    @staticmethod                                  <span style=\'color: red\'># If an anchor box is assigned to multiple gts, the one with the highest IoU will be selected.</span>\n    def select_highest_overlaps(mask_pos, overlaps, n_max_boxes):       <span style=\'color: red\'># torch.Size([4, 20, 8400]),torch.Size([4, 20, 8400]),20</span>\n        fg_mask = mask_pos.sum(-2)                 <span style=\'color: red\'># (b, n_max_boxes, h*w) -> (b, h*w)  torch.Size([4, 8400])</span>\n        if fg_mask.max() > 1:                      <span style=\'color: red\'># one anchor is assigned to multiple gt_bboxes  一个anchor都多个gt box</span>\n            mask_multi_gts = (fg_mask.unsqueeze(1) > 1).expand(-1, n_max_boxes, -1)  <span style=\'color: red\'># (b, n_max_boxes, h*w)  torch.Size([4, 20, 8400])</span>\n            max_overlaps_idx = overlaps.argmax(1)  <span style=\'color: red\'># (b, h*w)  torch.Size([4, 8400])</span>\n            is_max_overlaps = torch.zeros(mask_pos.shape, dtype=mask_pos.dtype, device=mask_pos.device)  <span style=\'color: red\'># torch.Size([4, 20, 8400])</span>\n            is_max_overlaps.scatter_(1, max_overlaps_idx.unsqueeze(1), 1)     <span style=\'color: red\'># 在第1维度根据索引。。。进行填充</span>\n            mask_pos = torch.where(mask_multi_gts, is_max_overlaps, mask_pos).float()  <span style=\'color: red\'># (b, n_max_boxes, h*w)</span>\n            fg_mask = mask_pos.sum(-2)\n        <span style=\'color: red\'># Find each grid serve which gt(index)</span>\n        target_gt_idx = mask_pos.argmax(-2)  <span style=\'color: red\'># (b, h*w) 该anchor最大的gt索引，该anchor有多少个gt进行匹配 ，20个GT和8400个anchor的overlaps值</span>\n        return target_gt_idx, fg_mask, mask_pos    <span style=\'color: red\'># torch.Size([4, 8400])，torch.Size([4, 8400])，torch.Size([4, 20, 8400])</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">class TaskAlignedAssigner(nn.Module):\n    def get_targets(self, gt_labels, gt_bboxes, target_gt_idx, fg_mask):   <span style=\'color: red\'># 该anchor最大的gt索引，该anchor有多少个gt进行匹配  </span>\n        batch_ind = torch.arange(end=self.bs, dtype=torch.int64, device=gt_labels.device)[..., None]  <span style=\'color: red\'># Assigned target labels, (b, 1) ---> tensor([[0], [1], [2], [3]], device=\'cuda:0\')</span>\n        target_gt_idx = target_gt_idx + batch_ind * self.n_max_boxes                                  <span style=\'color: red\'># (b, h*w) torch.Size([4, 8400]) + tensor([[0], [1*20], [2*20], [3*20]], device=\'cuda:0\') = torch.Size([4, 8400])</span>\n        target_labels = gt_labels.long().flatten()[target_gt_idx]                                     <span style=\'color: red\'># (b, h*w)  torch.Size([4, 8400])</span>\n        <span style=\'color: red\'># Assigned target boxes, (b, max_num_obj, 4) -> (b, h*w, 4)</span>\n        target_bboxes = gt_bboxes.view(-1, gt_bboxes.shape[-1])[target_gt_idx]                        <span style=\'color: red\'># torch.Size([4, 8400, 4])</span>\n        <span style=\'color: red\'># Assigned target scores</span>\n        target_labels.clamp_(0)\n        <span style=\'color: red\'># 10x faster than F.one_hot()</span>\n        target_scores = torch.zeros(\n            (target_labels.shape[0], target_labels.shape[1], self.num_classes),\n            dtype=torch.int64,\n            device=target_labels.device,\n        )  <span style=\'color: red\'># (b, h*w, 80)</span>\n        target_scores.scatter_(2, target_labels.unsqueeze(-1), 1)            <span style=\'color: red\'># torch.Size([4, 8400, 6])</span>\n        fg_scores_mask = fg_mask[:, :, None].repeat(1, 1, self.num_classes)  <span style=\'color: red\'># (b, h*w, 80)  torch.Size([4, 8400, 6])</span>\n        target_scores = torch.where(fg_scores_mask > 0, target_scores, 0)    <span style=\'color: red\'># 设置背景的label为0</span>\n        return target_labels, target_bboxes, target_scores         <span style=\'color: red\'># torch.Size([4, 8400]) + torch.Size([4, 8400, 4]) + torch.Size([4, 8400, 6])</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class BboxLoss(nn.Module):\n    def __init__(self, reg_max, use_dfl=False):\n        super().__init__()\n        self.reg_max = reg_max\n        self.use_dfl = use_dfl\n    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):  <span style=\'color: red\'># IoU loss</span>\n        weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)                                       <span style=\'color: red\'># torch.Size([245, 1])</span>\n        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)         <span style=\'color: red\'># torch.Size([245, 1])</span>\n        loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum\n        if self.use_dfl:               <span style=\'color: red\'># DFL loss</span>\n            target_ltrb = <span style=\'color: green;font-weight: bold;\'>bbox2dist</span>(anchor_points, target_bboxes, self.reg_max)                     <span style=\'color: red\'># self.reg_max=15</span>\n            loss_dfl = self._df_loss(pred_dist[fg_mask].view(-1, self.reg_max + 1), target_ltrb[fg_mask]) * weight\n            loss_dfl = loss_dfl.sum() / target_scores_sum\n        else:\n            loss_dfl = torch.tensor(0.0).to(pred_dist.device)\n        return loss_iou, loss_dfl\n    @staticmethod\n    def _df_loss(pred_dist, target):\n        tl = target.long()  <span style=\'color: red\'># target left   torch.Size([245, 4])</span>\n        tr = tl + 1         <span style=\'color: red\'># target right  torch.Size([245, 4])</span>\n        wl = tr - target    <span style=\'color: red\'># weight left</span>\n        wr = 1 - wl         <span style=\'color: red\'># weight right</span>\n        return (\n            F.cross_entropy(pred_dist, tl.view(-1), reduction="none").view(tl.shape) * wl\n            + F.cross_entropy(pred_dist, tr.view(-1), reduction="none").view(tl.shape) * wr\n        ).mean(-1, keepdim=True)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">def bbox2dist(anchor_points, bbox, reg_max):         <span style=\'color: red\'># Transform bbox(xyxy) to dist(ltrb)</span>\n    x1y1, x2y2 = bbox.chunk(2, -1)                   <span style=\'color: red\'># torch.Size([4, 8400, 2]),torch.Size([4, 8400, 2])</span>\n    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp_(0, reg_max - 0.01)  <span style=\'color: red\'># dist (lt, rb)</span>\n</code></pre></font>'}]}]}]}]}]}]}]}]}]})</script></body>
</html>
