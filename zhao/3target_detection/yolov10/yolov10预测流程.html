<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov10预测流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def predict(self,source=None, stream=False, predictor=None, **kwargs):      <span style=\'color: red\'>\'.......jpg\'  </span>\n        is_cli = (sys.argv[0].endswith("yolo") or sys.argv[0].endswith("ultralytics")) and any(x in sys.argv for x in ("predict","track","mode=predict","mode=track")) <span style=\'color: red\'>False</span>\n        custom = {"conf": 0.25, "batch": 1, "save": is_cli, "mode": "predict"}  <span style=\'color: red\'>method defaults  {\'conf\': 0.25, \'batch\': 1, \'save\': False, \'mode\': \'predict\'}</span>\n        <span style=\'color: red\'>{\'task\': \'detect\', \'data\': \'datasets/side_all/data.yaml\', \'imgsz\': 640, \'single_cls\': False, \'model\': \'runs/....../best.pt\', \'conf\': 0.25, \'batch\': 1, \'save\': False, \'mode\': \'predict\'}</span>\n        args = {**self.overrides, **custom, **kwargs}                           <span style=\'color: red\'>args</span>\n        prompts = args.pop("prompts", None)                                     <span style=\'color: red\'>for SAM-type models</span>\n        if not self.predictor:                                                  <span style=\'color: red\'>True predictor为None,</span>\n            self.predictor = predictor or self._smart_load("predictor")(overrides=args, _callbacks=self.callbacks)  <span style=\'color: red\'>ultralytics.models.yolov10.predict.YOLOv10DetectionPredictor</span>\n            self.predictor.<span style=\'color: green;font-weight: bold;\'>setup_model</span>(model=self.model, verbose=is_cli)\n        else:  <span style=\'color: red\'>only update args if predictor is already setup</span>\n            self.predictor.args = get_cfg(self.predictor.args, args)\n            if "project" in args or "name" in args:\n                self.predictor.save_dir = get_save_dir(self.predictor.args)\n        if prompts and hasattr(self.predictor, "set_prompts"):  <span style=\'color: red\'>for SAM-type models</span>\n            self.predictor.set_prompts(prompts)\n        return self.predictor.predict_cli(source=source) if is_cli else self.<span style=\'color: green;font-weight: bold;\'>predictor</span>(source=source, stream=stream)   <span style=\'color: red\'>ultralytics.models.yolov10.predict.YOLOv10DetectionPredictor</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def setup_model(self, model, verbose=True):          <span style=\'color: red\'># Initialize YOLO model with given parameters and set it to evaluation mode</span>\n        self.model = AutoBackend(\n            weights=model or self.args.model,\n            device=select_device(self.args.device, verbose=verbose),   <span style=\'color: red\'># None,False = device(type=\'cuda\', index=0)</span>\n            dnn=self.args.dnn,       <span style=\'color: red\'># False</span>\n            data=self.args.data,     <span style=\'color: red\'># \'datasets/img_2d/data.yaml\'</span>\n            fp16=self.args.half,     <span style=\'color: red\'># False</span>\n            batch=self.args.batch,   <span style=\'color: red\'># 1</span>\n            fuse=True,\n            verbose=verbose,         <span style=\'color: red\'># False</span>\n        )\n        self.device = self.model.device   <span style=\'color: red\'># update device device(type=\'cuda\', index=0)</span>\n        self.args.half = self.model.fp16  <span style=\'color: red\'># update half</span>\n        self.model.eval()\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python"><span style=\'color: red\'># YOLOv10DetectionPredictor-->DetectionPredictor-->BasePredictor</span>\nclass BasePredictor:\n    def __call__(self, source=None, model=None, stream=False, *args, **kwargs):       <span style=\'color: red\'># Performs inference on an image or stream</span>\n        self.stream = stream                               <span style=\'color: red\'># False</span>\n        if stream:\n            return self.stream_inference(source, model, *args, **kwargs)\n        else:\n            return list(self.<span style=\'color: green;font-weight: bold;\'>stream_inference</span>(source, model, *args, **kwargs))  <span style=\'color: red\'># merge list of Result into one</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    @smart_inference_mode()\n    def stream_inference(self, source=None, model=None, *args, **kwargs):\n        with self._lock:                                                              <span style=\'color: red\'># for thread-safe inference</span>\n            self.<span style=\'color: green;font-weight: bold;\'>setup_source</span>(source if source is not None else self.args.source)   <span style=\'color: red\'># Setup source every time predict is called</span>\n            if self.args.save or self.args.save_txt:                                  <span style=\'color: red\'># Check if save_dir/ label file exists  False</span>\n                (self.save_dir / "labels" if self.args.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)\n            if not self.done_warmup:                                                  <span style=\'color: red\'># Warmup model  -- False</span>\n                self.model.warmup(imgsz=(1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))  <span style=\'color: red\'># imgsz=(1, 3, 640, 640)  AutoBackend.warmup</span>\n                self.done_warmup = True\n            self.seen, self.windows, self.batch = 0, [], None\n            profilers = (ops.Profile(device=self.device),ops.Profile(device=self.device),ops.Profile(device=self.device))\n            self.run_callbacks("on_predict_start")\n            for self.batch in self.dataset:\n                self.run_callbacks("on_predict_batch_start")\n                paths, im0s, s = self.batch             <span style=\'color: red\'># [\'/sdb/zzhu/code_study...003760.jpg\'],[(1080, 1920, 3)],[\'image 1/1 /sdb/zzhu/...3760.jpg: \']</span>\n                <span style=\'color: red\'># Preprocess</span>\n                with profilers[0]:\n                    im = self.<span style=\'color: green;font-weight: bold;\'>preprocess</span>(im0s)        <span style=\'color: red\'># torch.Size([1, 3, 384, 640])</span>\n                <span style=\'color: red\'># Inference</span>\n                with profilers[1]:\n                    preds = self.<span style=\'color: green;font-weight: bold;\'>inference</span>(im, *args, **kwargs)\n                    if self.args.embed:                 <span style=\'color: red\'># None</span>\n                        yield from [preds] if isinstance(preds, torch.Tensor) else preds  <span style=\'color: red\'># yield embedding tensors</span>\n                        continue\n                <span style=\'color: red\'># Postprocess</span>\n                with profilers[2]:\n                    self.results = self.<span style=\'color: green;font-weight: bold;\'>postprocess</span>(preds, im, im0s)   <span style=\'color: red\'># return preds</span>\n                self.run_callbacks("on_predict_postprocess_end")\n                <span style=\'color: red\'># Visualize, save, write results</span>\n                n = len(im0s)\n                for i in range(n):\n                    self.seen += 1\n                    self.results[i].speed = {\n                        "preprocess": profilers[0].dt * 1e3 / n,\n                        "inference": profilers[1].dt * 1e3 / n,\n                        "postprocess": profilers[2].dt * 1e3 / n,\n                    }\n                    if self.args.verbose or self.args.save or self.args.save_txt or self.args.show:\n                        s[i] += self.write_results(i, Path(paths[i]), im, s)\n                <span style=\'color: red\'># Print batch results</span>\n                if self.args.verbose:\n                    LOGGER.info("\\n".join(s))\n                self.run_callbacks("on_predict_batch_end")\n                yield from self.results\n        <span style=\'color: red\'># Release assets</span>\n        for v in self.vid_writer.values():\n            if isinstance(v, cv2.VideoWriter):\n                v.release()\n        <span style=\'color: red\'># Print final results</span>\n        if self.args.verbose and self.seen:\n            t = tuple(x.t / self.seen * 1e3 for x in profilers)  <span style=\'color: red\'># speeds per image</span>\n            LOGGER.info(\n                f"Speed: %.1fms preprocess, %.1fms inference, %.1fms postprocess per image at shape "\n                f"{(min(self.args.batch, self.seen), 3, *im.shape[2:])}" % t\n            )\n        if self.args.save or self.args.save_txt or self.args.save_crop:\n            nl = len(list(self.save_dir.glob("labels/*.txt")))  <span style=\'color: red\'># number of labels</span>\n            s = f"\\n{nl} label{\'s\' * (nl > 1)} saved to {self.save_dir / \'labels\'}" if self.args.save_txt else ""\n            LOGGER.info(f"Results saved to {colorstr(\'bold\', self.save_dir)}{s}")\n        self.run_callbacks("on_predict_end")\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def setup_source(self, source):                  <span style=\'color: red\'># Sets up source and inference mode</span>\n        self.imgsz = check_imgsz(self.args.imgsz, stride=self.model.stride, min_dim=2)  <span style=\'color: red\'># check image size  [640, 640]</span>\n        self.transforms = (getattr(self.model.model,"transforms",classify_transforms(self.imgsz[0], crop_fraction=self.args.crop_fraction),)   <span style=\'color: red\'># None</span>\n            if self.args.task == "classify" else None)                                  <span style=\'color: red\'># ultralytics.data.loaders.LoadImagesAndVideos</span>\n        self.dataset = <span style=\'color: green;font-weight: bold;\'>load_inference_source</span>(source=source,batch=self.args.batch,vid_stride=self.args.vid_stride,buffer=self.args.stream_buffer) \n        self.source_type = self.dataset.source_type\n        if not getattr(self,"stream",True) and (self.source_type.stream or self.source_type.screenshot or len(self.dataset)>1000 or any(getattr(self.dataset,"video_flag",[False]))):\n            LOGGER.warning(STREAM_WARNING)\n        self.vid_writer = {}\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><font size="0"><pre class="language-python"><code class="language-python">def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):\n    source, stream, screenshot, from_img, in_memory, tensor = check_source(source)\n    source_type = source.source_type if in_memory else SourceTypes(stream, screenshot, from_img, tensor)\n    if tensor:\n        dataset = LoadTensor(source)\n    elif in_memory:\n        dataset = source\n    elif stream:\n        dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer)\n    elif screenshot:\n        dataset = LoadScreenshots(source)\n    elif from_img:\n        dataset = LoadPilAndNumpy(source)\n    else:\n        dataset = <span style=\'color: green;font-weight: bold;\'>LoadImagesAndVideos</span>(source, batch=batch, vid_stride=vid_stride)\n    setattr(dataset, "source_type", source_type)                  <span style=\'color: red\'># Attach source types to the dataset</span>\n    return dataset\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/loaders.py</p><font size="0"><pre class="language-python"><code class="language-python">class LoadImagesAndVideos:\n    def __next__(self):                <span style=\'color: red\'># 正常读取，没有做任何操作</span>\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def preprocess(self, im):\n        not_tensor = not isinstance(im, torch.Tensor)      <span style=\'color: red\'># True</span>\n        if not_tensor:\n            im = np.stack(self.<span style=\'color: green;font-weight: bold;\'>pre_transform</span>(im))          <span style=\'color: red\'># (1, 384, 640, 3)</span>\n            im = im[..., ::-1].transpose((0, 3, 1, 2))     <span style=\'color: red\'># BGR to RGB, BHWC to BCHW, (n, 3, h, w) (1, 3, 384, 640)</span>\n            im = np.ascontiguousarray(im)                  <span style=\'color: red\'># contiguous</span>\n            im = torch.from_numpy(im)\n        im = im.to(self.device)\n        im = im.half() if self.model.fp16 else im.float()  <span style=\'color: red\'># uint8 to fp16/32   torch.float32</span>\n        if not_tensor:                                     <span style=\'color: red\'># True</span>\n            im /= 255                                      <span style=\'color: red\'># 0 - 255 to 0.0 - 1.0</span>\n        return im\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    same_shapes = len({x.shape for x in im}) == 1\n    letterbox = <span style=\'color: green;font-weight: bold;\'>LetterBox</span>(self.imgsz, auto=same_shapes and self.model.pt, stride=self.model.stride) <span style=\'color: red\'># [640, 640],auto=True,32</span>\n    return [<span style=\'color: green;font-weight: bold;\'>letterbox</span>(image=x) for x in im]\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/augment.py</p><font size="0"><pre class="language-python"><code class="language-python">class LetterBox:\n    def __init__(self, new_shape=(640, 640), auto=False, scaleFill=False, scaleup=True, center=True, stride=32):\n        self.new_shape = new_shape      <span style=\'color: red\'># [640, 640]</span>\n        self.auto = auto                <span style=\'color: red\'># True</span>\n        self.scaleFill = scaleFill      <span style=\'color: red\'># False</span>\n        self.scaleup = scaleup          <span style=\'color: red\'># True</span>\n        self.stride = stride            <span style=\'color: red\'># 32</span>\n        self.center = center  <span style=\'color: red\'># Put the image in the middle or top-left  True</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/augment.py</p><font size="0"><pre class="language-python"><code class="language-python">class LetterBox:\n    def __call__(self, labels=None, image=None):\n        if labels is None:                <span style=\'color: red\'># None</span>\n            labels = {}\n        img = labels.get("img") if image is None else image       <span style=\'color: red\'># (1080, 1920, 3) ,值范围0-255</span>\n        shape = img.shape[:2]             <span style=\'color: red\'># current shape [height, width]   (1080, 1920)</span>\n        new_shape = labels.pop("rect_shape", self.new_shape)      <span style=\'color: red\'># [640, 640]</span>\n        if isinstance(new_shape, int):    <span style=\'color: red\'># False</span>\n            new_shape = (new_shape, new_shape)\n        <span style=\'color: red\'># Scale ratio (new / old)</span>\n        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1]) <span style=\'color: red\'># min(640/1080,640/1920) = 0.33333333333</span>\n        if not self.scaleup:  <span style=\'color: red\'># only scale down, do not scale up (for better val mAP)  False</span>\n            r = min(r, 1.0)\n        <span style=\'color: red\'># Compute padding</span>\n        ratio = r, r          <span style=\'color: red\'># width, height ratios  (0.3333333333333333, 0.3333333333333333)</span>\n        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))     <span style=\'color: red\'># (640, 360)</span>\n        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  <span style=\'color: red\'># wh padding  0,280</span>\n        if self.auto:         <span style=\'color: red\'># minimum rectangle  True</span>\n            dw, dh = np.mod(dw, self.stride), np.mod(dh, self.stride)      <span style=\'color: red\'># wh padding (0, 24)</span>\n        elif self.scaleFill:  <span style=\'color: red\'># stretch</span>\n            dw, dh = 0.0, 0.0\n            new_unpad = (new_shape[1], new_shape[0])\n            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  <span style=\'color: red\'># width, height ratios</span>\n        if self.center:       <span style=\'color: red\'># True</span>\n            dw /= 2           <span style=\'color: red\'># divide padding into 2 sides  0</span>\n            dh /= 2           <span style=\'color: red\'>#                              12.0</span>\n        if shape[::-1] != new_unpad:  <span style=\'color: red\'># resize  (1080, 1920)[::-1] != (640, 360)</span>\n            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)           <span style=\'color: red\'># (360, 640, 3)</span>\n        top, bottom = int(round(dh - 0.1)) if self.center else 0, int(round(dh + 0.1)) <span style=\'color: red\'># 12,12</span>\n        left, right = int(round(dw - 0.1)) if self.center else 0, int(round(dw + 0.1)) <span style=\'color: red\'># 0,0</span>\n        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))  <span style=\'color: red\'># add border (384, 640, 3)</span>\n        if labels.get("ratio_pad"):                                   <span style=\'color: red\'># False</span>\n            labels["ratio_pad"] = (labels["ratio_pad"], (left, top))  <span style=\'color: red\'># for evaluation</span>\n        if len(labels):                                               <span style=\'color: red\'># False</span>\n            ......\n        else:\n            return img\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def inference(self, im, *args, **kwargs):\n        visualize = (increment_path(self.save_dir / Path(self.batch[0][0]).stem, mkdir=True) if self.args.visualize and (not self.source_type.tensor) else False)  <span style=\'color: red\'># False</span>\n        return self.<span style=\'color: green;font-weight: bold;\'>model</span>(im, augment=self.args.augment, visualize=visualize, embed=self.args.embed, *args, **kwargs)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class v10Detect(Detect):\n    def forward(self, x):\n        one2one = self.<span style=\'color: green;font-weight: bold;\'>forward_feat</span>([xi.detach() for xi in x], self.one2one_cv2, self.one2one_cv3)  <span style=\'color: red\'># # [torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]]</span>\n        if not self.export:\n            one2many = super().<span style=\'color: green;font-weight: bold;\'>forward</span>(x)          <span style=\'color: red\'># (torch.Size([1, 10, 5040]),[torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]])</span>\n        if not self.training:                        <span style=\'color: red\'># True</span>\n            one2one = self.<span style=\'color: green;font-weight: bold;\'>inference</span>(one2one)      <span style=\'color: red\'># (torch.Size([1, 10, 5040]),[torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]])</span>\n            if not self.export:                      <span style=\'color: red\'># True</span>\n                return {"one2many": one2many, "one2one": one2one}        <span style=\'color: red\'># 返回</span>\n            else:\n                ......\n        else:\n            return {"one2many": one2many, "one2one": one2one}\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def forward_feat(self, x, cv2, cv3):\n        y = []\n        for i in range(self.nl):\n            y.append(torch.cat((cv2[i](x[i]), cv3[i](x[i])), 1))\n        return y          <span style=\'color: red\'># [torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]]</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def forward(self, x):\n        y = self.forward_feat(x, self.cv2, self.cv3)   <span style=\'color: red\'># [torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]]</span>\n        if self.training:                              <span style=\'color: red\'># Fasle</span>\n            return y\n        return self.<span style=\'color: green;font-weight: bold;\'>inference</span>(y)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def inference(self, x):                                                          <span style=\'color: red\'># [torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]]</span>\n        shape = x[0].shape                                                           <span style=\'color: red\'># BCHW     torch.Size([1, 70, 48, 80])</span>\n        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)           <span style=\'color: red\'># torch.Size([1, 70, 5040])</span>\n        if self.dynamic or self.shape != shape:                         <span style=\'color: red\'># False or (torch.Size([1, 70, 80, 80]) != torch.Size([1, 70, 48, 80]))</span>\n            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))   <span style=\'color: red\'># torch.Size([2, 5040]),torch.Size([1, 5040])</span>\n            self.shape = shape                                          <span style=\'color: red\'># torch.Size([1, 70, 48, 80])</span>\n        if self.export and self.format in ("saved_model", "pb", "tflite", "edgetpu", "tfjs"):  <span style=\'color: red\'># avoid TF FlexSplitV ops  False</span>\n            box = x_cat[:, : self.reg_max * 4]\n            cls = x_cat[:, self.reg_max * 4 :]\n        else:\n            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)      <span style=\'color: red\'># torch.Size([1, 64, 5040]),torch.Size([1, 6, 5040])</span>\n        if self.export and self.format in ("tflite", "edgetpu"):        <span style=\'color: red\'># False</span>\n            grid_h = shape[2]\n            grid_w = shape[3]\n            grid_size = torch.tensor([grid_w, grid_h, grid_w, grid_h], device=box.device).reshape(1, 4, 1)\n            norm = self.strides / (self.stride[0] * grid_size)\n            dbox = self.decode_bboxes(self.dfl(box) * norm, self.anchors.unsqueeze(0) * norm[:, :2])\n        else:\n            dbox = self.<span style=\'color: green;font-weight: bold;\'>decode_bboxes</span>(self.<span style=\'color: green;font-weight: bold;\'>dfl</span>(box), self.anchors.unsqueeze(0)) * self.strides     <span style=\'color: red\'># torch.Size([1, 4, 5040])</span>\n        y = torch.cat((dbox, cls.sigmoid()), 1)    <span style=\'color: red\'># torch.Size([1, 10, 5040])</span>\n        return y if self.export else (y, x)        <span style=\'color: red\'># self.export=False  (torch.Size([1, 10, 5040]),[torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/block.py</p><font size="0"><pre class="language-python"><code class="language-python">class DFL(nn.Module):\n    def __init__(self, c1=16):\n        super().__init__()\n        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n        x = torch.arange(c1, dtype=torch.float)\n        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n        self.c1 = c1\n    def forward(self, x):\n        b, _, a = x.shape                        <span style=\'color: red\'># torch.Size([1, 64, 5040])</span>\n        <span style=\'color: red\'># [1, 64, 5040]->1,4,16,5040->[1,16,4,5040]-(softmax)>[1,16,4,5040]==(self.conv)==[1, 1, 4, 5040]==>1,4,5040</span>\n        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)  \n</code></pre></font>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def decode_bboxes(self, bboxes, anchors):\n        if self.export:                         <span style=\'color: red\'># False</span>\n            return dist2bbox(bboxes, anchors, xywh=False, dim=1)\n        return <span style=\'color: green;font-weight: bold;\'>dist2bbox</span>(bboxes, anchors, xywh=True, dim=1)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">def dist2bbox(distance, anchor_points, xywh=True, dim=-1):    <span style=\'color: red\'># Transform distance(ltrb) to box(xywh or xyxy)</span>\n    assert(distance.shape[dim] == 4)\n    lt, rb = distance.split([2, 2], dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)  <span style=\'color: red\'># xywh bbox</span>\n    return torch.cat((x1y1, x2y2), dim)    <span style=\'color: red\'># xyxy bbox</span>\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def inference(self, x):                                                          <span style=\'color: red\'># [torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]]</span>\n        shape = x[0].shape                                                           <span style=\'color: red\'># BCHW     torch.Size([1, 70, 48, 80])</span>\n        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)           <span style=\'color: red\'># torch.Size([1, 70, 5040])</span>\n        if self.dynamic or self.shape != shape:                         <span style=\'color: red\'># False or (torch.Size([1, 70, 80, 80]) != torch.Size([1, 70, 48, 80]))</span>\n            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))   <span style=\'color: red\'># torch.Size([2, 5040]),torch.Size([1, 5040])</span>\n            self.shape = shape                                          <span style=\'color: red\'># torch.Size([1, 70, 48, 80])</span>\n        if self.export and self.format in ("saved_model", "pb", "tflite", "edgetpu", "tfjs"):  <span style=\'color: red\'># avoid TF FlexSplitV ops  False</span>\n            box = x_cat[:, : self.reg_max * 4]\n            cls = x_cat[:, self.reg_max * 4 :]\n        else:\n            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)      <span style=\'color: red\'># torch.Size([1, 64, 5040]),torch.Size([1, 6, 5040])</span>\n        if self.export and self.format in ("tflite", "edgetpu"):        <span style=\'color: red\'># False</span>\n            grid_h = shape[2]\n            grid_w = shape[3]\n            grid_size = torch.tensor([grid_w, grid_h, grid_w, grid_h], device=box.device).reshape(1, 4, 1)\n            norm = self.strides / (self.stride[0] * grid_size)\n            dbox = self.decode_bboxes(self.dfl(box) * norm, self.anchors.unsqueeze(0) * norm[:, :2])\n        else:\n            dbox = self.<span style=\'color: green;font-weight: bold;\'>decode_bboxes</span>(self.<span style=\'color: green;font-weight: bold;\'>dfl</span>(box), self.anchors.unsqueeze(0)) * self.strides     <span style=\'color: red\'># torch.Size([1, 4, 5040])</span>\n        y = torch.cat((dbox, cls.sigmoid()), 1)    <span style=\'color: red\'># torch.Size([1, 10, 5040])</span>\n        return y if self.export else (y, x)        <span style=\'color: red\'># self.export=False  (torch.Size([1, 10, 5040]),[torch.Size([1, 70, 48, 80]), [1, 70, 24, 40], [1, 70, 12, 20]])</span>\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolov10/predict.py</p><font size="0"><pre class="language-python"><code class="language-python">class YOLOv10DetectionPredictor(DetectionPredictor):\n    def postprocess(self, preds, img, orig_imgs):\n        if isinstance(preds, dict):\n            preds = preds["one2one"]                      <span style=\'color: red\'># torch.Size([1, 10, 5040])</span>\n        if isinstance(preds, (list, tuple)):\n            preds = preds[0]\n        if preds.shape[-1] == 6:\n            pass\n        else:\n            preds = preds.transpose(-1, -2)               <span style=\'color: red\'># torch.Size([1, 5040, 10])</span>\n            bboxes, scores, labels = ops.<span style=\'color: green;font-weight: bold;\'>v10postprocess</span>(preds, self.args.max_det, preds.shape[-1]-4)\n            bboxes = ops.<span style=\'color: green;font-weight: bold;\'>xywh2xyxy</span>(bboxes)\n            preds = torch.cat([bboxes, scores.unsqueeze(-1), labels.unsqueeze(-1)], dim=-1)    <span style=\'color: red\'># torch.Size([1, 300, 6])</span>\n        mask = preds[..., 4] > self.args.conf             <span style=\'color: red\'># 0.25</span>\n        if self.args.classes is not None:                 <span style=\'color: red\'># False</span>\n            mask = mask & (preds[..., 5:6] == torch.tensor(self.args.classes, device=preds.device).unsqueeze(0)).any(2)\n        preds = [p[mask[idx]] for idx, p in enumerate(preds)]     <span style=\'color: red\'># [torch.Size([15, 6])]</span>\n        if not isinstance(orig_imgs, list):  <span style=\'color: red\'># input images are a torch.Tensor, not a list</span>\n            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)\n        results = []\n        for i, pred in enumerate(preds):\n            orig_img = orig_imgs[i]\n            pred[:, :4] = ops.<span style=\'color: green;font-weight: bold;\'>scale_boxes</span>(img.shape[2:], pred[:, :4], orig_img.shape)\n            img_path = self.batch[0][i]\n            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))\n        return results\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/ops.py</p><font size="0"><pre class="language-python"><code class="language-python">def v10postprocess(preds, max_det, nc=80):          <span style=\'color: red\'># torch.Size([1, 5040, 10]),300,10</span>\n    assert(4 + nc == preds.shape[-1])\n    boxes, scores = preds.split([4, nc], dim=-1)    <span style=\'color: red\'># torch.Size([1, 5040, 4]) + torch.Size([1, 5040, 6])</span>\n    max_scores = scores.amax(dim=-1)                <span style=\'color: red\'># torch.Size([1, 5040])</span>\n    max_scores, index = torch.topk(max_scores, max_det, dim=-1)                        <span style=\'color: red\'># torch.Size([1, 300]), torch.Size([1, 300])</span>\n    index = index.unsqueeze(-1)                     <span style=\'color: red\'>#  torch.Size([1, 300, 1]),</span>\n    boxes = torch.gather(boxes, dim=1, index=index.repeat(1, 1, boxes.shape[-1]))      <span style=\'color: red\'># torch.Size([1, 300, 4])</span>\n    scores = torch.gather(scores, dim=1, index=index.repeat(1, 1, scores.shape[-1]))   <span style=\'color: red\'># torch.Size([1, 300, 6])</span>\n    scores, index = torch.topk(scores.flatten(1), max_det, dim=-1)        <span style=\'color: red\'># torch.Size([1, 1800])-->torch.Size([1, 300])+torch.Size([1, 300])  这里同一个框有两个label</span>\n    labels = index % nc             <span style=\'color: red\'># torch.Size([1, 300])</span>\n    index = index <span style=\'color: red\'>// nc</span>\n    boxes = boxes.gather(dim=1, index=index.unsqueeze(-1).repeat(1, 1, boxes.shape[-1]))\n    return boxes, scores, labels    <span style=\'color: red\'># torch.Size([1, 300, 4])，torch.Size([1, 300, 1])，torch.Size([1, 300, 1])</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/ops.py</p><font size="0"><pre class="language-python"><code class="language-python">def xywh2xyxy(x):\n    assert x.shape[-1] == 4, f"input shape last dimension expected 4 but input shape is {x.shape}"\n    y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)  <span style=\'color: red\'># faster than clone/copy</span>\n    dw = x[..., 2] / 2  <span style=\'color: red\'># half-width</span>\n    dh = x[..., 3] / 2  <span style=\'color: red\'># half-height</span>\n    y[..., 0] = x[..., 0] - dw  <span style=\'color: red\'># top left x</span>\n    y[..., 1] = x[..., 1] - dh  <span style=\'color: red\'># top left y</span>\n    y[..., 2] = x[..., 0] + dw  <span style=\'color: red\'># bottom right x</span>\n    y[..., 3] = x[..., 1] + dh  <span style=\'color: red\'># bottom right y</span>\n    return y\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/ops.py</p><font size="0"><pre class="language-python"><code class="language-python">def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None, padding=True, xywh=False):\n    if ratio_pad is None:                                                         <span style=\'color: red\'># calculate from img0_shape</span>\n        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  <span style=\'color: red\'># gain  = old / new  0.3333333333333333</span>\n        pad = (\n            round((img1_shape[1] - img0_shape[1] * gain) / 2 - 0.1),\n            round((img1_shape[0] - img0_shape[0] * gain) / 2 - 0.1),\n        )                                                                         <span style=\'color: red\'># wh padding</span>\n    else:\n        gain = ratio_pad[0][0]\n        pad = ratio_pad[1]\n    if padding:\n        boxes[..., 0] -= pad[0]  <span style=\'color: red\'># x padding</span>\n        boxes[..., 1] -= pad[1]  <span style=\'color: red\'># y padding</span>\n        if not xywh:\n            boxes[..., 2] -= pad[0]  <span style=\'color: red\'># x padding</span>\n            boxes[..., 3] -= pad[1]  <span style=\'color: red\'># y padding</span>\n    boxes[..., :4] /= gain\n    return <span style=\'color: green;font-weight: bold;\'>clip_boxes</span>(boxes, img0_shape)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/ops.py</p><font size="0"><pre class="language-python"><code class="language-python">def clip_boxes(boxes, shape):\n    if isinstance(boxes, torch.Tensor):  <span style=\'color: red\'># faster individually (WARNING: inplace .clamp_() Apple MPS bug)</span>\n        boxes[..., 0] = boxes[..., 0].clamp(0, shape[1])  <span style=\'color: red\'># x1</span>\n        boxes[..., 1] = boxes[..., 1].clamp(0, shape[0])  <span style=\'color: red\'># y1</span>\n        boxes[..., 2] = boxes[..., 2].clamp(0, shape[1])  <span style=\'color: red\'># x2</span>\n        boxes[..., 3] = boxes[..., 3].clamp(0, shape[0])  <span style=\'color: red\'># y2</span>\n    else:  <span style=\'color: red\'># np.array (faster grouped)</span>\n        boxes[..., [0, 2]] = boxes[..., [0, 2]].clip(0, shape[1])  <span style=\'color: red\'># x1, x2</span>\n        boxes[..., [1, 3]] = boxes[..., [1, 3]].clip(0, shape[0])  <span style=\'color: red\'># y1, y2</span>\n    return boxes\n</code></pre></font>'}]}]}]}]}]}]})</script></body>
</html>
