<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>detr训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/detr.py</p><span class=\'hidden-code\' data-code=\'class DETR(nn.Module):\n    def forward(self, samples: NestedTensor):\n        if isinstance(samples, (list, torch.Tensor)):\n            samples = nested_tensor_from_tensor_list(samples)\n        features, pos = self.backbone(samples)  # 先经过backbone得到pos位置嵌入和features是list，包含不同的backbone的layer 每个item是包含mask和tensors的NestedTesnor\n        src, mask = features[-1].decompose()      # 分解出feature[bs,2048,h,w]和mask[bs,2048,h,w] 分割任务的mask在不同的特征图尺寸上的插值\n        assert mask is not None\n        # self.input_proj = nn.Conv2d(backbone.num_channels, hidden_dim, kernel_size=1) 1x1 衔接 backbone和transformer input_proj [bs,2048,h,w] --input_proj--> [bs,256,h,w]\n        # query_embed.weight [100,256]里面[0] hs返回两个返回值，0就是transformer decoder的输出，1是encoder的输出 hs (6,bs,100,256)；用于seg使用\n        hs = self.`transformer`(self.input_proj(src), mask, self.query_embed.weight, pos[-1])[0]\n        outputs_class = self.class_embed(hs)             # 类别的输出  outpus_class (6,bs,100,92)     # 6代表6层的输出\n        outputs_coord = self.bbox_embed(hs).sigmoid()    # bbox的输出,[6,bs,100,4],bbox的值都是相对于图片的hw的因此都是小于1的，因此使用sigmoid将值约束在0-1\n        out = {&amp;#39;pred_logits&amp;#39;: outputs_class[-1], &amp;#39;pred_boxes&amp;#39;: outputs_coord[-1]}       # 6层decoder,取最后一层的输出\n        if self.aux_loss:\n            out[&amp;#39;aux_outputs&amp;#39;] = self._set_aux_loss(outputs_class, outputs_coord)       # 计算辅助loss，计算前几层decoder输出的loss\n        return out\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/transformer.py</p><span class=\'hidden-code\' data-code=\'class Transformer(nn.Module):\n    def forward(self, src, mask, query_embed, pos_embed):           # self.query_embed = nn.Embedding(num_queries, hidden_dim) 注意与pose_embed区别\n        # scr: (bs 256 H W)  mask: (bs H W) query_embed: (100,256) pos_embed: (bs 256 H W)\n        bs, c, h, w = src.shape                                     # flatten NxCxHxW to HWxNxC  -> HW,bs,256\n        src = src.flatten(2).permute(2, 0, 1)\n        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)           # HW,bs,256\n        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)     # query_embed 是给decoder使用的  100， 256 中间加个维度，并将这个维度重复 bs 次 -> 100,bs,256\n        mask = mask.flatten(1)                                      # hw 推平     \n        memory = self.`encoder`(src, src_key_padding_mask=mask, pos=pos_embed)    # feature和位置编码 进入encoder网络 输出 memory: HW,bs,256\n        tgt = torch.zeros_like(query_embed)    # [100,bs,256]\n        hs = self.`decoder`(tgt, memory, memory_key_padding_mask=mask,pos=pos_embed, query_pos=query_embed)  # tgt, encoder的输出，位置编码，以及query输入到decoder--->hs [6(decoder layer number),100,bs,256]\n        # hs  decoder的输出 [6,100,bs,256] --transpose--> [6,bs,100,256]\n        # memory  encoder的输出 [hw,bs,256] --permute--> [bs,256,hw] --view--> [bs,256,h,w]\n        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h, w)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/transformer.py</p><span class=\'hidden-code\' data-code=\'class TransformerEncoder(nn.Module):\n    def forward(self, src, mask, src_key_padding_mask, pos):\n        output = src\n        for layer in self.layers:         # 6层\n            output = `layer`(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, pos=pos)\n        if self.norm is not None:\n            output = self.norm(output)    # 最后经过norm\n        return output\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/transformer.py</p><span class=\'hidden-code\' data-code=\'class TransformerEncoderLayer(nn.Module):\n    def forward_post(self, src, src_mask, src_key_padding_mask, pos):\n        q = k = self.`with_pos_embed`(src, pos)    # src: (hw,3,256) [tensor + pos]   q k 融合位置编码，value不使用位置编码\n        src2 = self.`self_attn`(q, k, value=src, attn_mask=src_mask,key_padding_mask=src_key_padding_mask)[0]  # nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        src = src + self.dropout1(src2)\n        src = self.norm1(src)\n        # FFN\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n        # 残差的就直接加进去了\n        src = src + self.dropout2(src2)\n        src = self.norm2(src)\n        return src\n\'> </span>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/transformer.py</p><span class=\'hidden-code\' data-code=\'class TransformerDecoder(nn.Module):\n    def forward(self,tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask,\n                memory_key_padding_mask, pos, query_pos):\n        # tgt: [100,bs,256] 全0与query_embed大小相同\n        # memory: [hw,bs,256] encoder的输出    pos: [hw,bs,256]   query_pos: [100,bs,256]\n        output = tgt\n        intermediate = []      # 保留中间层的输出\n        for layer in self.layers:\n            # [100,bs,256]\n            output = `layer`(output, memory, tgt_mask=tgt_mask,memory_mask=memory_mask,tgt_key_padding_mask=tgt_key_padding_mask,\n                           memory_key_padding_mask=memory_key_padding_mask,pos=pos, query_pos=query_pos)\n            if self.return_intermediate:        # 每一个中间层计算的结果需要返回\n                intermediate.append(self.norm(output))\n        if self.norm is not None:\n            output = self.norm(output)         # 最后经过norm\n            if self.return_intermediate:\n                intermediate.pop()             # 弹出最后一个，加上上面经过norm的\n                intermediate.append(output)\n        if self.return_intermediate:\n            return torch.stack(intermediate)\n        return output.unsqueeze(0)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/transformer.py</p><span class=\'hidden-code\' data-code=\'class TransformerDecoderLayer(nn.Module):\n    # norm在操作后\n    def forward_post(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask,\n                     pos, query_pos):\n        q = k = self.with_pos_embed(tgt, query_pos)        # tensor + pos\n        tgt2 = self.self_attn(q,k,value=tgt,attn_mask=tgt_mask,key_padding_mask=tgt_key_padding_mask)[0]  # nn.MultiheadAttention\n        tgt = tgt + self.dropout1(tgt2)\n        tgt = self.norm1(tgt)  \n        tgt2 = self.multihead_attn(                         # 各项值的组合方式与论文中的图像是一致的\n            query=self.with_pos_embed(tgt, query_pos),      # 第二个attention的query是第一个attention的输出\n            key=self.with_pos_embed(memory, pos),           # 两个参数，跟上面的都不同 使用了encoder的输出memory，以及位置编码\n            value=memory,                                   # 上面是tgt，这个是memory  encoder的输出memory是decoder中第二个attention的value\n            attn_mask=memory_mask,\n            key_padding_mask=memory_key_padding_mask)[0]\n        # 第二个dropout  这里的tgt是第一个attention的输出 加上 第二个attention的输出\n        tgt = tgt + self.dropout2(tgt2)\n        tgt = self.norm2(tgt)\n        # FFN\n        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n        # 第三个dropout\n        tgt = tgt + self.dropout3(tgt2)\n        tgt = self.norm3(tgt)\n        return tgt\n\'> </span>'}]}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">loss计算</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/detr.py</p><span class=\'hidden-code\' data-code=\'class SetCriterion(nn.Module):\n    def forward(self, outputs, targets):\n        outputs_without_aux = {k: v for k, v in outputs.items() if k != &amp;#39;aux_outputs&amp;#39;}    # without 这里排除aux\n        # 进行匈牙利匹配\n        indices = self.`matcher`(outputs_without_aux, targets)    # indices是list, 长度是bs, 每个item是一个tuple, 第一个值是100个框的id，第二个值是gt的id\n        num_boxes = sum(len(t[&amp;#39;labels&amp;#39;]) for t in targets)      # batch中所有的box的数量\n        num_boxes = torch.as_tensor([num_boxes], dtype=torch.float, device=next(iter(outputs.values())).device)\n        if is_dist_avail_and_initialized():\n            torch.distributed.all_reduce(num_boxes)                           # 所有卡的num_boxes相同\n        num_boxes = torch.clamp(num_boxes / get_world_size(), min=1).item()   # 除以卡数\n        # 计算后是loss_ce, class_error, loss_bbox, loss_giou, cardinality_error\n        losses = {}\n        for loss in self.losses:                                                           # slef.losses 是labels,boxes, cardinality                                        \n            losses.update(self.get_loss(loss, outputs, targets, indices, num_boxes))       # 计算每一项的内容, 如 labels, boxes, cardinality\n        # 处理 aux loss\n        if &amp;#39;aux_outputs&amp;#39; in outputs:\n            for i, aux_outputs in enumerate(outputs[&amp;#39;aux_outputs&amp;#39;]):\n                indices = self.matcher(aux_outputs, targets)\n                for loss in self.losses:\n                    if loss == &amp;#39;masks&amp;#39;:                # masks的loss就不计算这个了，计算量大\n                        continue\n                    kwargs = {}\n                    if loss == &amp;#39;labels&amp;#39;:               # Logging is enabled only for the last layer\n                        kwargs = {&amp;#39;log&amp;#39;: False}\n                    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_boxes, **kwargs)\n                    l_dict = {k + f&amp;#39;_{i}&amp;#39;: v for k, v in l_dict.items()}\n                    losses.update(l_dict)\n        return losses\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/matcher.py</p><span class=\'hidden-code\' data-code=\'class HungarianMatcher(nn.Module):\n    def forward(self, outputs, targets):  \n        bs, num_queries = outputs[&amp;#39;pred_logits&amp;#39;].shape[:2]            # bs is batch_size; num_queries 是配置的每张图片中多少个目标=100\n        out_prob = outputs[&amp;#39;pred_logits&amp;#39;].flatten(0, 1).softmax(1)    # 前两个拉平在一起，最后一个维度是类别，进行softmax  [batch_size * num_queries, num_classes]\n        out_bbox = outputs[&amp;#39;pred_boxes&amp;#39;].flatten(0, 1)                # [batch_size * num_queries, 4]\n        # Also concat the target labels and boxes\n        tgt_ids = torch.cat([v[&amp;#39;labels&amp;#39;] for v in targets])           # target label\n        tgt_bbox = torch.cat([v[&amp;#39;boxes&amp;#39;] for v in targets])           # target bbox\n        # 取出对应的类别的分数，每个框 的 所有gt的label的分数 [bs*100,92][:,tgt_ids] --> [bs*100, 所有bs中img上的gt的数量和]\n        # 一个预测框上的 对应的 在所有的gt上的分数\n        cost_class = -out_prob[:, tgt_ids]\n        # out_bbox is [bs*100,4] tgt_box is [all_img_gt_count,4]\n        # Compute the L1 cost between boxes -> [bs*100, all_img_gt_count]    p=1 计算l1距离\n        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)              # cost_bbox 和 cost_class的维度是一样的\n        # 计算的GIoU  先进行中心点宽高变成坐上右下四个坐标值\n        # 所有的框，跟gt的giou [bs*100, all_img_gt_count]; Compute the giou cost betwen boxes\n        # 完全相同位置的框 giou是1，完全不相交的框，giou是负数  因此这里加了一个负号，完全不相交的框的值就变成了整数，表示了更大的代价\n        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))\n        # 最终的代价矩阵，匈牙利匹配使用的，最终是要总的分配的代价最小  前面都是各个项的权重系数\n        # Final cost matrix [bs*100, all_img_gt_count]\n        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou\n        # [bs*100, all_img_gt_count] -> [3,100,all_img_gt_count]    .cpu 为了给scipy计算 维度变为 batch_size , 100, gt的数量\n        C = C.view(bs, num_queries, -1).cpu()\n        # 每个图片对应的gt的数量\n        sizes = [len(v[&amp;#39;boxes&amp;#39;]) for v in targets]\n        # linear_sum_assignment 就是匈牙利算法\n        # C.split 按照每个图片的gt的数量进行切分;  第一个值是100内的id，表明100内取哪一个框，第二个应该是对应了哪一个gt的id\n        # indices的一个例子[(array([ 0, 51]), array([0, 1])), (array([13, 24, 54, 86]), array([0, 1, 3, 2]))]\n        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]\n        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]\n\'> </span>'}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
