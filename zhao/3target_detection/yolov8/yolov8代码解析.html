<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov8代码解析</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型结构</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/model.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class YOLO(Model):        <span style=\'color: red\'># YOLO (You Only Look Once) object detection model</span>\n    @property\n    def task_map(self):\n        return {\n            "classify": {\n                "model": ClassificationModel,\n                "trainer": yolo.classify.ClassificationTrainer,\n                "validator": yolo.classify.ClassificationValidator,\n                "predictor": yolo.classify.ClassificationPredictor,\n            },\n            "detect": {\n                "model": DetectionModel,\n                "trainer": yolo.detect.DetectionTrainer,\n                "validator": yolo.detect.DetectionValidator,\n                "predictor": yolo.detect.DetectionPredictor,\n            },\n        }\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class DetectionModel(BaseModel):           <span style=\'color: red\'># YOLOv8 detection model</span>\n    def __init__(self, cfg="yolov8n.yaml", ch=3, nc=None, verbose=True):    <span style=\'color: red\'># model, input channels, number of classes</span>\n        super().__init__()\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)  <span style=\'color: red\'># cfg dict</span>\n        <span style=\'color: red\'># Define model</span>\n        ch = self.yaml["ch"] = self.yaml.get("ch", ch)  <span style=\'color: red\'># input channels   3 </span>\n        if nc and nc != self.yaml["nc"]:\n            LOGGER.info(f"Overriding model.yaml nc={self.yaml[\'nc\']} with nc={nc}")\n            self.yaml["nc"] = nc                        <span style=\'color: red\'># override YAML value</span>\n        self.model, self.save = <span style=\'color: green;font-weight: bold;\'>parse_model</span>(deepcopy(self.yaml), ch=ch, verbose=verbose)  <span style=\'color: red\'># model, savelist</span>\n        self.names = {i: f"{i}" for i in range(self.yaml["nc"])}  <span style=\'color: red\'># default names dict</span>\n        self.inplace = self.yaml.get("inplace", True)\n        <span style=\'color: red\'># Build strides</span>\n        m = self.model[-1]  <span style=\'color: red\'># Detect()</span>\n        if isinstance(m, (Detect, Segment, Pose, OBB)):\n            s = 256  <span style=\'color: red\'># 2x min stride</span>\n            m.inplace = self.inplace\n            forward = lambda x: self.forward(x)[0] if isinstance(m, (Segment, Pose, OBB)) else self.forward(x)\n            m.stride = torch.tensor([s / x.shape[-2] for x in forward(torch.zeros(1, ch, s, s))])  <span style=\'color: red\'># forward</span>\n            self.stride = m.stride\n            m.bias_init()  <span style=\'color: red\'># only run once</span>\n        else:\n            self.stride = torch.Tensor([32])  <span style=\'color: red\'># default stride for i.e. RTDETR</span>\n        <span style=\'color: red\'># Init weights, biases</span>\n        initialize_weights(self)\n        if verbose:\n            self.info()\n            LOGGER.info("")\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def parse_model(d, ch, verbose=True):  <span style=\'color: red\'># model_dict-配置文件中的字典, input_channels(3)</span>\n    import ast\n    <span style=\'color: red\'># Args</span>\n    max_channels = float("inf")\n    nc, act, scales = (d.get(x) for x in ("nc", "activation", "scales"))                                  <span style=\'color: red\'># 80, None, {\'n\':[0.33, 0.25, 1024]} </span>\n    depth, width, kpt_shape = (d.get(x, 1.0) for x in ("depth_multiple", "width_multiple", "kpt_shape"))  <span style=\'color: red\'># 1, 1, 1</span>\n    if scales:\n        scale = d.get("scale")                     <span style=\'color: red\'># ""</span>\n        if not scale:\n            scale = tuple(scales.keys())[0]        <span style=\'color: red\'># n</span>\n            LOGGER.warning(f"WARNING ⚠️ no model scale passed. Assuming scale=\'{scale}\'.")\n        depth, width, max_channels = scales[scale] <span style=\'color: red\'># 0.33, 0.25, 1024</span>\n    if act:                                         <span style=\'color: red\'># None</span>\n        Conv.default_act = eval(act)                <span style=\'color: red\'># redefine default activation, i.e. Conv.default_act = nn.SiLU()</span>\n        if verbose:\n            LOGGER.info(f"{colorstr(\'activation:\')} {act}")  <span style=\'color: red\'># print</span>\n    if verbose:            <span style=\'color: red\'># True打印结果</span>\n        LOGGER.info(f"\\n{\'\':<span style=\'color: green;font-weight: bold;\'>></span>3}{\'from\':<span style=\'color: green;font-weight: bold;\'>></span>20}{\'n\':<span style=\'color: green;font-weight: bold;\'>></span>3}{\'params\':<span style=\'color: green;font-weight: bold;\'>></span>10}  {\'module\':<span style=\'color: green;font-weight: bold;\'><</span>45}{\'arguments\':<span style=\'color: green;font-weight: bold;\'><</span>30}")\n    ch = [ch]                          <span style=\'color: red\'># [3]</span>\n    layers, save, c2 = [], [], ch[-1]  <span style=\'color: red\'># layers-运行哪层, savelist, ch out</span>\n    for i, (f, n, m, args) in enumerate(d["backbone"] + d["head"]):  <span style=\'color: red\'># from, number, module, args</span>\n        m = getattr(torch.nn, m[3:]) if "nn." in m else globals()[m]  <span style=\'color: red\'># get module</span>\n        for j, a in enumerate(args):\n            if isinstance(a, str):\n                with contextlib.suppress(ValueError):\n                    args[j] = locals()[a] if a in locals() else ast.literal_eval(a)\n        n = n_ = max(round(n * depth), 1) if n > 1 else n  <span style=\'color: red\'># depth gain</span>\n        if m in (\n            Classify,\n            Conv,\n            ConvTranspose,\n            GhostConv,\n            Bottleneck,\n            GhostBottleneck,\n            SPP,\n            SPPF,\n            DWConv,\n            Focus,\n            BottleneckCSP,\n            C1,\n            C2,\n            C2f,\n            C3,\n            C3TR,\n            C3Ghost,\n            nn.ConvTranspose2d,\n            DWConvTranspose2d,\n            C3x,\n            RepC3,\n        ):\n            c1, c2 = ch[f], args[0]\n            if c2 != nc:  <span style=\'color: red\'># if c2 not equal to number of classes (i.e. for Classify() output)</span>\n                c2 = make_divisible(min(c2, max_channels) * width, 8)\n            args = [c1, c2, *args[1:]]\n            if m in (BottleneckCSP, C1, C2, C2f, C3, C3TR, C3Ghost, C3x, RepC3):\n                args.insert(2, n)  <span style=\'color: red\'># number of repeats</span>\n                n = 1\n        elif m is AIFI:\n            args = [ch[f], *args]\n        elif m in (HGStem, HGBlock):\n            c1, cm, c2 = ch[f], args[0], args[1]\n            args = [c1, cm, c2, *args[2:]]\n            if m is HGBlock:\n                args.insert(4, n)  <span style=\'color: red\'># number of repeats</span>\n                n = 1\n        elif m is ResNetLayer:\n            c2 = args[1] if args[3] else args[1] * 4\n        elif m is nn.BatchNorm2d:\n            args = [ch[f]]\n        elif m is Concat:\n            c2 = sum(ch[x] for x in f)\n        elif m in (Detect, Segment, Pose, OBB):\n            args.append([ch[x] for x in f])\n            if m is Segment:\n                args[2] = make_divisible(min(args[2], max_channels) * width, 8)\n        elif m is RTDETRDecoder:  <span style=\'color: red\'># special case, channels arg must be passed in index 1</span>\n            args.insert(1, [ch[x] for x in f])\n        else:\n            c2 = ch[f]\n        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  <span style=\'color: red\'># module</span>\n        t = str(m)[8:-2].replace("__main__.", "")  <span style=\'color: red\'># module type</span>\n        m.np = sum(x.numel() for x in m_.parameters())  <span style=\'color: red\'># number params</span>\n        m_.i, m_.f, m_.type = i, f, t  <span style=\'color: red\'># attach index, \'from\' index, type</span>\n        if verbose:\n            LOGGER.info(f"{i:<span style=\'color: green;font-weight: bold;\'>></span>3}{str(f):<span style=\'color: green;font-weight: bold;\'>></span>20}{n_:<span style=\'color: green;font-weight: bold;\'>></span>3}{m.np:10.0f}  {t:<span style=\'color: green;font-weight: bold;\'><</span>45}{str(args):<span style=\'color: green;font-weight: bold;\'><</span>30}")  <span style=\'color: red\'># print</span>\n        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  <span style=\'color: red\'># append to savelist</span>\n        layers.append(m_)\n        if i == 0:\n            ch = []\n        ch.append(c2)\n    return nn.Sequential(*layers), sorted(save)\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型head推理</p>'}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型预测</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class Detect(nn.Module):\n    def forward(self, x):\n        for i in range(self.nl):         <span style=\'color: red\'># [torch.Size([1, 128, 80, 80]),[1, 256, 40, 40],[1, 512, 20, 20]]-->[torch.Size([1, 144, 80, 80]),[1, 144, 40, 40],[1, 144, 20, 20]]</span>\n            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)  \n        if self.training:                <span style=\'color: red\'># Training path</span>\n            return x\n        <span style=\'color: red\'># Inference path</span>\n        shape = x[0].shape               <span style=\'color: red\'># BCHW  torch.Size([1, 144, 80, 80])</span>\n        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)       <span style=\'color: red\'># torch.Size([1, 144, 8400])</span>\n        if self.dynamic or self.shape != shape:                                  <span style=\'color: red\'># False or [136, 128, 80, 80]!=[1, 144, 80, 80]</span>\n            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))  <span style=\'color: red\'># torch.Size([2, 8400]) + torch.Size([1, 8400])</span>\n            self.shape = shape \n        if self.export and self.format in {"saved_model", "pb", "tflite", "edgetpu", "tfjs"}:  <span style=\'color: red\'># avoid TF FlexSplitV ops</span>\n            ......\n        else:\n            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)               <span style=\'color: red\'># torch.Size([1, 64, 8400]) + torch.Size([1, 80, 8400])</span>\n        if self.export and self.format in {"tflite", "edgetpu"}:\n            ......\n        else:\n            dbox = self.decode_bboxes(self.dfl(box), self.anchors.unsqueeze(0)) * self.strides          <span style=\'color: red\'># torch.Size([1, 4, 8400])</span>\n        y = torch.cat((dbox, cls.sigmoid()), 1)                                                         <span style=\'color: red\'># torch.Size([1, 84, 8400])  80个类别</span>\n        return y if self.export else (y, x)            <span style=\'color: red\'># False,(torch.Size([1, 84, 8400]), torch.Size([1, 144, 80, 80]),[1, 144, 40, 40],[1, 144, 20, 20] )     </span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/detect/predict.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class DetectionPredictor(BasePredictor):\n    def postprocess(self, preds, img, orig_imgs):\n        preds = ops.non_max_suppression(               \n            preds,                              <span style=\'color: red\'># torch.Size([1, 84, 6300]), [torch.Size([1, 144, 80, 60]), torch.Size([1, 144, 40, 30]), torch.Size([1, 144, 20, 15])]</span>\n            self.args.conf,                     <span style=\'color: red\'># 0.25</span>\n            self.args.iou,                      <span style=\'color: red\'># 0.7</span>\n            agnostic=self.args.agnostic_nms,    <span style=\'color: red\'># False</span>\n            max_det=self.args.max_det,          <span style=\'color: red\'># 300</span>\n            classes=self.args.classes,          <span style=\'color: red\'># None</span>\n        )\n        if not isinstance(orig_imgs, list):     <span style=\'color: red\'># input images are a torch.Tensor, not a list      False [(1080, 810, 3),]</span>\n            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)\n        results = []\n        for i, pred in enumerate(preds):        <span style=\'color: red\'># [torch.Size([5, 6])]</span>\n            orig_img = orig_imgs[i]\n            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)\n            img_path = self.batch[0][i]\n            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))\n        return results\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/ops.py</p>'}]}]}]})</script></body>
</html>
