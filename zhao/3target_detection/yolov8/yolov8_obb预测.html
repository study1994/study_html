<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov8_obb预测</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">预测过程</p><span class=\'hidden-code\' data-code=\'from ultralytics import YOLO\nmodel = `YOLO`(&amp;#39;yolov8s-obb.pt&amp;#39;)                        load an official model\nresults = `model`(&amp;#39;datasets/test_data/obb/P0015.png&amp;#39;)   predict on an image\nresults[0].save(&amp;#39;datasets/test_data/obb_res/P0015.png&amp;#39;)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/model.py</p><span class=\'hidden-code\' data-code=\'class YOLO(Model):\n    def __init__(self, model=&amp;#39;yolov8n.pt&amp;#39;, task=None, verbose=False):     \n        path = Path(model)                             # &amp;#39;yolov8s-obb.pt&amp;#39;\n        if &amp;#39;-world&amp;#39; in path.stem and path.suffix in {&amp;#39;.pt&amp;#39;, &amp;#39;.yaml&amp;#39;, &amp;#39;.yml&amp;#39;}:  # if YOLOWorld PyTorch model\n            ......\n        else:\n            super().`__init__`(model=model, task=task, verbose=verbose)          # Continue with default YOLO initialization\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    ......\n    self.`_load`(model, task=task)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def _load(self, weights: str, task=None) -> None:\n        weights = checks.check_model_file_from_stem(weights)  #  add suffix, i.e. yolov8n -> yolov8n.pt\n        if Path(weights).suffix == &amp;#39;.pt&amp;#39;:\n            self.model, self.ckpt = `attempt_load_one_weight`(weights)\n            self.task = self.model.args[&amp;#39;task&amp;#39;]               # &amp;#39;obb\n            self.overrides = self.model.args = self._reset_ckpt_args(self.model.args)\n            self.ckpt_path = self.model.pt_path               # &amp;#39;yolov8s-obb.pt&amp;#39;\n        else:\n            ......\n        self.overrides[&amp;#39;model&amp;#39;] = weights\n        self.overrides[&amp;#39;task&amp;#39;] = self.task\n        self.model_name = weights\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><span class=\'hidden-code\' data-code=\'def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):\n    ckpt, weight = torch_safe_load(weight)  # load ckpt\n    args = {**DEFAULT_CFG_DICT, **(ckpt.get(&amp;#39;train_args&amp;#39;, {}))}    # combine model and default args, preferring model args\n    model = (ckpt.get(&amp;#39;ema&amp;#39;) or ckpt[&amp;#39;model&amp;#39;]).to(device).float()  # FP32 model   OBBModel(......)\n    # Model compatibility updates\n    model.args = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # attach args to model\n    model.pt_path = weight                                         # attach *.pt file path to model\n    model.task = guess_model_task(model)                           # &amp;#39;obb&amp;#39;\n    if not hasattr(model, &amp;#39;stride&amp;#39;):\n        model.stride = torch.tensor([32.0])\n    model = model.fuse().eval() if fuse and hasattr(model, &amp;#39;fuse&amp;#39;) else model.eval()  # model in eval mode  fuse=False,hasattr(model, &amp;#39;fuse&amp;#39;)=True\n    # Module updates\n    for m in model.modules():\n        if hasattr(m, &amp;#39;inplace&amp;#39;):\n            m.inplace = inplace\n        elif isinstance(m, nn.Upsample) and not hasattr(m, &amp;#39;recompute_scale_factor&amp;#39;):\n            m.recompute_scale_factor = None  # torch 1.11.0 compatibility\n    return model, ckpt                       # OBBModel(......) + dict_keys([&amp;#39;epoch&amp;#39;,&amp;#39;best_fitness&amp;#39;,&amp;#39;model&amp;#39;,&amp;#39;ema&amp;#39;,&amp;#39;updates&amp;#39;,&amp;#39;optimizer&amp;#39;,&amp;#39;train_args&amp;#39;,&amp;#39;train_metrics&amp;#39;,&amp;#39;train_results&amp;#39;,&amp;#39;date&amp;#39;,&amp;#39;version&amp;#39;])\n\'> </span>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def __call__(self,source,stream,**kwargs):\n        return self.`predict`(source, stream, **kwargs)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class Model(nn.Module):\n    def predict(self,source,stream,predictor,**kwargs):                         # source=&amp;#39;datasets/test_data/obb/P0015.png&amp;#39;\n        custom = {&amp;#39;conf&amp;#39;: 0.25, &amp;#39;batch&amp;#39;: 1, &amp;#39;save&amp;#39;: is_cli, &amp;#39;mode&amp;#39;: &amp;#39;predict&amp;#39;}  # method defaults  is_cli=False\n        args = {**self.overrides, **custom, **kwargs}  # args.keys()=dict_keys([&amp;#39;task&amp;#39;, &amp;#39;data&amp;#39;, &amp;#39;imgsz&amp;#39;, &amp;#39;single_cls&amp;#39;, &amp;#39;model&amp;#39;, &amp;#39;conf&amp;#39;, &amp;#39;batch&amp;#39;, &amp;#39;save&amp;#39;, &amp;#39;mode&amp;#39;])\n        prompts = args.pop(&amp;#39;prompts&amp;#39;, None)            # for SAM-type models  None\n        if not self.predictor:                         # None->True\n            self.predictor = predictor or self.`_smart_load`(&amp;#39;predictor&amp;#39;)(overrides=args, _callbacks=self.callbacks)\n            self.predictor.`setup_model`(model=self.model, verbose=is_cli)\n        else:                                          # only update args if predictor is already setup\n            ......\n        if prompts and hasattr(self.predictor, &amp;#39;set_prompts&amp;#39;):                  # for SAM-type models None\n            self.predictor.set_prompts(prompts)\n        return self.predictor.predict_cli(source=source) if is_cli else self.`predictor`(source=source, stream=stream)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><span class=\'hidden-code\' data-code=\'class YOLO(Model):\n    @property\n    def task_map(self):\n        return {......\n            &amp;#39;obb&amp;#39;: {&amp;#39;model&amp;#39;: OBBModel,&amp;#39;trainer&amp;#39;: yolo.obb.OBBTrainer,&amp;#39;validator&amp;#39;: yolo.obb.OBBValidator,&amp;#39;predictor&amp;#39;: yolo.obb.`OBBPredictor`}}\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:         # OBBPredictor --> DetectionPredictor --> BasePredictor\n    def setup_model(self, model, verbose=True):\n        self.model = AutoBackend(\n            weights=model or self.args.model,                        # OBBModel(.....), OBBModel(\n            device=select_device(self.args.device, verbose=verbose), # device(type=&amp;#39;cuda&amp;#39;, index=0)\n            dnn=self.args.dnn,        # False\n            data=self.args.data,      # &amp;#39;runs/DOTAv1.0-ms.yaml&amp;#39;\n            fp16=self.args.half,      # False\n            batch=self.args.batch,    # 1\n            fuse=True,\n            verbose=verbose,          # False\n        )\n        self.device = self.model.device   # update device\n        self.args.half = self.model.fp16  # update half   False\n        self.model.eval()\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:\n    def __call__(self, source=None, model=None, stream=False, *args, **kwargs):\n        self.stream = stream   # False\n        if stream:\n            return self.stream_inference(source, model, *args, **kwargs)\n        else:\n            return list(self.`stream_inference`(source, model, *args, **kwargs))  # merge list of Result into one\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:\n    @smart_inference_mode()\n    def stream_inference(self, source=None, model=None, *args, **kwargs):\n        with self._lock:                                                              # for thread-safe inference\n            self.`setup_source`(source if source is not None else self.args.source)   # Setup source every time predict is called\n            if self.args.save or self.args.save_txt:                                  # Check if save_dir/ label file exists  False\n                (self.save_dir / &amp;#39;labels&amp;#39; if self.args.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)\n            if not self.done_warmup:                                                  # Warmup model  -- False\n                self.model.warmup(imgsz=(1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))  # imgsz=(1, 3, 640, 640)  AutoBackend.warmup\n                self.done_warmup = True\n            self.seen, self.windows, self.batch = 0, [], None\n            profilers = (ops.Profile(device=self.device),ops.Profile(device=self.device),ops.Profile(device=self.device))\n            self.run_callbacks(&amp;#39;on_predict_start&amp;#39;)\n            for self.batch in self.dataset:\n                self.run_callbacks(&amp;#39;on_predict_batch_start&amp;#39;)\n                paths, im0s, s = self.batch             # [&amp;#39;/sdb/zzhu/code_study...003760.jpg&amp;#39;],[(1080, 1920, 3)],[&amp;#39;image 1/1 /sdb/zzhu/...3760.jpg: &amp;#39;]\n                # Preprocess\n                with profilers[0]:\n                    im = self.`preprocess`(im0s)        # torch.Size([1, 3, 384, 640])\n                # Inference\n                with profilers[1]:\n                    preds = self.`inference`(im, *args, **kwargs)\n                    if self.args.embed:                 # None\n                        yield from [preds] if isinstance(preds, torch.Tensor) else preds  # yield embedding tensors\n                        continue\n                # Postprocess\n                with profilers[2]:\n                    self.results = self.`postprocess`(preds, im, im0s)   # return preds\n                self.run_callbacks(&amp;#39;on_predict_postprocess_end&amp;#39;)\n                # Visualize, save, write results\n                n = len(im0s)\n                for i in range(n):\n                    self.seen += 1\n                    self.results[i].speed = {\n                        &amp;#39;preprocess&amp;#39;: profilers[0].dt * 1e3 / n,\n                        &amp;#39;inference&amp;#39;: profilers[1].dt * 1e3 / n,\n                        &amp;#39;postprocess&amp;#39;: profilers[2].dt * 1e3 / n,\n                    }\n                    if self.args.verbose or self.args.save or self.args.save_txt or self.args.show:\n                        s[i] += self.write_results(i, Path(paths[i]), im, s)\n                # Print batch results\n                if self.args.verbose:\n                    LOGGER.info(&amp;#39;\\n&amp;#39;.join(s))\n                self.run_callbacks(&amp;#39;on_predict_batch_end&amp;#39;)\n                yield from self.results\n        # Release assets\n        for v in self.vid_writer.values():\n            if isinstance(v, cv2.VideoWriter):\n                v.release()\n        # Print final results\n        if self.args.verbose and self.seen:\n            t = tuple(x.t / self.seen * 1e3 for x in profilers)  # speeds per image\n            LOGGER.info(\n                f&amp;#39;Speed: %.1fms preprocess, %.1fms inference, %.1fms postprocess per image at shape &amp;#39;\n                f&amp;#39;{(min(self.args.batch, self.seen), 3, *im.shape[2:])}&amp;#39; % t\n            )\n        if self.args.save or self.args.save_txt or self.args.save_crop:\n            nl = len(list(self.save_dir.glob(&amp;#39;labels/*.txt&amp;#39;)))  # number of labels\n            s = f&amp;#39;\\n{nl} label{&amp;#39;s&amp;#39; * (nl > 1)} saved to {self.save_dir / &amp;#39;labels&amp;#39;}&amp;#39; if self.args.save_txt else &amp;#39;&amp;#39;\n            LOGGER.info(f&amp;#39;Results saved to {colorstr(&amp;#39;bold&amp;#39;, self.save_dir)}{s}&amp;#39;)\n        self.run_callbacks(&amp;#39;on_predict_end&amp;#39;)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:\n    def setup_source(self, source):                  # Sets up source and inference mode\n        self.imgsz = check_imgsz(self.args.imgsz, stride=self.model.stride, min_dim=2)  # check image size  [640, 640]\n        self.transforms = (getattr(self.model.model,&amp;#39;transforms&amp;#39;,classify_transforms(self.imgsz[0], crop_fraction=self.args.crop_fraction),)   # None\n            if self.args.task == &amp;#39;classify&amp;#39; else None)                                  # ultralytics.data.loaders.LoadImagesAndVideos\n        self.dataset = `load_inference_source`(source=source,batch=self.args.batch,vid_stride=self.args.vid_stride,buffer=self.args.stream_buffer) \n        self.source_type = self.dataset.source_type\n        if not getattr(self,&amp;#39;stream&amp;#39;,True) and (self.source_type.stream or self.source_type.screenshot or len(self.dataset)>1000 or any(getattr(self.dataset,&amp;#39;video_flag&amp;#39;,[False]))):\n            LOGGER.warning(STREAM_WARNING)\n        self.vid_writer = {}\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><span class=\'hidden-code\' data-code=\'def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):\n    source, stream, screenshot, from_img, in_memory, tensor = check_source(source)\n    source_type = source.source_type if in_memory else SourceTypes(stream, screenshot, from_img, tensor)\n    if tensor:\n        dataset = LoadTensor(source)\n    elif in_memory:\n        dataset = source\n    elif stream:\n        dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer)\n    elif screenshot:\n        dataset = LoadScreenshots(source)\n    elif from_img:\n        dataset = LoadPilAndNumpy(source)\n    else:\n        dataset = `LoadImagesAndVideos`(source, batch=batch, vid_stride=vid_stride)\n    setattr(dataset, &amp;#39;source_type&amp;#39;, source_type)                  # Attach source types to the dataset\n    return dataset\n\'> </span>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/loaders.py</p><span class=\'hidden-code\' data-code=\'class LoadImagesAndVideos:\n    def __next__(self):                # 正常读取，没有做任何操作\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:\n    def preprocess(self, im):\n        not_tensor = not isinstance(im, torch.Tensor)      # True\n        if not_tensor:\n            im = np.stack(self.`pre_transform`(im))          # (1, 384, 640, 3)\n            im = im[..., ::-1].transpose((0, 3, 1, 2))     # BGR to RGB, BHWC to BCHW, (n, 3, h, w) (1, 3, 384, 640)\n            im = np.ascontiguousarray(im)                  # contiguous\n            im = torch.from_numpy(im)\n        im = im.to(self.device)\n        im = im.half() if self.model.fp16 else im.float()  # uint8 to fp16/32   torch.float32\n        if not_tensor:                                     # True\n            im /= 255                                      # 0 - 255 to 0.0 - 1.0\n        return im\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:\n    same_shapes = len({x.shape for x in im}) == 1                                                     # 后面是从yolov10预测调整来的\n    letterbox = `LetterBox`(self.imgsz, auto=same_shapes and self.model.pt, stride=self.model.stride) # [1024, 4024],auto=True,32\n    return [`letterbox`(image=x) for x in im]\n\'> </span>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/augment.py</p><span class=\'hidden-code\' data-code=\'class LetterBox:\n    def __init__(self, new_shape=(640, 640), auto=False, scaleFill=False, scaleup=True, center=True, stride=32):\n        self.new_shape = new_shape      # [640, 640]\n        self.auto = auto                # True\n        self.scaleFill = scaleFill      # False\n        self.scaleup = scaleup          # True\n        self.stride = stride            # 32\n        self.center = center  # Put the image in the middle or top-left  True\n\'> </span>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/augment.py</p><span class=\'hidden-code\' data-code=\'class LetterBox:\n    def __call__(self, labels=None, image=None):\n        if labels is None:                # None\n            labels = {}\n        img = labels.get(&amp;#39;img&amp;#39;) if image is None else image       # (1080, 1920, 3) ,值范围0-255\n        shape = img.shape[:2]             # current shape [height, width]   (1080, 1920)\n        new_shape = labels.pop(&amp;#39;rect_shape&amp;#39;, self.new_shape)      # [640, 640]\n        if isinstance(new_shape, int):    # False\n            new_shape = (new_shape, new_shape)\n        # Scale ratio (new / old)\n        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1]) # min(640/1080,640/1920) = 0.33333333333\n        if not self.scaleup:  # only scale down, do not scale up (for better val mAP)  False\n            r = min(r, 1.0)\n        # Compute padding\n        ratio = r, r          # width, height ratios  (0.3333333333333333, 0.3333333333333333)\n        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))     # (640, 360)\n        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding  0,280\n        if self.auto:         # minimum rectangle  True\n            dw, dh = np.mod(dw, self.stride), np.mod(dh, self.stride)      # wh padding (0, 24)\n        elif self.scaleFill:  # stretch\n            dw, dh = 0.0, 0.0\n            new_unpad = (new_shape[1], new_shape[0])\n            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n        if self.center:       # True\n            dw /= 2           # divide padding into 2 sides  0\n            dh /= 2           #                              12.0\n        if shape[::-1] != new_unpad:  # resize  (1080, 1920)[::-1] != (640, 360)\n            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)           # (360, 640, 3)\n        top, bottom = int(round(dh - 0.1)) if self.center else 0, int(round(dh + 0.1)) # 12,12\n        left, right = int(round(dw - 0.1)) if self.center else 0, int(round(dw + 0.1)) # 0,0\n        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))  # add border (384, 640, 3)\n        if labels.get(&amp;#39;ratio_pad&amp;#39;):                                   # False\n            labels[&amp;#39;ratio_pad&amp;#39;] = (labels[&amp;#39;ratio_pad&amp;#39;], (left, top))  # for evaluation\n        if len(labels):                                               # False\n            ......\n        else:\n            return img\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><span class=\'hidden-code\' data-code=\'class BasePredictor:\n    def inference(self, im, *args, **kwargs):         # Runs inference on a given image using the specified model and arguments\n        visualize = (increment_path(self.save_dir / Path(self.batch[0][0]).stem, mkdir=True)\n            if self.args.visualize and (not self.source_type.tensor) else False)\n        return self.`model`(im, augment=self.args.augment, visualize=visualize, embed=self.args.embed, *args, **kwargs)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class OBB(Detect):\n    def forward(self, x):\n        bs = x[0].shape[0]                            # batch size  1   [torch.Size([1, 1, 124, 128]),[1, 1, 62, 64],[1, 1, 31, 32]]\n        angle = torch.cat([self.cv4[i](x[i]).view(bs, self.ne, -1) for i in range(self.nl)], 2)  # OBB theta logits \n        angle = (angle.sigmoid() - 0.25) * math.pi    # [-pi/4, 3pi/4]   torch.Size([1, 1, 20832])\n        # angle = angle.sigmoid() * math.pi / 2       # [0, pi/2]\n        if not self.training:\n            self.angle = angle                        # torch.Size([1, 1, 21504])\n        x = self.`detect`(self, x)\n        if self.training:\n            return x, angle\n        return torch.cat([x, angle], 1) if self.export else (torch.cat([x[0], angle], 1), (x[1], angle))\n\'> </span>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class Detect(nn.Module):\n    def forward(self, x):\n        for i in range(self.nl):                   # [torch.Size([1, 79, 128, 128]),[1, 79, 64, 64][1, 79, 32, 32]]\n            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)        # 15+16*4=79\n        if self.training:                          # Training path  ---  False\n            return x\n        # Inference path\n        shape = x[0].shape                         # BCHW = torch.Size([1, 79, 128, 128])             \n        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)     # torch.Size([1, 79, 21504])\n        if self.dynamic or self.shape != shape:\n            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))  # torch.Size([2, 21504]); torch.Size([1, 21504])\n            self.shape = shape                     # torch.Size([1, 79, 128, 128])\n        if self.export and self.format in {&amp;#39;saved_model&amp;#39;, &amp;#39;pb&amp;#39;, &amp;#39;tflite&amp;#39;, &amp;#39;edgetpu&amp;#39;, &amp;#39;tfjs&amp;#39;}:  # avoid TF FlexSplitV ops\n            box = x_cat[:, : self.reg_max * 4]\n            cls = x_cat[:, self.reg_max * 4 :]\n        else:\n            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)    # torch.Size([1, 64, 21504]) torch.Size([1, 15, 21504])\n        if self.export and self.format in {&amp;#39;tflite&amp;#39;, &amp;#39;edgetpu&amp;#39;}:\n            ......\n        else:\n            dbox = self.`decode_bboxes`(self.dfl(box), self.anchors.unsqueeze(0)) * self.strides\n        y = torch.cat((dbox, cls.sigmoid()), 1)\n        return y if self.export else (y, x)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><span class=\'hidden-code\' data-code=\'class OBB(Detect):\n    def decode_bboxes(self, bboxes, anchors):\n        return `dist2rbox`(bboxes, self.angle, anchors, dim=1)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><span class=\'hidden-code\' data-code=\'def dist2rbox(pred_dist, pred_angle, anchor_points, dim=-1):\n    lt, rb = pred_dist.split(2, dim=dim)                     # torch.Size([1, 2, 21504]);torch.Size([1, 2, 21504])\n    cos, sin = torch.cos(pred_angle), torch.sin(pred_angle)  # torch.Size([1, 1, 21504]);torch.Size([1, 1, 21504])\n    # (bs, h*w, 1)\n    xf, yf = ((rb - lt) / 2).split(1, dim=dim)               # torch.Size([1, 1, 21504]);torch.Size([1, 1, 21504])\n    x, y = xf * cos - yf * sin, xf * sin + yf * cos\n    xy = torch.cat([x, y], dim=dim) + anchor_points          # torch.Size([1, 2, 21504])\n    return torch.cat([xy, lt + rb], dim=dim)\n\'> </span>'}]}]}]}]}]}]}]}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
