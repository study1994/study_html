<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov8_obb预测</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">预测过程</p><font size="0"><pre class="language-python"><code class="language-python">from ultralytics import YOLO\nmodel = <span style=\'color: green;font-weight: bold;\'>YOLO</span>("yolov8s-obb.pt")                        <span style=\'color: red\'>load an official model</span>\nresults = <span style=\'color: green;font-weight: bold;\'>model</span>("datasets/test_data/obb/P0015.png")   <span style=\'color: red\'>predict on an image</span>\nresults[0].save("datasets/test_data/obb_res/P0015.png")\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/models/yolo/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class YOLO(Model):\n    def __init__(self, model="yolov8n.pt", task=None, verbose=False):     \n        path = Path(model)                             <span style=\'color: red\'># \'yolov8s-obb.pt\'</span>\n        if "-world" in path.stem and path.suffix in {".pt", ".yaml", ".yml"}:  <span style=\'color: red\'># if YOLOWorld PyTorch model</span>\n            ......\n        else:\n            super().<span style=\'color: green;font-weight: bold;\'>__init__</span>(model=model, task=task, verbose=verbose)          <span style=\'color: red\'># Continue with default YOLO initialization</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    ......\n    self.<span style=\'color: green;font-weight: bold;\'>_load</span>(model, task=task)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def _load(self, weights: str, task=None) -> None:\n        weights = checks.check_model_file_from_stem(weights)  <span style=\'color: red\'>#  add suffix, i.e. yolov8n -> yolov8n.pt</span>\n        if Path(weights).suffix == ".pt":\n            self.model, self.ckpt = <span style=\'color: green;font-weight: bold;\'>attempt_load_one_weight</span>(weights)\n            self.task = self.model.args["task"]               <span style=\'color: red\'># \'obb</span>\n            self.overrides = self.model.args = self._reset_ckpt_args(self.model.args)\n            self.ckpt_path = self.model.pt_path               <span style=\'color: red\'># \'yolov8s-obb.pt\'</span>\n        else:\n            ......\n        self.overrides["model"] = weights\n        self.overrides["task"] = self.task\n        self.model_name = weights\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/tasks.py</p><font size="0"><pre class="language-python"><code class="language-python">def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):\n    ckpt, weight = torch_safe_load(weight)  <span style=\'color: red\'># load ckpt</span>\n    args = {**DEFAULT_CFG_DICT, **(ckpt.get("train_args", {}))}    <span style=\'color: red\'># combine model and default args, preferring model args</span>\n    model = (ckpt.get("ema") or ckpt["model"]).to(device).float()  <span style=\'color: red\'># FP32 model   OBBModel(......)</span>\n    <span style=\'color: red\'># Model compatibility updates</span>\n    model.args = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  <span style=\'color: red\'># attach args to model</span>\n    model.pt_path = weight                                         <span style=\'color: red\'># attach *.pt file path to model</span>\n    model.task = guess_model_task(model)                           <span style=\'color: red\'># \'obb\'</span>\n    if not hasattr(model, "stride"):\n        model.stride = torch.tensor([32.0])\n    model = model.fuse().eval() if fuse and hasattr(model, "fuse") else model.eval()  <span style=\'color: red\'># model in eval mode  fuse=False,hasattr(model, "fuse")=True</span>\n    <span style=\'color: red\'># Module updates</span>\n    for m in model.modules():\n        if hasattr(m, "inplace"):\n            m.inplace = inplace\n        elif isinstance(m, nn.Upsample) and not hasattr(m, "recompute_scale_factor"):\n            m.recompute_scale_factor = None  <span style=\'color: red\'># torch 1.11.0 compatibility</span>\n    return model, ckpt                       <span style=\'color: red\'># OBBModel(......) + dict_keys([\'epoch\',\'best_fitness\',\'model\',\'ema\',\'updates\',\'optimizer\',\'train_args\',\'train_metrics\',\'train_results\',\'date\',\'version\'])</span>\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def __call__(self,source,stream,**kwargs):\n        return self.<span style=\'color: green;font-weight: bold;\'>predict</span>(source, stream, **kwargs)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class Model(nn.Module):\n    def predict(self,source,stream,predictor,**kwargs):                         <span style=\'color: red\'># source=\'datasets/test_data/obb/P0015.png\'</span>\n        custom = {"conf": 0.25, "batch": 1, "save": is_cli, "mode": "predict"}  <span style=\'color: red\'># method defaults  is_cli=False</span>\n        args = {**self.overrides, **custom, **kwargs}  <span style=\'color: red\'># args.keys()=dict_keys([\'task\', \'data\', \'imgsz\', \'single_cls\', \'model\', \'conf\', \'batch\', \'save\', \'mode\'])</span>\n        prompts = args.pop("prompts", None)            <span style=\'color: red\'># for SAM-type models  None</span>\n        if not self.predictor:                         <span style=\'color: red\'># None->True</span>\n            self.predictor = predictor or self.<span style=\'color: green;font-weight: bold;\'>_smart_load</span>("predictor")(overrides=args, _callbacks=self.callbacks)\n            self.predictor.<span style=\'color: green;font-weight: bold;\'>setup_model</span>(model=self.model, verbose=is_cli)\n        else:                                          <span style=\'color: red\'># only update args if predictor is already setup</span>\n            ......\n        if prompts and hasattr(self.predictor, "set_prompts"):                  <span style=\'color: red\'># for SAM-type models None</span>\n            self.predictor.set_prompts(prompts)\n        return self.predictor.predict_cli(source=source) if is_cli else self.<span style=\'color: green;font-weight: bold;\'>predictor</span>(source=source, stream=stream)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/model.py</p><font size="0"><pre class="language-python"><code class="language-python">class YOLO(Model):\n    @property\n    def task_map(self):\n        return {......\n            "obb": {"model": OBBModel,"trainer": yolo.obb.OBBTrainer,"validator": yolo.obb.OBBValidator,"predictor": yolo.obb.<span style=\'color: green;font-weight: bold;\'>OBBPredictor</span>}}\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:         <span style=\'color: red\'># OBBPredictor --> DetectionPredictor --> BasePredictor</span>\n    def setup_model(self, model, verbose=True):\n        self.model = AutoBackend(\n            weights=model or self.args.model,                        <span style=\'color: red\'># OBBModel(.....), OBBModel(</span>\n            device=select_device(self.args.device, verbose=verbose), <span style=\'color: red\'># device(type=\'cuda\', index=0)</span>\n            dnn=self.args.dnn,        <span style=\'color: red\'># False</span>\n            data=self.args.data,      <span style=\'color: red\'># \'runs/DOTAv1.0-ms.yaml\'</span>\n            fp16=self.args.half,      <span style=\'color: red\'># False</span>\n            batch=self.args.batch,    <span style=\'color: red\'># 1</span>\n            fuse=True,\n            verbose=verbose,          <span style=\'color: red\'># False</span>\n        )\n        self.device = self.model.device   <span style=\'color: red\'># update device</span>\n        self.args.half = self.model.fp16  <span style=\'color: red\'># update half   False</span>\n        self.model.eval()\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def __call__(self, source=None, model=None, stream=False, *args, **kwargs):\n        self.stream = stream   <span style=\'color: red\'># False</span>\n        if stream:\n            return self.stream_inference(source, model, *args, **kwargs)\n        else:\n            return list(self.<span style=\'color: green;font-weight: bold;\'>stream_inference</span>(source, model, *args, **kwargs))  <span style=\'color: red\'># merge list of Result into one</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    @smart_inference_mode()\n    def stream_inference(self, source=None, model=None, *args, **kwargs):\n        with self._lock:                                                              <span style=\'color: red\'># for thread-safe inference</span>\n            self.<span style=\'color: green;font-weight: bold;\'>setup_source</span>(source if source is not None else self.args.source)   <span style=\'color: red\'># Setup source every time predict is called</span>\n            if self.args.save or self.args.save_txt:                                  <span style=\'color: red\'># Check if save_dir/ label file exists  False</span>\n                (self.save_dir / "labels" if self.args.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)\n            if not self.done_warmup:                                                  <span style=\'color: red\'># Warmup model  -- False</span>\n                self.model.warmup(imgsz=(1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))  <span style=\'color: red\'># imgsz=(1, 3, 640, 640)  AutoBackend.warmup</span>\n                self.done_warmup = True\n            self.seen, self.windows, self.batch = 0, [], None\n            profilers = (ops.Profile(device=self.device),ops.Profile(device=self.device),ops.Profile(device=self.device))\n            self.run_callbacks("on_predict_start")\n            for self.batch in self.dataset:\n                self.run_callbacks("on_predict_batch_start")\n                paths, im0s, s = self.batch             <span style=\'color: red\'># [\'/sdb/zzhu/code_study...003760.jpg\'],[(1080, 1920, 3)],[\'image 1/1 /sdb/zzhu/...3760.jpg: \']</span>\n                <span style=\'color: red\'># Preprocess</span>\n                with profilers[0]:\n                    im = self.<span style=\'color: green;font-weight: bold;\'>preprocess</span>(im0s)        <span style=\'color: red\'># torch.Size([1, 3, 384, 640])</span>\n                <span style=\'color: red\'># Inference</span>\n                with profilers[1]:\n                    preds = self.<span style=\'color: green;font-weight: bold;\'>inference</span>(im, *args, **kwargs)\n                    if self.args.embed:                 <span style=\'color: red\'># None</span>\n                        yield from [preds] if isinstance(preds, torch.Tensor) else preds  <span style=\'color: red\'># yield embedding tensors</span>\n                        continue\n                <span style=\'color: red\'># Postprocess</span>\n                with profilers[2]:\n                    self.results = self.<span style=\'color: green;font-weight: bold;\'>postprocess</span>(preds, im, im0s)   <span style=\'color: red\'># return preds</span>\n                self.run_callbacks("on_predict_postprocess_end")\n                <span style=\'color: red\'># Visualize, save, write results</span>\n                n = len(im0s)\n                for i in range(n):\n                    self.seen += 1\n                    self.results[i].speed = {\n                        "preprocess": profilers[0].dt * 1e3 / n,\n                        "inference": profilers[1].dt * 1e3 / n,\n                        "postprocess": profilers[2].dt * 1e3 / n,\n                    }\n                    if self.args.verbose or self.args.save or self.args.save_txt or self.args.show:\n                        s[i] += self.write_results(i, Path(paths[i]), im, s)\n                <span style=\'color: red\'># Print batch results</span>\n                if self.args.verbose:\n                    LOGGER.info("\\n".join(s))\n                self.run_callbacks("on_predict_batch_end")\n                yield from self.results\n        <span style=\'color: red\'># Release assets</span>\n        for v in self.vid_writer.values():\n            if isinstance(v, cv2.VideoWriter):\n                v.release()\n        <span style=\'color: red\'># Print final results</span>\n        if self.args.verbose and self.seen:\n            t = tuple(x.t / self.seen * 1e3 for x in profilers)  <span style=\'color: red\'># speeds per image</span>\n            LOGGER.info(\n                f"Speed: %.1fms preprocess, %.1fms inference, %.1fms postprocess per image at shape "\n                f"{(min(self.args.batch, self.seen), 3, *im.shape[2:])}" % t\n            )\n        if self.args.save or self.args.save_txt or self.args.save_crop:\n            nl = len(list(self.save_dir.glob("labels/*.txt")))  <span style=\'color: red\'># number of labels</span>\n            s = f"\\n{nl} label{\'s\' * (nl > 1)} saved to {self.save_dir / \'labels\'}" if self.args.save_txt else ""\n            LOGGER.info(f"Results saved to {colorstr(\'bold\', self.save_dir)}{s}")\n        self.run_callbacks("on_predict_end")\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def setup_source(self, source):                  <span style=\'color: red\'># Sets up source and inference mode</span>\n        self.imgsz = check_imgsz(self.args.imgsz, stride=self.model.stride, min_dim=2)  <span style=\'color: red\'># check image size  [640, 640]</span>\n        self.transforms = (getattr(self.model.model,"transforms",classify_transforms(self.imgsz[0], crop_fraction=self.args.crop_fraction),)   <span style=\'color: red\'># None</span>\n            if self.args.task == "classify" else None)                                  <span style=\'color: red\'># ultralytics.data.loaders.LoadImagesAndVideos</span>\n        self.dataset = <span style=\'color: green;font-weight: bold;\'>load_inference_source</span>(source=source,batch=self.args.batch,vid_stride=self.args.vid_stride,buffer=self.args.stream_buffer) \n        self.source_type = self.dataset.source_type\n        if not getattr(self,"stream",True) and (self.source_type.stream or self.source_type.screenshot or len(self.dataset)>1000 or any(getattr(self.dataset,"video_flag",[False]))):\n            LOGGER.warning(STREAM_WARNING)\n        self.vid_writer = {}\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/build.py</p><font size="0"><pre class="language-python"><code class="language-python">def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):\n    source, stream, screenshot, from_img, in_memory, tensor = check_source(source)\n    source_type = source.source_type if in_memory else SourceTypes(stream, screenshot, from_img, tensor)\n    if tensor:\n        dataset = LoadTensor(source)\n    elif in_memory:\n        dataset = source\n    elif stream:\n        dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer)\n    elif screenshot:\n        dataset = LoadScreenshots(source)\n    elif from_img:\n        dataset = LoadPilAndNumpy(source)\n    else:\n        dataset = <span style=\'color: green;font-weight: bold;\'>LoadImagesAndVideos</span>(source, batch=batch, vid_stride=vid_stride)\n    setattr(dataset, "source_type", source_type)                  <span style=\'color: red\'># Attach source types to the dataset</span>\n    return dataset\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/loaders.py</p><font size="0"><pre class="language-python"><code class="language-python">class LoadImagesAndVideos:\n    def __next__(self):                <span style=\'color: red\'># 正常读取，没有做任何操作</span>\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def preprocess(self, im):\n        not_tensor = not isinstance(im, torch.Tensor)      <span style=\'color: red\'># True</span>\n        if not_tensor:\n            im = np.stack(self.<span style=\'color: green;font-weight: bold;\'>pre_transform</span>(im))          <span style=\'color: red\'># (1, 384, 640, 3)</span>\n            im = im[..., ::-1].transpose((0, 3, 1, 2))     <span style=\'color: red\'># BGR to RGB, BHWC to BCHW, (n, 3, h, w) (1, 3, 384, 640)</span>\n            im = np.ascontiguousarray(im)                  <span style=\'color: red\'># contiguous</span>\n            im = torch.from_numpy(im)\n        im = im.to(self.device)\n        im = im.half() if self.model.fp16 else im.float()  <span style=\'color: red\'># uint8 to fp16/32   torch.float32</span>\n        if not_tensor:                                     <span style=\'color: red\'># True</span>\n            im /= 255                                      <span style=\'color: red\'># 0 - 255 to 0.0 - 1.0</span>\n        return im\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    same_shapes = len({x.shape for x in im}) == 1                                                     <span style=\'color: red\'># 后面是从yolov10预测调整来的</span>\n    letterbox = <span style=\'color: green;font-weight: bold;\'>LetterBox</span>(self.imgsz, auto=same_shapes and self.model.pt, stride=self.model.stride) <span style=\'color: red\'># [1024, 4024],auto=True,32</span>\n    return [<span style=\'color: green;font-weight: bold;\'>letterbox</span>(image=x) for x in im]\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/augment.py</p><font size="0"><pre class="language-python"><code class="language-python">class LetterBox:\n    def __init__(self, new_shape=(640, 640), auto=False, scaleFill=False, scaleup=True, center=True, stride=32):\n        self.new_shape = new_shape      <span style=\'color: red\'># [640, 640]</span>\n        self.auto = auto                <span style=\'color: red\'># True</span>\n        self.scaleFill = scaleFill      <span style=\'color: red\'># False</span>\n        self.scaleup = scaleup          <span style=\'color: red\'># True</span>\n        self.stride = stride            <span style=\'color: red\'># 32</span>\n        self.center = center  <span style=\'color: red\'># Put the image in the middle or top-left  True</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/data/augment.py</p><font size="0"><pre class="language-python"><code class="language-python">class LetterBox:\n    def __call__(self, labels=None, image=None):\n        if labels is None:                <span style=\'color: red\'># None</span>\n            labels = {}\n        img = labels.get("img") if image is None else image       <span style=\'color: red\'># (1080, 1920, 3) ,值范围0-255</span>\n        shape = img.shape[:2]             <span style=\'color: red\'># current shape [height, width]   (1080, 1920)</span>\n        new_shape = labels.pop("rect_shape", self.new_shape)      <span style=\'color: red\'># [640, 640]</span>\n        if isinstance(new_shape, int):    <span style=\'color: red\'># False</span>\n            new_shape = (new_shape, new_shape)\n        <span style=\'color: red\'># Scale ratio (new / old)</span>\n        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1]) <span style=\'color: red\'># min(640/1080,640/1920) = 0.33333333333</span>\n        if not self.scaleup:  <span style=\'color: red\'># only scale down, do not scale up (for better val mAP)  False</span>\n            r = min(r, 1.0)\n        <span style=\'color: red\'># Compute padding</span>\n        ratio = r, r          <span style=\'color: red\'># width, height ratios  (0.3333333333333333, 0.3333333333333333)</span>\n        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))     <span style=\'color: red\'># (640, 360)</span>\n        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  <span style=\'color: red\'># wh padding  0,280</span>\n        if self.auto:         <span style=\'color: red\'># minimum rectangle  True</span>\n            dw, dh = np.mod(dw, self.stride), np.mod(dh, self.stride)      <span style=\'color: red\'># wh padding (0, 24)</span>\n        elif self.scaleFill:  <span style=\'color: red\'># stretch</span>\n            dw, dh = 0.0, 0.0\n            new_unpad = (new_shape[1], new_shape[0])\n            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  <span style=\'color: red\'># width, height ratios</span>\n        if self.center:       <span style=\'color: red\'># True</span>\n            dw /= 2           <span style=\'color: red\'># divide padding into 2 sides  0</span>\n            dh /= 2           <span style=\'color: red\'>#                              12.0</span>\n        if shape[::-1] != new_unpad:  <span style=\'color: red\'># resize  (1080, 1920)[::-1] != (640, 360)</span>\n            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)           <span style=\'color: red\'># (360, 640, 3)</span>\n        top, bottom = int(round(dh - 0.1)) if self.center else 0, int(round(dh + 0.1)) <span style=\'color: red\'># 12,12</span>\n        left, right = int(round(dw - 0.1)) if self.center else 0, int(round(dw + 0.1)) <span style=\'color: red\'># 0,0</span>\n        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))  <span style=\'color: red\'># add border (384, 640, 3)</span>\n        if labels.get("ratio_pad"):                                   <span style=\'color: red\'># False</span>\n            labels["ratio_pad"] = (labels["ratio_pad"], (left, top))  <span style=\'color: red\'># for evaluation</span>\n        if len(labels):                                               <span style=\'color: red\'># False</span>\n            ......\n        else:\n            return img\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/engine/predictor.py</p><font size="0"><pre class="language-python"><code class="language-python">class BasePredictor:\n    def inference(self, im, *args, **kwargs):         <span style=\'color: red\'># Runs inference on a given image using the specified model and arguments</span>\n        visualize = (increment_path(self.save_dir / Path(self.batch[0][0]).stem, mkdir=True)\n            if self.args.visualize and (not self.source_type.tensor) else False)\n        return self.<span style=\'color: green;font-weight: bold;\'>model</span>(im, augment=self.args.augment, visualize=visualize, embed=self.args.embed, *args, **kwargs)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class OBB(Detect):\n    def forward(self, x):\n        bs = x[0].shape[0]                            <span style=\'color: red\'># batch size  1   [torch.Size([1, 1, 124, 128]),[1, 1, 62, 64],[1, 1, 31, 32]]</span>\n        angle = torch.cat([self.cv4[i](x[i]).view(bs, self.ne, -1) for i in range(self.nl)], 2)  <span style=\'color: red\'># OBB theta logits </span>\n        angle = (angle.sigmoid() - 0.25) * math.pi    <span style=\'color: red\'># [-pi/4, 3pi/4]   torch.Size([1, 1, 20832])</span>\n        <span style=\'color: red\'># angle = angle.sigmoid() * math.pi / 2      </span>\n        if not self.training:\n            self.angle = angle                        <span style=\'color: red\'># torch.Size([1, 1, 21504])</span>\n        x = self.<span style=\'color: green;font-weight: bold;\'>detect</span>(self, x)\n        if self.training:\n            return x, angle\n        return torch.cat([x, angle], 1) if self.export else (torch.cat([x[0], angle], 1), (x[1], angle))\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 8, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class Detect(nn.Module):\n    def forward(self, x):\n        for i in range(self.nl):                   <span style=\'color: red\'># [torch.Size([1, 79, 128, 128]),[1, 79, 64, 64][1, 79, 32, 32]]</span>\n            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)        <span style=\'color: red\'># 15+16*4=79</span>\n        if self.training:                          <span style=\'color: red\'># Training path  ---  False</span>\n            return x\n        <span style=\'color: red\'># Inference path</span>\n        shape = x[0].shape                         <span style=\'color: red\'># BCHW = torch.Size([1, 79, 128, 128])             </span>\n        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)     <span style=\'color: red\'># torch.Size([1, 79, 21504])</span>\n        if self.dynamic or self.shape != shape:\n            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))  <span style=\'color: red\'># torch.Size([2, 21504]); torch.Size([1, 21504])</span>\n            self.shape = shape                     <span style=\'color: red\'># torch.Size([1, 79, 128, 128])</span>\n        if self.export and self.format in {"saved_model", "pb", "tflite", "edgetpu", "tfjs"}:  <span style=\'color: red\'># avoid TF FlexSplitV ops</span>\n            box = x_cat[:, : self.reg_max * 4]\n            cls = x_cat[:, self.reg_max * 4 :]\n        else:\n            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)    <span style=\'color: red\'># torch.Size([1, 64, 21504]) torch.Size([1, 15, 21504])</span>\n        if self.export and self.format in {"tflite", "edgetpu"}:\n            ......\n        else:\n            dbox = self.<span style=\'color: green;font-weight: bold;\'>decode_bboxes</span>(self.dfl(box), self.anchors.unsqueeze(0)) * self.strides\n        y = torch.cat((dbox, cls.sigmoid()), 1)\n        return y if self.export else (y, x)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 9, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/nn/modules/head.py</p><font size="0"><pre class="language-python"><code class="language-python">class OBB(Detect):\n    def decode_bboxes(self, bboxes, anchors):\n        return <span style=\'color: green;font-weight: bold;\'>dist2rbox</span>(bboxes, self.angle, anchors, dim=1)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 10, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ultralytics/utils/tal.py</p><font size="0"><pre class="language-python"><code class="language-python">def dist2rbox(pred_dist, pred_angle, anchor_points, dim=-1):\n    lt, rb = pred_dist.split(2, dim=dim)                     <span style=\'color: red\'># torch.Size([1, 2, 21504]);torch.Size([1, 2, 21504])</span>\n    cos, sin = torch.cos(pred_angle), torch.sin(pred_angle)  <span style=\'color: red\'># torch.Size([1, 1, 21504]);torch.Size([1, 1, 21504])</span>\n    <span style=\'color: red\'># (bs, h*w, 1)</span>\n    xf, yf = ((rb - lt) / 2).split(1, dim=dim)               <span style=\'color: red\'># torch.Size([1, 1, 21504]);torch.Size([1, 1, 21504])</span>\n    x, y = xf * cos - yf * sin, xf * sin + yf * cos\n    xy = torch.cat([x, y], dim=dim) + anchor_points          <span style=\'color: red\'># torch.Size([1, 2, 21504])</span>\n    return torch.cat([xy, lt + rb], dim=dim)\n</code></pre></font>'}]}]}]}]}]}]}]}]}]}]})</script></body>
</html>
