<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>训练transfusion</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 150vw;
  height: 200vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/transfusion.py:def forward_train</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/mvx_two_stage.py:def extract_feat</p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/transfusion.py:def extract_img_feat</p>\n<p>输入：img.size()=torch.Size([2, 6, 3, 448, 800])-&gt;torch.Size([12, 3, 448, 800])<br>\n经过<code>ResNet</code>：len(img_feats=4;<br>\nimg_feats[0].shape=torch.Size([12, 256, 112, 200]); img_feats[1].shape=torch.Size([12, 512, 56, 100]);<br>\nimg_feats[2].shape=torch.Size([12, 1024, 28, 50]); img_feats[3].shape=torch.Size([12, 2048, 14, 25])<br>\n经过<code>FPN</code>:len(img_feats)=5;<br>\nimg_feats[0].shape=torch.Size([12, 256, 112, 200]); img_feats[1].shape=torch.Size([12, 256, 56, 100]);<br>\nimg_feats[2].shape=torch.Size([12, 256, 28, 50]); img_feats[3].shape=torch.Size([12, 256, 14, 25]); img_feats[4].shape=torch.Size([12, 256, 7, 13]);<br></p>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/transfusion.py:def extract_pts_feat</p>\n<p><code>PillarFeatureNet-&gt;PointPillarsScatter-&gt;SECOND-&gt;SECONDFPN</code><br>\nlen(pts_feats)=1; pts_feats[0].shape=torch.Size([2, 384, 128, 128]);<br></p>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/transfusion_head.py:def forward_single</p>\n<p>lidar_feat.shape=torch.Size([2, 128, 128, 128])-&gt;lidar_feat_flatten.shape=torch.Size([2, 128, 16384])【bev_feat】<br>\nbev_pos.shape=torch.Size([2, 16384, 2]);128x128=16384个点，横竖的范围是[0.5,1.5,2.5]<br>\n<code>--------------------------------------if self.fuse_img-----------------------------------------------</code><br>\nimg_inputs.shape=torch.Size([12, 256, 112, 200])-&gt;img_feat=torch.Size([2, 128, 112, 1200])<br>\n原始图片1600x900-。800x448-&gt;200x112<br>\nimg_feat_collapsed.shape=torch.Size([2, 128, 1200])在h也就是112做max<br>\nimg_feat_collapsed_pos.shape=torch.Size([1, 1200, 2])<br>\ntorch.min(img_feat_collapsed_pos[:,:,0])=tensor(0.5000, device=\'cuda:0\')<br>\ntorch.max(img_feat_collapsed_pos[:,:,0])=tensor(1199.5000, device=\'cuda:0\')<br>\ntorch.min(img_feat_collapsed_pos[:,:,1])=tensor(0.5000, device=\'cuda:0\')<br>\ntorch.max(img_feat_collapsed_pos[:,:,1])=tensor(0.5000, device=\'cuda:0\')<br>\nself.decoder里面有8个<code>TransformerDecoderLayer0</code><br>\nbev_feat=[2, 128, 16384]作为Q，每张图片的img_feat_collapsed[...,v1:v2]作为kv<br>\n<code>--------------------------------------image guided query initialization--------------------------------</code><br>\ndense_heatmap.shape=torch.Size([2, 10, 128, 128]);10是类别数量<br>\ndense_heatmap_img.shape=torch.Size([2, 10, 128, 128])<br>\nheatmap.shape=torch.Size([2, 10, 128, 128])<br>\npadding=self.nms_kernel_size//2=3//2=1<br>\nlocal_max_inner.shape=torch.Size([2, 10, 126, 126])<br>\nlocal_max[:,8,].shape=torch.Size([2, 128, 128])<br>\ntop_proposals.shape=torch.Size([2, 200]); top_proposals_class.shape=torch.Size([2, 200])【self.query_labels】; top_proposals_index.shape=torch.Size([2, 200]);<br>\ntop_proposals_class:0-9, top_proposals_index:1502-16176<br>\nquery_feat.shape=torch.Size([2, 128, 200]);lidar_feat_flatten.gather从(2,128,128,128)的后两个128里面取值<br>\none_hot.shape=torch.Size([2, 10, 200]); query_cat_encoding.shape=torch.Size([2, 128, 200]); query_feat.shape=torch.Size([2, 128, 200]);<br>\nquery_pos = bev_pos.gather是从bve_pose=torch.Size([2, 16384, 2]里面得到 query_pos=(2,200,2)?<br>\n<code>---------------------------------------transformer decoder layer (LiDAR feature as K,V)----------------------------------------------</code><br>\nself.prediction_heads[i]=FFN((center)+(height)+(dim)+(rot)+(vel)+(heatmap))<br>\nres_layer.keys()=dict_keys([\'center\', \'height\', \'dim\', \'rot\', \'vel\', \'heatmap\'])<br>\nquery_pos.shape=torch.Size([2, 200, 2])利用中心点更新pose<br>\n<code>---------------------------------------transformer decoder layer (img feature as K,V)----------------------------------------------</code><br>\nimg_feat.shape=torch.Size([2, 6, 128, 112, 200]);-&gt;img_feat_flatten.shape=torch.Size([2, 6, 128, 22400])<br>\nimg_feat_pos.shape=torch.Size([1, 22400, 2]);<br>\nprev_query_feat.shape=torch.Size([2, 128, 200]);原先雷达的特征<br>\n到真实坐标点的，注意这里为什么x和y的坐标要相等<code>query_pos_realmetric = ... + self.test_cfg[\'pc_range\'][0]</code>:<br>\nquery_pos_realmetric.shape=torch.Size([2, 2, 200]); res_layer[\'height\'].shape=torch.Size([2, 1, 200]);这个是z坐标，需要减去高的一半回归3D box<br>\nquery_pos_3d.shape=torch.Size([2, 3, 200]);<br>\npred_boxes[0].keys()=dict_keys([\'bboxes\', \'scores\', \'labels\']);<br>\non_the_image_mask=torch.Size([2, 200]);<br>\n<code>=======================================for sample_idx in range(batch_size if self.fuse_img else 0)======================================</code><br>\nlidar2img_rt.shape=torch.Size([6, 4, 4]);<br>\nimg_scale_factor=tensor([0.4975, 0.4978], device=\'cuda:0\');<br>\nimg_shape=(448, 796); img_pad_shape=torch.Size([448, 800]); query_pos_3d_with_corners.shape=torch.Size([3, 1800]):可以认为是图像中心点<br>\nquery_pos_3d[sample_idx].shape=torch.Size([3, 200]);boxes.corners.permute(2, 0, 1).view(3, -1).shape=torch.Size([3, 1600]);query_pos_3d_with_corners.shape<br>\ntorch.Size([3, 1800]);200个中心点加<code>200*8</code>个角点，前面200个判断在哪个图片上面；<br>\npoints.shape=torch.Size([1800, 3])：1800=200+200x8<br>\n<code>++++++++++++++++++++++++++++++++++++++for view_idx in range(self.num_views)++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</code><br>\nview_idx=0;<br>\npts_4d.shape=torch.Size([1800, 4]); pts_2d.shape=torch.Size([1800, 4]);<br>\ncoor_x.shape=torch.Size([200, 1]); coor_y.shape=torch.Size([200, 1]);<br>\ncoor_corner_x.shape=torch.Size([1600, 1])=torch.Size([200, 8, 1]); coor_corner_y.shape=torch.Size([1600, 1])=torch.Size([200, 8, 1]);这个是预测的200个3Dbox的角点-&gt;coor_corner_xy=(200,8,2)<br>\non_the_image.shape=torch.Size([200]);<br>\ncenters.shape=torch.Size([33, 2])-&gt;corners.shape=torch.Size([33, 2]);表示在这个图像中有33个点在这图片里面，其中2表示醉最大的x，y范围<br>\nsigma/radius.shape=torch.Size([33]); distance.shape=torch.Size([33, 22400])<br>\nattn_mask.shape=torch.Size([33, 22400]);<br>\nquery_feat_view.shape=torch.Size([128, 33]); query_pos_view.shape=torch.Size([33, 2]);<br>\nimg_feat_flatten[sample_idx:sample_idx + 1, view_idx].shape=torch.Size([1, 128, 22400]);<br>\n<code>---------------------------------结束---------------------------------------------------------------------------------</code><br>\nnew_res.keys()=dict_keys([\'center\', \'height\', \'dim\', \'rot\', \'vel\', \'heatmap\', \'query_heatmap_score\', \'dense_heatmap\'])<br>\nnew_res[\'center\'].shape=torch.Size([2, 2, 200])； new_res[\'heatmap\'].shape=torch.Size([2, 10, 200])；<br>\nnew_res[\'query_heatmap_score\'].shape=torch.Size([2, 10, 200])；new_res[\'dense_heatmap\'].shape=torch.Size([2, 10, 128, 128])<br></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">get_targets_single</p>输入：gt_bboxes_3d, gt_labels_3d, preds_dict(模型预测的结果), batch_idx<br>\nboxes_dict[0].keys()=dict_keys([\'bboxes\', \'scores\', \'labels\']);boxes_dict[0][\'bboxes\'].shape=torch.Size([200, 9]);<br>\nnum_layer=1;bboxes_tensor_layer.shape=torch.Size([200, 9]);score_layer.shape=torch.Size([1, 7, 200]);<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">class HungarianAssigner3D</p>mmdet3d/core/bbox/assigners/hungarian_assigner.py:def assign<br>\nnum_gts=73;num_bboxes=200;<br>\n1. assign -1 by default<br>\nassigned_gt_inds.shape=torch.Size([200])<br>\n2. compute the weighted costs<br>\ncls_pred[0].T.shape=torch.Size([200, 7]);gt_labels.shape=torch.Size([73]);<br>\ncls_cost.shape=torch.Size([200, 73])<br>\n3. do Hungarian matching on CPU using linear_sum_assignment<br>\n4. assign backgrounds and foregrounds<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">get_targets_single_1</p>bbox_targets.shape=torch.Size([200, 10]);【x,y,z,w,h,l,raw_cos,raw_sin,vx,vy】<br>\nlabels[None].shape=(1, 200);<br>'}]}]})</script></body>
</html>
