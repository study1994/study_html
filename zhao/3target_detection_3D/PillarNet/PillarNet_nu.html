<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>PillarNet_nu</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">训练过程det3d/models/detectors/pillarnet.py</p><font size="0"><pre class="language-python"><code class="language-python">class PillarNet(SingleStageDetector):\n    def forward(self, example, return_loss=True, **kwargs):\n        batch_size = len(example[\'metadata\'])\n        data = dict(\n            points=example["points"],     <span style=\'color: red\'>[torch.Size([269832, 5]), torch.Size([231976, 5]), torch.Size([237052, 5]), torch.Size([292753, 5])]</span>\n            batch_size=batch_size,        <span style=\'color: red\'>batch_size=4</span>\n        )\n        bev_feature, backbone_features = self.<span style=\'color: green;font-weight: bold;\'>extract_feat</span>(data)        <span style=\'color: red\'>torch.Size([4, 256, 180, 180])+[1440,720,360,180,90]</span>\n        preds, _ = self.<span style=\'color: green;font-weight: bold;\'>bbox_head</span>(bev_feature, backbone_features)\n        if return_loss:\n            return self.bbox_head.<span style=\'color: green;font-weight: bold;\'>loss</span>(example, preds, self.test_cfg)\n        else:\n            return self.bbox_head.<span style=\'color: green;font-weight: bold;\'>predict</span>(example, preds, self.test_cfg)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/detectors/pillarnet.py</p><font size="0"><pre class="language-python"><code class="language-python">class PillarNet(SingleStageDetector):\n    def extract_feat(self, data):\n        sp_tensor = self.<span style=\'color: green;font-weight: bold;\'>reader</span>(data)                 <span style=\'color: red\'># class DynamicPillarFeatureNet   torch.Size([277028, 32])</span>\n        pillar_features = self.<span style=\'color: green;font-weight: bold;\'>backbone</span>(sp_tensor)\n        if self.with_neck:\n            x = self.<span style=\'color: green;font-weight: bold;\'>neck</span>(pillar_features)    <span style=\'color: red\'># RPNV2  torch.Size([4, 256, 180, 180])</span>\n        return x, pillar_features\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/readers/dynamic_pillar_encoder.py</p><font size="0"><pre class="language-python"><code class="language-python">class DynamicPillarFeatureNet(nn.Module):\n    def absl_to_relative(self, absolute):\n        relative = absolute.detach().clone()\n        relative[..., 0] -= self.pc_range[0]\n        relative[..., 1] -= self.pc_range[1]\n        relative[..., 2] -= self.pc_range[2]\n        return relative\n    def forward(self, example, **kwargs):\n        points_list = example.pop("points")        <span style=\'color: red\'># [torch.Size([269832, 5]), torch.Size([231976, 5]), torch.Size([237052, 5]), torch.Size([292753, 5])]</span>\n        device = points_list[0].device\n        if self.virtual:\n            <span style=\'color: red\'># virtual_point_mask = features[..., -2] == -1</span>\n            <span style=\'color: red\'># virtual_points = features[virtual_point_mask]</span>\n            <span style=\'color: red\'># virtual_points[..., -2] = 1</span>\n            <span style=\'color: red\'># features[..., -2] = 0</span>\n            <span style=\'color: red\'># features[virtual_point_mask] = virtual_points</span>\n            raise NotImplementedError\n        xyz = []\n        xyz_batch_cnt = []\n        for points in points_list:\n            points = self.absl_to_relative(points)\n            xyz_batch_cnt.append(len(points))\n            xyz.append(points[:, :3])\n        xyz = torch.cat(xyz, dim=0).contiguous()                    <span style=\'color: red\'># torch.Size([1031613, 3])</span>\n        pt_features = torch.cat(points_list, dim=0).contiguous()    <span style=\'color: red\'># torch.Size([1031613, 5])</span>\n        xyz_batch_cnt = torch.tensor(xyz_batch_cnt, dtype=torch.int32).to(device)      <span style=\'color: red\'># torch.Size([4])</span>\n        sp_tensor = self.<span style=\'color: green;font-weight: bold;\'>pfn_layers</span>(xyz, xyz_batch_cnt, pt_features)   <span style=\'color: red\'># class PillarMaxPooling</span>\n        return sp_tensor\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/ops/pillar_ops/pillar_modules.py</p><font size="0"><pre class="language-python"><code class="language-python">class PillarMaxPooling(nn.Module):\n    def forward(self, xyz, xyz_batch_cnt, pt_feature):  <span style=\'color: red\'># xyz: (N1+N2..., 3) + xyz_batch_cnt:  (N1, N2, ...) + point_features: (N1+N2..., C) + spatial_shape: [B, H, W]</span>\n        B = xyz_batch_cnt.shape[0]\n        pillar_indices, pillar_set_indices, group_features = self.<span style=\'color: green;font-weight: bold;\'>groups</span>(xyz, xyz_batch_cnt, pt_feature)   <span style=\'color: red\'># det3d/ops/pillar_ops/pillar_utils.py:PillarQueryAndGroup</span>\n        <span style=\'color: red\'># torch.Size([277028, 3]); torch.Size([1021213]); torch.Size([1021213, 11])</span>\n        group_features = self.<span style=\'color: green;font-weight: bold;\'>shared_mlps</span>(group_features)  <span style=\'color: red\'># (1, C, L)  torch.Size([1021213, 11])->torch.Size([1021213, 32])  【self.shared_mlps = nn.Sequential(*shared_mlp)】</span>\n        group_features = group_features.transpose(1, 0).contiguous()     <span style=\'color: red\'># torch.Size([32, 1021213])</span>\n        pillar_features = scatter_max(group_features, pillar_set_indices, pillar_indices.shape[0])   <span style=\'color: red\'># (C, M)  det3d/ops/pillar_ops/scatter_utils.py:torch.Size([32, 277028])</span>\n        pillar_features = pillar_features.transpose(1, 0)   <span style=\'color: red\'># (M, C)torch.Size([277028, 32])</span>\n        return spconv.SparseConvTensor(pillar_features, pillar_indices, (self.bev_height, self.bev_width), B)  <span style=\'color: red\'># pillars: (M1+M2..., 3) [byx]  +  pillar_features: (M, C)</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/ops/pillar_ops/pillar_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class PillarQueryAndGroup(nn.Module):\n    def forward(self, xyz, xyz_batch_cnt, point_features):  <span style=\'color: red\'># (N1+N2..., 3)  relative coordinates + (N1+N2...) + (N1+N2..., C)</span>\n        pillars, pillar_centers, indice_pairs = <span style=\'color: green;font-weight: bold;\'>gen_indice_pairs</span>(xyz, xyz_batch_cnt, self.pillar_size,self.spatial_shape, self.z_center) <span style=\'color: red\'># class GenIndicePairs</span>\n        point_set_indices, pillar_set_indices = <span style=\'color: green;font-weight: bold;\'>flatten_indices</span>(indice_pairs)           <span style=\'color: red\'># FlattenIndices--》torch.Size([1021213])；torch.Size([1021213])</span>\n        group_point_features = <span style=\'color: green;font-weight: bold;\'>gather_feature</span>(point_features, point_set_indices)        <span style=\'color: red\'># (L, C)  torch.Size([1031613, 5])+torch.Size([1021213])->torch.Size([1021213, 5])</span>\n        group_point_xyz = gather_feature(xyz, point_set_indices)  <span style=\'color: red\'># (L, 3) [xyz]            det3d/ops/pillar_ops/group_utils.py           ->torch.Size([1021213, 3])</span>\n        group_pillar_centers = gather_feature(pillar_centers, pillar_set_indices)  <span style=\'color: red\'># (L, 3)  [xyz]</span>\n        group_pillar_centers = group_point_xyz - group_pillar_centers\n        group_features = torch.cat([group_point_features.detach(), group_point_xyz.detach(),group_pillar_centers.detach()], dim=1)      <span style=\'color: red\'># torch.Size([1021213, 11])  5+3+3</span>\n        return pillars, pillar_set_indices, group_features                                   <span style=\'color: red\'># torch.Size([277028, 3])(b,x,y); torch.Size([1021213]); torch.Size([1021213, 11])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/ops/pillar_ops/pillar_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class GenIndicePairs(Function):\n    def forward(ctx, xyz:torch.Tensor, xyz_batch_cnt:torch.Tensor, pillar_size, spatial_shape, z_center):\n        B = xyz_batch_cnt.numel()       <span style=\'color: red\'># 4</span>\n        H, W = spatial_shape            <span style=\'color: red\'># (1440, 1440)   54*2/0.075=1440</span>\n        device = xyz.device\n        pillar_mask = torch.zeros([B, H, W], dtype=torch.bool, device=device)       <span style=\'color: red\'># torch.Size([4, 1440, 1440])</span>\n        pillar_cuda.create_pillar_indices_stack_wrapper(pillar_size, xyz, xyz_batch_cnt, pillar_mask)  <span style=\'color: red\'># 0.075, torch.Size([1031613, 3]), [269832, 231976, 237052, 292753],  pillar_mask.sum()=pillar_mask.sum()</span>\n        location = torch.cumsum(pillar_mask.view(-1), 0).int()                      <span style=\'color: red\'># pillar_mask.sum()=277028-->torch.Size([8294400])</span>\n        M = location[-1].item()                                                     <span style=\'color: red\'># torch.Size([8294400])</span>\n        pillar_bev_indices = location.view(B, H, W) * pillar_mask - 1               <span style=\'color: red\'># torch.Size([4, 1440, 1440]</span>\n        <span style=\'color: red\'># create indices (M, 3) [byx] </span>\n        pillars = torch.zeros([M, 3], dtype=torch.int32, device=device)             <span style=\'color: red\'># torch.Size([277028, 3])->byx</span>\n        pillar_cuda.create_pillar_indices_wrapper(pillar_bev_indices, pillars)\n        indice_pairs = torch.full([xyz.shape[0], 1], -1, dtype=torch.int32, device=device)   <span style=\'color: red\'># torch.Size([1031613, 1]) 1031613这个点云所在索引</span>\n        <span style=\'color: red\'># create pillar center [x y z]  值范围再0.5*0.075-(1439+0.5)*0.075=(0.0375,107.9625)</span>\n        pillar_centers = torch.zeros([pillars.shape[0], 3], dtype=torch.float32, device=device, requires_grad=False)   <span style=\'color: red\'># torch.Size([277028, 3])</span>\n        pillar_centers[:, 0] = (pillars[:, 2] + 0.5) * pillar_size\n        pillar_centers[:, 1] = (pillars[:, 1] + 0.5) * pillar_size\n        pillar_centers[:, 2] = z_center                                   <span style=\'color: red\'># -1.0</span>\n        pillar_cuda.create_pillar_indice_pairs_stack_wrapper(pillar_size, xyz, xyz_batch_cnt,pillar_bev_indices, indice_pairs)\n        return pillars, pillar_centers, indice_pairs\n</code></pre></font>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/ops/pillar_ops/group_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class FlattenIndices(Function):\n    @staticmethod\n    def forward(ctx, indice_pairs:torch.Tensor):\n        mask = indice_pairs.view(-1) > -1              <span style=\'color: red\'># torch.Size([1031613, 1])  mask.sum()=1021213为啥还会有-1存在</span>\n        position = torch.cumsum(mask, 0).int()\n        L = position[-1].item()                <span style=\'color: red\'># 1021213</span>\n        position = position * mask - 1\n        first_indices = torch.zeros(L, dtype=torch.int32, device=indice_pairs.device, requires_grad=False)\n        second_indices = torch.zeros(L, dtype=torch.int32, device=indice_pairs.device, requires_grad=False)\n        pillar_cuda.flatten_indice_pairs_wrapper(indice_pairs, position, first_indices, second_indices)\n        return first_indices, second_indices\n</code></pre></font>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/ops/pillar_ops/group_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class GatherFeature(Function):\n    def forward(ctx, features:torch.Tensor, set_indices:torch.Tensor):\n        new_features = features.new_zeros((set_indices.shape[0], features.shape[1]))       <span style=\'color: red\'># torch.Size([1021213, 5])</span>\n        pillar_cuda.gather_feature_wrapper(set_indices, features, new_features)\n        ctx.for_backwards = (features.shape[0], features.shape[1], set_indices)\n        return new_features\n    def backward(ctx, grad_out):\n        N, C, set_indices = ctx.for_backwards\n        grad_features = Variable(torch.cuda.FloatTensor(N, C).zero_())\n        grad_out_data = grad_out.data.contiguous()\n        pillar_cuda.gather_feature_grad_wrapper(set_indices, grad_out_data, grad_features)\n        return grad_features, None\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/pcnres18.py</p><font size="0"><pre class="language-python"><code class="language-python">class SpMiddlePillarEncoder18(nn.Module):\n    def forward(self, sp_tensor):\n        x_conv1 = self.conv1(sp_tensor)   <span style=\'color: red\'># spconv.pytorch.core.SparseConvTensor(torch.Size([277028, 32]),torch.Size([277028, 3]),[1440, 1440],4)->SparseConvTensor(torch.Size([277028, 32]),torch.Size([277028, 3]),[1440, 1440],4)</span>\n        x_conv2 = self.conv2(x_conv1)     <span style=\'color: red\'># SparseConvTensor(torch.Size([166641, 64]),torch.Size([166641, 3]),[720, 720],4)</span>\n        x_conv3 = self.conv3(x_conv2)     <span style=\'color: red\'># SparseConvTensor(torch.Size([70167, 128]),torch.Size([70167, 3]),[360, 360],4)</span>\n        x_conv4 = self.conv4(x_conv3)     <span style=\'color: red\'># SparseConvTensor(torch.Size([28006, 256]),torch.Size([28006, 3]),[180, 180],4)</span>\n        x_conv4 = x_conv4.dense()         <span style=\'color: red\'># torch.Size([4, 256, 180, 180])</span>\n        x_conv5 = self.conv5(x_conv4)     <span style=\'color: red\'># torch.Size([4, 256, 90, 90])</span>\n        return dict(\n            x_conv1=x_conv1,\n            x_conv2=x_conv2,\n            x_conv3=x_conv3,\n            x_conv4=x_conv4,\n            x_conv5=x_conv5\n        )\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/necks/rpn.py</p><font size="0"><pre class="language-python"><code class="language-python">class RPNV2(nn.Module):\n    def forward(self, pillar_features, **kwargs):\n        x_conv4 = pillar_features[\'x_conv4\']         <span style=\'color: red\'># torch.Size([4, 256, 180, 180])</span>\n        x_conv5 = pillar_features[\'x_conv5\']         <span style=\'color: red\'># torch.Size([4, 256, 90, 90])</span>\n        if isinstance(x_conv4, spconv.SparseConvTensor):\n            x_conv4 = x_conv4.dense()\n        if isinstance(x_conv5, spconv.SparseConvTensor):\n            x_conv5 = x_conv5.dense()\n        ups = [self.deblock_4(x_conv4)]     <span style=\'color: red\'># [torch.Size([4, 128, 180, 180])]</span>\n        x = self.block_5(x_conv5)           <span style=\'color: red\'># torch.Size([4, 256, 90, 90])</span>\n        ups.append(self.deblock_5(x))\n        x = torch.cat(ups, dim=1)           <span style=\'color: red\'># torch.Size([4, 256, 180, 180])</span>\n        x = self.block_4(x)                 <span style=\'color: red\'># torch.Size([4, 256, 180, 180])</span>\n        return x\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/bbox_heads/center_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(nn.Module):\n    def forward(self, x, *kwargs):\n        ret_dicts = []\n        x = self.shared_conv(x)        <span style=\'color: red\'># torch.Size([4, 256, 180, 180])->torch.Size([4, 64, 180, 180])</span>\n        for task in self.tasks:\n            ret_dicts.append(task(x))\n        return ret_dicts, x            <span style=\'color: red\'># len(ret_dicts)==6;</span>\n        <span style=\'color: red\'># [(key,value.shape) for key,value in ret_dicts[0].items()]</span>\n        <span style=\'color: red\'># (\'reg\', torch.Size([4, 2, 180, 180]))</span>\n        <span style=\'color: red\'># (\'height\', torch.Size([4, 1, 180, 180]))</span>\n        <span style=\'color: red\'># (\'dim\', torch.Size([4, 3, 180, 180]))</span>\n        <span style=\'color: red\'># (\'rot\', torch.Size([4, 2, 180, 180]))</span>\n        <span style=\'color: red\'># (\'vel\', torch.Size([4, 2, 180, 180]))</span>\n        <span style=\'color: red\'># (\'iou\', torch.Size([4, 1, 180, 180]))</span>\n        <span style=\'color: red\'># (\'hm\', torch.Size([4, 1, 180, 180]))</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/bbox_heads/center_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(nn.Module):\n    def loss(self, example, preds_dicts, test_cfg, **kwargs):\n        rets = []\n        for task_id, preds_dict in enumerate(preds_dicts):\n            preds_dict[\'hm\'] = self._sigmoid(preds_dict[\'hm\'])   <span style=\'color: red\'># heatmap focal loss</span>\n            hm_loss = self.<span style=\'color: green;font-weight: bold;\'>crit</span>(preds_dict[\'hm\'], example[\'hm\'][task_id], example[\'ind\'][task_id], example[\'mask\'][task_id], example[\'cat\'][task_id])  <span style=\'color: red\'># FastFocalLoss()</span>\n            target_box = example[\'anno_box\'][task_id]                    <span style=\'color: red\'># torch.Size([4, 500, 10])                 </span>\n            if self.dataset in [\'waymo\', \'nuscenes\']:\n                if \'vel\' in preds_dict:\n                    preds_dict[\'anno_box\'] = torch.cat((preds_dict[\'reg\'], preds_dict[\'height\'], preds_dict[\'dim\'],preds_dict[\'vel\'], preds_dict[\'rot\']), dim=1)  \n                else:\n                    preds_dict[\'anno_box\'] = torch.cat((preds_dict[\'reg\'], preds_dict[\'height\'], preds_dict[\'dim\'],preds_dict[\'rot\']), dim=1)   \n                    target_box = target_box[..., [0, 1, 2, 3, 4, 5, -2, -1]] <span style=\'color: red\'># remove vel target                       </span>\n            else:\n                raise NotImplementedError()\n            ret = {}            <span style=\'color: red\'># Regression loss for dimension, offset, height, rotation             </span>\n            box_loss = self.<span style=\'color: green;font-weight: bold;\'>crit_reg</span>(preds_dict[\'anno_box\'], example[\'mask\'][task_id], example[\'ind\'][task_id], target_box)  <span style=\'color: red\'># RegLoss()  torch.Size([4, 10, 180, 180]),torch.Size([4, 500]),torch.Size([4, 500]),torch.Size([4, 500, 10])</span>\n            loc_loss = (box_loss*box_loss.new_tensor(self.code_weights)).sum()\n            loss = hm_loss + self.weight * loc_loss                               <span style=\'color: red\'># torch.Size([10])  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0, 1.0]</span>\n            ret.update({\'hm_loss\': hm_loss.detach().cpu(),\'loc_loss\': loc_loss, \'loc_loss_elem\': box_loss.detach().cpu(),\'num_positive\': example[\'mask\'][task_id].float().sum()})\n            if self.with_iou or self.with_iou_reg:\n                batch_dim = torch.exp(torch.clamp(preds_dict[\'dim\'], min=-5, max=5))\n                batch_dim = batch_dim.permute(0, 2, 3, 1).contiguous()                      <span style=\'color: red\'># torch.Size([4, 3, 180, 180])->torch.Size([4, 180, 180, 3])</span>\n                batch_rot = preds_dict[\'rot\'].clone(); batch_rot = batch_rot.permute(0, 2, 3, 1).contiguous()\n                batch_rots = batch_rot[..., 0:1]                                            \n                batch_rotc = batch_rot[..., 1:2]\n                batch_reg = preds_dict[\'reg\'].clone().permute(0, 2, 3, 1).contiguous()\n                batch_hei = preds_dict[\'height\'].clone().permute(0, 2, 3, 1).contiguous()\n                batch_rot = torch.atan2(batch_rots, batch_rotc)                             <span style=\'color: red\'># torch.Size([4, 180, 180, 1])</span>\n                batch, H, W, _ = batch_dim.size()                                           <span style=\'color: red\'># 180,180</span>\n                batch_reg = batch_reg.reshape(batch, H * W, 2)                              <span style=\'color: red\'># torch.Size([4, 32400, 2])</span>\n                batch_hei = batch_hei.reshape(batch, H * W, 1)                              <span style=\'color: red\'># torch.Size([4, 32400, 1])</span>\n                batch_rot = batch_rot.reshape(batch, H * W, 1)                              <span style=\'color: red\'># torch.Size([4, 32400, 1])</span>\n                batch_dim = batch_dim.reshape(batch, H * W, 3)                              <span style=\'color: red\'># torch.Size([4, 32400, 3])</span>\n                ys, xs = torch.meshgrid([torch.arange(0, H), torch.arange(0, W)])\n                ys = ys.view(1, H, W).repeat(batch, 1, 1).to(batch_dim)            <span style=\'color: red\'># torch.Size([4, 180, 180])</span>\n                xs = xs.view(1, H, W).repeat(batch, 1, 1).to(batch_dim)            <span style=\'color: red\'># torch.Size([4, 180, 180])</span>\n                xs = xs.view(batch, -1, 1) + batch_reg[:, :, 0:1]                  <span style=\'color: red\'># torch.Size([4, 32400, 1])+torch.Size([4, 32400, 1])=torch.Size([4, 32400, 1])</span>\n                ys = ys.view(batch, -1, 1) + batch_reg[:, :, 1:2]\n                xs = xs * int(self.task_strides[task_id]) * test_cfg.voxel_size[0] + test_cfg.pc_range[0]     <span style=\'color: red\'># x*8*0.075+(-54)</span>\n                ys = ys * int(self.task_strides[task_id]) * test_cfg.voxel_size[1] + test_cfg.pc_range[1]\n                batch_box_preds = torch.cat([xs, ys, batch_hei, batch_dim, batch_rot], dim=2)\n                batch_box_preds = batch_box_preds.permute(0, 2, 1).contiguous().reshape(batch, -1, H, W)      <span style=\'color: red\'># 得到预测的3D box</span>\n                if self.with_iou:                                                    <span style=\'color: red\'># 预测iou的分支计算损失</span>\n                    pred_boxes_for_iou = batch_box_preds.detach()\n                    iou_loss = self.<span style=\'color: green;font-weight: bold;\'>crit_iou</span>(preds_dict[\'iou\'], example[\'mask\'][task_id], example[\'ind\'][task_id],pred_boxes_for_iou, example[\'gt_box\'][task_id])  <span style=\'color: red\'># IouLoss</span>\n                    loss = loss + iou_loss\n                    ret.update({\'iou_loss\': iou_loss.detach().cpu()})\n                if self.with_iou_reg:                                                <span style=\'color: red\'># 增加iou损失</span>\n                    iou_reg_loss = self.<span style=\'color: green;font-weight: bold;\'>crit_iou_reg</span>(batch_box_preds, example[\'mask\'][task_id], example[\'ind\'][task_id],example[\'gt_box\'][task_id])                <span style=\'color: red\'># RegLoss</span>\n                    loss = loss + self.weight * iou_reg_loss\n                    ret.update({\'iou_reg_loss\': iou_reg_loss.detach().cpu()})\n            ret.update({\'loss\': loss})\n            rets.append(ret)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/losses/centernet_loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class FastFocalLoss(nn.Module):\n    def __init__(self):\n    def forward(self, out, target, ind, mask, cat):  <span style=\'color: red\'># torch.Size([4, 1, 180, 180]); torch.Size([4, 1, 180, 180]); torch.Size([4, 500]); torch.Size([4, 500]); torch.Size([4, 500])</span>\n        mask = mask.float()\n        gt = torch.pow(1 - target, 4)\n        neg_loss = torch.log(1 - out) * torch.pow(out, 2) * gt     <span style=\'color: red\'># torch.Size([4, 1, 180, 180])</span>\n        neg_loss = neg_loss.sum()                                  <span style=\'color: red\'># tensor(-1378.7615, device=\'cuda:0\', grad_fn=<SumBackward0>)</span>\n        pos_pred_pix = <span style=\'color: green;font-weight: bold;\'>_transpose_and_gather_feat</span>(out, ind) <span style=\'color: red\'># B x M x C    torch.Size([4, 500, 1])</span>\n        pos_pred = pos_pred_pix.gather(2, cat.unsqueeze(2)) <span style=\'color: red\'># B x M        torch.Size([4, 500, 1])+ torch.Size([4, 500, 1])->torch.Size([4, 500, 1])</span>\n        num_pos = mask.sum()                                <span style=\'color: red\'># tensor(34., device=\'cuda:0\')</span>\n        pos_loss = torch.log(pos_pred) * torch.pow(1 - pos_pred, 2) * mask.unsqueeze(2)      <span style=\'color: red\'># torch.Size([4, 500, 1])</span>\n        pos_loss = pos_loss.sum()            <span style=\'color: red\'># tensor(-52.1852, device=\'cuda:0\', grad_fn=<SumBackward0>)</span>\n        if num_pos == 0:\n            return - neg_loss\n        return - (pos_loss + neg_loss) / num_pos\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/core/utils/center_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def _transpose_and_gather_feat(feat, ind):              <span style=\'color: red\'># torch.Size([4, 1, 180, 180])  torch.Size([4, 500])里面的每个值都是y*180-x</span>\n    feat = feat.permute(0, 2, 3, 1).contiguous()        <span style=\'color: red\'># torch.Size([4, 1, 180, 180])->torch.Size([4, 180, 180, 1])->torch.Size([4, 32400, 1])</span>\n    feat = feat.view(feat.size(0), -1, feat.size(3))\n    feat = _gather_feat(feat, ind)\n    return feat\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/core/utils/center_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def _gather_feat(feat, ind, mask=None):                <span style=\'color: red\'># torch.Size([4, 32400, 1])->torch.Size([4, 500])</span>\n    dim  = feat.size(2)                                <span style=\'color: red\'># 1</span>\n    ind  = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)  <span style=\'color: red\'># torch.Size([4, 500])->torch.Size([4, 500,1])</span>\n    feat = feat.gather(1, ind)                         <span style=\'color: red\'># torch.Size([4, 500, 1])</span>\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat                                         <span style=\'color: red\'># torch.Size([4, 500, 1])</span>\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/losses/centernet_loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class IouLoss(nn.Module):\n  def __init__(self):\n    super(IouLoss, self).__init__()\n  def forward(self, iou_pred, mask, ind, box_pred, box_gt):\n    if mask.sum() == 0:\n      return iou_pred.new_zeros((1))\n    mask = mask.bool()\n    pred = _transpose_and_gather_feat(iou_pred, ind)[mask]\n    pred_box = _transpose_and_gather_feat(box_pred, ind)\n    target = boxes_aligned_iou3d_gpu(pred_box[mask], box_gt[mask])\n    target = 2 * target - 1\n    loss = F.l1_loss(pred, target, reduction=\'sum\')\n    loss = loss / (mask.sum() + 1e-4)\n    return loss\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/losses/centernet_loss.py</p><font size="0"><pre class="language-python"><code class="language-python">class RegLoss(nn.Module):\n  def __init__(self):\n    super(RegLoss, self).__init__()\n  \n  def forward(self, output, mask, ind, target):\n    if mask.sum() == 0:\n      return output.new_zeros((target.shape[-1]))\n    pred = _transpose_and_gather_feat(output, ind)\n    mask = mask.float().unsqueeze(2)\n    loss = F.l1_loss(pred*mask, target*mask, reduction=\'none\')\n    loss = loss / (mask.sum() + 1e-4)\n    loss = loss.transpose(2 ,0).sum(dim=2).sum(dim=1)\n    return loss\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">预测流程det3d/models/detectors/pillarnet.py</p><font size="0"><pre class="language-python"><code class="language-python">class PillarNet(SingleStageDetector):\n    def forward_two_stage(self, example, return_loss=True, **kwargs):\n        batch_size = len(example[\'metadata\'])\n        data = dict(points=example["points"],batch_size=batch_size,)\n        bev_feature, backbone_features = self.extract_feat(data)\n        preds, _ = self.bbox_head(bev_feature, backbone_features)\n        boxes = self.bbox_head.<span style=\'color: green;font-weight: bold;\'>predict</span>(example, new_preds, self.test_cfg)\n        if return_loss:\n            return boxes, bev_feature, backbone_features, self.bbox_head.loss(example, preds, self.test_cfg)\n        else:\n            return boxes, bev_feature, backbone_features, None\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/bbox_heads/center_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(nn.Module):\n    def predict(self, example, preds_dicts, test_cfg, **kwargs):\n        rets = []\n        metas = []\n        double_flip = test_cfg.get(\'double_flip\', False)            <span style=\'color: red\'># True</span>\n        post_center_range = test_cfg.post_center_limit_range        <span style=\'color: red\'># [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]</span>\n        if len(post_center_range) > 0:\n            post_center_range = torch.tensor(post_center_range,dtype=preds_dicts[0][\'hm\'].dtype,device=preds_dicts[0][\'hm\'].device,)\n        for task_id, preds_dict in enumerate(preds_dicts):            \n            for key, val in preds_dict.items():\n                preds_dict[key] = val.permute(0, 2, 3, 1).contiguous()  <span style=\'color: red\'># convert N C H W to N H W C </span>\n            batch_size = preds_dict[\'hm\'].shape[0]    <span style=\'color: red\'># 24</span>\n            if double_flip:\n                ......\n            if "metadata" not in example or len(example["metadata"]) == 0:\n                meta_list = [None] * batch_size\n            else:\n                meta_list = example["metadata"]\n                if double_flip:\n                    meta_list = meta_list[:4*int(batch_size):4]\n            batch_hm = torch.sigmoid(preds_dict[\'hm\'])\n            batch_dim = torch.exp(torch.clamp(preds_dict[\'dim\'].clone(), min=-5, max=5))\n            if \'iou\' in preds_dict.keys():\n                batch_iou = (preds_dict[\'iou\'].squeeze(dim=-1) + 1) * 0.5    <span style=\'color: red\'># torch.Size([6, 4, 180, 180, 1])  target = 2 * target - 1;target范围0-1，最后得到-1->1这里预测(-1->1)还原到(0,1)</span>\n                batch_iou = batch_iou.type_as(batch_dim)\n            else:\n                batch_iou = torch.ones((batch_hm.shape[0], batch_hm.shape[1], batch_hm.shape[2]),dtype=batch_dim.dtype).to(batch_hm.device)\n            batch_rots = preds_dict[\'rot\'][..., 0:1]\n            batch_rotc = preds_dict[\'rot\'][..., 1:2]\n            batch_reg = preds_dict[\'reg\']\n            batch_hei = preds_dict[\'height\']\n            if double_flip:\n                ......\n            batch_rot = torch.atan2(batch_rots, batch_rotc)\n            batch, H, W, num_cls = batch_hm.size()\n            batch_reg = batch_reg.reshape(batch, H*W, 2)\n            batch_hei = batch_hei.reshape(batch, H*W, 1)\n            batch_rot = batch_rot.reshape(batch, H*W, 1)\n            batch_dim = batch_dim.reshape(batch, H*W, 3)\n            batch_hm = batch_hm.reshape(batch, H*W, num_cls)\n            ys, xs = torch.meshgrid([torch.arange(0, H), torch.arange(0, W)])\n            ys = ys.view(1, H, W).repeat(batch, 1, 1).to(batch_hm)\n            xs = xs.view(1, H, W).repeat(batch, 1, 1).to(batch_hm)\n            xs = xs.view(batch, -1, 1) + batch_reg[:, :, 0:1]       <span style=\'color: red\'># x,y</span>\n            ys = ys.view(batch, -1, 1) + batch_reg[:, :, 1:2]\n            xs = xs * int(self.task_strides[task_id]) * test_cfg.voxel_size[0] + test_cfg.pc_range[0]  <span style=\'color: red\'># x*8*0.075+(-54)预测范围(0,180),得到范围(-54,54)</span>\n            ys = ys * int(self.task_strides[task_id]) * test_cfg.voxel_size[1] + test_cfg.pc_range[1]\n            if \'vel\' in preds_dict:\n                batch_vel = preds_dict[\'vel\']\n                if double_flip:\n                    ......\n                batch_vel = batch_vel.reshape(batch, H*W, 2)\n                batch_box_preds = torch.cat([xs, ys, batch_hei, batch_dim, batch_vel, batch_rot], dim=2)\n            else: \n                batch_box_preds = torch.cat([xs, ys, batch_hei, batch_dim, batch_rot], dim=2)\n            metas.append(meta_list)\n            if test_cfg.get(\'per_class_nms\', False):\n                pass \n            else:\n                rets.append(self.<span style=\'color: green;font-weight: bold;\'>post_processing</span>(batch_box_preds, batch_hm, batch_iou, test_cfg, post_center_range, task_id))\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/bbox_heads/center_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(nn.Module):\n    def post_processing(self, batch_box_preds, batch_hm, batch_iou, test_cfg, post_center_range, task_id):\n        batch_size = len(batch_hm)            <span style=\'color: red\'># 6</span>\n        prediction_dicts = []\n        for i in range(batch_size):\n            box_preds = batch_box_preds[i]          <span style=\'color: red\'># torch.Size([32400, 9])  180*180=32400</span>\n            hm_preds = batch_hm[i]                  <span style=\'color: red\'># torch.Size([32400, 1])</span>\n            iou_preds = batch_iou[i].view(-1)       <span style=\'color: red\'># torch.Size([32400])</span>\n            num_class = hm_preds.shape[1]           <span style=\'color: red\'># 1</span>\n            scores, labels = torch.max(hm_preds, dim=-1)\n            score_mask = scores > test_cfg.score_threshold        <span style=\'color: red\'># 0.1</span>\n            distance_mask = (box_preds[..., :3] >= post_center_range[:3]).all(1) & (box_preds[..., :3] <= post_center_range[3:]).all(1)\n            mask = distance_mask & score_mask \n            box_preds = box_preds[mask]            <span style=\'color: red\'># torch.Size([99, 9])</span>\n            scores = scores[mask]                  <span style=\'color: red\'># torch.Size([99])</span>\n            labels = labels[mask]                  <span style=\'color: red\'># torch.Size([99])</span>\n            iou_preds = torch.clamp(iou_preds[mask], min=0, max=1.)        <span style=\'color: red\'># torch.Size([99])</span>\n            boxes_for_nms = box_preds[:, [0, 1, 2, 3, 4, 5, -1]]\n            if test_cfg.get(\'circular_nms\', False):\n                centers = boxes_for_nms[:, [0, 1]] \n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                selected = _circle_nms(boxes, min_radius=test_cfg.min_radius[task_id],post_max_size=test_cfg.nms.nms_post_max_size[task_id])\n                selected_boxes = box_preds[selected]\n                selected_scores = scores[selected]\n                selected_labels = labels[selected]\n            elif test_cfg.nms.get(\'use_rotate_nms\', False):         <span style=\'color: red\'># True</span>\n                scores = torch.pow(scores, 1-test_cfg.rectifier[task_id]) * torch.pow(iou_preds, test_cfg.rectifier[task_id])    <span style=\'color: red\'># test_cfg.rectifier=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]</span>\n                selected = box_torch_ops.rotate_nms_pcdet(boxes_for_nms.float(), scores.float(),\n                                                          thresh=test_cfg.nms.nms_iou_threshold[task_id],        <span style=\'color: red\'># [0.2, 0.2, 0.2, 0.2, 0.2, 0.2]</span>\n                                                          pre_maxsize=test_cfg.nms.nms_pre_max_size[task_id],    <span style=\'color: red\'># [1000, 1000, 1000, 1000, 1000, 1000]</span>\n                                                          post_max_size=test_cfg.nms.nms_post_max_size[task_id]) <span style=\'color: red\'># [83, 83, 83, 83, 83, 83]</span>\n                selected_boxes = box_preds[selected]\n                selected_scores = scores[selected]\n                selected_labels = labels[selected]\n            elif test_cfg.nms.get(\'use_multi_class_nms\', False):\n                selected_boxes, selected_scores, selected_labels = box_torch_ops.rotate_class_specific_nms_iou_pcdet(\n                    boxes_for_nms.float(), scores.float(), iou_preds, box_preds, labels, num_class,\n                    test_cfg.rectifier[task_id],\n                    thresh=test_cfg.nms.nms_iou_threshold[task_id],\n                    pre_maxsize=test_cfg.nms.nms_pre_max_size[task_id],\n                    post_max_size=test_cfg.nms.nms_post_max_size[task_id])\n            else:\n                raise NotImplementedError\n            prediction_dict = {\n                \'box3d_lidar\': selected_boxes,\n                \'scores\': selected_scores,\n                \'label_preds\': selected_labels\n            }\n            prediction_dicts.append(prediction_dict)\n        return prediction_dicts \n</code></pre></font>'}]}]}]})</script></body>
</html>
