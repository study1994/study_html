<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>SpMiddleResNetFHDFocal_forward</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/scn_focal.py</p><span class=\'hidden-code\' data-code=\'class SpMiddleResNetFHDFocal(nn.Module):\n    def forward(self, voxel_features, batch_dict, coors, batch_size, input_shape, fuse_func=None):\n        input: [41, 1600, 1408]\n        sparse_shape = np.array(input_shape[::-1]) + [1, 0, 0]      array([1440, 1440, 40])->  array([41, 1440, 1440])\n        coors = coors.int()\n        ret = spconv.SparseConvTensor(voxel_features, coors, sparse_shape, batch_size)   torch.Size([137566, 5])+ torch.Size([137566, 4])+\n        loss_box_of_pts = 0\n        x = self.conv_input(ret)\n        x_conv1, _loss = self.`conv1`(x, batch_dict)\n        loss_box_of_pts += _loss\n        if self.use_img:\n            x_conv1, _loss = self.conv_focal_multimodal(x_conv1, batch_dict, fuse_func)\n            loss_box_of_pts = loss_box_of_pts + _loss\n        x_conv2, _loss = self.conv2(x_conv1, batch_dict)\n        loss_box_of_pts += _loss\n        x_conv3, _loss = self.conv3(x_conv2, batch_dict)\n        loss_box_of_pts += _loss\n        x_conv4, _loss = self.conv4(x_conv3, batch_dict)\n        loss_box_of_pts += _loss\n        ret = self.extra_conv(x_conv4)\n        ret = ret.dense()\n        N, C, D, H, W = ret.shape\n        ret = ret.view(N, C * D, H, W)\n        multi_scale_voxel_features = {\n            &amp;#39;conv1&amp;#39;: x_conv1,\n            &amp;#39;conv2&amp;#39;: x_conv2,\n            &amp;#39;conv3&amp;#39;: x_conv3,\n            &amp;#39;conv4&amp;#39;: x_conv4,\n        }\n        return ret, multi_scale_voxel_features, loss_box_of_pts\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/focal_sparse_conv.py</p><span class=\'hidden-code\' data-code=\'class FocalSparseConv(spconv.SparseModule):\n    def forward(self, x, batch_dict, fuse_func=None):\n        spatial_indices = x.indices[:, 1:] * self.voxel_stride                      # torch.Size([137566, 3])*1\n        voxels_3d = spatial_indices * self.voxel_size + self.point_cloud_range[:3]  # 相当于到原始点云的范围坐标\n        x_predict = self.conv_enlarge(x) if self.conv_enlarge else x\n        if self.use_img:\n            x_predict = fuse_func(batch_dict, encoded_voxel=x_predict, layer_name=&amp;#39;layer1&amp;#39;)\n        imp3_3d = self.conv_imp(x_predict).features                       # [41, 1440, 1440]-->torch.Size([137566, 27])做个卷积，输出通道为3**3=27\n        out, loss_box_of_pts = self.`_gen_sparse_features`(x, imp3_3d, voxels_3d, batch_dict[&amp;#39;gt_boxes&amp;#39;] if self.training else None)\n        out = self.conv(out)            # 稀疏卷积操作\n        if self.use_img:\n            out = fuse_func(batch_dict, encoded_voxel=out, layer_name=&amp;#39;layer1&amp;#39;)\n        out = out.replace_feature(self.bn1(out.features))\n        out = out.replace_feature(self.relu(out.features))\n        return out, loss_box_of_pts\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/focal_sparse_conv.py</p><span class=\'hidden-code\' data-code=\'class FocalSparseConv(spconv.SparseModule):\n    def _gen_sparse_features(self, x, imp3_3d, voxels_3d, gt_boxes=None):\n        &amp;#39;&amp;#39;&amp;#39;\n            Generate the output sparse features from the focal sparse conv.\n            Args:\n                x: [N, C], lidar sparse features                               输入的稀疏卷积tensor\n                imps_3d: [N, kernelsize**3], the predicted importance values   torch.Size([137566, 27])；27是卷积的输出通道，由kernelsize**3决定\n                voxels_3d: [N, 3], the 3d positions of voxel centers\n                gt_boxes: for focal loss calculation\n        &amp;#39;&amp;#39;&amp;#39;\n        index = x.indices[:, 0]\n        batch_size = x.batch_size       # 2\n        voxel_features_fore = []\n        voxel_indices_fore = []\n        voxel_features_back = []\n        voxel_indices_back = []\n        box_of_pts_cls_targets = []\n        mask_voxels = []\n        loss_box_of_pts = 0\n        for b in range(batch_size):\n            if self.training and not self.skip_loss:\n                gt_boxes_batch = gt_boxes[b, :, :-1]                                # (100, 6)\n                gt_boxes_batch_idx = (gt_boxes_batch**2).sum(-1)>0                  # (100,)\n                gt_boxes_centers_batch = gt_boxes_batch[gt_boxes_batch_idx, :3]     # (100, 3)\n                gt_boxes_sizes_batch = gt_boxes_batch[gt_boxes_batch_idx, 3:6]\n                index = x.indices[:, 0]\n                batch_index = index==b\n                mask_voxel = imp3_3d[batch_index, -1].sigmoid()  # 卷积得到的特征做sigmoid\n                mask_voxels.append(mask_voxel)\n                voxels_3d_batch = voxels_3d[batch_index]         # torch.Size([106998, 3])\n                dist_voxels_to_gtboxes = (voxels_3d_batch[:, self.inv_idx].unsqueeze(1).repeat(1, gt_boxes_centers_batch.shape[0], 1) - gt_boxes_centers_batch.unsqueeze(0)).abs()      # torch.Size([106998, 100, 3])\n                offsets_dist_boundry = dist_voxels_to_gtboxes - gt_boxes_sizes_batch.unsqueeze(0)            # torch.Size([106998, 100, 3])与中心的距离与长度\n                inboxes_voxels = ~torch.all(~torch.all(offsets_dist_boundry<=0, dim=-1), dim=-1)             # 点距离100个里面任意一个box的x距离小于dx或者y的距离小于dy或者z的距离小于dz的点\n                box_of_pts_cls_targets.append(inboxes_voxels)\n            features_fore, indices_fore, features_back, indices_back = `split_voxels`(x, b, imp3_3d, voxels_3d, self.kernel_offsets, mask_multi=self.mask_multi, topk=self.topk, threshold=self.threshold)\n            voxel_features_fore.append(features_fore)\n            voxel_indices_fore.append(indices_fore)\n            voxel_features_back.append(features_back)\n            voxel_indices_back.append(indices_back)\n        voxel_features_fore = torch.cat(voxel_features_fore+voxel_features_back, dim=0)         # torch.Size([600673, 16])\n        voxel_indices_fore = torch.cat(voxel_indices_fore+voxel_indices_back, dim=0)            # torch.Size([600673, 4])\n        out = spconv.SparseConvTensor(voxel_features_fore, voxel_indices_fore, x.spatial_shape, x.batch_size)\n        \n        if self.training and not self.skip_loss:\n            mask_voxels = torch.cat(mask_voxels)                                 # torch.Size([137566])\n            box_of_pts_cls_targets = torch.cat(box_of_pts_cls_targets)           # torch.Size([137566])\n            mask_voxels_two_classes = torch.cat([1-mask_voxels.unsqueeze(-1), mask_voxels.unsqueeze(-1)], dim=1)      # torch.Size([137566, 2])\n            loss_box_of_pts += self.focal_loss(mask_voxels_two_classes, box_of_pts_cls_targets.long())\n        return out, loss_box_of_pts                                              # tensor(0.0922, device=&amp;#39;cuda:0&amp;#39;, grad_fn=`<`AddBackward0`>`)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><span class=\'hidden-code\' data-code=\'def split_voxels(x, b, imps_3d, voxels_3d, kernel_offsets, mask_multi=True, topk=True, threshold=0.5):\n    &amp;#39;&amp;#39;&amp;#39;\n        Generate and split the voxels into foreground and background sparse features, based on the predicted importance values.\n        Args:\n            x: [N, C], input sparse features                                 [41, 1440, 1440]的tensor\n            b: int, batch size id\n            imps_3d: [N, kernelsize**3], the prediced importance values      做了卷积计算，输出通道为k**3=27的特征\n            voxels_3d: [N, 3], the 3d positions of voxel centers \n            kernel_offsets: [kernelsize**3, 3], the offset coords in an kernel       # torch.Size([26, 3])？扔掉了(0,0,0)\n            mask_multi: bool, whether to multiply the predicted mask to features\n            topk: bool, whether to use topk or threshold for selection\n            threshold: float, threshold value\n    &amp;#39;&amp;#39;&amp;#39;\n    index = x.indices[:, 0]\n    batch_index = index==b\n    indices_ori = x.indices[batch_index]            # torch.Size([106998, 4])当前bacth的索引\n    features_ori = x.features[batch_index]          # torch.Size([106998, 16])\n    mask_voxel = imps_3d[batch_index, -1].sigmoid()   # torch.Size([106998])\n    mask_kernel = imps_3d[batch_index, :-1].sigmoid() # torch.Size([106998, 26])\n    if mask_multi:\n        features_ori *= mask_voxel.unsqueeze(-1)      # torch.Size([106998, 16])\n    if topk:\n        _, indices = mask_voxel.sort(descending=True)\n        indices_fore = indices[:int(mask_voxel.shape[0]*threshold)]    # torch.Size([53499])  取数值大的前面的作为前景点索引\n        indices_back = indices[int(mask_voxel.shape[0]*threshold):]    # torch.Size([53499])\n    else:\n        indices_fore = mask_voxel > threshold\n        indices_back = mask_voxel <= threshold\n    features_fore = features_ori[indices_fore]       # torch.Size([53499, 16])\n    coords_fore = indices_ori[indices_fore]          # torch.Size([53499, 4])\n    mask_kernel_fore = mask_kernel[indices_fore]     # torch.Size([53499, 26])\n    mask_kernel_bool = mask_kernel_fore>=threshold   # torch.Size([53499, 26])\n    voxel_kerels_imp = kernel_offsets.unsqueeze(0).repeat(mask_kernel_bool.shape[0],1, 1)     # torch.Size([26, 3])->torch.Size([53499, 26, 3])\n    indices_fore_kernels = coords_fore[:, 1:].unsqueeze(1).repeat(1, kernel_offsets.shape[0], 1)    # torch.Size([53499, 26, 3])\n    indices_with_imp = indices_fore_kernels + voxel_kerels_imp                                      # torch.Size([53499, 26, 3])   53499个前景点*26个位移\n    selected_indices = indices_with_imp[mask_kernel_bool]                                           # torch.Size([651511, 3])      53499个前景点*26个位移里面有651511个点满足条件\n    spatial_indices = (selected_indices[:, 0] >0) * (selected_indices[:, 1] >0) * (selected_indices[:, 2] >0)  * \\\n                        (selected_indices[:, 0] < x.spatial_shape[0]) * (selected_indices[:, 1] < x.spatial_shape[1]) * (selected_indices[:, 2] < x.spatial_shape[2])  # torch.Size([651511])\n    selected_indices = selected_indices[spatial_indices]                                            # torch.Size([651320, 3])      这些点里面又有651320个点在feature map比如0-1440里面\n    selected_indices = torch.cat([torch.ones((selected_indices.shape[0], 1), device=features_fore.device)*b, selected_indices], dim=1)   # torch.Size([651320, 4]) 相当于第0为给上索引\n    selected_features = torch.zeros((selected_indices.shape[0], features_ori.shape[1]), device=features_fore.device)                     # torch.Size([651320, 16])\n    selected_features, selected_indices = `check_repeat`(selected_features, selected_indices)         # torch.Size([384775, 16]); torch.Size([384775, 4])   651320去重有384775个点不重复？\n    features_fore_cat = torch.cat([features_fore, selected_features], dim=0)                          # torch.Size([438274, 16])    # 53499加上384775这些偏移的点便宜的点的特征是空的\n    coords_fore = torch.cat([coords_fore, selected_indices], dim=0)                                   # torch.Size([438274, 4])\n \n    features_fore, coords_fore = `check_repeat`(features_fore_cat, coords_fore, sort_first=True)      # 438274去重后剩下398124个点torch.Size([398124, 16])\n    features_back = features_ori[indices_back]                  # torch.Size([53499, 16])\n    coords_back = indices_ori[indices_back]                     # torch.Size([53499, 4])\n    return features_fore, coords_fore, features_back, coords_back\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><span class=\'hidden-code\' data-code=\'def check_repeat(features, indices, sort_first=False):\n    &amp;#39;&amp;#39;&amp;#39;\n        Check that whether there are replicate indices in the sparse features, \n        remove the replicate features if any.\n    &amp;#39;&amp;#39;&amp;#39;\n    if sort_first:\n        features, indices = sort_by_indices(features, indices)\n        features, indices = features.flip([0]), indices.flip([0])\n        idx = indices[:, 1:].int()\n        idx_sum = torch.add(torch.add(idx.select(1, 0) * idx[:, 1].max() * idx[:, 2].max(), idx.select(1, 1) * idx[:, 2].max()), idx.select(1, 2))\n        _unique, inverse = torch.unique_consecutive(idx_sum, return_inverse=True, dim=0)\n    else:\n        _unique, inverse = torch.unique(indices, return_inverse=True, dim=0)   # torch.Size([651320, 4])->torch.Size([384775, 4])+torch.Size([651320])\n    if _unique.shape[0] < indices.shape[0]:\n        perm = torch.arange(inverse.size(0), dtype=inverse.dtype, device=inverse.device)   # torch.Size([651320])值为(0,1,...,651319)\n        if sort_first:\n            features_new = torch.zeros((_unique.shape[0], features.shape[-1]), device=features.device)\n            features_new.index_add_(0, inverse.long(), features)\n            features = features_new\n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)\n            indices = indices[perm_].int()\n        else:\n            inverse, perm = inverse.flip([0]), perm.flip([0])                       # torch.Size([651320]); torch.Size([651320])\n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)   # torch.Size([384775])\n            features = features[perm_]                         # torch.Size([651320, 16])->torch.Size([384775, 16])\n            indices = _unique.int()\n    return features, indices\n\'> </span>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><span class=\'hidden-code\' data-code=\'def check_repeat(features, indices, sort_first=False):\n    &amp;#39;&amp;#39;&amp;#39;\n        Check that whether there are replicate indices in the sparse features, \n        remove the replicate features if any.\n    &amp;#39;&amp;#39;&amp;#39;\n    if sort_first:\n        features, indices = `sort_by_indices`(features, indices)   # torch.Size([438274, 16])+torch.Size([438274, 4])\n        features, indices = features.flip([0]), indices.flip([0])  # 翻转，第一行会变成最后一行\n        idx = indices[:, 1:].int()\n        idx_sum = torch.add(torch.add(idx.select(1, 0) * idx[:, 1].max() * idx[:, 2].max(), idx.select(1, 1) * idx[:, 2].max()), idx.select(1, 2))\n        _unique, inverse = torch.unique_consecutive(idx_sum, return_inverse=True, dim=0)        # 作唯一计算  torch.Size([398124])  torch.Size([438274])\n    else:\n        _unique, inverse = torch.unique(indices, return_inverse=True, dim=0)   \n    if _unique.shape[0] < indices.shape[0]:\n        perm = torch.arange(inverse.size(0), dtype=inverse.dtype, device=inverse.device) \n        if sort_first:\n            features_new = torch.zeros((_unique.shape[0], features.shape[-1]), device=features.device)   # torch.Size([398124, 16])\n            features_new.index_add_(0, inverse.long(), features)\n            features = features_new\n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)\n            indices = indices[perm_].int()                                                               # torch.Size([398124, 4])\n        else:\n            inverse, perm = inverse.flip([0]), perm.flip([0])                      \n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)  \n            features = features[perm_]                       \n            indices = _unique.int()\n    return features, indices\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><span class=\'hidden-code\' data-code=\'def sort_by_indices(features, indices):\n    &amp;#39;&amp;#39;&amp;#39; To sort the sparse features with its indices in a convenient manner.\n        Args:\n            features: [N, C], sparse features\n            indices: [N, 4], indices of sparse features\n    &amp;#39;&amp;#39;&amp;#39;\n    idx = indices[:, 1:]                # torch.Size([438274, 3])  就是排个序\n    idx_sum = idx.select(1, 0) * idx[:, 1].max() * idx[:, 2].max() + idx.select(1, 1) * idx[:, 2].max() + idx.select(1, 2)\n    _, ind = idx_sum.sort()\n    features = features[ind]\n    indices = indices[ind]\n    return features, indices\n\'> </span>'}]}]}]}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
