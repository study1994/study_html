<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>SpMiddleResNetFHDFocal_forward</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/scn_focal.py</p><font size="0"><pre class="language-python"><code class="language-python">class SpMiddleResNetFHDFocal(nn.Module):\n    def forward(self, voxel_features, batch_dict, coors, batch_size, input_shape, fuse_func=None):\n        <span style=\'color: red\'>input:</span>\n        sparse_shape = np.array(input_shape[::-1]) + [1, 0, 0]      <span style=\'color: red\'>array([1440, 1440, 40])->  array([41, 1440, 1440])</span>\n        coors = coors.int()\n        ret = spconv.SparseConvTensor(voxel_features, coors, sparse_shape, batch_size)   <span style=\'color: red\'>torch.Size([137566, 5])+ torch.Size([137566, 4])+</span>\n        loss_box_of_pts = 0\n        x = self.conv_input(ret)\n        x_conv1, _loss = self.<span style=\'color: green;font-weight: bold;\'>conv1</span>(x, batch_dict)\n        loss_box_of_pts += _loss\n        if self.use_img:\n            x_conv1, _loss = self.conv_focal_multimodal(x_conv1, batch_dict, fuse_func)\n            loss_box_of_pts = loss_box_of_pts + _loss\n        x_conv2, _loss = self.conv2(x_conv1, batch_dict)\n        loss_box_of_pts += _loss\n        x_conv3, _loss = self.conv3(x_conv2, batch_dict)\n        loss_box_of_pts += _loss\n        x_conv4, _loss = self.conv4(x_conv3, batch_dict)\n        loss_box_of_pts += _loss\n        ret = self.extra_conv(x_conv4)\n        ret = ret.dense()\n        N, C, D, H, W = ret.shape\n        ret = ret.view(N, C * D, H, W)\n        multi_scale_voxel_features = {\n            \'conv1\': x_conv1,\n            \'conv2\': x_conv2,\n            \'conv3\': x_conv3,\n            \'conv4\': x_conv4,\n        }\n        return ret, multi_scale_voxel_features, loss_box_of_pts\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/focal_sparse_conv.py</p><font size="0"><pre class="language-python"><code class="language-python">class FocalSparseConv(spconv.SparseModule):\n    def forward(self, x, batch_dict, fuse_func=None):\n        spatial_indices = x.indices[:, 1:] * self.voxel_stride                      <span style=\'color: red\'># torch.Size([137566, 3])*1</span>\n        voxels_3d = spatial_indices * self.voxel_size + self.point_cloud_range[:3]  <span style=\'color: red\'># 相当于到原始点云的范围坐标</span>\n        x_predict = self.conv_enlarge(x) if self.conv_enlarge else x\n        if self.use_img:\n            x_predict = fuse_func(batch_dict, encoded_voxel=x_predict, layer_name="layer1")\n        imp3_3d = self.conv_imp(x_predict).features                       <span style=\'color: red\'># [41, 1440, 1440]-->torch.Size([137566, 27])做个卷积，输出通道为3**3=27</span>\n        out, loss_box_of_pts = self.<span style=\'color: green;font-weight: bold;\'>_gen_sparse_features</span>(x, imp3_3d, voxels_3d, batch_dict[\'gt_boxes\'] if self.training else None)\n        out = self.conv(out)            <span style=\'color: red\'># 稀疏卷积操作</span>\n        if self.use_img:\n            out = fuse_func(batch_dict, encoded_voxel=out, layer_name="layer1")\n        out = out.replace_feature(self.bn1(out.features))\n        out = out.replace_feature(self.relu(out.features))\n        return out, loss_box_of_pts\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/focal_sparse_conv.py</p><font size="0"><pre class="language-python"><code class="language-python">class FocalSparseConv(spconv.SparseModule):\n    def _gen_sparse_features(self, x, imp3_3d, voxels_3d, gt_boxes=None):\n        """\n            Generate the output sparse features from the focal sparse conv.\n            Args:\n                x: [N, C], lidar sparse features                               输入的稀疏卷积tensor\n                imps_3d: [N, kernelsize**3], the predicted importance values   torch.Size([137566, 27])；27是卷积的输出通道，由kernelsize**3决定\n                voxels_3d: [N, 3], the 3d positions of voxel centers\n                gt_boxes: for focal loss calculation\n        """\n        index = x.indices[:, 0]\n        batch_size = x.batch_size       <span style=\'color: red\'># 2</span>\n        voxel_features_fore = []\n        voxel_indices_fore = []\n        voxel_features_back = []\n        voxel_indices_back = []\n        box_of_pts_cls_targets = []\n        mask_voxels = []\n        loss_box_of_pts = 0\n        for b in range(batch_size):\n            if self.training and not self.skip_loss:\n                gt_boxes_batch = gt_boxes[b, :, :-1]                                <span style=\'color: red\'># (100, 6)</span>\n                gt_boxes_batch_idx = (gt_boxes_batch**2).sum(-1)>0                  <span style=\'color: red\'># (100,)</span>\n                gt_boxes_centers_batch = gt_boxes_batch[gt_boxes_batch_idx, :3]     <span style=\'color: red\'># (100, 3)</span>\n                gt_boxes_sizes_batch = gt_boxes_batch[gt_boxes_batch_idx, 3:6]\n                index = x.indices[:, 0]\n                batch_index = index==b\n                mask_voxel = imp3_3d[batch_index, -1].sigmoid()  <span style=\'color: red\'># 卷积得到的特征做sigmoid</span>\n                mask_voxels.append(mask_voxel)\n                voxels_3d_batch = voxels_3d[batch_index]         <span style=\'color: red\'># torch.Size([106998, 3])</span>\n                dist_voxels_to_gtboxes = (voxels_3d_batch[:, self.inv_idx].unsqueeze(1).repeat(1, gt_boxes_centers_batch.shape[0], 1) - gt_boxes_centers_batch.unsqueeze(0)).abs()      <span style=\'color: red\'># torch.Size([106998, 100, 3])</span>\n                offsets_dist_boundry = dist_voxels_to_gtboxes - gt_boxes_sizes_batch.unsqueeze(0)            <span style=\'color: red\'># torch.Size([106998, 100, 3])与中心的距离与长度</span>\n                inboxes_voxels = ~torch.all(~torch.all(offsets_dist_boundry<=0, dim=-1), dim=-1)             <span style=\'color: red\'># 点距离100个里面任意一个box的x距离小于dx或者y的距离小于dy或者z的距离小于dz的点</span>\n                box_of_pts_cls_targets.append(inboxes_voxels)\n            features_fore, indices_fore, features_back, indices_back = <span style=\'color: green;font-weight: bold;\'>split_voxels</span>(x, b, imp3_3d, voxels_3d, self.kernel_offsets, mask_multi=self.mask_multi, topk=self.topk, threshold=self.threshold)\n            voxel_features_fore.append(features_fore)\n            voxel_indices_fore.append(indices_fore)\n            voxel_features_back.append(features_back)\n            voxel_indices_back.append(indices_back)\n        voxel_features_fore = torch.cat(voxel_features_fore+voxel_features_back, dim=0)         <span style=\'color: red\'># torch.Size([600673, 16])</span>\n        voxel_indices_fore = torch.cat(voxel_indices_fore+voxel_indices_back, dim=0)            <span style=\'color: red\'># torch.Size([600673, 4])</span>\n        out = spconv.SparseConvTensor(voxel_features_fore, voxel_indices_fore, x.spatial_shape, x.batch_size)\n        \n        if self.training and not self.skip_loss:\n            mask_voxels = torch.cat(mask_voxels)                                 <span style=\'color: red\'># torch.Size([137566])</span>\n            box_of_pts_cls_targets = torch.cat(box_of_pts_cls_targets)           <span style=\'color: red\'># torch.Size([137566])</span>\n            mask_voxels_two_classes = torch.cat([1-mask_voxels.unsqueeze(-1), mask_voxels.unsqueeze(-1)], dim=1)      <span style=\'color: red\'># torch.Size([137566, 2])</span>\n            loss_box_of_pts += self.focal_loss(mask_voxels_two_classes, box_of_pts_cls_targets.long())\n        return out, loss_box_of_pts                                              <span style=\'color: red\'># tensor(0.0922, device=\'cuda:0\', grad_fn=<AddBackward0>)</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def split_voxels(x, b, imps_3d, voxels_3d, kernel_offsets, mask_multi=True, topk=True, threshold=0.5):\n    """\n        Generate and split the voxels into foreground and background sparse features, based on the predicted importance values.\n        Args:\n            x: [N, C], input sparse features                                 [41, 1440, 1440]的tensor\n            b: int, batch size id\n            imps_3d: [N, kernelsize**3], the prediced importance values      做了卷积计算，输出通道为k**3=27的特征\n            voxels_3d: [N, 3], the 3d positions of voxel centers \n            kernel_offsets: [kernelsize**3, 3], the offset coords in an kernel       <span style=\'color: red\'># torch.Size([26, 3])？扔掉了(0,0,0)</span>\n            mask_multi: bool, whether to multiply the predicted mask to features\n            topk: bool, whether to use topk or threshold for selection\n            threshold: float, threshold value\n    """\n    index = x.indices[:, 0]\n    batch_index = index==b\n    indices_ori = x.indices[batch_index]            <span style=\'color: red\'># torch.Size([106998, 4])当前bacth的索引</span>\n    features_ori = x.features[batch_index]          <span style=\'color: red\'># torch.Size([106998, 16])</span>\n    mask_voxel = imps_3d[batch_index, -1].sigmoid()   <span style=\'color: red\'># torch.Size([106998])</span>\n    mask_kernel = imps_3d[batch_index, :-1].sigmoid() <span style=\'color: red\'># torch.Size([106998, 26])</span>\n    if mask_multi:\n        features_ori *= mask_voxel.unsqueeze(-1)      <span style=\'color: red\'># torch.Size([106998, 16])</span>\n    if topk:\n        _, indices = mask_voxel.sort(descending=True)\n        indices_fore = indices[:int(mask_voxel.shape[0]*threshold)]    <span style=\'color: red\'># torch.Size([53499])  取数值大的前面的作为前景点索引</span>\n        indices_back = indices[int(mask_voxel.shape[0]*threshold):]    <span style=\'color: red\'># torch.Size([53499])</span>\n    else:\n        indices_fore = mask_voxel > threshold\n        indices_back = mask_voxel <= threshold\n    features_fore = features_ori[indices_fore]       <span style=\'color: red\'># torch.Size([53499, 16])</span>\n    coords_fore = indices_ori[indices_fore]          <span style=\'color: red\'># torch.Size([53499, 4])</span>\n    mask_kernel_fore = mask_kernel[indices_fore]     <span style=\'color: red\'># torch.Size([53499, 26])</span>\n    mask_kernel_bool = mask_kernel_fore>=threshold   <span style=\'color: red\'># torch.Size([53499, 26])</span>\n    voxel_kerels_imp = kernel_offsets.unsqueeze(0).repeat(mask_kernel_bool.shape[0],1, 1)     <span style=\'color: red\'># torch.Size([26, 3])->torch.Size([53499, 26, 3])</span>\n    indices_fore_kernels = coords_fore[:, 1:].unsqueeze(1).repeat(1, kernel_offsets.shape[0], 1)    <span style=\'color: red\'># torch.Size([53499, 26, 3])</span>\n    indices_with_imp = indices_fore_kernels + voxel_kerels_imp                                      <span style=\'color: red\'># torch.Size([53499, 26, 3])   53499个前景点*26个位移</span>\n    selected_indices = indices_with_imp[mask_kernel_bool]                                           <span style=\'color: red\'># torch.Size([651511, 3])      53499个前景点*26个位移里面有651511个点满足条件</span>\n    spatial_indices = (selected_indices[:, 0] >0) * (selected_indices[:, 1] >0) * (selected_indices[:, 2] >0)  * \\\n                        (selected_indices[:, 0] < x.spatial_shape[0]) * (selected_indices[:, 1] < x.spatial_shape[1]) * (selected_indices[:, 2] < x.spatial_shape[2])  <span style=\'color: red\'># torch.Size([651511])</span>\n    selected_indices = selected_indices[spatial_indices]                                            <span style=\'color: red\'># torch.Size([651320, 3])      这些点里面又有651320个点在feature map比如0-1440里面</span>\n    selected_indices = torch.cat([torch.ones((selected_indices.shape[0], 1), device=features_fore.device)*b, selected_indices], dim=1)   <span style=\'color: red\'># torch.Size([651320, 4]) 相当于第0为给上索引</span>\n    selected_features = torch.zeros((selected_indices.shape[0], features_ori.shape[1]), device=features_fore.device)                     <span style=\'color: red\'># torch.Size([651320, 16])</span>\n    selected_features, selected_indices = <span style=\'color: green;font-weight: bold;\'>check_repeat</span>(selected_features, selected_indices)         <span style=\'color: red\'># torch.Size([384775, 16]); torch.Size([384775, 4])   651320去重有384775个点不重复？</span>\n    features_fore_cat = torch.cat([features_fore, selected_features], dim=0)                          <span style=\'color: red\'># torch.Size([438274, 16])   </span>\n    coords_fore = torch.cat([coords_fore, selected_indices], dim=0)                                   <span style=\'color: red\'># torch.Size([438274, 4])</span>\n \n    features_fore, coords_fore = <span style=\'color: green;font-weight: bold;\'>check_repeat</span>(features_fore_cat, coords_fore, sort_first=True)      <span style=\'color: red\'># 438274去重后剩下398124个点torch.Size([398124, 16])</span>\n    features_back = features_ori[indices_back]                  <span style=\'color: red\'># torch.Size([53499, 16])</span>\n    coords_back = indices_ori[indices_back]                     <span style=\'color: red\'># torch.Size([53499, 4])</span>\n    return features_fore, coords_fore, features_back, coords_back\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def check_repeat(features, indices, sort_first=False):\n    """\n        Check that whether there are replicate indices in the sparse features, \n        remove the replicate features if any.\n    """\n    if sort_first:\n        features, indices = sort_by_indices(features, indices)\n        features, indices = features.flip([0]), indices.flip([0])\n        idx = indices[:, 1:].int()\n        idx_sum = torch.add(torch.add(idx.select(1, 0) * idx[:, 1].max() * idx[:, 2].max(), idx.select(1, 1) * idx[:, 2].max()), idx.select(1, 2))\n        _unique, inverse = torch.unique_consecutive(idx_sum, return_inverse=True, dim=0)\n    else:\n        _unique, inverse = torch.unique(indices, return_inverse=True, dim=0)   <span style=\'color: red\'># torch.Size([651320, 4])->torch.Size([384775, 4])+torch.Size([651320])</span>\n    if _unique.shape[0] < indices.shape[0]:\n        perm = torch.arange(inverse.size(0), dtype=inverse.dtype, device=inverse.device)   <span style=\'color: red\'># torch.Size([651320])值为(0,1,...,651319)</span>\n        if sort_first:\n            features_new = torch.zeros((_unique.shape[0], features.shape[-1]), device=features.device)\n            features_new.index_add_(0, inverse.long(), features)\n            features = features_new\n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)\n            indices = indices[perm_].int()\n        else:\n            inverse, perm = inverse.flip([0]), perm.flip([0])                       <span style=\'color: red\'># torch.Size([651320]); torch.Size([651320])</span>\n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)   <span style=\'color: red\'># torch.Size([384775])</span>\n            features = features[perm_]                         <span style=\'color: red\'># torch.Size([651320, 16])->torch.Size([384775, 16])</span>\n            indices = _unique.int()\n    return features, indices\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def check_repeat(features, indices, sort_first=False):\n    """\n        Check that whether there are replicate indices in the sparse features, \n        remove the replicate features if any.\n    """\n    if sort_first:\n        features, indices = <span style=\'color: green;font-weight: bold;\'>sort_by_indices</span>(features, indices)   <span style=\'color: red\'># torch.Size([438274, 16])+torch.Size([438274, 4])</span>\n        features, indices = features.flip([0]), indices.flip([0])  <span style=\'color: red\'># 翻转，第一行会变成最后一行</span>\n        idx = indices[:, 1:].int()\n        idx_sum = torch.add(torch.add(idx.select(1, 0) * idx[:, 1].max() * idx[:, 2].max(), idx.select(1, 1) * idx[:, 2].max()), idx.select(1, 2))\n        _unique, inverse = torch.unique_consecutive(idx_sum, return_inverse=True, dim=0)        <span style=\'color: red\'># 作唯一计算  torch.Size([398124])  torch.Size([438274])</span>\n    else:\n        _unique, inverse = torch.unique(indices, return_inverse=True, dim=0)   \n    if _unique.shape[0] < indices.shape[0]:\n        perm = torch.arange(inverse.size(0), dtype=inverse.dtype, device=inverse.device) \n        if sort_first:\n            features_new = torch.zeros((_unique.shape[0], features.shape[-1]), device=features.device)   <span style=\'color: red\'># torch.Size([398124, 16])</span>\n            features_new.index_add_(0, inverse.long(), features)\n            features = features_new\n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)\n            indices = indices[perm_].int()                                                               <span style=\'color: red\'># torch.Size([398124, 4])</span>\n        else:\n            inverse, perm = inverse.flip([0]), perm.flip([0])                      \n            perm_ = inverse.new_empty(_unique.size(0)).scatter_(0, inverse, perm)  \n            features = features[perm_]                       \n            indices = _unique.int()\n    return features, indices\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/focal_sparse_conv/utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def sort_by_indices(features, indices):\n    """ To sort the sparse features with its indices in a convenient manner.\n        Args:\n            features: [N, C], sparse features\n            indices: [N, 4], indices of sparse features\n    """\n    idx = indices[:, 1:]                <span style=\'color: red\'># torch.Size([438274, 3])  就是排个序</span>\n    idx_sum = idx.select(1, 0) * idx[:, 1].max() * idx[:, 2].max() + idx.select(1, 1) * idx[:, 2].max() + idx.select(1, 2)\n    _, ind = idx_sum.sort()\n    features = features[ind]\n    indices = indices[ind]\n    return features, indices\n</code></pre></font>'}]}]}]}]}]}]})</script></body>
</html>
