<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>SpMiddleResNetFHDELKv3_forward</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/scn.py</p><font size="0"><pre class="language-python"><code class="language-python">class SpMiddleResNetFHDELKv3(nn.Module):\n    def __init__(self, num_input_features=128, norm_cfg=None, name="SpMiddleResNetFHDELKv3", **kwargs):\n        super(SpMiddleResNetFHDELKv3, self).__init__()\n        self.name = name\n        self.dcn = None\n        self.zero_init_residual = False\n        if norm_cfg is None:\n            norm_cfg = dict(type="BN1d", eps=1e-3, momentum=0.01)\n        self.planes = [16, 32, 64, 128]\n        <span style=\'color: red\'>self.planes = [16, 32, 32, 128]</span>\n        self.block_sz = 7\n        <span style=\'color: red\'>input:</span>\n        self.conv_input = spconv.SparseSequential(\n            SubMConv3d(num_input_features, self.planes[0], 3, bias=False, indice_key="res0"),        <span style=\'color: red\'>5,16,3x3</span>\n            build_norm_layer(norm_cfg, self.planes[0])[1],\n            nn.ReLU(inplace=True)\n        )\n        #######################################################################################################\n        self.conv1 = spconv.SparseSequential(        \n            SparseBasicBlock(self.planes[0], self.planes[0], norm_cfg=norm_cfg, indice_key="res1"),  <span style=\'color: red\'>32,32</span>\n            SparseBasicBlock(self.planes[0], self.planes[0], norm_cfg=norm_cfg, indice_key="res1"),  <span style=\'color: red\'>32,32</span>\n        )\n        self.conv1_tail = spconv.SparseSequential(\n            SubMConv3d(self.planes[0], self.planes[0], 3, bias=False, indice_key="res1_tail"),       <span style=\'color: red\'>32,32 3x3</span>\n            build_norm_layer(norm_cfg, self.planes[0])[1],\n        )\n        self.elk1 = TSELKBlock(self.planes[0], self.planes[0])\n        self.elk1_tail = spconv.SparseSequential(\n            SubMConv3d(self.planes[0], self.planes[0], 3, bias=False, indice_key="elk1_tail"),\n            build_norm_layer(norm_cfg, self.planes[0])[1],\n        )\n        self.act1 = nn.ReLU(inplace=True)\n        self.down2 = spconv.SparseSequential(\n            SparseConv3d(self.planes[0], self.planes[1], 3, 2, padding=1, bias=False),  <span style=\'color: red\'>[1600, 1200, 41] -> [800, 600, 21]</span>\n            build_norm_layer(norm_cfg, self.planes[1])[1],\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, voxel_features, coors, batch_size, input_shape):      <span style=\'color: red\'>torch.Size([137566, 5]); torch.Size([137566, 4]); 2; [1440, 1440, 40]</span>\n        <span style=\'color: red\'>input:</span>\n        sparse_shape = np.array(input_shape[::-1]) + [1, 0, 0]              <span style=\'color: red\'>[41, 1440, 1440]</span>\n        coors = coors.int()\n        ret = spconv.SparseConvTensor(voxel_features, coors, sparse_shape, batch_size)     <span style=\'color: red\'>[41, 1440, 1440]</span>\n        x = self.conv_input(ret)                                                           <span style=\'color: red\'>[41, 1440, 1440]</span>\n        ######################################################################################################\n        x_conv1 = self.conv1_tail(self.conv1(x))                                          <span style=\'color: red\'>[41, 1440, 1440]</span>\n        x_lk1 = self.elk1_tail(self.<span style=\'color: green;font-weight: bold;\'>elk1</span>(x, self.block_sz))                               <span style=\'color: red\'>x+7->[41, 1440, 1440]</span>\n        <span style=\'color: red\'>x_conv1 = self.conv1(x)</span>\n        <span style=\'color: red\'>x_lk1 = self.elk1(x, 7)</span>\n        x_conv1 = replace_feature(x_conv1, self.act1(x_conv1.features + x_lk1.features))  <span style=\'color: red\'>[41, 1440, 1440]</span>\n        x_down2 = self.down2(x_conv1)                                                     <span style=\'color: red\'>[21, 720, 720]</span>\n        ######################################################################################################\n        x_conv2 = self.conv2_tail(self.conv2(x_down2))                                    <span style=\'color: red\'>[21, 720, 720]</span>\n        x_lk2 = self.elk2_tail(self.elk2(x_down2, self.block_sz))                         <span style=\'color: red\'>[21, 720, 720]</span>\n        <span style=\'color: red\'>x_conv2 = self.conv2(x_down2)</span>\n        <span style=\'color: red\'>x_lk2 = self.elk2(x_down2, 7)</span>\n        x_conv2 = replace_feature(x_conv2, self.act2(x_conv2.features + x_lk2.features))  <span style=\'color: red\'>[21, 720, 720]</span>\n        x_down3 = self.down3(x_conv2)\n        ######################################################################################################\n        x_conv3 = self.conv3_tail(self.conv3(x_down3))\n        x_lk3 = self.elk3_tail(self.elk3(x_down3, self.block_sz))\n        <span style=\'color: red\'>x_conv3 = self.conv3(x_down3)</span>\n        <span style=\'color: red\'>x_lk3 = self.elk3(x_down3, 7)</span>\n        x_conv3 = replace_feature(x_conv3, self.act3(x_conv3.features + x_lk3.features))\n        x_down4 = self.down4(x_conv3)\n        ######################################################################################################\n        x_conv4 = self.conv4_tail(self.conv4(x_down4))\n        x_lk4 = self.elk4_tail(self.elk4(x_down4, self.block_sz))\n        <span style=\'color: red\'>x_conv4 = self.conv4(x_down4)</span>\n        <span style=\'color: red\'>x_lk4 = self.elk4(x_down4, 7)</span>\n        x_conv4 = replace_feature(x_conv4, self.act4(x_conv4.features + x_lk4.features))      <span style=\'color: red\'>[5, 180, 180]</span>\n        ######################################################################################################\n        ret = self.extra_conv(x_conv4)\n        ret = ret.dense()\n        N, C, D, H, W = ret.shape                        <span style=\'color: red\'>torch.Size([2, 128, 2, 180, 180])</span>\n        ret = ret.view(N, C * D, H, W)\n        multi_scale_voxel_features = {\n            \'conv1\': x_conv1,\n            \'conv2\': x_conv2,\n            \'conv3\': x_conv3,\n            \'conv4\': x_conv4,\n        }\n        return ret, multi_scale_voxel_features\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><font size="0"><pre class="language-python"><code class="language-python">class TSELKBlock(nn.Module):\n    def forward(self, sct: spconv.SparseConvTensor, stride):\n        """sct: SparseConvTensor (in spconv)"""\n        st, sct_save = <span style=\'color: green;font-weight: bold;\'>spconv2ts</span>(sct)            <span style=\'color: red\'># [41, 1440, 1440]  将spconv的稀疏卷积变成torchsparse的卷积</span>\n        new_st = self.<span style=\'color: green;font-weight: bold;\'>forward_</span>(st, stride)\n        new_sct = <span style=\'color: green;font-weight: bold;\'>ts2spconv</span>(new_st, sct_save)    <span style=\'color: red\'># 将torchsparse的卷积变回来</span>\n        return new_sct\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><font size="0"><pre class="language-python"><code class="language-python">def spconv2ts(sct: spconv.SparseConvTensor):\n    """sct: SparseConvTensor (spconv)\n        returns: \n          - st: SparseTensor (torchsparse)\n          - sct_save: a dict including some info from sct, for the use of inverse transformation.\n    """\n    feats = sct.features                                        <span style=\'color: red\'># torch.Size([137566, 16])</span>\n    coords = torch.index_select(sct.indices, 1, torch.LongTensor([3,2,1,0]).to(sct.indices.device)).contiguous()  <span style=\'color: red\'># torch.Size([137566, 4])->(B,Z,Y,Z)=>(X,Y,Z,B)?</span>\n    st = SparseTensor(feats, coords, 1)                         <span style=\'color: red\'># 这里将自带的tensor转变到torchsparse的tensor</span>\n    sct_save = dict()\n    sct_save[\'batch_size\'] = sct.batch_size                     <span style=\'color: red\'># 2</span>\n    sct_save[\'benchmark\'] = sct.benchmark                       <span style=\'color: red\'># False</span>\n    sct_save[\'benchmark_record\'] = sct.benchmark_record         <span style=\'color: red\'># {}</span>\n    sct_save[\'grid\'] = sct.grid                                 <span style=\'color: red\'># tensor([])</span>\n    sct_save[\'indice_dict\'] = sct.indice_dict                   <span style=\'color: red\'># {\'res0\': <spconv.pytorch.core...8910bc4f0>}</span>\n    sct_save[\'spatial_shape\'] = sct.spatial_shape               <span style=\'color: red\'># [41, 1440, 1440]</span>\n    sct_save[\'voxel_num\'] = sct.voxel_num                       <span style=\'color: red\'># None</span>\n    return st, sct_save\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><font size="0"><pre class="language-python"><code class="language-python">class TSELKBlock(nn.Module):\n    def forward_(self, st: SparseTensor, stride):\n        \'\'\'  st: SparseTensor\n             stride: scale of large kernel\n        \'\'\'\n        F_input = self.pre_mix(st.F)    <span style=\'color: red\'># st.F=torch.Size([137566, 16]) -> torch.Size([137566, 16])</span>\n        local_mix = self.local_mix(st)\n        if self.baseop == \'sin\':\n            ......\n        elif self.baseop == \'cos\':\n            pos_weight = self.pos_weight(st.C[:,:3].float())              <span style=\'color: red\'># torch.Size([137566, 4])  坐标用3维变成16维--》torch.Size([137566, 16])</span>\n            pos_weight = pos_weight[:,:self.inc//2].repeat([1,2])         <span style=\'color: red\'># channel grouping  torch.Size([137566, 8])->torch.Size([137566, 16])沿着第二维重复</span>\n            pos_weight_sin = torch.sin(pos_weight)                        <span style=\'color: red\'># torch.Size([137566, 16])</span>\n            pos_weight_cos = torch.cos(pos_weight)                        <span style=\'color: red\'># torch.Size([137566, 16])</span>\n            F_weighted_sin = F_input*pos_weight_sin                       <span style=\'color: red\'># torch.Size([137566, 16])</span>\n            F_weighted_cos = F_input*pos_weight_cos\n            st.F = torch.cat([F_weighted_cos, F_weighted_sin], dim=1).contiguous()     <span style=\'color: red\'># torch.Size([137566, 32])     K^(0)(a)*f_a+k^(1)(a)*f_a</span>\n            small_st, idx, counts = <span style=\'color: green;font-weight: bold;\'>large_to_small</span>(st, stride=stride)    <span style=\'color: red\'># 应该是7x7下采样得到新的tensor</span>\n            large_st = <span style=\'color: green;font-weight: bold;\'>small_to_large_v2</span>(small_st, st, idx, counts)      <span style=\'color: red\'># torch.Size([137566, 32])</span>\n            new_st_F = large_st.F[:,:self.inc]*pos_weight_cos + large_st.F[:,self.inc:]*pos_weight_sin  <span style=\'color: red\'># self.inc=16; -->torch.Size([137566, 16])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><font size="0"><pre class="language-python"><code class="language-python"><span style=\'color: red\'># x: SparseTensor->large, stride: scale of kernel  return : SparseTensor->small</span>\ndef large_to_small(large_x, stride):              <span style=\'color: red\'># torch.Size([137566, 32])，7  分成7快大小s</span>\n    x_C = torch.cat([torch.div(large_x.C[:,:3], stride, rounding_mode=\'floor\').int(), large_x.C[:,3:]], dim=1)   <span style=\'color: red\'># 相当于把x,y,z的位置除以7，可能有不同的点下采样到同一个点  torch.Size([137566, 4])</span>\n    large_x_hash = F.sphash(x_C.to(large_x.F.device))                      <span style=\'color: red\'># torch.Size([137566])</span>\n    small_x_C = torch.unique(x_C, dim=0)                                   <span style=\'color: red\'># torch.Size([13740, 4])</span>\n    small_x_hash = F.sphash(small_x_C.to(large_x.F.device))                <span style=\'color: red\'># torch.Size([13740])</span>\n    idx_query = F.sphashquery(large_x_hash, small_x_hash)                  <span style=\'color: red\'># torch.Size([137566])</span>\n    counts = F.spcount(idx_query.int(), len(small_x_hash))                 <span style=\'color: red\'># torch.Size([13740])</span>\n    inserted_feat = F.spvoxelize(large_x.F, idx_query, counts)\n    small_x = SparseTensor(inserted_feat, small_x_C, stride)\n    small_x.cmaps = large_x.cmaps\n    small_x.kmaps = large_x.kmaps\n    return small_x, idx_query, counts\n<span style=\'color: red\'># F.sphash()是一个函数，用于将一个点云的坐标和特征编码成一个哈希表。这个哈希表存储了点云中每个点的坐标和特征信息，以及这些点在原始点云中的索引。它使用了点云的体素化方法，将空间分成了许多小的体素，每个体素内部存储其内包含的点的信息。</span>\n<span style=\'color: red\'># 这种压缩方式可以大大减少点云的存储空间，并且可以加速点云的相关计算，如点云分割和物体检测。</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><font size="0"><pre class="language-python"><code class="language-python">def small_to_large_v2(small_x, large_x, idx, counts):\n    <span style=\'color: red\'># local offsets to index neighbors</span>\n    ## [2^3,3]\n    kernel_size = 3\n    offsets = get_kernel_offsets(kernel_size, 1, 1, device=large_x.F.device)   <span style=\'color: red\'># torch.Size([27, 3])</span>\n    neighbor_hash = F.sphash(small_x.C, offsets)                                                                          <span style=\'color: red\'># torch.Size([13740, 4]) + torch.Size([27, 3])  torch.Size([27, 13740])</span>\n    small_hash = F.sphash(small_x.C.to(large_x.F.device))                      <span style=\'color: red\'># torch.Size([13740])</span>\n    idx_query = F.sphashquery(neighbor_hash, small_hash)                       <span style=\'color: red\'># torch.Size([27, 13740])    </span>\n    idx_query = idx_query.transpose(0,1).contiguous()                          <span style=\'color: red\'># torch.Size([13740, 27])</span>\n    idx_query_flat = idx_query.view(-1)\n    f = torch.cat([small_x.F, torch.ones_like(small_x.F[:,:1]).to(small_x.F.device)], dim=1)   <span style=\'color: red\'># torch.Size([13740, 32])+torch.Size([13740, 1])->torch.Size([13740, 33])</span>\n    f = f*counts.unsqueeze(dim=-1)                                                             <span style=\'color: red\'># torch.Size([13740, 33])</span>\n    weights = torch.ones(small_x.F.shape[0], kernel_size**3).to(small_x.F.device).float()      <span style=\'color: red\'># torch.Size([13740, 27])</span>\n    weights[idx_query == -1] = 0\n    new_feat = F.spdevoxelize(f, idx_query, weights, kernel_size)              <span style=\'color: red\'># torch.Size([13740, 33])</span>\n    new_feat = new_feat[:,:-1] / new_feat[:,-1:]                               <span style=\'color: red\'># torch.Size([13740, 32])</span>\n    large_x.F = new_feat[idx]                                                  <span style=\'color: red\'># large_x.F.shape = torch.Size([137566, 32])   idx.shape=torch.Size([137566])</span>\n    return large_x\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><font size="0"><pre class="language-python"><code class="language-python">def ts2spconv(st: SparseTensor, sct_save: dict):\n    """- st: SparseTensor (torchsparse)\n       - sct_save: a dict including some additional info for sct\n        returns: \n            sct: SparseConvTensor (spconv)\n    """ \n    features = st.feats                 <span style=\'color: red\'># torch.Size([137566, 16])</span>\n    indices = torch.index_select(st.coords, 1, torch.LongTensor([3,2,1,0]).to(st.coords.device)).contiguous()\n    sct = spconv.SparseConvTensor(\n                features,\n                indices,\n                spatial_shape=sct_save[\'spatial_shape\'],      <span style=\'color: red\'># [41, 1440, 1440]</span>\n                batch_size=sct_save[\'batch_size\'],\n                grid=sct_save[\'grid\'],\n                voxel_num=sct_save[\'voxel_num\'],\n                indice_dict=sct_save[\'indice_dict\'],\n                benchmark=sct_save[\'benchmark\']\n    )\n    sct.benchmark_record = sct_save[\'benchmark_record\']\n    return sct\n</code></pre></font>'}]}]}]})</script></body>
</html>
