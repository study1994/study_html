<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>SpMiddleResNetFHDELKv3_forward</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/backbones/scn.py</p><span class=\'hidden-code\' data-code=\'class SpMiddleResNetFHDELKv3(nn.Module):\n    def __init__(self, num_input_features=128, norm_cfg=None, name=&amp;#39;SpMiddleResNetFHDELKv3&amp;#39;, **kwargs):\n        super(SpMiddleResNetFHDELKv3, self).__init__()\n        self.name = name\n        self.dcn = None\n        self.zero_init_residual = False\n        if norm_cfg is None:\n            norm_cfg = dict(type=&amp;#39;BN1d&amp;#39;, eps=1e-3, momentum=0.01)\n        self.planes = [16, 32, 64, 128]\n        self.planes = [16, 32, 32, 128]\n        self.block_sz = 7\n        input: [1600, 1200, 41]\n        self.conv_input = spconv.SparseSequential(\n            SubMConv3d(num_input_features, self.planes[0], 3, bias=False, indice_key=&amp;#39;res0&amp;#39;),        5,16,3x3\n            build_norm_layer(norm_cfg, self.planes[0])[1],\n            nn.ReLU(inplace=True)\n        )\n        #######################################################################################################\n        self.conv1 = spconv.SparseSequential(        \n            SparseBasicBlock(self.planes[0], self.planes[0], norm_cfg=norm_cfg, indice_key=&amp;#39;res1&amp;#39;),  32,32\n            SparseBasicBlock(self.planes[0], self.planes[0], norm_cfg=norm_cfg, indice_key=&amp;#39;res1&amp;#39;),  32,32\n        )\n        self.conv1_tail = spconv.SparseSequential(\n            SubMConv3d(self.planes[0], self.planes[0], 3, bias=False, indice_key=&amp;#39;res1_tail&amp;#39;),       32,32 3x3\n            build_norm_layer(norm_cfg, self.planes[0])[1],\n        )\n        self.elk1 = TSELKBlock(self.planes[0], self.planes[0])\n        self.elk1_tail = spconv.SparseSequential(\n            SubMConv3d(self.planes[0], self.planes[0], 3, bias=False, indice_key=&amp;#39;elk1_tail&amp;#39;),\n            build_norm_layer(norm_cfg, self.planes[0])[1],\n        )\n        self.act1 = nn.ReLU(inplace=True)\n        self.down2 = spconv.SparseSequential(\n            SparseConv3d(self.planes[0], self.planes[1], 3, 2, padding=1, bias=False),  [1600, 1200, 41] -> [800, 600, 21]\n            build_norm_layer(norm_cfg, self.planes[1])[1],\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, voxel_features, coors, batch_size, input_shape):      torch.Size([137566, 5]); torch.Size([137566, 4]); 2; [1440, 1440, 40]\n        input: [41, 1600, 1408]\n        sparse_shape = np.array(input_shape[::-1]) + [1, 0, 0]              [41, 1440, 1440]\n        coors = coors.int()\n        ret = spconv.SparseConvTensor(voxel_features, coors, sparse_shape, batch_size)     [41, 1440, 1440]\n        x = self.conv_input(ret)                                                           [41, 1440, 1440]\n        ######################################################################################################\n        x_conv1 = self.conv1_tail(self.conv1(x))                                          [41, 1440, 1440]\n        x_lk1 = self.elk1_tail(self.`elk1`(x, self.block_sz))                               x+7->[41, 1440, 1440]\n        x_conv1 = self.conv1(x)\n        x_lk1 = self.elk1(x, 7)\n        x_conv1 = replace_feature(x_conv1, self.act1(x_conv1.features + x_lk1.features))  [41, 1440, 1440]\n        x_down2 = self.down2(x_conv1)                                                     [21, 720, 720]\n        ######################################################################################################\n        x_conv2 = self.conv2_tail(self.conv2(x_down2))                                    [21, 720, 720]\n        x_lk2 = self.elk2_tail(self.elk2(x_down2, self.block_sz))                         [21, 720, 720]\n        x_conv2 = self.conv2(x_down2)\n        x_lk2 = self.elk2(x_down2, 7)\n        x_conv2 = replace_feature(x_conv2, self.act2(x_conv2.features + x_lk2.features))  [21, 720, 720]\n        x_down3 = self.down3(x_conv2)\n        ######################################################################################################\n        x_conv3 = self.conv3_tail(self.conv3(x_down3))\n        x_lk3 = self.elk3_tail(self.elk3(x_down3, self.block_sz))\n        x_conv3 = self.conv3(x_down3)\n        x_lk3 = self.elk3(x_down3, 7)\n        x_conv3 = replace_feature(x_conv3, self.act3(x_conv3.features + x_lk3.features))\n        x_down4 = self.down4(x_conv3)\n        ######################################################################################################\n        x_conv4 = self.conv4_tail(self.conv4(x_down4))\n        x_lk4 = self.elk4_tail(self.elk4(x_down4, self.block_sz))\n        x_conv4 = self.conv4(x_down4)\n        x_lk4 = self.elk4(x_down4, 7)\n        x_conv4 = replace_feature(x_conv4, self.act4(x_conv4.features + x_lk4.features))      [5, 180, 180]\n        ######################################################################################################\n        ret = self.extra_conv(x_conv4)\n        ret = ret.dense()\n        N, C, D, H, W = ret.shape                        torch.Size([2, 128, 2, 180, 180])\n        ret = ret.view(N, C * D, H, W)\n        multi_scale_voxel_features = {\n            &amp;#39;conv1&amp;#39;: x_conv1,\n            &amp;#39;conv2&amp;#39;: x_conv2,\n            &amp;#39;conv3&amp;#39;: x_conv3,\n            &amp;#39;conv4&amp;#39;: x_conv4,\n        }\n        return ret, multi_scale_voxel_features\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><span class=\'hidden-code\' data-code=\'class TSELKBlock(nn.Module):\n    def forward(self, sct: spconv.SparseConvTensor, stride):\n        &amp;#39;&amp;#39;&amp;#39;sct: SparseConvTensor (in spconv)&amp;#39;&amp;#39;&amp;#39;\n        st, sct_save = `spconv2ts`(sct)            # [41, 1440, 1440]  将spconv的稀疏卷积变成torchsparse的卷积\n        new_st = self.`forward_`(st, stride)\n        new_sct = `ts2spconv`(new_st, sct_save)    # 将torchsparse的卷积变回来\n        return new_sct\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><span class=\'hidden-code\' data-code=\'def spconv2ts(sct: spconv.SparseConvTensor):\n    &amp;#39;&amp;#39;&amp;#39;sct: SparseConvTensor (spconv)\n        returns: \n          - st: SparseTensor (torchsparse)\n          - sct_save: a dict including some info from sct, for the use of inverse transformation.\n    &amp;#39;&amp;#39;&amp;#39;\n    feats = sct.features                                        # torch.Size([137566, 16])\n    coords = torch.index_select(sct.indices, 1, torch.LongTensor([3,2,1,0]).to(sct.indices.device)).contiguous()  # torch.Size([137566, 4])->(B,Z,Y,Z)=>(X,Y,Z,B)?\n    st = SparseTensor(feats, coords, 1)                         # 这里将自带的tensor转变到torchsparse的tensor\n    sct_save = dict()\n    sct_save[&amp;#39;batch_size&amp;#39;] = sct.batch_size                     # 2\n    sct_save[&amp;#39;benchmark&amp;#39;] = sct.benchmark                       # False\n    sct_save[&amp;#39;benchmark_record&amp;#39;] = sct.benchmark_record         # {}\n    sct_save[&amp;#39;grid&amp;#39;] = sct.grid                                 # tensor([])\n    sct_save[&amp;#39;indice_dict&amp;#39;] = sct.indice_dict                   # {&amp;#39;res0&amp;#39;: `<`spconv.pytorch.core...8910bc4f0`>`}\n    sct_save[&amp;#39;spatial_shape&amp;#39;] = sct.spatial_shape               # [41, 1440, 1440]\n    sct_save[&amp;#39;voxel_num&amp;#39;] = sct.voxel_num                       # None\n    return st, sct_save\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><span class=\'hidden-code\' data-code=\'class TSELKBlock(nn.Module):\n    def forward_(self, st: SparseTensor, stride):\n        &amp;#39;&amp;#39;&amp;#39;  st: SparseTensor\n             stride: scale of large kernel\n        &amp;#39;&amp;#39;&amp;#39;\n        F_input = self.pre_mix(st.F)    # st.F=torch.Size([137566, 16]) -> torch.Size([137566, 16])\n        local_mix = self.local_mix(st)\n        if self.baseop == &amp;#39;sin&amp;#39;:\n            ......\n        elif self.baseop == &amp;#39;cos&amp;#39;:\n            pos_weight = self.pos_weight(st.C[:,:3].float())              # torch.Size([137566, 4])  坐标用3维变成16维--》torch.Size([137566, 16])\n            pos_weight = pos_weight[:,:self.inc//2].repeat([1,2])         # channel grouping  torch.Size([137566, 8])->torch.Size([137566, 16])沿着第二维重复\n            pos_weight_sin = torch.sin(pos_weight)                        # torch.Size([137566, 16])\n            pos_weight_cos = torch.cos(pos_weight)                        # torch.Size([137566, 16])\n            F_weighted_sin = F_input*pos_weight_sin                       # torch.Size([137566, 16])\n            F_weighted_cos = F_input*pos_weight_cos\n            st.F = torch.cat([F_weighted_cos, F_weighted_sin], dim=1).contiguous()     # torch.Size([137566, 32])     K^(0)(a)*f_a+k^(1)(a)*f_a\n            small_st, idx, counts = `large_to_small`(st, stride=stride)    # 应该是7x7下采样得到新的tensor\n            large_st = `small_to_large_v2`(small_st, st, idx, counts)      # torch.Size([137566, 32])\n            new_st_F = large_st.F[:,:self.inc]*pos_weight_cos + large_st.F[:,self.inc:]*pos_weight_sin  # self.inc=16; -->torch.Size([137566, 16])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><span class=\'hidden-code\' data-code=\'# x: SparseTensor->large, stride: scale of kernel  return : SparseTensor->small\ndef large_to_small(large_x, stride):              # torch.Size([137566, 32])，7  分成7快大小s\n    x_C = torch.cat([torch.div(large_x.C[:,:3], stride, rounding_mode=&amp;#39;floor&amp;#39;).int(), large_x.C[:,3:]], dim=1)   # 相当于把x,y,z的位置除以7，可能有不同的点下采样到同一个点  torch.Size([137566, 4])\n    large_x_hash = F.sphash(x_C.to(large_x.F.device))                      # torch.Size([137566])\n    small_x_C = torch.unique(x_C, dim=0)                                   # torch.Size([13740, 4])\n    small_x_hash = F.sphash(small_x_C.to(large_x.F.device))                # torch.Size([13740])\n    idx_query = F.sphashquery(large_x_hash, small_x_hash)                  # torch.Size([137566])\n    counts = F.spcount(idx_query.int(), len(small_x_hash))                 # torch.Size([13740])\n    inserted_feat = F.spvoxelize(large_x.F, idx_query, counts)\n    small_x = SparseTensor(inserted_feat, small_x_C, stride)\n    small_x.cmaps = large_x.cmaps\n    small_x.kmaps = large_x.kmaps\n    return small_x, idx_query, counts\n# F.sphash()是一个函数，用于将一个点云的坐标和特征编码成一个哈希表。这个哈希表存储了点云中每个点的坐标和特征信息，以及这些点在原始点云中的索引。它使用了点云的体素化方法，将空间分成了许多小的体素，每个体素内部存储其内包含的点的信息。\n# 这种压缩方式可以大大减少点云的存储空间，并且可以加速点云的相关计算，如点云分割和物体检测。\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><span class=\'hidden-code\' data-code=\'def small_to_large_v2(small_x, large_x, idx, counts):\n    # local offsets to index neighbors\n    ## [2^3,3]\n    kernel_size = 3\n    offsets = get_kernel_offsets(kernel_size, 1, 1, device=large_x.F.device)   # torch.Size([27, 3])\n    neighbor_hash = F.sphash(small_x.C, offsets)                                                                          # torch.Size([13740, 4]) + torch.Size([27, 3])  torch.Size([27, 13740])\n    small_hash = F.sphash(small_x.C.to(large_x.F.device))                      # torch.Size([13740])\n    idx_query = F.sphashquery(neighbor_hash, small_hash)                       # torch.Size([27, 13740])     # 有13740个bi块\n    idx_query = idx_query.transpose(0,1).contiguous()                          # torch.Size([13740, 27])\n    idx_query_flat = idx_query.view(-1)\n    f = torch.cat([small_x.F, torch.ones_like(small_x.F[:,:1]).to(small_x.F.device)], dim=1)   # torch.Size([13740, 32])+torch.Size([13740, 1])->torch.Size([13740, 33])\n    f = f*counts.unsqueeze(dim=-1)                                                             # torch.Size([13740, 33])\n    weights = torch.ones(small_x.F.shape[0], kernel_size**3).to(small_x.F.device).float()      # torch.Size([13740, 27])\n    weights[idx_query == -1] = 0\n    new_feat = F.spdevoxelize(f, idx_query, weights, kernel_size)              # torch.Size([13740, 33])\n    new_feat = new_feat[:,:-1] / new_feat[:,-1:]                               # torch.Size([13740, 32])\n    large_x.F = new_feat[idx]                                                  # large_x.F.shape = torch.Size([137566, 32])   idx.shape=torch.Size([137566])\n    return large_x\n\'> </span>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">det3d/models/utils/ts_elk.py</p><span class=\'hidden-code\' data-code=\'def ts2spconv(st: SparseTensor, sct_save: dict):\n    &amp;#39;&amp;#39;&amp;#39;- st: SparseTensor (torchsparse)\n       - sct_save: a dict including some additional info for sct\n        returns: \n            sct: SparseConvTensor (spconv)\n    &amp;#39;&amp;#39;&amp;#39; \n    features = st.feats                 # torch.Size([137566, 16])\n    indices = torch.index_select(st.coords, 1, torch.LongTensor([3,2,1,0]).to(st.coords.device)).contiguous()\n    sct = spconv.SparseConvTensor(\n                features,\n                indices,\n                spatial_shape=sct_save[&amp;#39;spatial_shape&amp;#39;],      # [41, 1440, 1440]\n                batch_size=sct_save[&amp;#39;batch_size&amp;#39;],\n                grid=sct_save[&amp;#39;grid&amp;#39;],\n                voxel_num=sct_save[&amp;#39;voxel_num&amp;#39;],\n                indice_dict=sct_save[&amp;#39;indice_dict&amp;#39;],\n                benchmark=sct_save[&amp;#39;benchmark&amp;#39;]\n    )\n    sct.benchmark_record = sct_save[&amp;#39;benchmark_record&amp;#39;]\n    return sct\n\'> </span>'}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
