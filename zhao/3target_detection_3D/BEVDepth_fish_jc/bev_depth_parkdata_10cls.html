<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>bev_depth_parkdata_10cls</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">初始化</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">exps/bev_depth_parkdata_10cls.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEVDepthLightningModel(LightningModule):\n    def __init__(...):\n        super().__init__()\n        self.save_hyperparameters()\n        self.gpus = gpus\n        self.eval_interval = eval_interval                 <span style=\'color: red\'># 1</span>\n        self.batch_size_per_device = batch_size_per_device <span style=\'color: red\'># 8</span>\n        self.data_root = data_root                         <span style=\'color: red\'># ../data/parkdata</span>\n        self.basic_lr_per_img = 2e-4 / 64                  <span style=\'color: red\'># 最初2e-4 / 64</span>\n        self.class_names = class_names                     <span style=\'color: red\'># [\'car\']</span>\n        self.backbone_conf = backbone_conf\n        self.head_conf = head_conf\n        self.ida_aug_conf = ida_aug_conf                   <span style=\'color: red\'># {\'resize_dim\': (640, 400), \'final_dim\': (640, 384), \'H\': 800, \'W\': 1280}</span>\n        self.bda_aug_conf = bda_aug_conf                   <span style=\'color: red\'># {\'rot_lim\': (-22.5, 22.5), \'scale_lim\': (0.95, 1.05), \'flip_dx_ratio\': 0.5, \'flip_dy_ratio\': 0.5}</span>\n        mmcv.mkdir_or_exist(default_root_dir)              <span style=\'color: red\'># \'./outputs/bev_depth_parkdata_3task_384x640_120x88_1key\'</span>\n        self.default_root_dir = default_root_dir\n        self.model = <span style=\'color: green;font-weight: bold;\'>BEVPark10CLS</span>(self.backbone_conf,self.head_conf)\n        self.mode = \'valid\'\n        self.img_conf = img_conf                           <span style=\'color: red\'># img_mean img_std to_rgb=True   {\'img_mean\': [0.0, 0.0, 0.0], \'img_std\': [255.0, 255.0, 255.0], \'to_rgb\': True}</span>\n        self.data_use_cbgs = False\n        self.num_sweeps = 1\n        self.sweep_idxes = []\n        self.key_idxes = []\n        #self.data_return_depth = False\n        self.model_use_ema = True\n        self.downsample_factor = self.backbone_conf[\'downsample_factor\']    <span style=\'color: red\'># 8</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/bev_park10cls.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEVPark10CLS(nn.Module):\n    def __init__(self, backbone_conf, head_conf):\n        super(BEVPark10CLS, self).__init__()\n        self.backbone = <span style=\'color: green;font-weight: bold;\'>SampleFPN10</span>(**backbone_conf)\n        self.head = <span style=\'color: green;font-weight: bold;\'>BEV10CLSHead</span>(**head_conf)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/backbones/sample_fpn_10.py</p><font size="0"><pre class="language-python"><code class="language-python">class SampleFPN10(nn.Module):\n    def __init__():\n        super(SampleFPN10, self).__init__()\n        <span style=\'color: red\'># \'x_bound\': [-16.36, 16.36, 28*scale],  x向前,y朝左</span>\n        <span style=\'color: red\'># \'y_bound\': [-12, 12, 28*scale],</span>\n        <span style=\'color: red\'># \'z_bound\': [-1, 3, 4], </span>\n        self.XMIN, self.XMAX, self.vox_size_X = x_bound[:3]\n        self.YMIN, self.YMAX, self.vox_size_Y = y_bound[:3]\n        self.ZMIN, self.ZMAX, self.vox_size_Z = z_bound[:3]\n        self.X = round((x_bound[1]-x_bound[0])/x_bound[2]) <span style=\'color: red\'># 120</span>\n        self.Y = round((y_bound[1]-y_bound[0])/y_bound[2]) <span style=\'color: red\'># 88</span>\n        self.Z = round((z_bound[1]-z_bound[0])/z_bound[2]) <span style=\'color: red\'>#  4</span>\n        \n        self.downsample_factor = downsample_factor         <span style=\'color: red\'># 8 (640,384)下采样8倍, ->80,48</span>\n        self.output_channels = output_channels             <span style=\'color: red\'># 128</span>\n        <span style=\'color: red\'># ResNet50</span>\n        self.img_backbone = build_backbone(img_backbone_conf)\n        self.img_backbone.init_weights()\n        \n        <span style=\'color: red\'># SECONDFPN</span>\n        self.img_neck = build_neck(img_neck_conf)\n        self.img_neck.init_weights()\n        \n        <span style=\'color: red\'># ResNet18</span>\n        self.bevimg_backbone = build_backbone(bevimg_backbone_conf)\n        self.bevimg_backbone.init_weights()\n        \n        self.bevimg_neck = build_neck(bevimg_neck_conf)\n        self.bevimg_neck.init_weights()\n        \n        \n        fpn_out_channels = img_neck_conf[\'out_channels\']       <span style=\'color: red\'># [128, 128, 128, 128]</span>\n        fpnout_C = int(sum(fpn_out_channels))                  <span style=\'color: red\'># 512</span>\n        \n        bev_out_channels = bevimg_neck_conf[\'out_channels\']    <span style=\'color: red\'># [64, 64, 64, 64]</span>\n        bevout_C = int(sum(bev_out_channels))                  <span style=\'color: red\'># 256</span>\n        \n        self.do_fpn_compress = do_fpn_compress                 <span style=\'color: red\'># True</span>\n        self.do_bev_compress = do_bev_compress                 <span style=\'color: red\'># True</span>\n        \n        if do_fpn_compress:                                    <span style=\'color: red\'># 将512->128</span>\n            self.fpn_compressor = nn.Sequential(\n                nn.Conv2d(fpnout_C, fpnout_C//4, kernel_size=1,bias=False),\n                nn.BatchNorm2d(fpnout_C//4),\n                nn.ReLU(inplace=True)\n            )\n            for m in self.fpn_compressor.modules():\n                if isinstance(m, nn.Conv2d):\n                    torch.nn.init.kaiming_normal_(m.weight)\n        \n        bev_inchannel = fpnout_C//4*self.Z + bevout_C         <span style=\'color: red\'># 512//4*4+256=768-->768</span>\n        if do_bev_compress:\n            self.bev_compressor = nn.Sequential(\n                nn.Conv2d(bev_inchannel, self.output_channels, kernel_size=1, bias=False),\n                nn.BatchNorm2d(self.output_channels),\n                nn.ReLU(),\n            )\n            for m in self.bev_compressor.modules():\n                if isinstance(m, nn.Conv2d):\n                    torch.nn.init.kaiming_normal_(m.weight)\n        \n        self.cams = cams\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/heads/bev10cls_sample_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEV10CLSHead(ParkBEVCenterHead):\n    def __init__():\n        self.trunk = build_backbone(bev_backbone_conf)   <span style=\'color: red\'># {\'type\': \'ResNet\', \'in_channels\': 128, \'depth\': 18, \'num_stages\': 3, \'strides\': (1, 2, 2), \'dilations\': (1, 1, 1), \'out_indices\': [0, 1, 2], \'norm_eval\': False, \'base_channels\': 160}</span>\n        self.trunk.init_weights()\n        del self.trunk.maxpool\n        \n        self.neck = build_neck(bev_neck_conf)            <span style=\'color: red\'># {\'type\': \'SECONDFPN\', \'in_channels\': [128, 160, 320, 640], \'upsample_strides\': [1, 2, 4, 8], \'out_channels\': [64, 64, 64, 64]}</span>\n        self.neck.init_weights()\n        \n        self.gaussian_overlap = gaussian_overlap         <span style=\'color: red\'># 0.1</span>\n        self.min_radius = min_radius                     <span style=\'color: red\'># 2</span>\n        self.train_cfg = train_cfg\n        self.test_cfg = test_cfg\n        \n        self.debug = True\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdetection3d/mmdet3d/models/dense_heads/centerpoint_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class ParkBEVCenterHead(BaseModule):\n    def __init__():\n        num_classes = [len(t[\'class_names\']) for t in tasks]        <span style=\'color: red\'># [1, 2, 1, 5, 1]</span>\n        self.class_names = [t[\'class_names\'] for t in tasks]        <span style=\'color: red\'># [[\'car\'], [\'wheel_2\', \'rider\'], [\'people\'], [\'cone\', \'wsign\', \'stone\', \'piles\', \'lock\'], [\'"pillar"\']]</span>\n        self.train_cfg = train_cfg\n        self.test_cfg = test_cfg\n        self.in_channels = in_channels\n        self.num_classes = num_classes\n        self.norm_bbox = norm_bbox        <span style=\'color: red\'># True</span>\n        self.loss_cls = build_loss(loss_cls)\n        self.loss_bbox = build_loss(loss_bbox)\n        self.bbox_coder = build_bbox_coder(bbox_coder)\n        self.num_anchor_per_locs = [n for n in num_classes]\n        self.fp16_enabled = False\n        self.code_size = bbox_coder[\'code_size\']\n        <span style=\'color: red\'># a shared convolution</span>\n        self.shared_conv = ConvModule(\n            in_channels,                   <span style=\'color: red\'># 256</span>\n            share_conv_channel,            <span style=\'color: red\'># 64</span>\n            kernel_size=3,\n            padding=1,\n            conv_cfg=conv_cfg,\n            norm_cfg=norm_cfg,\n            bias=bias)\n        self.task_heads = nn.ModuleList()\n        for num_cls in num_classes:\n            heads = copy.deepcopy(common_heads)\n            heads.update(dict(heatmap=(num_cls, num_heatmap_convs))) #加入heatmap\n            separate_head.update(\n                in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n            self.task_heads.append(builder.build_head(separate_head))\n</code></pre></font>'}]}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">前向推理</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">exps/bev_depth_parkdata_10cls.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEVDepthLightningModel(LightningModule):\n    def training_step(self, batch):\n        (sweep_imgs,sweep_bevimgs,mats, img_metas, gt_boxes, gt_labels,gt_sjzs,gt_xrs) = batch\n        if torch.cuda.is_available():\n            for key, value in mats.items():\n                mats[key] = value.cuda()\n            sweep_imgs = sweep_imgs.cuda()\n            sweep_bevimgs = sweep_bevimgs.cuda()\n            gt_boxes = [gt_box.cuda() for gt_box in gt_boxes]\n            gt_labels = [gt_label.cuda() for gt_label in gt_labels]\n            gt_sjzs = [gt_sjz.cuda() for gt_sjz in gt_sjzs]\n            gt_xrs = [gt_xr.cuda() for gt_xr in gt_xrs]\n            \n        preds = <span style=\'color: green;font-weight: bold;\'>self</span>(sweep_imgs,sweep_bevimgs,mats)        <span style=\'color: red\'># preds: ([每个任务对应的{\'reg\':,\'height\':,\'...\'}],[{}])</span>\n        if isinstance(self.model, torch.nn.parallel.DistributedDataParallel):\n            targets = self.model.module.get_targets(gt_boxes, gt_labels)  <span style=\'color: red\'># type: ignore</span>\n            detection_loss = self.model.module.loss(targets, preds)  <span style=\'color: red\'># type: ignore</span>\n        else:\n            targets = self.model.<span style=\'color: green;font-weight: bold;\'>get_targets</span>(gt_boxes, gt_labels) <span style=\'color: red\'># tuple(list[Tensor],list[tensor],..)         </span>\n            detection_loss = self.model.<span style=\'color: green;font-weight: bold;\'>loss</span>(targets, preds)\n        self.log(\'car_loss\',detection_loss, prog_bar=True)\n        loss = detection_loss\n        return loss\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">exps/bev_depth_parkdata_10cls.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEVDepthLightningModel(LightningModule):\n    def forward(self,sweep_imgs,sweep_bevimgs,mats):\n        x = self.<span style=\'color: green;font-weight: bold;\'>backbone</span>(x,sweep_bevimgs,mats_dict)    <span style=\'color: red\'># torch.Size([10, 1, 4, 3, 384, 640])+torch.Size([10, 1, 3, 480, 352])-->torch.Size([10, 128, 120, 88])</span>\n        preds = self.<span style=\'color: green;font-weight: bold;\'>head</span>(x)                            <span style=\'color: red\'># ([{每个任务:{\'reg\':,\'height\':,\'...\'}}],[{}])</span>\n        return preds\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/backbones/sample_fpn_10.py</p><font size="0"><pre class="language-python"><code class="language-python">class SampleFPN10(nn.Module)::\n    def _forward_single_sweep(self,sweep_imgs,sweep_bevimg,mats_dict):\n        img_feats = self.<span style=\'color: green;font-weight: bold;\'>get_cam_feats</span>(sweep_imgs)            <span style=\'color: red\'># torch.Size([bs, 4, 3, 384, 640])-> [bs,4,512,48,80]</span>\n        bevimg_feat = self.<span style=\'color: green;font-weight: bold;\'>get_bevimg_feat</span>(sweep_bevimg)      <span style=\'color: red\'># torch.Size([bx, 3, 480, 352])   -> b,256,120,88</span>\n        \n        bev_fea = self.<span style=\'color: green;font-weight: bold;\'>get_bev_fea</span>(img_feats.float(),mats_dict["points"])       <span style=\'color: red\'># b,128*4,120,88</span>\n        bev_fea = torch.cat([bevimg_feat,bev_fea.float()],dim=1) <span style=\'color: red\'># b,256+512,120,88</span>\n        \n        if self.do_bev_compress:                                 <span style=\'color: red\'># torch.Size([10, 128, 120, 88])</span>\n            bev_fea = self.bev_compressor(bev_fea)\n        \n        return bev_fea.float() <span style=\'color: red\'># -> bs,128,120,88</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/backbones/sample_fpn_10.py</p><font size="0"><pre class="language-python"><code class="language-python">class SampleFPN10(nn.Module)::\n    def get_cam_feats(self, imgs):\n        batch_size, num_cams, num_channels, imH, imW = imgs.shape                   <span style=\'color: red\'># imgH:384 imgW:640</span>\n        imgs = imgs.flatten().view(batch_size * num_cams,num_channels, imH, imW)\n        bonefea = self.img_backbone(imgs)\n        img_feats = self.img_neck(bonefea)[0]                                       <span style=\'color: red\'># 下采样8倍 -> [b,512,48,80]</span>\n        <span style=\'color: red\'># self.img_backbone(imgs)出来: [b,256,96,160],[b,512,48,80],[b,1024,24,40],[b,2048,12,20]</span>\n        if self.do_fpn_compress:\n            img_feats = self.fpn_compressor(img_feats)                             <span style=\'color: red\'># 512压缩到128</span>\n        img_feats = img_feats.reshape(batch_size, num_cams,img_feats.shape[1], img_feats.shape[2],img_feats.shape[3])\n        return img_feats\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/backbones/sample_fpn_10.py</p><font size="0"><pre class="language-python"><code class="language-python">class SampleFPN10(nn.Module)::\n    def get_bevimg_feat(self,sweep_bevimg):\n        """Get feature maps from images."""\n        batch_size, num_channels, imH, imW = sweep_bevimg.shape           <span style=\'color: red\'># torch.Size([bs, 3, 480, 352])</span>\n        <span style=\'color: red\'># imgH:480 imgW:352</span>\n        sweep_bevimg = sweep_bevimg.flatten().view(batch_size, num_channels, imH, imW)\n        bonebevfea = self.bevimg_backbone(sweep_bevimg)\n        bevimg_feats = self.bevimg_neck(bonebevfea)[0]                    <span style=\'color: red\'># 下采样4倍 -> [b,256,120,88]</span>\n        <span style=\'color: red\'># self.bevimg_backbone(imgs)出来: [b,64,120,88],[b,128,60,44],[b,256,30,22],[b,512,15,22]</span>\n        bevimg_feats = bevimg_feats.reshape(batch_size,bevimg_feats.shape[1], bevimg_feats.shape[2],bevimg_feats.shape[3])\n        return bevimg_feats                                               <span style=\'color: red\'># b,256,120,88</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/backbones/sample_fpn_10.py</p><font size="0"><pre class="language-python"><code class="language-python">class SampleFPN10(nn.Module)::\n    def get_bev_fea(self,source_features,points):\n        <span style=\'color: red\'># source_features: [bs,4,512,48,80]              </span>\n        bs,num_cams,C,fh,fw = source_features.shape              <span style=\'color: red\'># torch.Size([10, 4, 128, 48, 80])</span>\n        <span style=\'color: red\'># points = torch.from_numpy(copy.deepcopy(self.mapcors))</span>\n        <span style=\'color: red\'># scale = float(1/(2*self.downsample_factor))           </span>\n        <span style=\'color: red\'># points[:,:,:2] = points[:,:,:2] * scale</span>\n        <span style=\'color: red\'># points = points.unsqueeze(0).repeat(bs,1,1,1).contiguous()</span>\n        \n        EPS = 1e-6\n        x,y,z = points[:,:,:,0],points[:,:,:,1],points[:,:,:,2]  <span style=\'color: red\'># torch.Size([10, 4, 42240])</span>\n        \n        <span style=\'color: red\'># 获取有效的点位,过滤掉不在截锥范围内的</span>\n        x_valid = (x>=0).bool() & (x<fw).bool()\n        y_valid = (y>=0).bool() & (y<fh).bool()\n        z_valid = (z>0.0).bool()\n        valid_fea = (x_valid & y_valid & z_valid).reshape(bs,num_cams,1,self.X,self.Y,self.Z).float()\n        valid_fea = valid_fea.to(source_features.device)        <span style=\'color: red\'># torch.Size([10, 4, 1, 120, 88, 4])    值要么为1，要么为0</span>\n        \n        <span style=\'color: red\'># 对x,y进行归一化，满足-1到1之间。</span>\n        grid_x = 2.0*(x/float(fw-1)) - 1.0 <span style=\'color: red\'># b,4,n           fw = 80         2D空间的范围</span>\n        grid_y = 2.0*(y/float(fh-1)) - 1.0 <span style=\'color: red\'># b,4,n           fh = 48</span>\n        grid_x = torch.clamp(grid_x, min=-2.0, max=2.0)   <span style=\'color: red\'># b,4,n</span>\n        grid_y = torch.clamp(grid_y, min=-2.0, max=2.0)   <span style=\'color: red\'># b,4,n</span>\n        \n        <span style=\'color: red\'># 获取grid_sample满足的坐标</span>\n        grid_z = torch.zeros_like(x)  <span style=\'color: red\'># b,4,n</span>\n        xyz_pix = torch.stack([grid_x,grid_y,grid_z],axis=3)            <span style=\'color: red\'># b,4,n,3       torch.Size([10, 4, 42240, 3])</span>\n        xyz_pix = xyz_pix.reshape([bs*num_cams,self.X,self.Y,self.Z,3]) <span style=\'color: red\'># b,x,y,z,3    </span>\n        xyz_pix = xyz_pix.to(source_features.device)                    <span style=\'color: red\'># torch.Size([40, 120, 88, 4, 3])</span>\n        <span style=\'color: red\'># grid_sample采样对应的图像特征点</span>\n        <span style=\'color: red\'># print(\'source_features dtype\',source_features.dtype)</span>\n        source_features = source_features.reshape([bs*num_cams,C,1,fh,fw]) <span style=\'color: red\'># b,C,1,fh,fw   torch.Size([10, 4, 128, 48, 80])</span>\n        bev_fea_ = F.grid_sample(source_features,xyz_pix.float(),align_corners=False)\n        <span style=\'color: red\'># grid_sample (-1,-1)对应采样特征图的左上角. (1,1)对应采样特征图的右下角。</span>\n        <span style=\'color: red\'># 其采样结果特征图的顺序对应xyz_pix的顺序坐标,而xyz_pix的顺序对应原始的定义格子顺序</span>\n        <span style=\'color: red\'># 利用b*4,X,Y,Z,3 从 b*4,C,1,fh,fw 获取 b*4,C,X,Y,Z</span>\n        <span style=\'color: red\'># 其每个格子投影到每个相机的图像面对应的点为xyz_pix。3维度的顺序必须对应特征的fw,fh,1</span>\n        bev_fea_ = bev_fea_.contiguous().reshape([bs,num_cams,C,self.X,self.Y,self.Z]) <span style=\'color: red\'># fp16</span>\n        bev_fea_ = bev_fea_ * valid_fea <span style=\'color: red\'># fp32</span>\n        \n        <span style=\'color: red\'># 对bev_fea做相机的均值处理,消除相机维度。</span>\n        mask_fea = (torch.abs(bev_fea_)>0).float()\n        fea_prob = bev_fea_ * mask_fea                                           <span style=\'color: red\'># torch.Size([10, 4, 128, 120, 88, 4])</span>\n        camsum = torch.sum(fea_prob,dim=1,keepdim=False)\n        nonzeronum = EPS+torch.sum(mask_fea, dim=1, keepdim=False)\n        bev_fea_ = camsum/nonzeronum <span style=\'color: red\'># bs,c,x,y,z</span>\n        <span style=\'color: red\'># collapse z</span>\n        bev_fea = bev_fea_.permute(0,1,4,3,2).reshape(bs,C*self.Z,self.X,self.Y) <span style=\'color: red\'># fp32  torch.Size([10, 512, 120, 88])</span>\n        return bev_fea.float().contiguous() <span style=\'color: red\'># bs,C,X,Y(X对应特征的H维度)</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/heads/bev10cls_sample_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEV10CLSHead(ParkBEVCenterHead):\n    def forward_offical(self,x):\n        <span style=\'color: red\'># FPN</span>\n        trunk_outs = [x]                  <span style=\'color: red\'># x: B,128,120,88</span>\n        if self.trunk.deep_stem:          <span style=\'color: red\'># False</span>\n            x = self.trunk.stem(x)\n        else:\n            x = self.trunk.conv1(x)       <span style=\'color: red\'># torch.Size([bs, 160, 60, 44])</span>\n            x = self.trunk.norm1(x)\n            x = self.trunk.relu(x)        <span style=\'color: red\'># B,160,60,44</span>\n        for i, layer_name in enumerate(self.trunk.res_layers):\n            res_layer = getattr(self.trunk, layer_name)\n            x = res_layer(x)\n            if i in self.trunk.out_indices:\n                trunk_outs.append(x)             <span style=\'color: red\'># 依次加入 [B,160,60,44], [B, 320, 30,22],[B, 640, 15,11]</span>\n        fpn_output = self.neck(trunk_outs)       <span style=\'color: red\'># B,256,120,88</span>\n        ret_values = super().<span style=\'color: green;font-weight: bold;\'>forward</span>(fpn_output) <span style=\'color: red\'># ([{每个任务:{\'reg\':,\'height\':,\'...\'}}],[{}])</span>\n        return ret_values        \n    @autocast(False)\n    def forward(self, x):\n        return self.forward_offical(x)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdetection3d/mmdet3d/models/dense_heads/centerpoint_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class ParkBEVCenterHead(BaseModule):\n    def forward_single(self, x):\n        ret_dicts = []\n        x = self.shared_conv(x)\n        for task in self.task_heads:                        <span style=\'color: red\'># task: 是一个SeparateHead类 reg 2 dim 2 rot 2 heatmap 1</span>\n            ret_dicts.append(task(x))\n        """\n        [(key,value.shape) for ret_dict in ret_dicts for key,value in ret_dict.items()]\n        <span style=\'color: red\'># (\'reg\', torch.Size([10, 2, 120, 88]))</span>\n        <span style=\'color: red\'># (\'dim\', torch.Size([10, 2, 120, 88]))</span>\n        <span style=\'color: red\'># (\'rot\', torch.Size([10, 2, 120, 88]))</span>\n        <span style=\'color: red\'># (\'heatmap\', torch.Size([10, 5, 120, 88]))       </span>\n        """\n        return ret_dicts                                   <span style=\'color: red\'># list列表存了三个dict,每个dict负责一个目标任务。</span>\n    def forward(self, feats):\n        return multi_apply(self.forward_single, feats)\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/bev_park10cls.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEVPark10CLS(nn.Module):\n    def get_targets(self, gt_boxes, gt_labels):\n        return self.head.<span style=\'color: green;font-weight: bold;\'>get_targets</span>(gt_boxes, gt_labels)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdetection3d/mmdet3d/models/dense_heads/centerpoint_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(BaseModule):\n    def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">layers/heads/bev10cls_sample_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEV10CLSHead(ParkBEVCenterHead):\n    def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">models/bev_park10cls.py</p><font size="0"><pre class="language-python"><code class="language-python">class BEVPark10CLS(nn.Module):\n    def loss(self, targets, preds_dicts)\n</code></pre></font>'}]}]}]})</script></body>
</html>
