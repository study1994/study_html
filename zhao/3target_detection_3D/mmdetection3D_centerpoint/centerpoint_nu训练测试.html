<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>centerpoint_nu训练测试</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">训练centerpoint_01voxel_second_secfpn_4x8_cyclic_20e_nus.py</p><font size="0"><pre class="language-python"><code class="language-python">point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]+voxel_size=[0.1, 0.1, 0.2]->1024,1024,40=(51.2x2/0.1)\npoint_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]+voxel_size=[0.075, 0.075, 0.2]->1440,1440,40=(54x2/0.1)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/centerpoint.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterPoint(MVXTwoStageDetector):\n    def extract_pts_feat(self, pts, img_feats, img_metas):\n        voxels, num_points, coors = self.<span style=\'color: green;font-weight: bold;\'>voxelize</span>(pts)      <span style=\'color: red\'># voxels.shape=torch.Size([118162, 10, 5]);num_points.shape;torch.Size([118162]);coors.shape=torch.Size([118162, 4]);  </span>\n        voxel_features = self.<span style=\'color: green;font-weight: bold;\'>pts_voxel_encoder</span>(voxels, num_points, coors) <span style=\'color: red\'># 求特征均值  torch.Size([118162, 5]) </span>\n        batch_size = coors[-1, 0] + 1\n        x = self.<span style=\'color: green;font-weight: bold;\'>pts_middle_encoder</span>(voxel_features, coors, batch_size)     <span style=\'color: red\'># torch.Size([4, 256, 128, 128]) </span>\n        x = self.<span style=\'color: green;font-weight: bold;\'>pts_backbone</span>(x)       <span style=\'color: red\'># second     x[0].shape=torch.Size([4, 128, 128, 128]);x[1].shape=torch.Size([4, 256, 64, 64])</span>\n        if self.with_pts_neck: \n            x = self.<span style=\'color: green;font-weight: bold;\'>pts_neck</span>(x)       <span style=\'color: red\'># second_fpn torch.Size([4, 512, 128, 128])</span>\n        return x\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/mvx_two_stage.py</p><font size="0"><pre class="language-python"><code class="language-python">class MVXTwoStageDetector(Base3DDetector):\n    def voxelize(self, points):                     <span style=\'color: red\'># Points of each sample.  len(points)=4</span>\n        voxels, coors, num_points = [], [], []      <span style=\'color: red\'># points[0].shape=torch.Size([239859, 5])5是值每个点云点的维度(x,y,z,r,?); </span>\n        for res in points:\n            res_voxels, res_coors, res_num_points = self.<span style=\'color: green;font-weight: bold;\'>pts_voxel_layer</span>(res)\n            voxels.append(res_voxels)\n            coors.append(res_coors)\n            num_points.append(res_num_points)\n        voxels = torch.cat(voxels, dim=0)\n        num_points = torch.cat(num_points, dim=0)\n        coors_batch = []\n        for i, coor in enumerate(coors):               <span style=\'color: red\'># coors[0].shape=torch.Size([34181, 3]) </span>\n            coor_pad = F.pad(coor, (1, 0), mode=\'constant\', value=i)\n            coors_batch.append(coor_pad)\n        coors_batch = torch.cat(coors_batch, dim=0)    <span style=\'color: red\'># coor_pad.shape=torch.Size([34181, 4])---》(batch_idx, z_idx, y_idx, x_idx) </span>\n        return voxels, num_points, coors_batch         <span style=\'color: red\'># Concatenated points, number of points per voxel, coordinates</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/voxel/voxelize.py</p><font size="0"><pre class="language-python"><code class="language-python">class _Voxelization(Function):\n    @staticmethod\n    def forward(ctx,\n                points,                <span style=\'color: red\'># [N, ndim] float tensor. points[:, :3] contain xyz points and points[:, 3:] contain other information like  reflectivity</span>\n                voxel_size,            <span style=\'color: red\'># [3] list/tuple or array, float. xyz, indicate voxel size</span>\n                coors_range,           <span style=\'color: red\'># [6] list/tuple or array, float. indicate voxel range. format: xyzxyz, minmax</span>\n                max_points=35,\n                max_voxels=20000,\n                deterministic=True):  <span style=\'color: red\'># True</span>\n        if max_points == -1 or max_voxels == -1:\n            coors = points.new_zeros(size=(points.size(0), 3), dtype=torch.int)\n            dynamic_voxelize(points, coors, voxel_size, coors_range, 3)\n            return coors\n        else:\n            voxels = points.new_zeros(size=(max_voxels, max_points, points.size(1)))      <span style=\'color: red\'># voxels.shape=torch.Size([90000, 10, 5]);  10是指每个小格子里面最少有10个点云值; </span>\n            coors = points.new_zeros(size=(max_voxels, 3), dtype=torch.int)               <span style=\'color: red\'># coors.shape=torch.Size([90000, 3]);</span>\n            num_points_per_voxel = points.new_zeros(size=(max_voxels, ), dtype=torch.int) <span style=\'color: red\'># num_points_per_voxel.shape=torch.Size([90000]) </span>\n            voxel_num = hard_voxelize(points, voxels, coors,num_points_per_voxel, voxel_size,coors_range, max_points, max_voxels, 3,deterministic) <span style=\'color: red\'># voxel_num=34181有34181个小格子里面满足条件  </span>\n            <span style=\'color: red\'># select the valid voxels</span>\n            voxels_out = voxels[:voxel_num]\n            coors_out = coors[:voxel_num]\n            num_points_per_voxel_out = num_points_per_voxel[:voxel_num]\n            return voxels_out, coors_out, num_points_per_voxel_out   <span style=\'color: red\'># voxels.shape=torch.Size([34181, 10, 5]);coors.shape=torch.Size([34181, 3]);num_points_per_voxel.shape=torch.Size([34181]) </span>\n</code></pre><p></font>\n<code>mmdet3d/ops/voxel/src/voxelization_cpu.cpp</code>:<code>int hard_voxelize_cpu</code><br>\ncoor_to_voxelidx:(40,1024,1024);初始值都是-1<br>\n<code>mmdet3d/ops/voxel/src/voxelization_cpu.cpp</code>:<code>void hard_voxelize_kernel</code><br>\ntemp_coors:每个点的位置求出来(239859,3);后面的3-0维范围0-40，1维范围0-1024，2维范围0-1024，不在这个范围指位-1<br>\ncoor_to_voxelidx:(40,1024,1024);初始值都是-1，变成每个里面每个格子第几个，比如(0,0,0)有9个=0,(0,0,1)有10个=1,(0,0,1)有0个为原值=-1；<br>\ncoors：（90000,3）第0个体素的位置，第1个体素的位置，......，第n个体素的位置<br>\nnum_points_per_voxel：（90000,）<br>\nvoxels.shape=(90000,10,5)<br>\n<code>mmdet3d/ops/voxel/src/voxelization_cpu.cpp</code>:<code>void dynamic_voxelize_cpu</code>执行的是上面的一小步<br>\ntemp_coors:每个点的位置求出来(239859,3);后面的3-0维范围0-40，1维范围0-1024，2维范围0-1024，不在这个范围指位-1<br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/voxel_encoders/voxel_encoder.py</p><font size="0"><pre class="language-python"><code class="language-python">class HardSimpleVFE(nn.Module):\n    def forward(self, features, num_points, coors):  <span style=\'color: red\'># (N, M, 3(4)). N is the number of voxels and M is the maximum number of points inside a single voxel.</span>\n        points_mean = features[:, :, :self.num_features].sum(dim=1, keepdim=False) / num_points.type_as(features).view(-1, 1)\n        return points_mean.contiguous()    <span style=\'color: red\'># self.num_features=5;points_mean.shape=torch.Size([118162, 5]); </span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/spconv/structure.py</p><font size="0"><pre class="language-python"><code class="language-python">class SparseConvTensor(object):\n    def spatial_size(self):\n    def find_indice_pair(self, key):\n    def dense(self, channels_first=True):\n    def sparity(self):\n</code></pre><p></font>\n<a href="https://gitee.com/zhao-study/data_code/tree/master/3target_detection_3D/project/mmdetection3D/SparseConvTensor.md">SparseConvTensor.md</a>; <a href="https://gitee.com/zhao-study/data_code/tree/master/3target_detection_3D/project/mmdetection3D/SparseEncoder.md">SparseEncoder.md</a><br>\n<code>class SparseEncoder/def forward:mmdet3d/models/middle_encoders/sparse_encoder.py</code><br>\nx = self.conv_input(input_sp_tensor)===============SparseConv3d()+BN+RELU<br>\nx.features.shape=torch.Size([118162, 16])<br>\nself.encoder_layers:\'encoder_layer1\':[SparseBasicBlock(conv1,bn1,conv2,bn2,relu),,],\'encoder_layer2\':...,\'encoder_layer3\':...,\'encoder_layer4\':...。<br>\nencode_features[-1].features.shape=torch.Size([26438, 128]);encode_features[-1].spatial_shape=[5, 128, 128]<br>\nself.conv_out:SparseConv3d()+BN+RELU<br>\nout.features.shape=torch.Size([20137, 128]);out.spatial_shape=[2, 128, 128]<br>\nspatial_features.shape=torch.Size([4, 128, 2, 128, 128])=torch.Size([4, 256, 128, 128])<br></p>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/backbones/second.py</p><font size="0"><pre class="language-python"><code class="language-python">class SECOND(BaseModule):\n    def forward(self, x):\n        outs = []\n        for i in range(len(self.blocks)):\n            x = self.blocks[i](x)\n            outs.append(x)\n        return tuple(outs)\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/second_fpn.py</p><font size="0"><pre class="language-python"><code class="language-python">class SECONDFPN(BaseModule):\n    def forward(self, x):\n        assert len(x) == len(self.in_channels)\n        ups = [deblock(x[i]) for i, deblock in enumerate(self.deblocks)]\n        if len(ups) > 1:\n            out = torch.cat(ups, dim=1)\n        else:\n            out = ups[0]\n        return [out]\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">输入到head进行loss训练</p><font size="0"><pre class="language-python"><code class="language-python">class CenterPoint(MVXTwoStageDetector):\n    def forward_pts_train(self,pts_feats,gt_bboxes_3d,gt_labels_3d,img_metas,gt_bboxes_ignore=None):\n        outs = self.<span style=\'color: green;font-weight: bold;\'>pts_bbox_head</span>(pts_feats)\n        loss_inputs = [gt_bboxes_3d, gt_labels_3d, outs]\n        losses = self.pts_bbox_head.<span style=\'color: green;font-weight: bold;\'>loss</span>(*loss_inputs)\n        return losses\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/centerpoint_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(BaseModule):\n    def forward_single(self, x):\n        ret_dicts = []\n        x = self.shared_conv(x)   <span style=\'color: red\'># [B, 512, 128, 128]->torch.Size([4, 64, 128, 128]) </span>\n        for task in self.task_heads:\n            ret_dicts.append(task(x))\n        return ret_dicts\n    def forward(self, feats,img_feats=None, img_metas=None):\n        return multi_apply(self.forward_single, feats)    <span style=\'color: red\'># tuple(list[dict]): Output results for tasks.</span>\nlen(ret_dicts)=6;   \nret_dicts[0].keys()=dict_keys([\'reg\', \'height\', \'dim\', \'rot\', \'vel\', \'heatmap\']);   \nret_dicts[0][\'reg\'].shape=torch.Size([4, 2, 128, 128]);②目标尺寸    \nret_dicts[0][\'height\'].shape=torch.Size([4, 1, 128, 128])②目标尺寸   \nret_dicts[0][\'dim\'].shape=torch.Size([4, 3, 128, 128])②目标尺寸    \nret_dicts[0][\'rot\'].shape=torch.Size([4, 2, 128, 128])③目标朝向   \nret_dicts[0][\'vel\'].shape=torch.Size([4, 2, 128, 128])④目标速度               \nret_dicts[0][\'heatmap\'].shape=torch.Size([4, N, 128, 128])N为num_class类别数 ①表征目标中心位置的热力图 \n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/centerpoint_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(BaseModule):\n    def loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n        heatmaps, anno_boxes, inds, masks = self.<span style=\'color: green;font-weight: bold;\'>get_targets</span>(gt_bboxes_3d, gt_labels_3d)  <span style=\'color: red\'># len(heatmaps)=6,heatmaps[0].shape=torch.Size([4, 1, 128, 128]);anno_boxes[0].shape=torch.Size([4, 500, 10]);inds[0].shape=torch.Size([4, 500]);masks[0].shape=torch.Size([4, 500])   </span>\n        loss_dict = dict()\n        for task_id, preds_dict in enumerate(preds_dicts):\n            <span style=\'color: red\'># heatmap focal loss</span>\n            preds_dict[0][\'heatmap\'] = clip_sigmoid(preds_dict[0][\'heatmap\'])\n            num_pos = heatmaps[task_id].eq(1).float().sum().item()\n            loss_heatmap = self.loss_cls(preds_dict[0][\'heatmap\'],heatmaps[task_id],avg_factor=max(num_pos, 1))\n            target_box = anno_boxes[task_id]\n            <span style=\'color: red\'># reconstruct the anno_box from multiple reg heads</span>\n            if \'vel\' in preds_dict[0]:\n                preds_dict[0][\'anno_box\'] = torch.cat((preds_dict[0][\'reg\'], preds_dict[0][\'height\'],\n                    preds_dict[0][\'dim\'], preds_dict[0][\'rot\'],preds_dict[0][\'vel\']),dim=1)\n            else:\n                preds_dict[0][\'anno_box\'] = torch.cat((preds_dict[0][\'reg\'], preds_dict[0][\'height\'],\n                    preds_dict[0][\'dim\'], preds_dict[0][\'rot\']),dim=1)\n            <span style=\'color: red\'># Regression loss for dimension, offset, height, rotation</span>\n            ind = inds[task_id]\n            num = masks[task_id].float().sum()\n            pred = preds_dict[0][\'anno_box\'].permute(0, 2, 3, 1).contiguous()\n            pred = pred.view(pred.size(0), -1, pred.size(3))   <span style=\'color: red\'># pred.shape=torch.Size([4, 16384, 10]); 128*128=16384</span>\n            pred = self.<span style=\'color: green;font-weight: bold;\'>_gather_feat</span>(pred, ind)              <span style=\'color: red\'># ind.shape=torch.Size([4, 500])-->pred=torch.Size([4, 500, 10])</span>\n            mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n            isnotnan = (~torch.isnan(target_box)).float()\n            mask *= isnotnan\n            code_weights = self.train_cfg.get(\'code_weights\', None)\n            bbox_weights = mask * mask.new_tensor(code_weights)\n            loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=(num + 1e-4))\n            loss_dict[f\'task{task_id}.loss_heatmap\'] = loss_heatmap\n            loss_dict[f\'task{task_id}.loss_bbox\'] = loss_bbox\n        return loss_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/centerpoint_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class CenterHead(BaseModule):\n    def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n        heatmaps, anno_boxes, inds, masks = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n        <span style=\'color: red\'># Transpose heatmaps</span>\n        heatmaps = list(map(list, zip(*heatmaps)))\n        heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n        <span style=\'color: red\'># Transpose anno_boxes</span>\n        anno_boxes = list(map(list, zip(*anno_boxes)))\n        anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n        <span style=\'color: red\'># Transpose inds</span>\n        inds = list(map(list, zip(*inds)))\n        inds = [torch.stack(inds_) for inds_ in inds]\n        <span style=\'color: red\'># Transpose inds</span>\n        masks = list(map(list, zip(*masks)))\n        masks = [torch.stack(masks_) for masks_ in masks]\n        return heatmaps, anno_boxes, inds, masks\n    def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):  <span style=\'color: red\'># (:obj:<span style=\'color: green;font-weight: bold;\'>LiDARInstance3DBoxes</span>): Ground truth gt boxes + (torch.Tensor): Labels of boxes. torch.Size([n])</span>\n        gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]),dim=1).to(device)  <span style=\'color: red\'># LiDARInstance3DBoxes(nx7)/LiDARInstance3DBoxes(nx9)</span>\n        max_objs = self.train_cfg[\'max_objs\'] * self.train_cfg[\'dense_reg\']      <span style=\'color: red\'># 500x1=500</span>\n        grid_size = torch.tensor(self.train_cfg[\'grid_size\'])                    <span style=\'color: red\'># tensor([1024, 1024,   40])   </span>\n        pc_range = torch.tensor(self.train_cfg[\'point_cloud_range\'])             <span style=\'color: red\'># tensor([-51.2000, -51.2000,  -5.0000,  51.2000,  51.2000,   3.0000])    </span>\n        voxel_size = torch.tensor(self.train_cfg[\'voxel_size\'])                  <span style=\'color: red\'># tensor([0.1000, 0.1000, 0.2000])   </span>\n        feature_map_size = grid_size[:2] // self.train_cfg[\'out_size_factor\']    <span style=\'color: red\'># tensor([128, 128])  1024/8</span>\n        <span style=\'color: red\'># reorganize the gt_dict by tasks</span>\n        task_masks = []\n        flag = 0\n        for class_name in self.class_names:\n            task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag)for i in class_name])\n            flag += len(class_name)\n        task_boxes = []\n        task_classes = []\n        flag2 = 0\n        for idx, mask in enumerate(task_masks):\n            task_box = []\n            task_class = []\n            for m in mask:\n                task_box.append(gt_bboxes_3d[m])\n                task_class.append(gt_labels_3d[m] + 1 - flag2)     <span style=\'color: red\'># 0 is background for each task, so we need to add 1 here.</span>\n            task_boxes.append(torch.cat(task_box, axis=0).to(device))\n            task_classes.append(torch.cat(task_class).long().to(device))\n            flag2 += len(mask)\n        draw_gaussian = draw_heatmap_gaussian\n        heatmaps, anno_boxes, inds, masks = [], [], [], []\n        for idx, task_head in enumerate(self.task_heads):                                                            <span style=\'color: red\'># idx=0   </span>\n            heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1],feature_map_size[0]))  <span style=\'color: red\'>#  torch.Size([1, 128, 128]) </span>\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, int(gt_bboxes_3d.shape[1]+1)),dtype=torch.float32)          <span style=\'color: red\'># torch.Size([500, 10]) </span>\n            ind = gt_labels_3d.new_zeros((max_objs), dtype=torch.int64)                                              <span style=\'color: red\'># torch.Size([500]) </span>\n            mask = gt_bboxes_3d.new_zeros((max_objs), dtype=torch.uint8)                                             <span style=\'color: red\'># torch.Size([500]) </span>\n            num_objs = min(task_boxes[idx].shape[0], max_objs)                                                       <span style=\'color: red\'># 33  </span>\n            for k in range(num_objs):\n                cls_id = task_classes[idx][k] - 1\n                width = task_boxes[idx][k][3]                                           <span style=\'color: red\'># tensor(1.9776, device=\'cuda:0\')</span>\n                length = task_boxes[idx][k][4]                                          <span style=\'color: red\'># tensor(4.6753, device=\'cuda:0\')</span>\n                width = width / voxel_size[0] / self.train_cfg[\'out_size_factor\']       <span style=\'color: red\'># 1.9776/0.1/8=2.4719    注意这里宽度的处理</span>\n                length = length / voxel_size[1] / self.train_cfg[\'out_size_factor\']     <span style=\'color: red\'># 4.6753/0.1/8=5.8441</span>\n                if width > 0 and length > 0:\n                    radius = gaussian_radius((length, width),min_overlap=self.train_cfg[\'gaussian_overlap\'])   <span style=\'color: red\'># 2,0.1</span>\n                    radius = max(self.train_cfg[\'min_radius\'], int(radius))                                    <span style=\'color: red\'># 2</span>\n                    <span style=\'color: red\'># be really careful for the coordinate system of your box annotation.</span>\n                    x, y, z = task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2]\n                    coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg[\'out_size_factor\']\n                    coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg[\'out_size_factor\']\n                    center = torch.tensor([coor_x, coor_y],dtype=torch.float32,device=device)\n                    center_int = center.to(torch.int32)\n                    <span style=\'color: red\'># throw out not in range objects to avoid out of array area when creating the heatmap</span>\n                    if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                        continue\n                    draw_gaussian(heatmap[cls_id], center_int, radius)\n                    new_idx = k\n                    x, y = center_int[0], center_int[1]\n                    assert (y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1])\n                    ind[new_idx] = y * feature_map_size[0] + x\n                    mask[new_idx] = 1\n                    <span style=\'color: red\'># TODO: support other outdoor dataset</span>\n                    rot = task_boxes[idx][k][6]\n                    box_dim = task_boxes[idx][k][3:6]\n                    if self.norm_bbox:\n                        box_dim = box_dim.log()\n                    if len(task_boxes[idx][k])==9:\n                        vx, vy = task_boxes[idx][k][7:]\n                        anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device),z.unsqueeze(0), box_dim,\n                            torch.sin(rot).unsqueeze(0),torch.cos(rot).unsqueeze(0),vx.unsqueeze(0),vy.unsqueeze(0)])\n                    else:\n                        <span style=\'color: red\'># vx, vy = torch.zeros_like(task_boxes[idx][k][5]),torch.zeros_like(task_boxes[idx][k][6])</span>\n                        anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device),z.unsqueeze(0), box_dim,\n                            torch.sin(rot).unsqueeze(0),torch.cos(rot).unsqueeze(0)\n                        ])\n            heatmaps.append(heatmap)\n            anno_boxes.append(anno_box)\n            masks.append(mask)\n            inds.append(ind)\n        return heatmaps, anno_boxes, inds, masks  <span style=\'color: red\'># inds是y*fature_map_size[0]+x,masks是1说明该box有用</span>\n</code></pre></font>'}]}]}]})</script></body>
</html>
