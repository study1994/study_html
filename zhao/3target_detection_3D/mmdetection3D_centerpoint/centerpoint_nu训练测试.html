<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>centerpoint_nu训练测试</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">训练centerpoint_01voxel_second_secfpn_4x8_cyclic_20e_nus.py</p><span class=\'hidden-code\' data-code=\'point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]+voxel_size=[0.1, 0.1, 0.2]->1024,1024,40=(51.2x2/0.1)\npoint_cloud_range=[-54, -54, -5.0, 54, 54, 3.0]+voxel_size=[0.075, 0.075, 0.2]->1440,1440,40=(54x2/0.1)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/centerpoint.py</p><span class=\'hidden-code\' data-code=\'class CenterPoint(MVXTwoStageDetector):\n    def extract_pts_feat(self, pts, img_feats, img_metas):\n        voxels, num_points, coors = self.`voxelize`(pts)      # voxels.shape=torch.Size([118162, 10, 5]);num_points.shape;torch.Size([118162]);coors.shape=torch.Size([118162, 4]);  \n        voxel_features = self.`pts_voxel_encoder`(voxels, num_points, coors) # 求特征均值  torch.Size([118162, 5]) \n        batch_size = coors[-1, 0] + 1\n        x = self.`pts_middle_encoder`(voxel_features, coors, batch_size)     # torch.Size([4, 256, 128, 128]) \n        x = self.`pts_backbone`(x)       # second     x[0].shape=torch.Size([4, 128, 128, 128]);x[1].shape=torch.Size([4, 256, 64, 64])\n        if self.with_pts_neck: \n            x = self.`pts_neck`(x)       # second_fpn torch.Size([4, 512, 128, 128])\n        return x\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/mvx_two_stage.py</p><span class=\'hidden-code\' data-code=\'class MVXTwoStageDetector(Base3DDetector):\n    def voxelize(self, points):                     # Points of each sample.  len(points)=4\n        voxels, coors, num_points = [], [], []      # points[0].shape=torch.Size([239859, 5])5是值每个点云点的维度(x,y,z,r,?); \n        for res in points:\n            res_voxels, res_coors, res_num_points = self.`pts_voxel_layer`(res)\n            voxels.append(res_voxels)\n            coors.append(res_coors)\n            num_points.append(res_num_points)\n        voxels = torch.cat(voxels, dim=0)\n        num_points = torch.cat(num_points, dim=0)\n        coors_batch = []\n        for i, coor in enumerate(coors):               # coors[0].shape=torch.Size([34181, 3]) \n            coor_pad = F.pad(coor, (1, 0), mode=\'constant\', value=i)\n            coors_batch.append(coor_pad)\n        coors_batch = torch.cat(coors_batch, dim=0)    # coor_pad.shape=torch.Size([34181, 4])---》(batch_idx, z_idx, y_idx, x_idx) \n        return voxels, num_points, coors_batch         # Concatenated points, number of points per voxel, coordinates\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/voxel/voxelize.py</p><span class=\'hidden-code\' data-code=\'class _Voxelization(Function):\n    @staticmethod\n    def forward(ctx,\n                points,                # [N, ndim] float tensor. points[:, :3] contain xyz points and points[:, 3:] contain other information like  reflectivity\n                voxel_size,            # [3] list/tuple or array, float. xyz, indicate voxel size\n                coors_range,           # [6] list/tuple or array, float. indicate voxel range. format: xyzxyz, minmax\n                max_points=35,\n                max_voxels=20000,\n                deterministic=True):  # True\n        if max_points == -1 or max_voxels == -1:\n            coors = points.new_zeros(size=(points.size(0), 3), dtype=torch.int)\n            dynamic_voxelize(points, coors, voxel_size, coors_range, 3)\n            return coors\n        else:\n            voxels = points.new_zeros(size=(max_voxels, max_points, points.size(1)))      # voxels.shape=torch.Size([90000, 10, 5]);  10是指每个小格子里面最少有10个点云值; \n            coors = points.new_zeros(size=(max_voxels, 3), dtype=torch.int)               # coors.shape=torch.Size([90000, 3]);\n            num_points_per_voxel = points.new_zeros(size=(max_voxels, ), dtype=torch.int) # num_points_per_voxel.shape=torch.Size([90000]) \n            voxel_num = hard_voxelize(points, voxels, coors,num_points_per_voxel, voxel_size,coors_range, max_points, max_voxels, 3,deterministic) # voxel_num=34181有34181个小格子里面满足条件  \n            # select the valid voxels\n            voxels_out = voxels[:voxel_num]\n            coors_out = coors[:voxel_num]\n            num_points_per_voxel_out = num_points_per_voxel[:voxel_num]\n            return voxels_out, coors_out, num_points_per_voxel_out   # voxels.shape=torch.Size([34181, 10, 5]);coors.shape=torch.Size([34181, 3]);num_points_per_voxel.shape=torch.Size([34181]) \n\'> </span><p><code>mmdet3d/ops/voxel/src/voxelization_cpu.cpp</code>:<code>int hard_voxelize_cpu</code><br>\ncoor_to_voxelidx:(40,1024,1024);初始值都是-1<br>\n<code>mmdet3d/ops/voxel/src/voxelization_cpu.cpp</code>:<code>void hard_voxelize_kernel</code><br>\ntemp_coors:每个点的位置求出来(239859,3);后面的3-0维范围0-40，1维范围0-1024，2维范围0-1024，不在这个范围指位-1<br>\ncoor_to_voxelidx:(40,1024,1024);初始值都是-1，变成每个里面每个格子第几个，比如(0,0,0)有9个=0,(0,0,1)有10个=1,(0,0,1)有0个为原值=-1；<br>\ncoors：（90000,3）第0个体素的位置，第1个体素的位置，......，第n个体素的位置<br>\nnum_points_per_voxel：（90000,）<br>\nvoxels.shape=(90000,10,5)<br>\n<code>mmdet3d/ops/voxel/src/voxelization_cpu.cpp</code>:<code>void dynamic_voxelize_cpu</code>执行的是上面的一小步<br>\ntemp_coors:每个点的位置求出来(239859,3);后面的3-0维范围0-40，1维范围0-1024，2维范围0-1024，不在这个范围指位-1<br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/voxel_encoders/voxel_encoder.py</p><span class=\'hidden-code\' data-code=\'class HardSimpleVFE(nn.Module):\n    def forward(self, features, num_points, coors):  # (N, M, 3(4)). N is the number of voxels and M is the maximum number of points inside a single voxel.\n        points_mean = features[:, :, :self.num_features].sum(dim=1, keepdim=False) / num_points.type_as(features).view(-1, 1)\n        return points_mean.contiguous()    # self.num_features=5;points_mean.shape=torch.Size([118162, 5]); \n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/spconv/structure.py</p><span class=\'hidden-code\' data-code=\'class SparseConvTensor(object):\n    def spatial_size(self):\n    def find_indice_pair(self, key):\n    def dense(self, channels_first=True):\n    def sparity(self):\n\'> </span><p><a href="https://gitee.com/zhao-study/data_code/tree/master/3target_detection_3D/project/mmdetection3D/SparseConvTensor.md">SparseConvTensor.md</a>; <a href="https://gitee.com/zhao-study/data_code/tree/master/3target_detection_3D/project/mmdetection3D/SparseEncoder.md">SparseEncoder.md</a><br>\n<code>class SparseEncoder/def forward:mmdet3d/models/middle_encoders/sparse_encoder.py</code><br>\nx = self.conv_input(input_sp_tensor)===============SparseConv3d()+BN+RELU<br>\nx.features.shape=torch.Size([118162, 16])<br>\nself.encoder_layers:\'encoder_layer1\':[SparseBasicBlock(conv1,bn1,conv2,bn2,relu),,],\'encoder_layer2\':...,\'encoder_layer3\':...,\'encoder_layer4\':...。<br>\nencode_features[-1].features.shape=torch.Size([26438, 128]);encode_features[-1].spatial_shape=[5, 128, 128]<br>\nself.conv_out:SparseConv3d()+BN+RELU<br>\nout.features.shape=torch.Size([20137, 128]);out.spatial_shape=[2, 128, 128]<br>\nspatial_features.shape=torch.Size([4, 128, 2, 128, 128])=torch.Size([4, 256, 128, 128])<br></p>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/backbones/second.py</p><span class=\'hidden-code\' data-code=\'class SECOND(BaseModule):\n    def forward(self, x):\n        outs = []\n        for i in range(len(self.blocks)):\n            x = self.blocks[i](x)       # torch.Size([4, 256, 128, 128])->torch.Size([4, 128, 128, 128])->torch.Size([4, 256, 64, 64])\n            outs.append(x)\n        return tuple(outs)\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/second_fpn.py</p><span class=\'hidden-code\' data-code=\'class SECONDFPN(BaseModule):\n    def forward(self, x):\n        assert len(x) == len(self.in_channels)\n        ups = [deblock(x[i]) for i, deblock in enumerate(self.deblocks)]      # 64这个会上采样\n        if len(ups) > 1:\n            out = torch.cat(ups, dim=1)        # torch.Size([4, 512, 128, 128])\n        else:\n            out = ups[0]\n        return [out]\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">输入到head进行loss训练</p><span class=\'hidden-code\' data-code=\'class CenterPoint(MVXTwoStageDetector):\n    def forward_pts_train(self,pts_feats,gt_bboxes_3d,gt_labels_3d,img_metas,gt_bboxes_ignore=None):\n        outs = self.`pts_bbox_head`(pts_feats)\n        loss_inputs = [gt_bboxes_3d, gt_labels_3d, outs]\n        losses = self.pts_bbox_head.`loss`(*loss_inputs)\n        return losses\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/centerpoint_head.py</p><span class=\'hidden-code\' data-code=\'class CenterHead(BaseModule):\n    def forward_single(self, x):\n        ret_dicts = []\n        x = self.shared_conv(x)   # [B, 512, 128, 128]->torch.Size([4, 64, 128, 128]) \n        for task in self.task_heads:\n            ret_dicts.append(task(x))\n        return ret_dicts\n    def forward(self, feats,img_feats=None, img_metas=None):\n        return multi_apply(self.forward_single, feats)    # tuple(list[dict]): Output results for tasks.\nlen(ret_dicts)=6;   \nret_dicts[0].keys()=dict_keys([\'reg\', \'height\', \'dim\', \'rot\', \'vel\', \'heatmap\']);   \nret_dicts[0][\'reg\'].shape=torch.Size([4, 2, 128, 128]);②目标尺寸    \nret_dicts[0][\'height\'].shape=torch.Size([4, 1, 128, 128])②目标尺寸   \nret_dicts[0][\'dim\'].shape=torch.Size([4, 3, 128, 128])②目标尺寸    \nret_dicts[0][\'rot\'].shape=torch.Size([4, 2, 128, 128])③目标朝向   \nret_dicts[0][\'vel\'].shape=torch.Size([4, 2, 128, 128])④目标速度               \nret_dicts[0][\'heatmap\'].shape=torch.Size([4, N, 128, 128])N为num_class类别数 ①表征目标中心位置的热力图 \n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/centerpoint_head.py</p><span class=\'hidden-code\' data-code=\'class CenterHead(BaseModule):\n    def loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n        heatmaps, anno_boxes, inds, masks = self.`get_targets`(gt_bboxes_3d, gt_labels_3d)  # len(heatmaps)=6,heatmaps[0].shape=torch.Size([4, 1, 128, 128]);anno_boxes[0].shape=torch.Size([4, 500, 10]);inds[0].shape=torch.Size([4, 500]);masks[0].shape=torch.Size([4, 500])   \n        loss_dict = dict()\n        for task_id, preds_dict in enumerate(preds_dicts):\n            # heatmap focal loss\n            preds_dict[0][\'heatmap\'] = clip_sigmoid(preds_dict[0][\'heatmap\'])\n            num_pos = heatmaps[task_id].eq(1).float().sum().item()\n            loss_heatmap = self.loss_cls(preds_dict[0][\'heatmap\'],heatmaps[task_id],avg_factor=max(num_pos, 1))\n            target_box = anno_boxes[task_id]\n            # reconstruct the anno_box from multiple reg heads\n            if \'vel\' in preds_dict[0]:\n                preds_dict[0][\'anno_box\'] = torch.cat((preds_dict[0][\'reg\'], preds_dict[0][\'height\'],\n                    preds_dict[0][\'dim\'], preds_dict[0][\'rot\'],preds_dict[0][\'vel\']),dim=1)\n            else:\n                preds_dict[0][\'anno_box\'] = torch.cat((preds_dict[0][\'reg\'], preds_dict[0][\'height\'],\n                    preds_dict[0][\'dim\'], preds_dict[0][\'rot\']),dim=1)\n            # Regression loss for dimension, offset, height, rotation\n            ind = inds[task_id]\n            num = masks[task_id].float().sum()\n            pred = preds_dict[0][\'anno_box\'].permute(0, 2, 3, 1).contiguous()\n            pred = pred.view(pred.size(0), -1, pred.size(3))   # pred.shape=torch.Size([4, 16384, 10]); 128*128=16384\n            pred = self.`_gather_feat`(pred, ind)              # ind.shape=torch.Size([4, 500])-->pred=torch.Size([4, 500, 10])\n            mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n            isnotnan = (~torch.isnan(target_box)).float()\n            mask *= isnotnan\n            code_weights = self.train_cfg.get(\'code_weights\', None)\n            bbox_weights = mask * mask.new_tensor(code_weights)\n            loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=(num + 1e-4))\n            loss_dict[f\'task{task_id}.loss_heatmap\'] = loss_heatmap\n            loss_dict[f\'task{task_id}.loss_bbox\'] = loss_bbox\n        return loss_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/centerpoint_head.py</p><span class=\'hidden-code\' data-code=\'class CenterHead(BaseModule):\n    def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n        heatmaps, anno_boxes, inds, masks = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n        # Transpose heatmaps\n        heatmaps = list(map(list, zip(*heatmaps)))\n        heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n        # Transpose anno_boxes\n        anno_boxes = list(map(list, zip(*anno_boxes)))\n        anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n        # Transpose inds\n        inds = list(map(list, zip(*inds)))\n        inds = [torch.stack(inds_) for inds_ in inds]\n        # Transpose inds\n        masks = list(map(list, zip(*masks)))\n        masks = [torch.stack(masks_) for masks_ in masks]\n        return heatmaps, anno_boxes, inds, masks\n    def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):  # (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes + (torch.Tensor): Labels of boxes. torch.Size([n])\n        gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]),dim=1).to(device)  # LiDARInstance3DBoxes(nx7)/LiDARInstance3DBoxes(nx9)\n        max_objs = self.train_cfg[\'max_objs\'] * self.train_cfg[\'dense_reg\']      # 500x1=500\n        grid_size = torch.tensor(self.train_cfg[\'grid_size\'])                    # tensor([1024, 1024,   40])   \n        pc_range = torch.tensor(self.train_cfg[\'point_cloud_range\'])             # tensor([-51.2000, -51.2000,  -5.0000,  51.2000,  51.2000,   3.0000])    \n        voxel_size = torch.tensor(self.train_cfg[\'voxel_size\'])                  # tensor([0.1000, 0.1000, 0.2000])   \n        feature_map_size = grid_size[:2] // self.train_cfg[\'out_size_factor\']    # tensor([128, 128])  1024/8\n        # reorganize the gt_dict by tasks\n        task_masks = []\n        flag = 0\n        for class_name in self.class_names:\n            task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag)for i in class_name])\n            flag += len(class_name)\n        task_boxes = []\n        task_classes = []\n        flag2 = 0\n        for idx, mask in enumerate(task_masks):\n            task_box = []\n            task_class = []\n            for m in mask:\n                task_box.append(gt_bboxes_3d[m])\n                task_class.append(gt_labels_3d[m] + 1 - flag2)     # 0 is background for each task, so we need to add 1 here.\n            task_boxes.append(torch.cat(task_box, axis=0).to(device))\n            task_classes.append(torch.cat(task_class).long().to(device))\n            flag2 += len(mask)\n        draw_gaussian = draw_heatmap_gaussian\n        heatmaps, anno_boxes, inds, masks = [], [], [], []\n        for idx, task_head in enumerate(self.task_heads):                                                            # idx=0   \n            heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1],feature_map_size[0]))  #  torch.Size([1, 128, 128]) \n            anno_box = gt_bboxes_3d.new_zeros((max_objs, int(gt_bboxes_3d.shape[1]+1)),dtype=torch.float32)          # torch.Size([500, 10]) \n            ind = gt_labels_3d.new_zeros((max_objs), dtype=torch.int64)                                              # torch.Size([500]) \n            mask = gt_bboxes_3d.new_zeros((max_objs), dtype=torch.uint8)                                             # torch.Size([500]) \n            num_objs = min(task_boxes[idx].shape[0], max_objs)                                                       # 33  \n            for k in range(num_objs):\n                cls_id = task_classes[idx][k] - 1\n                width = task_boxes[idx][k][3]                                           # tensor(1.9776, device=\'cuda:0\')\n                length = task_boxes[idx][k][4]                                          # tensor(4.6753, device=\'cuda:0\')\n                width = width / voxel_size[0] / self.train_cfg[\'out_size_factor\']       # 1.9776/0.1/8=2.4719    注意这里宽度的处理\n                length = length / voxel_size[1] / self.train_cfg[\'out_size_factor\']     # 4.6753/0.1/8=5.8441\n                if width > 0 and length > 0:\n                    radius = gaussian_radius((length, width),min_overlap=self.train_cfg[\'gaussian_overlap\'])   # 2,0.1\n                    radius = max(self.train_cfg[\'min_radius\'], int(radius))                                    # 2\n                    # be really careful for the coordinate system of your box annotation.\n                    x, y, z = task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2]\n                    coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg[\'out_size_factor\']\n                    coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg[\'out_size_factor\']\n                    center = torch.tensor([coor_x, coor_y],dtype=torch.float32,device=device)\n                    center_int = center.to(torch.int32)\n                    # throw out not in range objects to avoid out of array area when creating the heatmap\n                    if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                        continue\n                    draw_gaussian(heatmap[cls_id], center_int, radius)\n                    new_idx = k\n                    x, y = center_int[0], center_int[1]\n                    assert (y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1])\n                    ind[new_idx] = y * feature_map_size[0] + x\n                    mask[new_idx] = 1\n                    # TODO: support other outdoor dataset\n                    rot = task_boxes[idx][k][6]\n                    box_dim = task_boxes[idx][k][3:6]\n                    if self.norm_bbox:\n                        box_dim = box_dim.log()\n                    if len(task_boxes[idx][k])==9:\n                        vx, vy = task_boxes[idx][k][7:]\n                        anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device),z.unsqueeze(0), box_dim,\n                            torch.sin(rot).unsqueeze(0),torch.cos(rot).unsqueeze(0),vx.unsqueeze(0),vy.unsqueeze(0)])\n                    else:\n                        # vx, vy = torch.zeros_like(task_boxes[idx][k][5]),torch.zeros_like(task_boxes[idx][k][6])\n                        anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device),z.unsqueeze(0), box_dim,\n                            torch.sin(rot).unsqueeze(0),torch.cos(rot).unsqueeze(0)\n                        ])\n            heatmaps.append(heatmap)\n            anno_boxes.append(anno_box)\n            masks.append(mask)\n            inds.append(ind)\n        return heatmaps, anno_boxes, inds, masks  # inds是y*fature_map_size[0]+x,masks是1说明该box有用\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">head部分(DCN)</p>[4, 512, 128, 128]<br>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">shared_conv</p><span class=\'hidden-code\' data-code=\' ConvModule(\n    (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (activate): ReLU(inplace=True)\n )\n\'> </span>\n[4, 64, 128, 128]<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">第一个类别</p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">feature_adapt_cls</p><span class=\'hidden-code\' data-code=\'DeformConv2dPack(in_channels=64,out_channels=64,kernel_size=(3, 3),stride=(1, 1),padding=(1, 1),dilation=(1, 1),groups=4,deform_groups=1,bias=False)\n\'> </span>\n[4, 64, 128, 128]<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">cls_head</p><span class=\'hidden-code\' data-code=\'ConvModule(\n    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (activate): ReLU(inplace=True)\n)\nConv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\'> </span>\n[4, 1, 128, 128]--->heatmap<br>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">feature_adapt_reg</p><span class=\'hidden-code\' data-code=\'DeformConv2dPack(in_channels=64,out_channels=64,kernel_size=(3, 3),stride=(1, 1),padding=(1, 1),dilation=(1, 1),groups=4,deform_groups=1,bias=False)\n\'> </span>\n[4, 64, 128, 128]<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">task_head(SeparateHead)</p><span class=\'hidden-code\' data-code=\'init_cfg={\'type\': \'Kaiming\', \'layer\': \'Conv2d\'})\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">reg</p><span class=\'hidden-code\' data-code=\'Sequential(\n    (0): ConvModule(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activate): ReLU(inplace=True)\n    )\n    (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)\n\'> </span>\n[4, 2, 128, 128]--->reg<br>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">height</p><span class=\'hidden-code\' data-code=\'Sequential(\n    (0): ConvModule(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activate): ReLU(inplace=True)\n    )\n    (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)\n\'> </span>\n[4, 1, 128, 128]--->height<br>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">dim</p><span class=\'hidden-code\' data-code=\'Sequential(\n    (0): ConvModule(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activate): ReLU(inplace=True)\n    )\n    (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n\'> </span>\n[4, 3, 128, 128]--->dim<br>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">rot</p><span class=\'hidden-code\' data-code=\'Sequential(\n    (0): ConvModule(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activate): ReLU(inplace=True)\n    )\n    (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n\'> </span>\n[4, 2, 128, 128]--->rot<br>'}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">vel</p><span class=\'hidden-code\' data-code=\'Sequential(\n    (0): ConvModule(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (activate): ReLU(inplace=True)\n    )\n    (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n)\n\'> </span>\n[4, 2, 128, 128]--->vel<br>'}]}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">第二个类别</p>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">第三个类别</p>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">第四个类别</p>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">第五个类别</p>'}]}]}]})</script>
    <script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
  </body>
</html>
