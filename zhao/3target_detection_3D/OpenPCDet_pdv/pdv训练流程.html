<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>pdv训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_single.py</p><font size="0"><pre class="language-python"><code class="language-python">class AnchorHeadSingle(AnchorHeadTemplate):\n    def __init__(self, model_cfg, input_channels, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training=True, **kwargs):\n    def forward(self, data_dict):\n        spatial_features_2d = data_dict[\'spatial_features_2d\']  <span style=\'color: red\'>torch.Size([1, 512, 200, 176])</span>\n        cls_preds = self.conv_cls(spatial_features_2d)          <span style=\'color: red\'>torch.Size([1, 18, 200, 176]) 3个类别*6个anchor[每个类别2个anchor]</span>\n        box_preds = self.conv_box(spatial_features_2d)          <span style=\'color: red\'>torch.Size([1, 42, 200, 176]) 7个属性*6个anchor</span>\n        cls_preds = cls_preds.permute(0, 2, 3, 1).contiguous()  <span style=\'color: red\'>[N, H, W, C]</span>\n        box_preds = box_preds.permute(0, 2, 3, 1).contiguous()  <span style=\'color: red\'>[N, H, W, C]</span>\n        self.forward_ret_dict[\'cls_preds\'] = cls_preds          <span style=\'color: red\'>预测的，与anchor做计算才能得到真实box</span>\n        self.forward_ret_dict[\'box_preds\'] = box_preds\n        if self.conv_dir_cls is not None:\n            dir_cls_preds = self.conv_dir_cls(spatial_features_2d)    <span style=\'color: red\'>torch.Size([1, 12, 200, 176]) 2*6个anchor</span>\n            dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).contiguous()\n            self.forward_ret_dict[\'dir_cls_preds\'] = dir_cls_preds\n        else:\n            dir_cls_preds = None\n        if self.training:\n            targets_dict = self.<span style=\'color: green;font-weight: bold;\'>assign_targets</span>(gt_boxes=data_dict[\'gt_boxes\'])\n            self.forward_ret_dict.update(targets_dict)\n        if not self.training or self.predict_boxes_when_training:\n            batch_cls_preds, batch_box_preds = self.<span style=\'color: green;font-weight: bold;\'>generate_predicted_boxes</span>(\n                batch_size=data_dict[\'batch_size\'],cls_preds=cls_preds, box_preds=box_preds, dir_cls_preds=dir_cls_preds\n            )\n            data_dict[\'batch_cls_preds\'] = batch_cls_preds      <span style=\'color: red\'>torch.Size([1, 211200, 3])  与anchor做计算预测的也是最终的结果3Dbox</span>\n            data_dict[\'batch_box_preds\'] = batch_box_preds      <span style=\'color: red\'>torch.Size([1, 211200, 7])</span>\n            data_dict[\'cls_preds_normalized\'] = False\n        return data_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class AnchorHeadTemplate(nn.Module):\n    def __init__(self, model_cfg, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training):\n        super().__init__()\n        self.model_cfg = model_cfg\n        self.num_class = num_class\n        self.class_names = class_names\n        self.predict_boxes_when_training = predict_boxes_when_training\n        self.use_multihead = self.model_cfg.get(\'USE_MULTIHEAD\', False)\n        anchor_target_cfg = self.model_cfg.TARGET_ASSIGNER_CONFIG\n        self.box_coder = getattr(box_coder_utils, anchor_target_cfg.BOX_CODER)(\n            num_dir_bins=anchor_target_cfg.get(\'NUM_DIR_BINS\', 6),\n            **anchor_target_cfg.get(\'BOX_CODER_CONFIG\', {})\n        )\n        anchor_generator_cfg = self.model_cfg.ANCHOR_GENERATOR_CONFIG\n        anchors, self.num_anchors_per_location = self.generate_anchors(\n            anchor_generator_cfg, grid_size=grid_size, point_cloud_range=point_cloud_range,\n            anchor_ndim=self.box_coder.code_size\n        )\n        self.anchors = [x.cuda() for x in anchors]\n        self.target_assigner = self.get_target_assigner(anchor_target_cfg)\n        self.forward_ret_dict = {}\n        self.build_losses(self.model_cfg.LOSS_CONFIG)\n    @staticmethod\n    def generate_anchors(anchor_generator_cfg, grid_size, point_cloud_range, anchor_ndim=7):\n        anchor_generator = AnchorGenerator(\n            anchor_range=point_cloud_range,\n            anchor_generator_config=anchor_generator_cfg\n        )\n        feature_map_size = [grid_size[:2] <span style=\'color: red\'>// config[\'feature_map_stride\'] for config in anchor_generator_cfg]</span>\n        anchors_list, num_anchors_per_location_list = anchor_generator.generate_anchors(feature_map_size)\n        if anchor_ndim != 7:\n            for idx, anchors in enumerate(anchors_list):\n                pad_zeros = anchors.new_zeros([*anchors.shape[0:-1], anchor_ndim - 7])\n                new_anchors = torch.cat((anchors, pad_zeros), dim=-1)\n                anchors_list[idx] = new_anchors\n        return anchors_list, num_anchors_per_location_list\n    def get_target_assigner(self, anchor_target_cfg):\n        if anchor_target_cfg.NAME == \'ATSS\':\n            target_assigner = ATSSTargetAssigner(\n                topk=anchor_target_cfg.TOPK,\n                box_coder=self.box_coder,\n                use_multihead=self.use_multihead,\n                match_height=anchor_target_cfg.MATCH_HEIGHT\n            )\n        elif anchor_target_cfg.NAME == \'AxisAlignedTargetAssigner\':\n            target_assigner = AxisAlignedTargetAssigner(\n                model_cfg=self.model_cfg,\n                class_names=self.class_names,\n                box_coder=self.box_coder,\n                match_height=anchor_target_cfg.MATCH_HEIGHT\n            )\n        else:\n            raise NotImplementedError\n        return target_assigner\n    def build_losses(self, losses_cfg):\n        self.add_module(\n            \'cls_loss_func\',\n            loss_utils.SigmoidFocalClassificationLoss(alpha=0.25, gamma=2.0)\n        )\n        reg_loss_name = \'WeightedSmoothL1Loss\' if losses_cfg.get(\'REG_LOSS_TYPE\', None) is None \\\n            else losses_cfg.REG_LOSS_TYPE\n        self.add_module(\n            \'reg_loss_func\',\n            getattr(loss_utils, reg_loss_name)(code_weights=losses_cfg.LOSS_WEIGHTS[\'code_weights\'])\n        )\n        self.add_module(\n            \'dir_loss_func\',\n            loss_utils.WeightedCrossEntropyLoss()\n        )\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class AnchorHeadTemplate(nn.Module):\n    def assign_targets(self, gt_boxes):\n        targets_dict = self.target_assigner.<span style=\'color: green;font-weight: bold;\'>assign_targets</span>(self.anchors, gt_boxes)\n        return targets_dict <span style=\'color: red\'># [torch.Size([1, 200, 176, 1, 2, 7]),torch.Size([1, 200, 176, 1, 2, 7]),torch.Size([1, 200, 176, 1, 2, 7])] + torch.Size([1, 39, 8])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/target_assigner/axis_aligned_target_assigner.py</p><font size="0"><pre class="language-python"><code class="language-python">class AxisAlignedTargetAssigner(object):\n    def assign_targets(self, all_anchors, gt_boxes_with_classes):\n        bbox_targets,cls_labels,reg_weights = [],[],[]\n        batch_size = gt_boxes_with_classes.shape[0]         <span style=\'color: red\'># 1</span>\n        gt_classes = gt_boxes_with_classes[:, :, -1]        <span style=\'color: red\'># torch.Size([1, 39]) 标签</span>\n        gt_boxes = gt_boxes_with_classes[:, :, :-1]         <span style=\'color: red\'># torch.Size([1, 39, 7])</span>\n        for k in range(batch_size):\n            cur_gt = gt_boxes[k]                            <span style=\'color: red\'># torch.Size([39, 7])</span>\n            cnt = cur_gt.__len__() - 1                      <span style=\'color: red\'># 38</span>\n            while cnt > 0 and cur_gt[cnt].sum() == 0:\n                cnt -= 1\n            cur_gt = cur_gt[:cnt + 1]                       <span style=\'color: red\'># torch.Size([39, 7])</span>\n            cur_gt_classes = gt_classes[k][:cnt + 1].int()  <span style=\'color: red\'># 标签不为0开始，有1,2,3   torch.Size([39])</span>\n            target_list = []\n            for anchor_class_name, anchors in zip(self.anchor_class_names, all_anchors):    <span style=\'color: red\'># \'car\' torch.Size([1, 200, 176, 1, 2, 7])</span>\n                if cur_gt_classes.shape[0] > 1:\n                    mask = torch.from_numpy(self.class_names[cur_gt_classes.cpu() - 1] == anchor_class_name)    <span style=\'color: red\'># torch.Size([39])</span>\n                else:\n                    mask = torch.tensor([self.class_names[c - 1] == anchor_class_namefor c in cur_gt_classes], dtype=torch.bool)\n                if self.use_multihead:               <span style=\'color: red\'># False</span>\n                    anchors = anchors.permute(3, 4, 0, 1, 2, 5).contiguous().view(-1, anchors.shape[-1])\n                    selected_classes = cur_gt_classes[mask]\n                else:\n                    feature_map_size = anchors.shape[:3]             <span style=\'color: red\'># torch.Size([1, 200, 176])</span>\n                    anchors = anchors.view(-1, anchors.shape[-1])    <span style=\'color: red\'># torch.Size([70400, 7])</span>\n                    selected_classes = cur_gt_classes[mask]          <span style=\'color: red\'># torch.Size([11]) 39里面有11个为0类</span>\n                single_target = self.<span style=\'color: green;font-weight: bold;\'>assign_targets_single</span>(\n                    anchors,cur_gt[mask],gt_classes=selected_classes,\n                    matched_threshold=self.matched_thresholds[anchor_class_name],       <span style=\'color: red\'># {\'Car\': 0.6, \'Pedestrian\': 0.5, \'Cyclist\': 0.5}</span>\n                    unmatched_threshold=self.unmatched_thresholds[anchor_class_name]    <span style=\'color: red\'># {\'Car\': 0.45, \'Pedestrian\': 0.35, \'Cyclist\': 0.35}</span>\n                )\n                target_list.append(single_target)\n            if self.use_multihead:          <span style=\'color: red\'># False</span>\n                target_dict = {\n                    \'box_cls_labels\': [t[\'box_cls_labels\'].view(-1) for t in target_list],\n                    \'box_reg_targets\': [t[\'box_reg_targets\'].view(-1, self.box_coder.code_size) for t in target_list],\n                    \'reg_weights\': [t[\'reg_weights\'].view(-1) for t in target_list]\n                }\n                target_dict[\'box_reg_targets\'] = torch.cat(target_dict[\'box_reg_targets\'], dim=0)\n                target_dict[\'box_cls_labels\'] = torch.cat(target_dict[\'box_cls_labels\'], dim=0).view(-1)\n                target_dict[\'reg_weights\'] = torch.cat(target_dict[\'reg_weights\'], dim=0).view(-1)\n            else:\n                target_dict = {\n                    \'box_cls_labels\': [t[\'box_cls_labels\'].view(*feature_map_size, -1) for t in target_list],             <span style=\'color: red\'># feature_map_size=torch.Size([1, 200, 176])</span>\n                    \'box_reg_targets\': [t[\'box_reg_targets\'].view(*feature_map_size, -1, self.box_coder.code_size) for t in target_list],\n                    \'reg_weights\': [t[\'reg_weights\'].view(*feature_map_size, -1) for t in target_list]\n                }\n                target_dict[\'box_reg_targets\'] = torch.cat(target_dict[\'box_reg_targets\'], dim=-2).view(-1, self.box_coder.code_size)\n                target_dict[\'box_cls_labels\'] = torch.cat(target_dict[\'box_cls_labels\'], dim=-1).view(-1)\n                target_dict[\'reg_weights\'] = torch.cat(target_dict[\'reg_weights\'], dim=-1).view(-1)\n            bbox_targets.append(target_dict[\'box_reg_targets\'])\n            cls_labels.append(target_dict[\'box_cls_labels\'])\n            reg_weights.append(target_dict[\'reg_weights\'])\n        bbox_targets = torch.stack(bbox_targets, dim=0)\n        cls_labels = torch.stack(cls_labels, dim=0)\n        reg_weights = torch.stack(reg_weights, dim=0)\n        all_targets_dict = {\n            \'box_cls_labels\': cls_labels,           <span style=\'color: red\'># torch.Size([1, 211200])</span>\n            \'box_reg_targets\': bbox_targets,        <span style=\'color: red\'># torch.Size([1, 211200, 7])</span>\n            \'reg_weights\': reg_weights              <span style=\'color: red\'># torch.Size([1, 211200])</span>\n        }\n        return all_targets_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/target_assigner/axis_aligned_target_assigner.py</p><font size="0"><pre class="language-python"><code class="language-python">class AxisAlignedTargetAssigner(object):\n    def assign_targets_single(self, anchors, gt_boxes, gt_classes, matched_threshold=0.6, unmatched_threshold=0.45):\n        <span style=\'color: red\'># torch.Size([70400, 7])；torch.Size([11, 7])；torch.Size([11])；0.6；0.45</span>\n        num_anchors = anchors.shape[0]        <span style=\'color: red\'># 70400</span>\n        num_gt = gt_boxes.shape[0]\n        labels = torch.ones((num_anchors,), dtype=torch.int32, device=anchors.device) * -1\n        gt_ids = torch.ones((num_anchors,), dtype=torch.int32, device=anchors.device) * -1\n        if len(gt_boxes) > 0 and anchors.shape[0] > 0:\n            anchor_by_gt_overlap = iou3d_nms_utils.boxes_iou3d_gpu(anchors[:, 0:7], gt_boxes[:, 0:7]) if self.match_height else box_utils.boxes3d_nearest_bev_iou(anchors[:, 0:7], gt_boxes[:, 0:7])\n            <span style=\'color: red\'># torch.Size([70400, 11])70400个anchor与11个gt的iou结果</span>\n            <span style=\'color: red\'># NOTE: The speed of these two versions depends the environment and the number of anchors</span>\n            <span style=\'color: red\'># anchor_to_gt_argmax = torch.from_numpy(anchor_by_gt_overlap.cpu().numpy().argmax(axis=1)).cuda()</span>\n            anchor_to_gt_argmax = anchor_by_gt_overlap.argmax(dim=1)       <span style=\'color: red\'># torch.Size([70400])；每个anchor与最大iou的那个box索引</span>\n            anchor_to_gt_max = anchor_by_gt_overlap[torch.arange(num_anchors, device=anchors.device), anchor_to_gt_argmax]  <span style=\'color: red\'># torch.Size([70400])对应的iou值</span>\n            <span style=\'color: red\'># gt_to_anchor_argmax = torch.from_numpy(anchor_by_gt_overlap.cpu().numpy().argmax(axis=0)).cuda()</span>\n            gt_to_anchor_argmax = anchor_by_gt_overlap.argmax(dim=0)      <span style=\'color: red\'># torch.Size([11]) 11个真值与最大iou的那个anchor索引</span>\n            gt_to_anchor_max = anchor_by_gt_overlap[gt_to_anchor_argmax, torch.arange(num_gt, device=anchors.device)]  <span style=\'color: red\'># torch.Size([11])最大的iou值</span>\n            empty_gt_mask = gt_to_anchor_max == 0\n            gt_to_anchor_max[empty_gt_mask] = -1         <span style=\'color: red\'># 将iou为0的设置为-1</span>\n            anchors_with_max_overlap = (anchor_by_gt_overlap == gt_to_anchor_max).nonzero()[:, 0]    <span style=\'color: red\'># torch.Size([14]), 70400个anchor与Gt有14个anchor的iou不为0</span>\n            gt_inds_force = anchor_to_gt_argmax[anchors_with_max_overlap]                            <span style=\'color: red\'># 范围为11个box的索引0-10</span>\n            labels[anchors_with_max_overlap] = gt_classes[gt_inds_force]\n            gt_ids[anchors_with_max_overlap] = gt_inds_force.int()\n            pos_inds = anchor_to_gt_max >= matched_threshold\n            gt_inds_over_thresh = anchor_to_gt_argmax[pos_inds]\n            labels[pos_inds] = gt_classes[gt_inds_over_thresh]\n            gt_ids[pos_inds] = gt_inds_over_thresh.int()\n            bg_inds = (anchor_to_gt_max < unmatched_threshold).nonzero()[:, 0]\n        else:\n            bg_inds = torch.arange(num_anchors, device=anchors.device)\n        fg_inds = (labels > 0).nonzero()[:, 0]     <span style=\'color: red\'># torch.Size([54])总共54个前景anchor</span>\n        if self.pos_fraction is not None:          <span style=\'color: red\'># None</span>\n            ......\n        else:\n            if len(gt_boxes) == 0 or anchors.shape[0] == 0:\n                labels[:] = 0\n            else:\n                labels[bg_inds] = 0\n                labels[anchors_with_max_overlap] = gt_classes[gt_inds_force]       <span style=\'color: red\'># 可以理解1个anchor多个GT？然后强制取某个GT？</span>\n        bbox_targets = anchors.new_zeros((num_anchors, self.box_coder.code_size))  <span style=\'color: red\'># torch.Size([70400, 7])</span>\n        if len(gt_boxes) > 0 and anchors.shape[0] > 0: \n            fg_gt_boxes = gt_boxes[anchor_to_gt_argmax[fg_inds], :]                            <span style=\'color: red\'># torch.Size([54, 7])54个匹配的anchor对应的3Dbox</span>\n            fg_anchors = anchors[fg_inds, :]                                                   <span style=\'color: red\'># 54个anchor</span>\n            bbox_targets[fg_inds, :] = self.box_coder.<span style=\'color: green;font-weight: bold;\'>encode_torch</span>(fg_gt_boxes, fg_anchors)    <span style=\'color: red\'># pcdet.utils.box_coder_utils.ResidualCoder  torch.Size([70400, 7])</span>\n        reg_weights = anchors.new_zeros((num_anchors,))\n        if self.norm_by_num_examples:\n            num_examples = (labels >= 0).sum()\n            num_examples = num_examples if num_examples > 1.0 else 1.0\n            reg_weights[labels > 0] = 1.0 / num_examples\n        else:\n            reg_weights[labels > 0] = 1.0       <span style=\'color: red\'># 有box的才做回归</span>\n        ret_dict = {\n            \'box_cls_labels\': labels,           <span style=\'color: red\'># 对应的标签</span>\n            \'box_reg_targets\': bbox_targets,    <span style=\'color: red\'># anchor与GTbox做计算得到</span>\n            \'reg_weights\': reg_weights,\n        }\n        return ret_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/box_coder_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class ResidualCoder(object):\n    def encode_torch(self, boxes, anchors):\n        anchors[:, 3:6] = torch.clamp_min(anchors[:, 3:6], min=1e-5)\n        boxes[:, 3:6] = torch.clamp_min(boxes[:, 3:6], min=1e-5)\n        xa, ya, za, dxa, dya, dza, ra, *cas = torch.split(anchors, 1, dim=-1)    <span style=\'color: red\'># cas=[]</span>\n        xg, yg, zg, dxg, dyg, dzg, rg, *cgs = torch.split(boxes, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)                               <span style=\'color: red\'># torch.Size([54, 1])</span>\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n        if self.encode_angle_by_sincos:\n            rt_cos = torch.cos(rg) - torch.cos(ra)\n            rt_sin = torch.sin(rg) - torch.sin(ra)\n            rts = [rt_cos, rt_sin]\n        else:\n            rts = [rg - ra]\n        cts = [g - a for g, a in zip(cgs, cas)]\n        return torch.cat([xt, yt, zt, dxt, dyt, dzt, *rts, *cts], dim=-1)\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class AnchorHeadTemplate(nn.Module):\n    def generate_predicted_boxes(self, batch_size, cls_preds, box_preds, dir_cls_preds=None):\n        if isinstance(self.anchors, list):\n            if self.use_multihead:\n                anchors = torch.cat([anchor.permute(3, 4, 0, 1, 2, 5).contiguous().view(-1, anchor.shape[-1])for anchor in self.anchors], dim=0)\n            else:\n                anchors = torch.cat(self.anchors, dim=-3)        <span style=\'color: red\'># torch.Size([1, 200, 176, 3, 2, 7])</span>\n        else:\n            anchors = self.anchors\n        num_anchors = anchors.view(-1, anchors.shape[-1]).shape[0]                         <span style=\'color: red\'># 211200</span>\n        batch_anchors = anchors.view(1, -1, anchors.shape[-1]).repeat(batch_size, 1, 1)    <span style=\'color: red\'># torch.Size([1, 211200, 7])</span>\n        batch_cls_preds = cls_preds.view(batch_size, num_anchors, -1).float() if not isinstance(cls_preds, list) else cls_preds <span style=\'color: red\'># torch.Size([1, 211200, 3])</span>\n        batch_box_preds = box_preds.view(batch_size, num_anchors, -1) if not isinstance(box_preds, list) else torch.cat(box_preds, dim=1).view(batch_size, num_anchors, -1)  <span style=\'color: red\'># torch.Size([1, 211200, 7])</span>\n        batch_box_preds = self.box_coder.<span style=\'color: green;font-weight: bold;\'>decode_torch</span>(batch_box_preds, batch_anchors)\n        if dir_cls_preds is not None:\n            dir_offset = self.model_cfg.DIR_OFFSET                                         <span style=\'color: red\'># 0.78539</span>\n            dir_limit_offset = self.model_cfg.DIR_LIMIT_OFFSET\n            dir_cls_preds = dir_cls_preds.view(batch_size, num_anchors, -1) if not isinstance(dir_cls_preds, list) else torch.cat(dir_cls_preds, dim=1).view(batch_size, num_anchors, -1)\n            dir_labels = torch.max(dir_cls_preds, dim=-1)[1]\n            period = (2 * np.pi / self.model_cfg.NUM_DIR_BINS)\n            dir_rot = common_utils.limit_period(batch_box_preds[..., 6] - dir_offset, dir_limit_offset, period)   <span style=\'color: red\'># torch.Size([1, 211200])</span>\n            batch_box_preds[..., 6] = dir_rot + dir_offset + period * dir_labels.to(batch_box_preds.dtype)\n        if isinstance(self.box_coder, box_coder_utils.PreviousResidualDecoder):\n            batch_box_preds[..., 6] = common_utils.limit_period(-(batch_box_preds[..., 6] + np.pi / 2), offset=0.5, period=np.pi * 2)\n        return batch_cls_preds, batch_box_preds       <span style=\'color: red\'># torch.Size([1, 211200, 3])  torch.Size([1, 211200, 7])</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelAggregationHead(RoIHeadTemplate):\n    def forward(self, batch_dict):\n         <span style=\'color: red\'>[(\'x_conv3\', torch.Size([7512, 64])), (\'x_conv4\', torch.Size([3578, 64]))] [(\'x_conv3\', torch.Size([7512, 4])), (\'x_conv4\', torch.Size([3578, 4]))]</span>\n        batch_dict[\'point_features\'], batch_dict[\'point_coords\'] = self.<span style=\'color: green;font-weight: bold;\'>get_point_voxel_features</span>(batch_dict)                        <span style=\'color: red\'>获取体素特征和体素坐标</span>\n        targets_dict = self.<span style=\'color: green;font-weight: bold;\'>proposal_layer</span>(batch_dict, nms_config=self.model_cfg.NMS_CONFIG[\'TRAIN\' if self.training else \'TEST\'])  <span style=\'color: red\'>做nms，主要是获取roi和对应label</span>\n        if self.training:\n            targets_dict = self.<span style=\'color: green;font-weight: bold;\'>assign_targets</span>(batch_dict)\n            batch_dict[\'rois\'] = targets_dict[\'rois\']               <span style=\'color: red\'>rois是网络预测的与gt匹配到的 torch.Size([1, 128, 7])</span>\n            batch_dict[\'roi_labels\'] = targets_dict[\'roi_labels\']   <span style=\'color: red\'></span>\n        <span style=\'color: red\'>RoI aware pooling   torch.Size([128, 216, 128]),torch.Size([1, 27648, 3]),torch.Size([128, 216, 3]),torch.Size([128, 216, 64])</span>\n        pooled_features, global_roi_grid_points, local_roi_grid_points, ball_idxs = self.<span style=\'color: green;font-weight: bold;\'>roi_grid_pool</span>(batch_dict)  <span style=\'color: red\'>(BxN, 6x6x6, C)</span>\n        batch_size_rcnn = pooled_features.shape[0]\n        if self.pool_cfg.get(\'ATTENTION\', {}).get(\'ENABLED\'):             <span style=\'color: red\'>True</span>\n            src_key_padding_mask = None\n            if self.pool_cfg.ATTENTION.get(\'MASK_EMPTY_POINTS\'):\n                src_key_padding_mask = (ball_idxs == 0).all(-1)           <span style=\'color: red\'>torch.Size([128, 216])</span>\n            positional_input = self.<span style=\'color: green;font-weight: bold;\'>get_positional_input</span>(batch_dict[\'points\'], batch_dict[\'rois\'], local_roi_grid_points)  <span style=\'color: red\'>torch.Size([128, 216, 4])</span>\n            <span style=\'color: red\'>Attention</span>\n            attention_output = self.<span style=\'color: green;font-weight: bold;\'>attention_head</span>(pooled_features, positional_input, src_key_padding_mask) <span style=\'color: red\'>(BxN, 6x6x6, C)  torch.Size([128, 216, 128])</span>\n            if self.pool_cfg.ATTENTION.get(\'COMBINE\'):\n                attention_output = pooled_features + attention_output     <span style=\'color: red\'>torch.Size([128, 216, 128])</span>\n            <span style=\'color: red\'>Permute</span>\n            grid_size = self.model_cfg.ROI_GRID_POOL.GRID_SIZE            <span style=\'color: red\'>6</span>\n            batch_size_rcnn = attention_output.shape[0]                   <span style=\'color: red\'>128</span>\n            pooled_features = attention_output.permute(0, 2, 1).contiguous().view(batch_size_rcnn, -1, grid_size, grid_size, grid_size) <span style=\'color: red\'>(BxN, C, 6, 6, 6)-torch.Size([128, 128, 6, 6, 6])</span>\n        shared_features = self.shared_fc_layer(pooled_features.view(batch_size_rcnn, -1, 1))     <span style=\'color: red\'>一堆卷积->torch.Size([128, 256, 1])</span>\n        rcnn_reg = self.reg_layers(shared_features).transpose(1, 2).contiguous().squeeze(dim=1)  <span style=\'color: red\'>(B, C) torch.Size([128, 7, 1])->torch.Size([128, 7])</span>\n        if self.model_cfg.get(\'DENSITY_CONFIDENCE\', {}).get(\'ENABLED\'):         <span style=\'color: red\'>True</span>\n            with torch.no_grad():\n                <span style=\'color: red\'>Calculate number of points in each rcnn_reg     密度置信度预测  == 添加两个额外特征（分别是当前bbox的点质心特征以及bbox中的点数）</span>\n                _, batch_box_preds = self.<span style=\'color: green;font-weight: bold;\'>generate_predicted_boxes</span>(batch_size=batch_dict[\'batch_size\'], rois=batch_dict[\'rois\'], cls_preds=None, box_preds=rcnn_reg) <span style=\'color: red\'>torch.Size([1, 128, 7])</span>\n                points_per_part = density_utils.<span style=\'color: green;font-weight: bold;\'>find_num_points_per_part_multi</span>(batch_dict[\'points\'],batch_box_preds,             <span style=\'color: red\'>torch.Size([22969, 5]);torch.Size([1, 128, 7])  -->torch.Size([1, 128, 1, 1, 1])</span>\n                                                                               self.model_cfg.DENSITY_CONFIDENCE.GRID_SIZE,        <span style=\'color: red\'>1</span>\n                                                                               self.model_cfg.DENSITY_CONFIDENCE.MAX_NUM_BOXES)    <span style=\'color: red\'>20</span>\n                points_per_part = torch.log10(points_per_part.float() + 0.5).reshape(-1, self.model_cfg.DENSITY_CONFIDENCE.GRID_SIZE ** 3, 1) - (math.log10(0.5) if self.model_cfg.get(\'DENSITY_LOG_SHIFT\') else 0) <span style=\'color: red\'>torch.Size([128, 1, 1])</span>\n                point_cloud_range = torch.tensor(self.point_cloud_range, device=batch_box_preds.device)      <span style=\'color: red\'>tensor([  0.0000, -40.0000,  -3.0000,  70.4000,  40.0000,   1.0000],</span>\n                batch_box_preds_xyz = batch_box_preds.reshape(-1, batch_box_preds.shape[-1], 1)[:, :3]       <span style=\'color: red\'>torch.Size([128, 3, 1])</span>\n                batch_box_preds_xyz /= (point_cloud_range[3:] - point_cloud_range[:3]).unsqueeze(0).unsqueeze(-1)  <span style=\'color: red\'>torch.Size([128, 3, 1])</span>\n                density_features = [points_per_part, batch_box_preds_xyz]    <span style=\'color: red\'>[torch.Size([1, 128, 1, 1, 1]),torch.Size([128, 3, 1])]</span>\n                if self.model_cfg.DENSITY_CONFIDENCE.ADD_SHARED_FEATURES:\n                    density_features.append(shared_features)                 <span style=\'color: red\'>torch.Size([128, 256, 1])->[torch.Size([1, 128, 1, 1, 1]),torch.Size([128, 3, 1]),torch.Size([128, 256, 1])]</span>\n            density_features = torch.cat(density_features, dim=1)            <span style=\'color: red\'>torch.Size([128, 260, 1])</span>\n            rcnn_cls = self.<span style=\'color: green;font-weight: bold;\'>cls_layers</span>(density_features)  <span style=\'color: red\'>(B, 1 or 2)   </span>\n        else:\n            rcnn_cls = self.cls_layers(shared_features)\n        rcnn_cls = rcnn_cls.transpose(1, 2).contiguous().squeeze(dim=1)      <span style=\'color: red\'>torch.Size([128, 1])  没有做具体类别？</span>\n        if not self.training:\n            batch_cls_preds, batch_box_preds = self.<span style=\'color: green;font-weight: bold;\'>generate_predicted_boxes</span>(\n                batch_size=batch_dict[\'batch_size\'], rois=batch_dict[\'rois\'], cls_preds=rcnn_cls, box_preds=rcnn_reg\n            )\n            batch_dict[\'batch_cls_preds\'] = batch_cls_preds\n            batch_dict[\'batch_box_preds\'] = batch_box_preds\n            batch_dict[\'cls_preds_normalized\'] = False\n        else:\n            targets_dict[\'rcnn_cls\'] = rcnn_cls\n            targets_dict[\'rcnn_reg\'] = rcnn_reg\n            self.forward_ret_dict = targets_dict\n        return batch_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class PDVHead(VoxelAggregationHead):\n    def get_point_voxel_features(self, batch_dict):\n        point_features = {}\n        point_coords = {}       <span style=\'color: red\'># 就是求点云属于哪个voxel，求里面的点云平均以及属于哪个大voxel</span>\n        centroids_all, centroid_voxel_idxs_all = voxel_aggregation_utils.<span style=\'color: green;font-weight: bold;\'>get_centroids_per_voxel_layer</span>(batch_dict[\'points\'],  <span style=\'color: red\'># torch.Size([22795, 5])</span>\n            self.model_cfg.VOXEL_AGGREGATION.FEATURE_LOCATIONS,       <span style=\'color: red\'># [\'x_conv3\', \'x_conv4\']</span>\n            batch_dict[\'multi_scale_3d_strides\'],                     <span style=\'color: red\'># {\'x_conv1\': 1, \'x_conv2\': 2, \'x_conv3\': 4, \'x_conv4\': 8}</span>\n            self.voxel_size,                                          <span style=\'color: red\'># [0.05, 0.05, 0.1]</span>\n            self.point_cloud_range                                    <span style=\'color: red\'># [0.0, -40.0, -3.0, 70.4, 40.0, 1.0]</span>\n        )\n        for feature_location in self.model_cfg.VOXEL_AGGREGATION.FEATURE_LOCATIONS:        <span style=\'color: red\'># [\'x_conv3\', \'x_conv4\']</span>\n            centroids = centroids_all[feature_location][:, :4]                             <span style=\'color: red\'># torch.Size([7732, 4])该voxel里面的平均</span>\n            centroid_voxel_idxs = centroid_voxel_idxs_all[feature_location]\n            x_conv = batch_dict[\'multi_scale_3d_features\'][feature_location]               <span style=\'color: red\'># 该feature的3D特征[11, 400, 352]</span>\n            overlapping_voxel_feature_indices_nonempty, overlapping_voxel_feature_nonempty_mask = \\\n                voxel_aggregation_utils.<span style=\'color: green;font-weight: bold;\'>get_nonempty_voxel_feature_indices</span>(centroid_voxel_idxs, x_conv)  <span style=\'color: red\'># torch.Size([7512]) ；torch.Size([7732]) 前面是去掉空的体素</span>\n            if self.model_cfg.VOXEL_AGGREGATION.get(\'USE_EMPTY_VOXELS\'):  <span style=\'color: red\'># 是否用空体素特征</span>\n                ......\n            else:           <span style=\'color: red\'># False</span>\n                x_conv_features = torch.zeros((centroids.shape[0], x_conv.features.shape[-1]), dtype=x_conv.features.dtype, device=centroids.device)  <span style=\'color: red\'># torch.Size([7732, 64])</span>\n                x_conv_features[overlapping_voxel_feature_nonempty_mask] = x_conv.features[overlapping_voxel_feature_indices_nonempty]\n                point_features[feature_location] = x_conv_features[overlapping_voxel_feature_nonempty_mask]   <span style=\'color: red\'># torch.Size([7732, 64])->torch.Size([7512, 64])</span>\n                point_coords[feature_location] = centroids[overlapping_voxel_feature_nonempty_mask]           <span style=\'color: red\'># torch.Size([7732, 4])大voxcel所有点云的平均，没包括反射率</span>\n        return point_features, point_coords\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_centroids_per_voxel_layer(points, feature_locations, multi_scale_3d_strides, voxel_size, point_cloud_range):\n    assert len(points.shape) == 2\n    assert len(feature_locations) > 0\n    centroids_all = {}\n    centroid_voxel_idxs_all = {}\n    <span style=\'color: red\'># Take first layer feature locations</span>\n    feature_location_first = feature_locations[0]                             <span style=\'color: red\'># \'x_conv3\'</span>\n    downsample_factor_first = multi_scale_3d_strides[feature_location_first]  <span style=\'color: red\'># 4</span>\n    <span style=\'color: red\'># Calculate centroids</span>\n    voxel_idxs = <span style=\'color: green;font-weight: bold;\'>get_overlapping_voxel_indices</span>(points[:, 1:4],\n                                               downsample_times=downsample_factor_first,\n                                               voxel_size=voxel_size,\n                                               point_cloud_range=point_cloud_range)   <span style=\'color: red\'># torch.Size([22795, 3])这些点属于哪个voxel</span>\n    <span style=\'color: red\'># Add batch_idx</span>\n    voxel_idxs = torch.cat((points[:,0:1].long(), voxel_idxs), dim=-1)      <span style=\'color: red\'># 加入batch idx</span>\n    <span style=\'color: red\'># Filter out points that are outside the valid point cloud range (invalid indices have -1)</span>\n    voxel_idxs_valid_mask = (voxel_idxs != -1).all(-1)\n    voxel_idxs_valid = voxel_idxs[voxel_idxs_valid_mask]                    <span style=\'color: red\'># torch.Size([22187, 4])</span>\n    <span style=\'color: red\'># Convert voxel_indices from (bxyz) to (bzyx) format for properly indexing voxelization layer</span>\n    voxel_idxs_valid = voxel_idxs_valid[:, [0,3,2,1]]                       <span style=\'color: red\'># torch.Size([22187, 4])</span>\n    points_valid = points[voxel_idxs_valid_mask]                            <span style=\'color: red\'># torch.Size([22187, 5])</span>\n    centroids_first, centroid_voxel_idxs_first, num_points_in_centroids_first = <span style=\'color: green;font-weight: bold;\'>get_centroid_per_voxel</span>(points_valid, voxel_idxs_valid)\n    centroids_all[feature_location_first] = centroids_first                            <span style=\'color: red\'># torch.Size([7732, 5])</span>\n    centroid_voxel_idxs_all[feature_location_first] = centroid_voxel_idxs_first        <span style=\'color: red\'># torch.Size([7732, 4])</span>\n    for feature_location in feature_locations[1:]:        <span style=\'color: red\'># [\'x_conv3\', \'x_conv4\']</span>\n        grid_scaling = int(multi_scale_3d_strides[feature_location] / downsample_factor_first)     <span style=\'color: red\'># 2=8/4</span>\n        voxel_idxs = centroid_voxel_idxs_first.clone()\n        voxel_idxs[:, 1:] = centroid_voxel_idxs_first[:, 1:] // grid_scaling     <span style=\'color: red\'># [  0,   1, 179, 149]->[ 0,  0, 89, 74]</span>\n        centroids, centroid_voxel_idxs, _ = <span style=\'color: green;font-weight: bold;\'>get_centroid_per_voxel</span>(centroids_first, voxel_idxs, num_points_in_centroids_first)   <span style=\'color: red\'># 每个大voxel所有点云求平均，对应的B,Z,Y,Z;</span>\n        centroids_all[feature_location] = centroids\n        centroid_voxel_idxs_all[feature_location] = centroid_voxel_idxs\n    return centroids_all, centroid_voxel_idxs_all\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_overlapping_voxel_indices(point_coords, downsample_times, voxel_size, point_cloud_range):\n    assert point_coords.shape[1] == 3\n    voxel_size = torch.tensor(voxel_size, device=point_coords.device).float() * downsample_times  <span style=\'color: red\'># [0.05, 0.05, 0.1]->[0.2, 0.2, 0.4]</span>\n    pc_range = torch.tensor(point_cloud_range, device=point_coords.device).float()                <span style=\'color: red\'># tensor([  0, -40,  -3,  70.4,  40,   1],</span>\n    voxel_indices = ((point_coords - pc_range[0:3]) / voxel_size)                                 <span style=\'color: red\'># torch.Size([22795, 3]) 每个点在xyz上面的索引</span>\n    <span style=\'color: red\'># Calculate number of voxels in each dimension</span>\n    grid_size = ((pc_range[3:6] - pc_range[0:3]) / voxel_size).long()                            <span style=\'color: red\'># tensor([352, 400,  10], device=\'cuda:0\') 有多少个voxels</span>\n    <span style=\'color: red\'># Check which points are in and which points are outside the point cloud range and set to -1</span>\n    points_out_of_range = ((voxel_indices < 0) | (voxel_indices >= grid_size)).sum(dim=-1) > 0   <span style=\'color: red\'># 大于的为-1</span>\n    voxel_indices[points_out_of_range] = -1\n    return voxel_indices.long() <span style=\'color: red\'># (xyz)</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_centroid_per_voxel(points, voxel_idxs, num_points_in_voxel=None):   <span style=\'color: red\'># torch.Size([22187, 5])；torch.Size([22187, 4])；</span>\n    assert points.shape[0] == voxel_idxs.shape[0]\n    <span style=\'color: red\'># torch.Size([7732, 4]) 7732个非0唯一voxel；torch.Size([22187])属于哪个voxle， torch.Size([7732])告诉哪个voxel有多少个</span>\n    centroid_voxel_idxs, unique_idxs, labels_count = voxel_idxs.unique(dim=0, return_inverse=True, return_counts=True)  \n    unique_idxs = unique_idxs.view(unique_idxs.size(0), 1).expand(-1, points.size(-1)) <span style=\'color: red\'># torch.Size([22187, 5]) unique_idxs[0]=[4242, 4242, 4242, 4242, 4242]</span>\n    <span style=\'color: red\'># Scatter add points based on unique voxel idxs</span>\n    if num_points_in_voxel is not None:\n        ......\n    else:\n        centroids = torch.zeros((centroid_voxel_idxs.shape[0], points.shape[-1]), device=points.device, dtype=torch.float).scatter_add_(0, unique_idxs, points)   <span style=\'color: red\'># torch.Size([7732, 5])将点云相加求平均</span>\n        centroids = centroids / labels_count.float().unsqueeze(-1)\n    return centroids, centroid_voxel_idxs, labels_count       <span style=\'color: red\'># 每个大voxel所有点云求平均，对应的B,Z,Y,Z; 每个大voxel的点云数量</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_centroid_per_voxel(points, voxel_idxs, num_points_in_voxel=None):   <span style=\'color: red\'># torch.Size([7732, 5])；torch.Size([7732, 4])； torch.Size([7732])</span>\n    assert points.shape[0] == voxel_idxs.shape[0]\n    <span style=\'color: red\'># torch.Size([3623, 4]) 3623个非0唯一voxel；torch.Size([7732])属于哪个voxle， torch.Size([3623])告诉哪个voxel有多少个</span>\n    centroid_voxel_idxs, unique_idxs, labels_count = voxel_idxs.unique(dim=0, return_inverse=True, return_counts=True)  \n    unique_idxs = unique_idxs.view(unique_idxs.size(0), 1).expand(-1, points.size(-1)) <span style=\'color: red\'># torch.Size([7732, 5]) unique_idxs[0]=[0, 0, 0, 0, 0]</span>\n    <span style=\'color: red\'># Scatter add points based on unique voxel idxs</span>\n    if num_points_in_voxel is not None:\n        centroids = torch.zeros((centroid_voxel_idxs.shape[0], points.shape[-1]), device=points.device, dtype=torch.float).scatter_add_(0, unique_idxs, points * num_points_in_voxel.unsqueeze(-1))\n        num_points_in_centroids = torch.zeros((centroid_voxel_idxs.shape[0]), device=points.device, dtype=torch.int64).scatter_add_(0, unique_idxs[:,0], num_points_in_voxel)   <span style=\'color: red\'># torch.Size([7732])->torch.Size([3623])</span>\n        centroids = centroids / num_points_in_centroids.float().unsqueeze(-1)\n    else:\n        ......\n    return centroids, centroid_voxel_idxs, labels_count       <span style=\'color: red\'># 每个大voxel所有点云求平均，对应的B,Z,Y,Z; 每个大voxel的点云数量</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_nonempty_voxel_feature_indices(voxel_indices, x_conv):\n    x_conv_hash_table = <span style=\'color: green;font-weight: bold;\'>get_voxel_indices_to_voxel_list_index</span>(x_conv)       <span style=\'color: red\'># [11, 400, 352]-->torch.Size([1, 11, 400, 352])</span>\n    <span style=\'color: red\'># Get corresponding voxel feature indices</span>\n    overlapping_voxel_feature_indices = torch.zeros(voxel_indices.shape[0], device=voxel_indices.device, dtype=torch.int64) <span style=\'color: red\'># torch.Size([7732])</span>\n    overlapping_voxel_feature_indices = x_conv_hash_table[voxel_indices[:,0], voxel_indices[:,1],\n                                                          voxel_indices[:,2], voxel_indices[:,3]]   <span style=\'color: red\'># BZYX? torch.Size([7732])值从1->7732</span>\n    <span style=\'color: red\'># Remove empty voxels features</span>\n    overlapping_voxel_feature_nonempty_mask = overlapping_voxel_feature_indices != 0      <span style=\'color: red\'># torch.Size([7732])</span>\n    <span style=\'color: red\'># Filter and shift indices back by -1   没看懂，不能直接返回torch.arange(1, x_conv_indices.shape[0]+1, device=x_conv_indices.device)？因为有空的体素</span>\n    overlapping_voxel_feature_indices_nonempty = overlapping_voxel_feature_indices[overlapping_voxel_feature_nonempty_mask] - 1\n    return overlapping_voxel_feature_indices_nonempty, overlapping_voxel_feature_nonempty_mask     <span style=\'color: red\'># torch.Size([7512]);torch.Size([7732])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def get_voxel_indices_to_voxel_list_index(x_conv):\n    x_conv_indices = x_conv.indices      <span style=\'color: red\'># [11, 400, 352]->torch.Size([21177, 4]) [:,0]的范围(0-10),[:,1]的范围(1-10),[:,2]的范围(179-399),[:,3]的范围(11-351)</span>\n    <span style=\'color: red\'># Note that we need to offset the values by 1 since the dense representation has "0" to indicate an empty location</span>\n    x_conv_values = torch.arange(1, x_conv_indices.shape[0]+1, device=x_conv_indices.device)      <span style=\'color: red\'># torch.Size([21177])从1-21177</span>\n    x_conv_shape = [x_conv.batch_size] + list(x_conv.spatial_shape)                               <span style=\'color: red\'># [1, 11, 400, 352]</span>\n    <span style=\'color: red\'># x_conv_indices.T->(4,21177)  x_conv_values->(21177)    x_conv_shape=[1, 11, 400, 352]  存放的索引，存放的值，要生成稀疏张量的shape</span>\n    <span style=\'color: red\'># TODO: Need to convert to_dense representation. Can we use rule table instead? Can try scatter_nd in spconv too</span>\n    x_conv_hash_table = torch.sparse_coo_tensor(x_conv_indices.T, x_conv_values, x_conv_shape, device=x_conv_indices.device).to_dense()   <span style=\'color: red\'># torch.Size([1, 11, 400, 352])</span>\n    return x_conv_hash_table\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/roi_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class RoIHeadTemplate(nn.Module):\n    def proposal_layer(self, batch_dict, nms_config):\n        if batch_dict.get(\'rois\', None) is not None:\n            return batch_dict  \n        batch_size = batch_dict[\'batch_size\']               <span style=\'color: red\'># 1</span>\n        batch_box_preds = batch_dict[\'batch_box_preds\']     <span style=\'color: red\'># torch.Size([1, 211200, 7])  第一阶段生成的预测box，是真的box</span>\n        batch_cls_preds = batch_dict[\'batch_cls_preds\']     <span style=\'color: red\'># torch.Size([1, 211200, 3])  第一阶段模型预测的类别</span>\n        rois = batch_box_preds.new_zeros((batch_size, nms_config.NMS_POST_MAXSIZE, batch_box_preds.shape[-1]))     <span style=\'color: red\'># torch.Size([1, 512, 7])</span>\n        roi_scores = batch_box_preds.new_zeros((batch_size, nms_config.NMS_POST_MAXSIZE))                          <span style=\'color: red\'># torch.Size([1, 512])</span>\n        roi_labels = batch_box_preds.new_zeros((batch_size, nms_config.NMS_POST_MAXSIZE), dtype=torch.long)        <span style=\'color: red\'># torch.Size([1, 512])</span>\n        for index in range(batch_size):                    <span style=\'color: red\'># 1</span>\n            if batch_dict.get(\'batch_index\', None) is not None:\n                assert batch_cls_preds.shape.__len__() == 2\n                batch_mask = (batch_dict[\'batch_index\'] == index)\n            else:\n                assert batch_dict[\'batch_cls_preds\'].shape.__len__() == 3\n                batch_mask = index\n            box_preds = batch_box_preds[batch_mask]       <span style=\'color: red\'># torch.Size([211200, 7])</span>\n            cls_preds = batch_cls_preds[batch_mask]       <span style=\'color: red\'># torch.Size([211200, 3])</span>\n            cur_roi_scores, cur_roi_labels = torch.max(cls_preds, dim=1)  <span style=\'color: red\'># torch.Size([211200]；3各类别，值范围为0->2</span>\n            if nms_config.MULTI_CLASSES_NMS:\n                raise NotImplementedError\n            else:\n                selected, selected_scores = class_agnostic_nms(                       <span style=\'color: red\'># 对box无视类别做nms</span>\n                    box_scores=cur_roi_scores, box_preds=box_preds, nms_config=nms_config\n                )\n            rois[index, :len(selected), :] = box_preds[selected]\n            roi_scores[index, :len(selected)] = cur_roi_scores[selected]\n            roi_labels[index, :len(selected)] = cur_roi_labels[selected]\n        batch_dict[\'rois\'] = rois                         <span style=\'color: red\'># torch.Size([1, 512, 7])</span>\n        batch_dict[\'roi_scores\'] = roi_scores             <span style=\'color: red\'># torch.Size([1, 512])</span>\n        batch_dict[\'roi_labels\'] = roi_labels + 1         <span style=\'color: red\'># torch.Size([1, 512])</span>\n        batch_dict[\'has_class_labels\'] = True if batch_cls_preds.shape[-1] > 1 else False  <span style=\'color: red\'># True，有类别预测</span>\n        batch_dict.pop(\'batch_index\', None)\n        return batch_dict\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/roi_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class RoIHeadTemplate(nn.Module):\n    def assign_targets(self, batch_dict):\n        batch_size = batch_dict[\'batch_size\']\n        with torch.no_grad():\n            targets_dict = self.proposal_target_layer.<span style=\'color: green;font-weight: bold;\'>forward</span>(batch_dict)       <span style=\'color: red\'># pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</span>\n        <span style=\'color: red\'># [(\'rois\', torch.Size([1, 128, 7])), (\'gt_of_rois\', torch.Size([1, 128, 8])), (\'gt_iou_of_rois\', torch.Size([1, 128])), (\'roi_scores\', torch.Size([1, 128])), (\'roi_labels\', torch.Size([1, 128])), (\'reg_valid_mask\', torch.Size([1, 128])), (\'rcnn_cls_labels\', torch.Size([1, 128]))]</span>\n        rois = targets_dict[\'rois\']  <span style=\'color: red\'># (B, N, 7 + C)                           </span>\n        gt_of_rois = targets_dict[\'gt_of_rois\']  <span style=\'color: red\'># (B, N, 7 + C + 1)           </span>\n        targets_dict[\'gt_of_rois_src\'] = gt_of_rois.clone().detach()            <span style=\'color: red\'># torch.Size([1, 128, 8])</span>\n        <span style=\'color: red\'># canonical transformation</span>\n        roi_center = rois[:, :, 0:3]                                  <span style=\'color: red\'># torch.Size([1, 128, 3])</span>\n        roi_ry = rois[:, :, 6] % (2 * np.pi)                          <span style=\'color: red\'># torch.Size([1, 128])</span>\n        gt_of_rois[:, :, 0:3] = gt_of_rois[:, :, 0:3] - roi_center    <span style=\'color: red\'># 匹配到的gt-预测的gt</span>\n        gt_of_rois[:, :, 6] = gt_of_rois[:, :, 6] - roi_ry\n        <span style=\'color: red\'># transfer LiDAR coords to local coords    pcdet/utils/common_utils.py   torch.Size([1, 128, 8])3Dbox就与角度无关了</span>\n        gt_of_rois = common_utils.<span style=\'color: green;font-weight: bold;\'>rotate_points_along_z</span>(\n            points=gt_of_rois.view(-1, 1, gt_of_rois.shape[-1]), angle=-roi_ry.view(-1)\n        ).view(batch_size, -1, gt_of_rois.shape[-1])\n        <span style=\'color: red\'># flip orientation if rois have opposite orientation</span>\n        heading_label = gt_of_rois[:, :, 6] % (2 * np.pi)  <span style=\'color: red\'># 0 ~ 2pi</span>\n        opposite_flag = (heading_label > np.pi * 0.5) & (heading_label < np.pi * 1.5)         <span style=\'color: red\'># 角度在pi/2->3pi/2</span>\n        heading_label[opposite_flag] = (heading_label[opposite_flag] + np.pi) % (2 * np.pi)  <span style=\'color: red\'># (0 ~ pi/2, 3pi/2 ~ 2pi)</span>\n        flag = heading_label > np.pi\n        heading_label[flag] = heading_label[flag] - np.pi * 2  <span style=\'color: red\'># (-pi/2, pi/2)  后面部分变成了(-pi/2,0)</span>\n        heading_label = torch.clamp(heading_label, min=-np.pi / 2, max=np.pi / 2)\n        gt_of_rois[:, :, 6] = heading_label\n        targets_dict[\'gt_of_rois\'] = gt_of_rois      \n        return targets_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><font size="0"><pre class="language-python"><code class="language-python">class ProposalTargetLayer(nn.Module):\n    def forward(self, batch_dict):\n        batch_rois, batch_gt_of_rois, batch_roi_ious, batch_roi_scores, batch_roi_labels = self.<span style=\'color: green;font-weight: bold;\'>sample_rois_for_rcnn</span>(batch_dict=batch_dict)\n        <span style=\'color: red\'># regression valid mask</span>\n        reg_valid_mask = (batch_roi_ious > self.roi_sampler_cfg.REG_FG_THRESH).long()        <span style=\'color: red\'># roi匹配到0.55的才算有用的torch.Size([1, 128])+0.55->torch.Size([1, 128])</span>\n        <span style=\'color: red\'># classification label</span>\n        if self.roi_sampler_cfg.CLS_SCORE_TYPE == \'cls\':\n            batch_cls_labels = (batch_roi_ious > self.roi_sampler_cfg.CLS_FG_THRESH).long()\n            ignore_mask = (batch_roi_ious > self.roi_sampler_cfg.CLS_BG_THRESH) & (batch_roi_ious < self.roi_sampler_cfg.CLS_FG_THRESH)\n            batch_cls_labels[ignore_mask > 0] = -1\n        elif self.roi_sampler_cfg.CLS_SCORE_TYPE == \'roi_iou\':               <span style=\'color: red\'># \'roi_iou\'</span>\n            iou_bg_thresh = self.roi_sampler_cfg.CLS_BG_THRESH               <span style=\'color: red\'># 0.25</span>\n            iou_fg_thresh = self.roi_sampler_cfg.CLS_FG_THRESH               <span style=\'color: red\'># 0.75</span>\n            fg_mask = batch_roi_ious > iou_fg_thresh                         <span style=\'color: red\'># torch.Size([1, 128])</span>\n            bg_mask = batch_roi_ious < iou_bg_thresh\n            interval_mask = (fg_mask == 0) & (bg_mask == 0)\n            batch_cls_labels = (fg_mask > 0).float()                         <span style=\'color: red\'># torch.Size([1, 128])  处于两者中间的label搞到0-1之间</span>\n            batch_cls_labels[interval_mask] = (batch_roi_ious[interval_mask] - iou_bg_thresh) / (iou_fg_thresh - iou_bg_thresh)\n        else:\n            raise NotImplementedError\n        targets_dict = {\'rois\': batch_rois, \'gt_of_rois\': batch_gt_of_rois, \'gt_iou_of_rois\': batch_roi_ious,\n                        \'roi_scores\': batch_roi_scores, \'roi_labels\': batch_roi_labels,\n                        \'reg_valid_mask\': reg_valid_mask,            <span style=\'color: red\'># roi这里只有正负样本</span>\n                        \'rcnn_cls_labels\': batch_cls_labels}\n        return targets_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><font size="0"><pre class="language-python"><code class="language-python">class ProposalTargetLayer(nn.Module):\n    def sample_rois_for_rcnn(self, batch_dict):\n        batch_size = batch_dict[\'batch_size\']      <span style=\'color: red\'># 1</span>\n        rois = batch_dict[\'rois\']                  <span style=\'color: red\'># torch.Size([1, 512, 7])</span>\n        roi_scores = batch_dict[\'roi_scores\']      <span style=\'color: red\'># torch.Size([1, 512])</span>\n        roi_labels = batch_dict[\'roi_labels\']      <span style=\'color: red\'># torch.Size([1, 512])</span>\n        gt_boxes = batch_dict[\'gt_boxes\']          <span style=\'color: red\'># torch.Size([1, 39, 8]) 为啥是8，最后维度为label</span>\n        code_size = rois.shape[-1]\n        batch_rois = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE, code_size)               <span style=\'color: red\'># torch.Size([1, 128, 7])</span>\n        batch_gt_of_rois = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE, code_size + 1)     <span style=\'color: red\'># torch.Size([1, 128, 8])</span>\n        batch_roi_ious = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE)                      <span style=\'color: red\'># torch.Size([1, 128])</span>\n        batch_roi_scores = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE)                    <span style=\'color: red\'># torch.Size([1, 128])</span>\n        batch_roi_labels = rois.new_zeros((batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE), dtype=torch.long)  <span style=\'color: red\'># torch.Size([1, 128])</span>\n \n        for index in range(batch_size):\n            cur_roi, cur_gt, cur_roi_labels, cur_roi_scores = \\\n                rois[index], gt_boxes[index], roi_labels[index], roi_scores[index]       <span style=\'color: red\'># torch.Size([512, 7])；torch.Size([39, 8])；torch.Size([512])范围1-3；torch.Size([512])</span>\n            k = cur_gt.__len__() - 1\n            while k >= 0 and cur_gt[k].sum() == 0:\n                k -= 1\n            cur_gt = cur_gt[:k + 1]\n            cur_gt = cur_gt.new_zeros((1, cur_gt.shape[1])) if len(cur_gt) == 0 else cur_gt\n            if self.roi_sampler_cfg.get(\'SAMPLE_ROI_BY_EACH_CLASS\', False):         <span style=\'color: red\'># True</span>\n                max_overlaps, gt_assignment = self.<span style=\'color: green;font-weight: bold;\'>get_max_iou_with_same_class</span>(rois=cur_roi, roi_labels=cur_roi_labels,gt_boxes=cur_gt[:, 0:7], gt_labels=cur_gt[:, -1].long())\n            else:\n                iou3d = iou3d_nms_utils.boxes_iou3d_gpu(cur_roi, cur_gt[:, 0:7])  <span style=\'color: red\'># (M, N)</span>\n                max_overlaps, gt_assignment = torch.max(iou3d, dim=1)\n            sampled_inds = self.<span style=\'color: green;font-weight: bold;\'>subsample_rois</span>(max_overlaps=max_overlaps)        <span style=\'color: red\'># torch.Size([128])</span>\n            batch_rois[index] = cur_roi[sampled_inds]\n            batch_roi_labels[index] = cur_roi_labels[sampled_inds]\n            batch_roi_ious[index] = max_overlaps[sampled_inds]\n            batch_roi_scores[index] = cur_roi_scores[sampled_inds]\n            batch_gt_of_rois[index] = cur_gt[gt_assignment[sampled_inds]]        <span style=\'color: red\'># 对应采样到的gt</span>\n        return batch_rois, batch_gt_of_rois, batch_roi_ious, batch_roi_scores, batch_roi_labels      <span style=\'color: red\'># torch.Size([1, 128, 7])；torch.Size([1, 128, 8])；torch.Size([1, 128])；torch.Size([1, 128])；torch.Size([1, 128])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><font size="0"><pre class="language-python"><code class="language-python">class ProposalTargetLayer(nn.Module):\n    max_overlaps = rois.new_zeros(rois.shape[0])               <span style=\'color: red\'># torch.Size([512])</span>\n    gt_assignment = roi_labels.new_zeros(roi_labels.shape[0])  <span style=\'color: red\'># torch.Size([512])</span>\n    for k in range(gt_labels.min().item(), gt_labels.max().item() + 1):\n        roi_mask = (roi_labels == k)\n        gt_mask = (gt_labels == k)\n        if roi_mask.sum() > 0 and gt_mask.sum() > 0:\n            cur_roi = rois[roi_mask]                 <span style=\'color: red\'># torch.Size([128, 7])</span>\n            cur_gt = gt_boxes[gt_mask]               <span style=\'color: red\'># torch.Size([11, 7])</span>\n            original_gt_assignment = gt_mask.nonzero().view(-1)                     <span style=\'color: red\'># torch.Size([11])</span>\n            iou3d = iou3d_nms_utils.boxes_iou3d_gpu(cur_roi[:, :7], cur_gt[:, :7])  <span style=\'color: red\'># (M, N) torch.Size([128, 11])</span>\n            cur_max_overlaps, cur_gt_assignment = torch.max(iou3d, dim=1)           <span style=\'color: red\'># torch.Size([128])；torch.Size([128]) roi匹配到的iou值和对应的GT</span>\n            max_overlaps[roi_mask] = cur_max_overlaps\n            gt_assignment[roi_mask] = original_gt_assignment[cur_gt_assignment]\n    return max_overlaps, gt_assignment\n</code></pre></font>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><font size="0"><pre class="language-python"><code class="language-python">class ProposalTargetLayer(nn.Module):\n    def subsample_rois(self, max_overlaps):\n        <span style=\'color: red\'># sample fg, easy_bg, hard_bg   </span>\n        fg_rois_per_image = int(np.round(self.roi_sampler_cfg.FG_RATIO * self.roi_sampler_cfg.ROI_PER_IMAGE))    <span style=\'color: red\'># 0.5*128=64个作为前景？ </span>\n        fg_thresh = min(self.roi_sampler_cfg.REG_FG_THRESH, self.roi_sampler_cfg.CLS_FG_THRESH)                  <span style=\'color: red\'># min(0.55,0.75)=0.55</span>\n        fg_inds = ((max_overlaps >= fg_thresh)).nonzero().view(-1)                                       <span style=\'color: red\'># iou>0.55的0</span>\n        easy_bg_inds = ((max_overlaps < self.roi_sampler_cfg.CLS_BG_THRESH_LO)).nonzero().view(-1)       <span style=\'color: red\'># iou在0->0.1之间的     torch.Size([488])</span>\n        hard_bg_inds = ((max_overlaps < self.roi_sampler_cfg.REG_FG_THRESH) &                            <span style=\'color: red\'># iou在0.1->0.55之间的  torch.Size([24])</span>\n                (max_overlaps >= self.roi_sampler_cfg.CLS_BG_THRESH_LO)).nonzero().view(-1)\n        fg_num_rois = fg_inds.numel()\n        bg_num_rois = hard_bg_inds.numel() + easy_bg_inds.numel()\n        if fg_num_rois > 0 and bg_num_rois > 0:                                     <span style=\'color: red\'># 既有前景，又有背景</span>\n            <span style=\'color: red\'># sampling fg               </span>\n            fg_rois_per_this_image = min(fg_rois_per_image, fg_num_rois)            <span style=\'color: red\'># 64，0 -0，前景最多64个</span>\n            rand_num = torch.from_numpy(np.random.permutation(fg_num_rois)).type_as(max_overlaps).long()   <span style=\'color: red\'># 采样前景</span>\n            fg_inds = fg_inds[rand_num[:fg_rois_per_this_image]]\n            <span style=\'color: red\'># sampling bg</span>\n            bg_rois_per_this_image = self.roi_sampler_cfg.ROI_PER_IMAGE - fg_rois_per_this_image     <span style=\'color: red\'># 采样背景</span>\n            bg_inds = self.sample_bg_inds(hard_bg_inds, easy_bg_inds, bg_rois_per_this_image, self.roi_sampler_cfg.HARD_BG_RATIO)\n        elif fg_num_rois > 0 and bg_num_rois == 0:\n            <span style=\'color: red\'># sampling fg 只有前景</span>\n            rand_num = np.floor(np.random.rand(self.roi_sampler_cfg.ROI_PER_IMAGE) * fg_num_rois)\n            rand_num = torch.from_numpy(rand_num).type_as(max_overlaps).long()\n            fg_inds = fg_inds[rand_num]\n            bg_inds = fg_inds[fg_inds < 0] <span style=\'color: red\'># yield empty tensor</span>\n        elif bg_num_rois > 0 and fg_num_rois == 0:\n            <span style=\'color: red\'># sampling bg </span>\n            bg_rois_per_this_image = self.roi_sampler_cfg.ROI_PER_IMAGE\n            bg_inds = self.sample_bg_inds(hard_bg_inds, easy_bg_inds, bg_rois_per_this_image, self.roi_sampler_cfg.HARD_BG_RATIO)\n        else:\n            print(\'maxoverlaps:(min=%f, max=%f)\' % (max_overlaps.min().item(), max_overlaps.max().item()))\n            print(\'ERROR: FG=%d, BG=%d\' % (fg_num_rois, bg_num_rois))\n            raise NotImplementedError\n        sampled_inds = torch.cat((fg_inds, bg_inds), dim=0)          <span style=\'color: red\'># torch.Size([128])前景加上背景128个</span>\n        return sampled_inds\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/common_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def rotate_points_along_z(points, angle):\n    points, is_numpy = check_numpy_to_torch(points)\n    angle, _ = check_numpy_to_torch(angle)\n    cosa = torch.cos(angle)\n    sina = torch.sin(angle)\n    zeros = angle.new_zeros(points.shape[0])\n    ones = angle.new_ones(points.shape[0])\n    rot_matrix = torch.stack((\n        cosa,  sina, zeros,\n        -sina, cosa, zeros,\n        zeros, zeros, ones\n    ), dim=1).view(-1, 3, 3).float()\n    points_rot = torch.matmul(points[:, :, 0:3], rot_matrix)\n    points_rot = torch.cat((points_rot, points[:, :, 3:]), dim=-1)\n    return points_rot.numpy() if is_numpy else points_rot\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelAggregationHead(RoIHeadTemplate):\n    def roi_grid_pool(self, batch_dict):\n        batch_size = batch_dict[\'batch_size\']\n        batch_rois = batch_dict[\'rois\']\n        <span style=\'color: red\'># 128个roi，每个roi里面给6x6x6的小格子  这里得到128个roi中6x6x6的每个小格子的中心点  ；以及没有旋转和中心大为原点的原始小格子中心点</span>\n        global_roi_grid_points, local_roi_grid_points = self.<span style=\'color: green;font-weight: bold;\'>get_global_grid_points_of_roi</span>(   <span style=\'color: red\'># torch.Size([128, 216, 3]) torch.Size([128, 216, 3])</span>\n            batch_dict, grid_size=self.model_cfg.ROI_GRID_POOL.GRID_SIZE\n        )  <span style=\'color: red\'># (BxN, 6x6x6, 3)</span>\n        global_roi_grid_points = global_roi_grid_points.view(batch_size, -1, 3)  <span style=\'color: red\'># (B, Nx6x6x6, 3)  torch.Size([1, 27648, 3])</span>\n        new_xyz = global_roi_grid_points.view(-1, 3)                             <span style=\'color: red\'># torch.Size([27648, 3])</span>\n \n        pooled_features_list = []\n        ball_idxs_list = []\n        for k, src_name in enumerate(self.pool_cfg.FEATURE_LOCATIONS):         <span style=\'color: red\'># [\'x_conv3\', \'x_conv4\']</span>\n            point_coords = batch_dict[\'point_coords\'][src_name]                <span style=\'color: red\'># torch.Size([7512, 4])</span>\n            point_features = batch_dict[\'point_features\'][src_name]            <span style=\'color: red\'># torch.Size([7512, 64])</span>\n            pool_layer = self.roi_grid_pool_layers[k]                          <span style=\'color: red\'># StackSAModuleMSGAttention</span>\n            xyz = point_coords[:, 1:4]                               <span style=\'color: red\'># torch.Size([7512, 3])</span>\n            xyz_batch_cnt = xyz.new_zeros(batch_size).int()          <span style=\'color: red\'># torch.Size([1])   统计该batch有多少个rois->tensor([7512])</span>\n            batch_idx = point_coords[:, 0]\n            for k in range(batch_size):\n                xyz_batch_cnt[k] = (batch_idx == k).sum()\n            <span style=\'color: red\'># 体素特征层中采样，采样的是以网格点为中心，半径为r的球形区域中的体素点质心，然后基于这些体素点质心得到新的点特征（包括体素点质心的特征、体素点质心与网格点的相对距离以及使用KDE生成的当前网格点下对于体素点质心的密度估计</span>\n            new_xyz_batch_cnt = xyz.new_zeros(batch_size).int().fill_(global_roi_grid_points.shape[1]) <span style=\'color: red\'># tensor([27648])长度为batch的值</span>\n            pool_output = pool_layer(                     <span style=\'color: red\'># [torch.Size([27648, 3]), torch.Size([27648, 64])=》pooled_features, torch.Size([27648, 32])]=》ball_idxs</span>\n                xyz=xyz.contiguous(),                     <span style=\'color: red\'># torch.Size([7512, 3]) </span>\n                xyz_batch_cnt=xyz_batch_cnt,\n                new_xyz=new_xyz,                          <span style=\'color: red\'># torch.Size([27648, 3])</span>\n                new_xyz_batch_cnt=new_xyz_batch_cnt,\n                features=point_features.contiguous(),     <span style=\'color: red\'># torch.Size([7512, 64])</span>\n            )  <span style=\'color: red\'># (M1 + M2 ..., C)</span>\n            if self.pool_cfg.get(\'ATTENTION\', {}).get(\'ENABLED\'):\n                _, pooled_features, ball_idxs = pool_output   <span style=\'color: red\'># torch.Size([27648, 64]), torch.Size([27648, 32])</span>\n            else:\n                _, pooled_features = pool_output\n            pooled_features = pooled_features.view(               <span style=\'color: red\'># torch.Size([128, 216, 64])</span>\n                -1, self.model_cfg.ROI_GRID_POOL.GRID_SIZE ** 3,\n                pooled_features.shape[-1]\n            )  <span style=\'color: red\'># (BxN, 6x6x6, C)</span>\n            pooled_features_list.append(pooled_features)\n            if self.pool_cfg.get(\'ATTENTION\', {}).get(\'ENABLED\'):        <span style=\'color: red\'># True</span>\n                ball_idxs = ball_idxs.view(                              <span style=\'color: red\'># torch.Size([128, 216, 32])</span>\n                    -1, self.model_cfg.ROI_GRID_POOL.GRID_SIZE **3,\n                    ball_idxs.shape[-1]\n                )\n                ball_idxs_list.append(ball_idxs)\n        all_pooled_features = torch.cat(pooled_features_list, dim=-1)        <span style=\'color: red\'># torch.Size([128, 216, 128])</span>\n        if self.pool_cfg.get(\'ATTENTION\', {}).get(\'ENABLED\'):\n            all_ball_idxs = torch.cat(ball_idxs_list, dim=-1)                <span style=\'color: red\'># torch.Size([128, 216, 64])</span>\n        else:\n            all_ball_idxs = []\n        return all_pooled_features, global_roi_grid_points, local_roi_grid_points, all_ball_idxs  <span style=\'color: red\'># torch.Size([128, 216, 128]),torch.Size([1, 27648, 3]),torch.Size([128, 216, 3]),torch.Size([128, 216, 64])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelAggregationHead(RoIHeadTemplate):\n    def get_global_grid_points_of_roi(self, batch_dict, grid_size):   <span style=\'color: red\'># 6</span>\n        rois = batch_dict[\'rois\']              <span style=\'color: red\'># torch.Size([1, 128, 7])预测的roi</span>\n        rois = rois.view(-1, rois.shape[-1])   <span style=\'color: red\'># torch.Size([128, 7])</span>\n        batch_size_rcnn = rois.shape[0]        <span style=\'color: red\'># 128</span>\n        local_roi_grid_points = self.<span style=\'color: green;font-weight: bold;\'>get_dense_grid_points</span>(rois, batch_size_rcnn, grid_size)  <span style=\'color: red\'># torch.Size([128, 7])+128+6->(B, 6x6x6, 3)</span>\n        global_roi_grid_points = common_utils.<span style=\'color: green;font-weight: bold;\'>rotate_points_along_z</span>(         <span style=\'color: red\'># torch.Size([128, 216, 3]) 所有的点沿着角度旋转</span>\n            local_roi_grid_points.clone(), rois[:, 6]\n        ).squeeze(dim=1)\n        global_center = rois[:, 0:3].clone()\n        global_roi_grid_points += global_center.unsqueeze(dim=1)     <span style=\'color: red\'># 再加上中心点  </span>\n        return global_roi_grid_points, local_roi_grid_points\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelAggregationHead(RoIHeadTemplate):\n    def get_dense_grid_points(rois, batch_size_rcnn, grid_size):\n        faked_features = rois.new_ones((grid_size, grid_size, grid_size))       <span style=\'color: red\'># torch.Size([6, 6, 6])</span>\n        dense_idx = faked_features.nonzero()  <span style=\'color: red\'># (N, 3) [x_idx, y_idx, z_idx]   </span>\n        dense_idx = dense_idx.repeat(batch_size_rcnn, 1, 1).float()             <span style=\'color: red\'># (B, 6x6x6, 3)</span>\n        <span style=\'color: red\'># torch.Size([128, 3])长宽高将设对一个(1,2,3)的做计算：roi_grid_points[0]=(-0.4167,-0.8333,-1.25) roi_grid_points[-1]=(0.4167,0.8333,1.25) </span>\n        local_roi_size = rois.view(batch_size_rcnn, -1)[:, 3:6]                 \n        roi_grid_points = (dense_idx + 0.5) / grid_size * local_roi_size.unsqueeze(dim=1) - (local_roi_size.unsqueeze(dim=1) / 2)  <span style=\'color: red\'># (B, 6x6x6, 3) </span>\n        return roi_grid_points\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/common_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def rotate_points_along_z(points, angle):\n    points, is_numpy = check_numpy_to_torch(points)\n    angle, _ = check_numpy_to_torch(angle)\n    cosa = torch.cos(angle)\n    sina = torch.sin(angle)\n    zeros = angle.new_zeros(points.shape[0])\n    ones = angle.new_ones(points.shape[0])\n    rot_matrix = torch.stack((\n        cosa,  sina, zeros,\n        -sina, cosa, zeros,\n        zeros, zeros, ones\n    ), dim=1).view(-1, 3, 3).float()\n    points_rot = torch.matmul(points[:, :, 0:3], rot_matrix)\n    points_rot = torch.cat((points_rot, points[:, :, 3:]), dim=-1)\n    return points_rot.numpy() if is_numpy else points_rot\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelAggregationHead(RoIHeadTemplate):\n    def get_positional_input(self, points, rois, local_roi_grid_points):     <span style=\'color: red\'># torch.Size([22969, 5]); torch.Size([1, 128, 7]); torch.Size([128, 216, 3])</span>\n        points_per_part = density_utils.<span style=\'color: green;font-weight: bold;\'>find_num_points_per_part_multi</span>(points,                                       <span style=\'color: red\'># torch.Size([1, 128, 6, 6, 6])</span>\n                                                                       rois,\n                                                                       self.model_cfg.ROI_GRID_POOL.GRID_SIZE,         <span style=\'color: red\'># 6</span>\n                                                                       self.pool_cfg.ATTENTION.MAX_NUM_BOXES,          <span style=\'color: red\'># 20</span>\n                                                                       return_centroid=self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == \'density_centroid\')\n        points_per_part_num_features = 1 if len(points_per_part.shape) <= 5 else points_per_part.shape[-1]          <span style=\'color: red\'># 1</span>\n        points_per_part = points_per_part.view(points_per_part.shape[0]*points_per_part.shape[1], -1, points_per_part_num_features).float()  <span style=\'color: red\'># torch.Size([128, 216, 1])</span>\n        <span style=\'color: red\'># First feature is density, other potential features are xyz</span>\n        points_per_part[..., 0] = torch.log10(points_per_part[..., 0] + 0.5) - (math.log10(0.5) if self.model_cfg.get(\'DENSITY_LOG_SHIFT\') else 0)\n        if self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == \'grid_points\':\n            positional_input = local_roi_grid_points\n        elif self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == \'density\':\n            positional_input = points_per_part\n        elif self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == \'density_grid_points\':\n            positional_input = torch.cat((local_roi_grid_points, points_per_part), dim=-1)  <span style=\'color: red\'># torch.Size([128, 216, 4])</span>\n        else:\n            positional_input = None\n        return positional_input\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/density_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def find_num_points_per_part_multi(batch_points, batch_boxes, grid_size, max_num_boxes, return_centroid=False): <span style=\'color: red\'># torch.Size([22969, 5]),torch.Size([1, 128, 7]),6,20,False</span>\n    batch_idx = batch_points[:, 0]\n    batch_points = batch_points[:, 1:4]\n    points_per_parts = []\n    for i in range(batch_boxes.shape[0]):\n        boxes = batch_boxes[i]                   <span style=\'color: red\'># torch.Size([128, 7])</span>\n        bs_mask = (batch_idx == i)               <span style=\'color: red\'># torch.Size([128, 7])</span>\n        points = batch_points[bs_mask]           <span style=\'color: red\'># torch.Size([22969, 3])</span>\n        box_idxs_of_pts = roiaware_pool3d_utils.<span style=\'color: green;font-weight: bold;\'>points_in_multi_boxes_gpu</span>(points.unsqueeze(0), boxes.unsqueeze(0), max_num_boxes).squeeze(0)  <span style=\'color: red\'># torch.Size([22969, 20])</span>\n        box_for_each_point = boxes[box_idxs_of_pts.long()]                 <span style=\'color: red\'># torch.Size([22969, 20, 7])</span>\n        xyz_local = points.unsqueeze(1) - box_for_each_point[..., 0:3]     <span style=\'color: red\'># torch.Size([22969, 20, 3])</span>\n        xyz_local_original_shape = xyz_local.shape\n        xyz_local = xyz_local.reshape(-1, 1, 3)                            <span style=\'color: red\'># torch.Size([459380, 1, 3])</span>\n        <span style=\'color: red\'># Flatten for rotating points           </span>\n        xyz_local = common_utils.<span style=\'color: green;font-weight: bold;\'>rotate_points_along_z</span>(\n            xyz_local, -box_for_each_point.reshape(-1, 7)[:, 6]\n        )\n        <span style=\'color: red\'># Change coordinate frame to corner instead of center of box</span>\n        xyz_local_corner = xyz_local.reshape(xyz_local_original_shape) + box_for_each_point[..., 3:6] / 2      <span style=\'color: red\'># torch.Size([22969, 20, 3])</span>\n        <span style=\'color: red\'># points_in_boxes_gpu gets points slightly outside of box, clamp values to make sure no out of index values</span>\n        xyz_local_grid = (xyz_local_corner / (box_for_each_point[..., 3:6] / grid_size))                       <span style=\'color: red\'># torch.Size([22969, 20, 3])</span>\n        points_out_of_range = ((xyz_local_grid < 0) | (xyz_local_grid >= grid_size) | (xyz_local_grid.isnan())).any(-1).flatten()   <span style=\'color: red\'># torch.Size([459380])=22969x20</span>\n        xyz_local_grid = torch.cat((box_idxs_of_pts.unsqueeze(-1),xyz_local_grid), dim=-1).long()              <span style=\'color: red\'># torch.Size([22969, 20, 4])</span>\n        xyz_local_grid = xyz_local_grid.reshape(-1, xyz_local_grid.shape[-1])      <span style=\'color: red\'># torch.Size([459380, 4])</span>\n        <span style=\'color: red\'># Filter based on valid box_idxs</span>\n        valid_points_mask = (xyz_local_grid[:, 0] != -1) & (~points_out_of_range)  <span style=\'color: red\'># torch.Size([459380])</span>\n        xyz_local_grid = xyz_local_grid[valid_points_mask]                         <span style=\'color: red\'># torch.Size([18946, 4])</span>\n        if return_centroid:\n            ......\n        else:\n            part_idxs, points_per_part = xyz_local_grid.unique(dim=0, return_counts=True)      <span style=\'color: red\'># torch.Size([4526, 4]);torch.Size([4526])</span>\n            <span style=\'color: red\'># Sometimes no points in boxes, usually in the first few iterations. Return empty tensor in that case</span>\n            if part_idxs.shape[0] == 0:\n                points_per_part_dense = torch.zeros((boxes.shape[0], grid_size, grid_size, grid_size), dtype=points_per_part.dtype, device=points.device)\n            else:\n                points_per_part_dense = torch.sparse_coo_tensor(part_idxs.T, points_per_part, size=(boxes.shape[0], grid_size, grid_size, grid_size)).to_dense()  <span style=\'color: red\'># torch.Size([128, 6, 6, 6])</span>\n        points_per_parts.append(points_per_part_dense)     <span style=\'color: red\'># [torch.Size([128, 6, 6, 6])]</span>\n    return torch.stack(points_per_parts)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def points_in_multi_boxes_gpu(points, boxes, max_num_boxes):\n    assert boxes.shape[0] == points.shape[0]\n    assert boxes.shape[2] == 7 and points.shape[2] == 3\n    batch_size, num_points, _ = points.shape       <span style=\'color: red\'># 1,22969</span>\n    box_idxs_of_pts = points.new_zeros((batch_size, num_points, max_num_boxes), dtype=torch.int).fill_(-1)   <span style=\'color: red\'># (1,22969,20)</span>\n    roiaware_pool3d_cuda.points_in_multi_boxes_gpu(boxes.contiguous(), points.contiguous(), box_idxs_of_pts, max_num_boxes)\n    return box_idxs_of_pts\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/attention_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">class TransformerEncoder(nn.Module):\n    def forward(self, point_features, positional_input, src_key_padding_mask=None): <span style=\'color: red\'># torch.Size([128, 216, 128]),torch.Size([128, 216, 4]),torch.Size([128, 216])</span>\n        <span style=\'color: red\'># Clone point features to prevent mutating input arguments</span>\n        attended_features = torch.clone(point_features)\n        if src_key_padding_mask is not None:\n            empty_rois_mask = src_key_padding_mask.all(-1)                              <span style=\'color: red\'># torch.Size([128])</span>\n            attended_features_filtered = attended_features[~empty_rois_mask]            <span style=\'color: red\'># torch.Size([128, 216, 128])</span>\n            if self.pos_encoder is not None:                                            <span style=\'color: red\'># FeedForwardPositionalEncoding</span>\n                src_key_padding_mask_filtered = src_key_padding_mask[~empty_rois_mask]  <span style=\'color: red\'># torch.Size([128, 216])</span>\n                attended_features_filtered[~src_key_padding_mask_filtered] = self.pos_encoder(attended_features_filtered,\n                                                                                              positional_input[~empty_rois_mask] if positional_input is not None else None)[~src_key_padding_mask_filtered]\n            <span style=\'color: red\'># (b, xyz, f) -> (xyz, b, f)</span>\n            attended_features_filtered = attended_features_filtered.permute(1, 0, 2)    <span style=\'color: red\'># torch.Size([128, 216, 128])->torch.Size([216, 128, 128])</span>\n            <span style=\'color: red\'># (xyz, b, f) -> (b, xyz, f)</span>\n            attended_features[~empty_rois_mask] = self.transformer_encoder(attended_features_filtered,\n                                                                           src_key_padding_mask=src_key_padding_mask[~empty_rois_mask]).permute(1, 0, 2).contiguous()\n        else:\n            ......\n        return attended_features\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/roi_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class RoIHeadTemplate(nn.Module):\n    def generate_predicted_boxes(self, batch_size, rois, cls_preds, box_preds):  <span style=\'color: red\'># 1,torch.Size([1, 128, 7]),torch.Size([1, 128, 7]),None,torch.Size([128, 7])</span>\n        code_size = self.box_coder.code_size    <span style=\'color: red\'># 7</span>\n        <span style=\'color: red\'># batch_cls_preds: (B, N, num_class or 1)</span>\n        if cls_preds is None:\n            batch_cls_preds = None\n        else:\n            batch_cls_preds = cls_preds.view(batch_size, -1, cls_preds.shape[-1])\n        batch_box_preds = box_preds.view(batch_size, -1, code_size)         <span style=\'color: red\'># torch.Size([1, 128, 7])</span>\n        roi_ry = rois[:, :, 6].view(-1)                     <span style=\'color: red\'># torch.Size([128])</span>\n        roi_xyz = rois[:, :, 0:3].view(-1, 3)               <span style=\'color: red\'># torch.Size([128,7])</span>\n        local_rois = rois.clone().detach()\n        local_rois[:, :, 0:3] = 0\n        batch_box_preds = self.box_coder.decode_torch(batch_box_preds, local_rois).view(-1, code_size)  <span style=\'color: red\'># torch.Size([128, 7])</span>\n        batch_box_preds = common_utils.rotate_points_along_z(batch_box_preds.unsqueeze(dim=1), roi_ry).squeeze(dim=1)\n        batch_box_preds[:, 0:3] += roi_xyz                 <span style=\'color: red\'># torch.Size([128, 7])</span>\n        batch_box_preds = batch_box_preds.view(batch_size, -1, code_size)\n        return batch_cls_preds, batch_box_preds            <span style=\'color: red\'># None,torch.Size([1,128, 7])</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/density_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def find_num_points_per_part_multi(batch_points, batch_boxes, grid_size, max_num_boxes, return_centroid=False): <span style=\'color: red\'># torch.Size([22969, 5]),torch.Size([1, 128, 7]),1,20,False</span>\n    batch_idx = batch_points[:, 0]\n    batch_points = batch_points[:, 1:4]\n    points_per_parts = []\n    for i in range(batch_boxes.shape[0]):\n        boxes = batch_boxes[i]                   <span style=\'color: red\'># torch.Size([128, 7])</span>\n        bs_mask = (batch_idx == i)               <span style=\'color: red\'># torch.Size([22969])</span>\n        points = batch_points[bs_mask]           <span style=\'color: red\'># torch.Size([22969, 3])</span>\n        box_idxs_of_pts = roiaware_pool3d_utils.<span style=\'color: green;font-weight: bold;\'>points_in_multi_boxes_gpu</span>(points.unsqueeze(0), boxes.unsqueeze(0), max_num_boxes).squeeze(0)  <span style=\'color: red\'># torch.Size([22969, 20])  22969最多在20个box里面，这里记录box的索引</span>\n        box_for_each_point = boxes[box_idxs_of_pts.long()]                 <span style=\'color: red\'># torch.Size([22969, 20, 7])       就是每个点给其配20个box</span>\n        xyz_local = points.unsqueeze(1) - box_for_each_point[..., 0:3]     <span style=\'color: red\'># torch.Size([22969, 20, 3])</span>\n        xyz_local_original_shape = xyz_local.shape\n        xyz_local = xyz_local.reshape(-1, 1, 3)                            <span style=\'color: red\'># torch.Size([459380, 1, 3])       以box为中心的点</span>\n        <span style=\'color: red\'># Flatten for rotating points           </span>\n        xyz_local = common_utils.rotate_points_along_z(\n            xyz_local, -box_for_each_point.reshape(-1, 7)[:, 6]\n        )\n        <span style=\'color: red\'># Change coordinate frame to corner instead of center of box</span>\n        xyz_local_corner = xyz_local.reshape(xyz_local_original_shape) + box_for_each_point[..., 3:6] / 2      <span style=\'color: red\'># torch.Size([22969, 20, 3])   中心点从 box中心点为中心点 改成了 长宽高一半为中心点</span>\n        <span style=\'color: red\'># points_in_boxes_gpu gets points slightly outside of box, clamp values to make sure no out of index values</span>\n        xyz_local_grid = (xyz_local_corner / (box_for_each_point[..., 3:6] / grid_size))                       <span style=\'color: red\'># torch.Size([22969, 20, 3])   归一化</span>\n        points_out_of_range = ((xyz_local_grid < 0) | (xyz_local_grid >= grid_size) | (xyz_local_grid.isnan())).any(-1).flatten()   <span style=\'color: red\'># torch.Size([459380])=22969x20</span>\n        xyz_local_grid = torch.cat((box_idxs_of_pts.unsqueeze(-1),xyz_local_grid), dim=-1).long()              <span style=\'color: red\'># torch.Size([22969, 20, 4])   第0维是哪个box</span>\n        xyz_local_grid = xyz_local_grid.reshape(-1, xyz_local_grid.shape[-1])      <span style=\'color: red\'># torch.Size([19572, 4])</span>\n        <span style=\'color: red\'># Filter based on valid box_idxs</span>\n        valid_points_mask = (xyz_local_grid[:, 0] != -1) & (~points_out_of_range)  <span style=\'color: red\'># torch.Size([459380])</span>\n        xyz_local_grid = xyz_local_grid[valid_points_mask]                         <span style=\'color: red\'># torch.Size([19572, 4])    </span>\n        if return_centroid:\n            ......\n        else:\n            part_idxs, points_per_part = xyz_local_grid.unique(dim=0, return_counts=True)      <span style=\'color: red\'># torch.Size([127, 4]);torch.Size([127])</span>\n            <span style=\'color: red\'># Sometimes no points in boxes, usually in the first few iterations. Return empty tensor in that case</span>\n            if part_idxs.shape[0] == 0:\n                points_per_part_dense = torch.zeros((boxes.shape[0], grid_size, grid_size, grid_size), dtype=points_per_part.dtype, device=points.device)\n            else:\n                points_per_part_dense = torch.sparse_coo_tensor(part_idxs.T, points_per_part, size=(boxes.shape[0], grid_size, grid_size, grid_size)).to_dense()  <span style=\'color: red\'># torch.Size([128, 1, 1, 1])</span>\n        points_per_parts.append(points_per_part_dense)     <span style=\'color: red\'># [torch.Size([128, 6, 6, 6])]</span>\n    return torch.stack(points_per_parts)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def points_in_multi_boxes_gpu(points, boxes, max_num_boxes):\n    assert boxes.shape[0] == points.shape[0]\n    assert boxes.shape[2] == 7 and points.shape[2] == 3\n    batch_size, num_points, _ = points.shape       <span style=\'color: red\'># 1,22969</span>\n    box_idxs_of_pts = points.new_zeros((batch_size, num_points, max_num_boxes), dtype=torch.int).fill_(-1)   <span style=\'color: red\'># (1,22969,20)   最后得到的结果</span>\n    roiaware_pool3d_cuda.points_in_multi_boxes_gpu(boxes.contiguous(), points.contiguous(), box_idxs_of_pts, max_num_boxes)\n    return box_idxs_of_pts\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/roiaware_pool3d/src/roiaware_pool3d_kernel.cu</p><font size="0"><pre class="language-cpp"><code class="language-cpp">__global__ void points_in_boxes_kernel(int batch_size, int boxes_num, int pts_num, const float *boxes,const float *pts, int *box_idx_of_points){\n    <span style=\'color: red\'>// params boxes: (B, N, 7) [x, y, z, dx, dy, dz, heading] (x, y, z) is the box center</span>\n    <span style=\'color: red\'>// params pts: (B, npoints, 3) [x, y, z] in LiDAR coordinate</span>\n    <span style=\'color: red\'>// params boxes_idx_of_points: (B, npoints), default -1</span>\n    int bs_idx = blockIdx.y;\n    int pt_idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (bs_idx >= batch_size || pt_idx >= pts_num) return;\n    boxes += bs_idx * boxes_num * 7;\n    pts += bs_idx * pts_num * 3 + pt_idx * 3;\n    box_idx_of_points += bs_idx * pts_num + pt_idx;\n    float local_x = 0, local_y = 0;\n    int cur_in_flag = 0;\n    for (int k = 0; k < boxes_num; k++){\n        cur_in_flag = check_pt_in_box3d(pts, boxes + k * 7, local_x, local_y);   <span style=\'color: red\'>// 判断该点云是不是在box里面</span>\n        if (cur_in_flag){\n            box_idx_of_points[0] = k;                                            <span style=\'color: red\'>// 点云在box里面的话，值为哪个box</span>\n            break;\n        }\n    }\n}\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/pdv.py：loss计算</p><font size="0"><pre class="language-python"><code class="language-python">class PDV(Detector3DTemplate):\n    def __init__(self, model_cfg, num_class, dataset):\n        super().__init__(model_cfg=model_cfg, num_class=num_class, dataset=dataset)\n        self.module_list = self.build_networks()\n    def forward(self, batch_dict):\n        for cur_module in self.module_list:\n            batch_dict = cur_module(batch_dict)\n        if self.training:\n            loss, tb_dict, disp_dict = self.get_training_loss()\n            ret_dict = {\n                \'loss\': loss\n            }\n            return ret_dict, tb_dict, disp_dict\n        else:\n            pred_dicts, recall_dicts = self.post_processing(batch_dict)\n            return pred_dicts, recall_dicts\n    def get_training_loss(self):\n        disp_dict = {}\n        loss_rpn, tb_dict = self.dense_head.<span style=\'color: green;font-weight: bold;\'>get_loss</span>()\n        loss_rcnn, tb_dict = self.roi_head.<span style=\'color: green;font-weight: bold;\'>get_loss</span>(tb_dict)\n        loss = loss_rpn + loss_rcnn\n        return loss, tb_dict, disp_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class AnchorHeadTemplate(nn.Module):\n    def get_loss(self):\n        cls_loss, tb_dict = self.<span style=\'color: green;font-weight: bold;\'>get_cls_layer_loss</span>()\n        box_loss, tb_dict_box = self.<span style=\'color: green;font-weight: bold;\'>get_box_reg_layer_loss</span>()\n        tb_dict.update(tb_dict_box)\n        rpn_loss = cls_loss + box_loss\n        tb_dict[\'rpn_loss\'] = rpn_loss.item()\n        return rpn_loss, tb_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><font size="0"><pre class="language-python"><code class="language-python">class AnchorHeadTemplate(nn.Module):\n</code></pre></font>'}]}]}]})</script></body>
</html>
