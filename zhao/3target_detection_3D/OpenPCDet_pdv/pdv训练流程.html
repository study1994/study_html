<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>pdv训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_single.py</p><span class=\'hidden-code\' data-code=\'class AnchorHeadSingle(AnchorHeadTemplate):\n    def __init__(self, model_cfg, input_channels, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training=True, **kwargs):\n    def forward(self, data_dict):\n        spatial_features_2d = data_dict[&amp;#39;spatial_features_2d&amp;#39;]  torch.Size([1, 512, 200, 176])\n        cls_preds = self.conv_cls(spatial_features_2d)          torch.Size([1, 18, 200, 176]) 3个类别*6个anchor[每个类别2个anchor]\n        box_preds = self.conv_box(spatial_features_2d)          torch.Size([1, 42, 200, 176]) 7个属性*6个anchor\n        cls_preds = cls_preds.permute(0, 2, 3, 1).contiguous()  [N, H, W, C]\n        box_preds = box_preds.permute(0, 2, 3, 1).contiguous()  [N, H, W, C]\n        self.forward_ret_dict[&amp;#39;cls_preds&amp;#39;] = cls_preds          预测的，与anchor做计算才能得到真实box\n        self.forward_ret_dict[&amp;#39;box_preds&amp;#39;] = box_preds\n        if self.conv_dir_cls is not None:\n            dir_cls_preds = self.conv_dir_cls(spatial_features_2d)    torch.Size([1, 12, 200, 176]) 2*6个anchor\n            dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).contiguous()\n            self.forward_ret_dict[&amp;#39;dir_cls_preds&amp;#39;] = dir_cls_preds\n        else:\n            dir_cls_preds = None\n        if self.training:\n            targets_dict = self.`assign_targets`(gt_boxes=data_dict[&amp;#39;gt_boxes&amp;#39;])\n            self.forward_ret_dict.update(targets_dict)\n        if not self.training or self.predict_boxes_when_training:\n            batch_cls_preds, batch_box_preds = self.`generate_predicted_boxes`(\n                batch_size=data_dict[&amp;#39;batch_size&amp;#39;],cls_preds=cls_preds, box_preds=box_preds, dir_cls_preds=dir_cls_preds\n            )\n            data_dict[&amp;#39;batch_cls_preds&amp;#39;] = batch_cls_preds      torch.Size([1, 211200, 3])  与anchor做计算预测的也是最终的结果3Dbox\n            data_dict[&amp;#39;batch_box_preds&amp;#39;] = batch_box_preds      torch.Size([1, 211200, 7])\n            data_dict[&amp;#39;cls_preds_normalized&amp;#39;] = False\n        return data_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><span class=\'hidden-code\' data-code=\'class AnchorHeadTemplate(nn.Module):\n    def __init__(self, model_cfg, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training):\n        super().__init__()\n        self.model_cfg = model_cfg\n        self.num_class = num_class\n        self.class_names = class_names\n        self.predict_boxes_when_training = predict_boxes_when_training\n        self.use_multihead = self.model_cfg.get(&amp;#39;USE_MULTIHEAD&amp;#39;, False)\n        anchor_target_cfg = self.model_cfg.TARGET_ASSIGNER_CONFIG\n        self.box_coder = getattr(box_coder_utils, anchor_target_cfg.BOX_CODER)(\n            num_dir_bins=anchor_target_cfg.get(&amp;#39;NUM_DIR_BINS&amp;#39;, 6),\n            **anchor_target_cfg.get(&amp;#39;BOX_CODER_CONFIG&amp;#39;, {})\n        )\n        anchor_generator_cfg = self.model_cfg.ANCHOR_GENERATOR_CONFIG\n        anchors, self.num_anchors_per_location = self.generate_anchors(\n            anchor_generator_cfg, grid_size=grid_size, point_cloud_range=point_cloud_range,\n            anchor_ndim=self.box_coder.code_size\n        )\n        self.anchors = [x.cuda() for x in anchors]\n        self.target_assigner = self.get_target_assigner(anchor_target_cfg)\n        self.forward_ret_dict = {}\n        self.build_losses(self.model_cfg.LOSS_CONFIG)\n    @staticmethod\n    def generate_anchors(anchor_generator_cfg, grid_size, point_cloud_range, anchor_ndim=7):\n        anchor_generator = AnchorGenerator(\n            anchor_range=point_cloud_range,\n            anchor_generator_config=anchor_generator_cfg\n        )\n        feature_map_size = [grid_size[:2] // config[&amp;#39;feature_map_stride&amp;#39;] for config in anchor_generator_cfg]\n        anchors_list, num_anchors_per_location_list = anchor_generator.generate_anchors(feature_map_size)\n        if anchor_ndim != 7:\n            for idx, anchors in enumerate(anchors_list):\n                pad_zeros = anchors.new_zeros([*anchors.shape[0:-1], anchor_ndim - 7])\n                new_anchors = torch.cat((anchors, pad_zeros), dim=-1)\n                anchors_list[idx] = new_anchors\n        return anchors_list, num_anchors_per_location_list\n    def get_target_assigner(self, anchor_target_cfg):\n        if anchor_target_cfg.NAME == &amp;#39;ATSS&amp;#39;:\n            target_assigner = ATSSTargetAssigner(\n                topk=anchor_target_cfg.TOPK,\n                box_coder=self.box_coder,\n                use_multihead=self.use_multihead,\n                match_height=anchor_target_cfg.MATCH_HEIGHT\n            )\n        elif anchor_target_cfg.NAME == &amp;#39;AxisAlignedTargetAssigner&amp;#39;:\n            target_assigner = AxisAlignedTargetAssigner(\n                model_cfg=self.model_cfg,\n                class_names=self.class_names,\n                box_coder=self.box_coder,\n                match_height=anchor_target_cfg.MATCH_HEIGHT\n            )\n        else:\n            raise NotImplementedError\n        return target_assigner\n    def build_losses(self, losses_cfg):\n        self.add_module(\n            &amp;#39;cls_loss_func&amp;#39;,\n            loss_utils.SigmoidFocalClassificationLoss(alpha=0.25, gamma=2.0)\n        )\n        reg_loss_name = &amp;#39;WeightedSmoothL1Loss&amp;#39; if losses_cfg.get(&amp;#39;REG_LOSS_TYPE&amp;#39;, None) is None \\\n            else losses_cfg.REG_LOSS_TYPE\n        self.add_module(\n            &amp;#39;reg_loss_func&amp;#39;,\n            getattr(loss_utils, reg_loss_name)(code_weights=losses_cfg.LOSS_WEIGHTS[&amp;#39;code_weights&amp;#39;])\n        )\n        self.add_module(\n            &amp;#39;dir_loss_func&amp;#39;,\n            loss_utils.WeightedCrossEntropyLoss()\n        )\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><span class=\'hidden-code\' data-code=\'class AnchorHeadTemplate(nn.Module):\n    def assign_targets(self, gt_boxes):\n        targets_dict = self.target_assigner.`assign_targets`(self.anchors, gt_boxes)\n        return targets_dict # [torch.Size([1, 200, 176, 1, 2, 7]),torch.Size([1, 200, 176, 1, 2, 7]),torch.Size([1, 200, 176, 1, 2, 7])] + torch.Size([1, 39, 8])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/target_assigner/axis_aligned_target_assigner.py</p><span class=\'hidden-code\' data-code=\'class AxisAlignedTargetAssigner(object):\n    def assign_targets(self, all_anchors, gt_boxes_with_classes):\n        bbox_targets,cls_labels,reg_weights = [],[],[]\n        batch_size = gt_boxes_with_classes.shape[0]         # 1\n        gt_classes = gt_boxes_with_classes[:, :, -1]        # torch.Size([1, 39]) 标签\n        gt_boxes = gt_boxes_with_classes[:, :, :-1]         # torch.Size([1, 39, 7])\n        for k in range(batch_size):\n            cur_gt = gt_boxes[k]                            # torch.Size([39, 7])\n            cnt = cur_gt.__len__() - 1                      # 38\n            while cnt > 0 and cur_gt[cnt].sum() == 0:\n                cnt -= 1\n            cur_gt = cur_gt[:cnt + 1]                       # torch.Size([39, 7])\n            cur_gt_classes = gt_classes[k][:cnt + 1].int()  # 标签不为0开始，有1,2,3   torch.Size([39])\n            target_list = []\n            for anchor_class_name, anchors in zip(self.anchor_class_names, all_anchors):    # &amp;#39;car&amp;#39; torch.Size([1, 200, 176, 1, 2, 7])\n                if cur_gt_classes.shape[0] > 1:\n                    mask = torch.from_numpy(self.class_names[cur_gt_classes.cpu() - 1] == anchor_class_name)    # torch.Size([39])\n                else:\n                    mask = torch.tensor([self.class_names[c - 1] == anchor_class_namefor c in cur_gt_classes], dtype=torch.bool)\n                if self.use_multihead:               # False\n                    anchors = anchors.permute(3, 4, 0, 1, 2, 5).contiguous().view(-1, anchors.shape[-1])\n                    selected_classes = cur_gt_classes[mask]\n                else:\n                    feature_map_size = anchors.shape[:3]             # torch.Size([1, 200, 176])\n                    anchors = anchors.view(-1, anchors.shape[-1])    # torch.Size([70400, 7])\n                    selected_classes = cur_gt_classes[mask]          # torch.Size([11]) 39里面有11个为0类\n                single_target = self.`assign_targets_single`(\n                    anchors,cur_gt[mask],gt_classes=selected_classes,\n                    matched_threshold=self.matched_thresholds[anchor_class_name],       # {&amp;#39;Car&amp;#39;: 0.6, &amp;#39;Pedestrian&amp;#39;: 0.5, &amp;#39;Cyclist&amp;#39;: 0.5}\n                    unmatched_threshold=self.unmatched_thresholds[anchor_class_name]    # {&amp;#39;Car&amp;#39;: 0.45, &amp;#39;Pedestrian&amp;#39;: 0.35, &amp;#39;Cyclist&amp;#39;: 0.35}\n                )\n                target_list.append(single_target)\n            if self.use_multihead:          # False\n                target_dict = {\n                    &amp;#39;box_cls_labels&amp;#39;: [t[&amp;#39;box_cls_labels&amp;#39;].view(-1) for t in target_list],\n                    &amp;#39;box_reg_targets&amp;#39;: [t[&amp;#39;box_reg_targets&amp;#39;].view(-1, self.box_coder.code_size) for t in target_list],\n                    &amp;#39;reg_weights&amp;#39;: [t[&amp;#39;reg_weights&amp;#39;].view(-1) for t in target_list]\n                }\n                target_dict[&amp;#39;box_reg_targets&amp;#39;] = torch.cat(target_dict[&amp;#39;box_reg_targets&amp;#39;], dim=0)\n                target_dict[&amp;#39;box_cls_labels&amp;#39;] = torch.cat(target_dict[&amp;#39;box_cls_labels&amp;#39;], dim=0).view(-1)\n                target_dict[&amp;#39;reg_weights&amp;#39;] = torch.cat(target_dict[&amp;#39;reg_weights&amp;#39;], dim=0).view(-1)\n            else:\n                target_dict = {\n                    &amp;#39;box_cls_labels&amp;#39;: [t[&amp;#39;box_cls_labels&amp;#39;].view(*feature_map_size, -1) for t in target_list],             # feature_map_size=torch.Size([1, 200, 176])\n                    &amp;#39;box_reg_targets&amp;#39;: [t[&amp;#39;box_reg_targets&amp;#39;].view(*feature_map_size, -1, self.box_coder.code_size) for t in target_list],\n                    &amp;#39;reg_weights&amp;#39;: [t[&amp;#39;reg_weights&amp;#39;].view(*feature_map_size, -1) for t in target_list]\n                }\n                target_dict[&amp;#39;box_reg_targets&amp;#39;] = torch.cat(target_dict[&amp;#39;box_reg_targets&amp;#39;], dim=-2).view(-1, self.box_coder.code_size)\n                target_dict[&amp;#39;box_cls_labels&amp;#39;] = torch.cat(target_dict[&amp;#39;box_cls_labels&amp;#39;], dim=-1).view(-1)\n                target_dict[&amp;#39;reg_weights&amp;#39;] = torch.cat(target_dict[&amp;#39;reg_weights&amp;#39;], dim=-1).view(-1)\n            bbox_targets.append(target_dict[&amp;#39;box_reg_targets&amp;#39;])\n            cls_labels.append(target_dict[&amp;#39;box_cls_labels&amp;#39;])\n            reg_weights.append(target_dict[&amp;#39;reg_weights&amp;#39;])\n        bbox_targets = torch.stack(bbox_targets, dim=0)\n        cls_labels = torch.stack(cls_labels, dim=0)\n        reg_weights = torch.stack(reg_weights, dim=0)\n        all_targets_dict = {\n            &amp;#39;box_cls_labels&amp;#39;: cls_labels,           # torch.Size([1, 211200])\n            &amp;#39;box_reg_targets&amp;#39;: bbox_targets,        # torch.Size([1, 211200, 7])\n            &amp;#39;reg_weights&amp;#39;: reg_weights              # torch.Size([1, 211200])\n        }\n        return all_targets_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/target_assigner/axis_aligned_target_assigner.py</p><span class=\'hidden-code\' data-code=\'class AxisAlignedTargetAssigner(object):\n    def assign_targets_single(self, anchors, gt_boxes, gt_classes, matched_threshold=0.6, unmatched_threshold=0.45):\n        # torch.Size([70400, 7])；torch.Size([11, 7])；torch.Size([11])；0.6；0.45\n        num_anchors = anchors.shape[0]        # 70400\n        num_gt = gt_boxes.shape[0]\n        labels = torch.ones((num_anchors,), dtype=torch.int32, device=anchors.device) * -1\n        gt_ids = torch.ones((num_anchors,), dtype=torch.int32, device=anchors.device) * -1\n        if len(gt_boxes) > 0 and anchors.shape[0] > 0:\n            anchor_by_gt_overlap = iou3d_nms_utils.boxes_iou3d_gpu(anchors[:, 0:7], gt_boxes[:, 0:7]) if self.match_height else box_utils.boxes3d_nearest_bev_iou(anchors[:, 0:7], gt_boxes[:, 0:7])\n            # torch.Size([70400, 11])70400个anchor与11个gt的iou结果\n            # NOTE: The speed of these two versions depends the environment and the number of anchors\n            # anchor_to_gt_argmax = torch.from_numpy(anchor_by_gt_overlap.cpu().numpy().argmax(axis=1)).cuda()\n            anchor_to_gt_argmax = anchor_by_gt_overlap.argmax(dim=1)       # torch.Size([70400])；每个anchor与最大iou的那个box索引\n            anchor_to_gt_max = anchor_by_gt_overlap[torch.arange(num_anchors, device=anchors.device), anchor_to_gt_argmax]  # torch.Size([70400])对应的iou值\n            # gt_to_anchor_argmax = torch.from_numpy(anchor_by_gt_overlap.cpu().numpy().argmax(axis=0)).cuda()\n            gt_to_anchor_argmax = anchor_by_gt_overlap.argmax(dim=0)      # torch.Size([11]) 11个真值与最大iou的那个anchor索引\n            gt_to_anchor_max = anchor_by_gt_overlap[gt_to_anchor_argmax, torch.arange(num_gt, device=anchors.device)]  # torch.Size([11])最大的iou值\n            empty_gt_mask = gt_to_anchor_max == 0\n            gt_to_anchor_max[empty_gt_mask] = -1         # 将iou为0的设置为-1\n            anchors_with_max_overlap = (anchor_by_gt_overlap == gt_to_anchor_max).nonzero()[:, 0]    # torch.Size([14]), 70400个anchor与Gt有14个anchor的iou不为0\n            gt_inds_force = anchor_to_gt_argmax[anchors_with_max_overlap]                            # 范围为11个box的索引0-10\n            labels[anchors_with_max_overlap] = gt_classes[gt_inds_force]\n            gt_ids[anchors_with_max_overlap] = gt_inds_force.int()\n            pos_inds = anchor_to_gt_max >= matched_threshold\n            gt_inds_over_thresh = anchor_to_gt_argmax[pos_inds]\n            labels[pos_inds] = gt_classes[gt_inds_over_thresh]\n            gt_ids[pos_inds] = gt_inds_over_thresh.int()\n            bg_inds = (anchor_to_gt_max < unmatched_threshold).nonzero()[:, 0]\n        else:\n            bg_inds = torch.arange(num_anchors, device=anchors.device)\n        fg_inds = (labels > 0).nonzero()[:, 0]     # torch.Size([54])总共54个前景anchor\n        if self.pos_fraction is not None:          # None\n            ......\n        else:\n            if len(gt_boxes) == 0 or anchors.shape[0] == 0:\n                labels[:] = 0\n            else:\n                labels[bg_inds] = 0\n                labels[anchors_with_max_overlap] = gt_classes[gt_inds_force]       # 可以理解1个anchor多个GT？然后强制取某个GT？\n        bbox_targets = anchors.new_zeros((num_anchors, self.box_coder.code_size))  # torch.Size([70400, 7])\n        if len(gt_boxes) > 0 and anchors.shape[0] > 0: \n            fg_gt_boxes = gt_boxes[anchor_to_gt_argmax[fg_inds], :]                            # torch.Size([54, 7])54个匹配的anchor对应的3Dbox\n            fg_anchors = anchors[fg_inds, :]                                                   # 54个anchor\n            bbox_targets[fg_inds, :] = self.box_coder.`encode_torch`(fg_gt_boxes, fg_anchors)    # pcdet.utils.box_coder_utils.ResidualCoder  torch.Size([70400, 7])\n        reg_weights = anchors.new_zeros((num_anchors,))\n        if self.norm_by_num_examples:\n            num_examples = (labels >= 0).sum()\n            num_examples = num_examples if num_examples > 1.0 else 1.0\n            reg_weights[labels > 0] = 1.0 / num_examples\n        else:\n            reg_weights[labels > 0] = 1.0       # 有box的才做回归\n        ret_dict = {\n            &amp;#39;box_cls_labels&amp;#39;: labels,           # 对应的标签\n            &amp;#39;box_reg_targets&amp;#39;: bbox_targets,    # anchor与GTbox做计算得到\n            &amp;#39;reg_weights&amp;#39;: reg_weights,\n        }\n        return ret_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/box_coder_utils.py</p><span class=\'hidden-code\' data-code=\'class ResidualCoder(object):\n    def encode_torch(self, boxes, anchors):\n        anchors[:, 3:6] = torch.clamp_min(anchors[:, 3:6], min=1e-5)\n        boxes[:, 3:6] = torch.clamp_min(boxes[:, 3:6], min=1e-5)\n        xa, ya, za, dxa, dya, dza, ra, *cas = torch.split(anchors, 1, dim=-1)    # cas=[]\n        xg, yg, zg, dxg, dyg, dzg, rg, *cgs = torch.split(boxes, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)                               # torch.Size([54, 1])\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n        if self.encode_angle_by_sincos:\n            rt_cos = torch.cos(rg) - torch.cos(ra)\n            rt_sin = torch.sin(rg) - torch.sin(ra)\n            rts = [rt_cos, rt_sin]\n        else:\n            rts = [rg - ra]\n        cts = [g - a for g, a in zip(cgs, cas)]\n        return torch.cat([xt, yt, zt, dxt, dyt, dzt, *rts, *cts], dim=-1)\n\'> </span>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><span class=\'hidden-code\' data-code=\'class AnchorHeadTemplate(nn.Module):\n    def generate_predicted_boxes(self, batch_size, cls_preds, box_preds, dir_cls_preds=None):\n        if isinstance(self.anchors, list):\n            if self.use_multihead:\n                anchors = torch.cat([anchor.permute(3, 4, 0, 1, 2, 5).contiguous().view(-1, anchor.shape[-1])for anchor in self.anchors], dim=0)\n            else:\n                anchors = torch.cat(self.anchors, dim=-3)        # torch.Size([1, 200, 176, 3, 2, 7])\n        else:\n            anchors = self.anchors\n        num_anchors = anchors.view(-1, anchors.shape[-1]).shape[0]                         # 211200\n        batch_anchors = anchors.view(1, -1, anchors.shape[-1]).repeat(batch_size, 1, 1)    # torch.Size([1, 211200, 7])\n        batch_cls_preds = cls_preds.view(batch_size, num_anchors, -1).float() if not isinstance(cls_preds, list) else cls_preds # torch.Size([1, 211200, 3])\n        batch_box_preds = box_preds.view(batch_size, num_anchors, -1) if not isinstance(box_preds, list) else torch.cat(box_preds, dim=1).view(batch_size, num_anchors, -1)  # torch.Size([1, 211200, 7])\n        batch_box_preds = self.box_coder.`decode_torch`(batch_box_preds, batch_anchors)\n        if dir_cls_preds is not None:\n            dir_offset = self.model_cfg.DIR_OFFSET                                         # 0.78539\n            dir_limit_offset = self.model_cfg.DIR_LIMIT_OFFSET\n            dir_cls_preds = dir_cls_preds.view(batch_size, num_anchors, -1) if not isinstance(dir_cls_preds, list) else torch.cat(dir_cls_preds, dim=1).view(batch_size, num_anchors, -1)\n            dir_labels = torch.max(dir_cls_preds, dim=-1)[1]\n            period = (2 * np.pi / self.model_cfg.NUM_DIR_BINS)\n            dir_rot = common_utils.limit_period(batch_box_preds[..., 6] - dir_offset, dir_limit_offset, period)   # torch.Size([1, 211200])\n            batch_box_preds[..., 6] = dir_rot + dir_offset + period * dir_labels.to(batch_box_preds.dtype)\n        if isinstance(self.box_coder, box_coder_utils.PreviousResidualDecoder):\n            batch_box_preds[..., 6] = common_utils.limit_period(-(batch_box_preds[..., 6] + np.pi / 2), offset=0.5, period=np.pi * 2)\n        return batch_cls_preds, batch_box_preds       # torch.Size([1, 211200, 3])  torch.Size([1, 211200, 7])\n\'> </span>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelAggregationHead(RoIHeadTemplate):\n    def forward(self, batch_dict):\n         [(&amp;#39;x_conv3&amp;#39;, torch.Size([7512, 64])), (&amp;#39;x_conv4&amp;#39;, torch.Size([3578, 64]))] [(&amp;#39;x_conv3&amp;#39;, torch.Size([7512, 4])), (&amp;#39;x_conv4&amp;#39;, torch.Size([3578, 4]))]\n        batch_dict[&amp;#39;point_features&amp;#39;], batch_dict[&amp;#39;point_coords&amp;#39;] = self.`get_point_voxel_features`(batch_dict)                        获取体素特征和体素坐标\n        targets_dict = self.`proposal_layer`(batch_dict, nms_config=self.model_cfg.NMS_CONFIG[&amp;#39;TRAIN&amp;#39; if self.training else &amp;#39;TEST&amp;#39;])  做nms，主要是获取roi和对应label\n        if self.training:\n            targets_dict = self.`assign_targets`(batch_dict)\n            batch_dict[&amp;#39;rois&amp;#39;] = targets_dict[&amp;#39;rois&amp;#39;]               rois是网络预测的与gt匹配到的 torch.Size([1, 128, 7])\n            batch_dict[&amp;#39;roi_labels&amp;#39;] = targets_dict[&amp;#39;roi_labels&amp;#39;]   (1,128)值在1->3\n        RoI aware pooling   torch.Size([128, 216, 128]),torch.Size([1, 27648, 3]),torch.Size([128, 216, 3]),torch.Size([128, 216, 64])\n        pooled_features, global_roi_grid_points, local_roi_grid_points, ball_idxs = self.`roi_grid_pool`(batch_dict)  (BxN, 6x6x6, C)\n        batch_size_rcnn = pooled_features.shape[0]\n        if self.pool_cfg.get(&amp;#39;ATTENTION&amp;#39;, {}).get(&amp;#39;ENABLED&amp;#39;):             True\n            src_key_padding_mask = None\n            if self.pool_cfg.ATTENTION.get(&amp;#39;MASK_EMPTY_POINTS&amp;#39;):\n                src_key_padding_mask = (ball_idxs == 0).all(-1)           torch.Size([128, 216])\n            positional_input = self.`get_positional_input`(batch_dict[&amp;#39;points&amp;#39;], batch_dict[&amp;#39;rois&amp;#39;], local_roi_grid_points)  torch.Size([128, 216, 4])\n            Attention\n            attention_output = self.`attention_head`(pooled_features, positional_input, src_key_padding_mask) (BxN, 6x6x6, C)  torch.Size([128, 216, 128])\n            if self.pool_cfg.ATTENTION.get(&amp;#39;COMBINE&amp;#39;):\n                attention_output = pooled_features + attention_output     torch.Size([128, 216, 128])\n            Permute\n            grid_size = self.model_cfg.ROI_GRID_POOL.GRID_SIZE            6\n            batch_size_rcnn = attention_output.shape[0]                   128\n            pooled_features = attention_output.permute(0, 2, 1).contiguous().view(batch_size_rcnn, -1, grid_size, grid_size, grid_size) (BxN, C, 6, 6, 6)-torch.Size([128, 128, 6, 6, 6])\n        shared_features = self.shared_fc_layer(pooled_features.view(batch_size_rcnn, -1, 1))     一堆卷积->torch.Size([128, 256, 1])\n        rcnn_reg = self.reg_layers(shared_features).transpose(1, 2).contiguous().squeeze(dim=1)  (B, C) torch.Size([128, 7, 1])->torch.Size([128, 7])\n        if self.model_cfg.get(&amp;#39;DENSITY_CONFIDENCE&amp;#39;, {}).get(&amp;#39;ENABLED&amp;#39;):         True\n            with torch.no_grad():\n                Calculate number of points in each rcnn_reg     密度置信度预测  == 添加两个额外特征（分别是当前bbox的点质心特征以及bbox中的点数）\n                _, batch_box_preds = self.`generate_predicted_boxes`(batch_size=batch_dict[&amp;#39;batch_size&amp;#39;], rois=batch_dict[&amp;#39;rois&amp;#39;], cls_preds=None, box_preds=rcnn_reg) torch.Size([1, 128, 7])\n                points_per_part = density_utils.`find_num_points_per_part_multi`(batch_dict[&amp;#39;points&amp;#39;],batch_box_preds,             torch.Size([22969, 5]);torch.Size([1, 128, 7])  -->torch.Size([1, 128, 1, 1, 1])\n                                                                               self.model_cfg.DENSITY_CONFIDENCE.GRID_SIZE,        1\n                                                                               self.model_cfg.DENSITY_CONFIDENCE.MAX_NUM_BOXES)    20\n                points_per_part = torch.log10(points_per_part.float() + 0.5).reshape(-1, self.model_cfg.DENSITY_CONFIDENCE.GRID_SIZE ** 3, 1) - (math.log10(0.5) if self.model_cfg.get(&amp;#39;DENSITY_LOG_SHIFT&amp;#39;) else 0) torch.Size([128, 1, 1])\n                point_cloud_range = torch.tensor(self.point_cloud_range, device=batch_box_preds.device)      tensor([  0.0000, -40.0000,  -3.0000,  70.4000,  40.0000,   1.0000],\n                batch_box_preds_xyz = batch_box_preds.reshape(-1, batch_box_preds.shape[-1], 1)[:, :3]       torch.Size([128, 3, 1])\n                batch_box_preds_xyz /= (point_cloud_range[3:] - point_cloud_range[:3]).unsqueeze(0).unsqueeze(-1)  torch.Size([128, 3, 1])\n                density_features = [points_per_part, batch_box_preds_xyz]    [torch.Size([1, 128, 1, 1, 1]),torch.Size([128, 3, 1])]\n                if self.model_cfg.DENSITY_CONFIDENCE.ADD_SHARED_FEATURES:\n                    density_features.append(shared_features)                 torch.Size([128, 256, 1])->[torch.Size([1, 128, 1, 1, 1]),torch.Size([128, 3, 1]),torch.Size([128, 256, 1])]\n            density_features = torch.cat(density_features, dim=1)            torch.Size([128, 260, 1])\n            rcnn_cls = self.`cls_layers`(density_features)  (B, 1 or 2)    torch.Size([128, 1, 1])\n        else:\n            rcnn_cls = self.cls_layers(shared_features)\n        rcnn_cls = rcnn_cls.transpose(1, 2).contiguous().squeeze(dim=1)      torch.Size([128, 1])  没有做具体类别？\n        if not self.training:\n            batch_cls_preds, batch_box_preds = self.`generate_predicted_boxes`(\n                batch_size=batch_dict[&amp;#39;batch_size&amp;#39;], rois=batch_dict[&amp;#39;rois&amp;#39;], cls_preds=rcnn_cls, box_preds=rcnn_reg\n            )\n            batch_dict[&amp;#39;batch_cls_preds&amp;#39;] = batch_cls_preds\n            batch_dict[&amp;#39;batch_box_preds&amp;#39;] = batch_box_preds\n            batch_dict[&amp;#39;cls_preds_normalized&amp;#39;] = False\n        else:\n            targets_dict[&amp;#39;rcnn_cls&amp;#39;] = rcnn_cls\n            targets_dict[&amp;#39;rcnn_reg&amp;#39;] = rcnn_reg\n            self.forward_ret_dict = targets_dict\n        return batch_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><span class=\'hidden-code\' data-code=\'class PDVHead(VoxelAggregationHead):\n    def get_point_voxel_features(self, batch_dict):\n        point_features = {}\n        point_coords = {}       # 就是求点云属于哪个voxel，求里面的点云平均以及属于哪个大voxel\n        centroids_all, centroid_voxel_idxs_all = voxel_aggregation_utils.`get_centroids_per_voxel_layer`(batch_dict[&amp;#39;points&amp;#39;],  # torch.Size([22795, 5])\n            self.model_cfg.VOXEL_AGGREGATION.FEATURE_LOCATIONS,       # [&amp;#39;x_conv3&amp;#39;, &amp;#39;x_conv4&amp;#39;]\n            batch_dict[&amp;#39;multi_scale_3d_strides&amp;#39;],                     # {&amp;#39;x_conv1&amp;#39;: 1, &amp;#39;x_conv2&amp;#39;: 2, &amp;#39;x_conv3&amp;#39;: 4, &amp;#39;x_conv4&amp;#39;: 8}\n            self.voxel_size,                                          # [0.05, 0.05, 0.1]\n            self.point_cloud_range                                    # [0.0, -40.0, -3.0, 70.4, 40.0, 1.0]\n        )\n        for feature_location in self.model_cfg.VOXEL_AGGREGATION.FEATURE_LOCATIONS:        # [&amp;#39;x_conv3&amp;#39;, &amp;#39;x_conv4&amp;#39;]\n            centroids = centroids_all[feature_location][:, :4]                             # torch.Size([7732, 4])该voxel里面的平均\n            centroid_voxel_idxs = centroid_voxel_idxs_all[feature_location]\n            x_conv = batch_dict[&amp;#39;multi_scale_3d_features&amp;#39;][feature_location]               # 该feature的3D特征[11, 400, 352]\n            overlapping_voxel_feature_indices_nonempty, overlapping_voxel_feature_nonempty_mask = \\\n                voxel_aggregation_utils.`get_nonempty_voxel_feature_indices`(centroid_voxel_idxs, x_conv)  # torch.Size([7512]) ；torch.Size([7732]) 前面是去掉空的体素\n            if self.model_cfg.VOXEL_AGGREGATION.get(&amp;#39;USE_EMPTY_VOXELS&amp;#39;):  # 是否用空体素特征\n                ......\n            else:           # False\n                x_conv_features = torch.zeros((centroids.shape[0], x_conv.features.shape[-1]), dtype=x_conv.features.dtype, device=centroids.device)  # torch.Size([7732, 64])\n                x_conv_features[overlapping_voxel_feature_nonempty_mask] = x_conv.features[overlapping_voxel_feature_indices_nonempty]\n                point_features[feature_location] = x_conv_features[overlapping_voxel_feature_nonempty_mask]   # torch.Size([7732, 64])->torch.Size([7512, 64])\n                point_coords[feature_location] = centroids[overlapping_voxel_feature_nonempty_mask]           # torch.Size([7732, 4])大voxcel所有点云的平均，没包括反射率\n        return point_features, point_coords\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><span class=\'hidden-code\' data-code=\'def get_centroids_per_voxel_layer(points, feature_locations, multi_scale_3d_strides, voxel_size, point_cloud_range):\n    assert len(points.shape) == 2\n    assert len(feature_locations) > 0\n    centroids_all = {}\n    centroid_voxel_idxs_all = {}\n    # Take first layer feature locations\n    feature_location_first = feature_locations[0]                             # &amp;#39;x_conv3&amp;#39;\n    downsample_factor_first = multi_scale_3d_strides[feature_location_first]  # 4\n    # Calculate centroids\n    voxel_idxs = `get_overlapping_voxel_indices`(points[:, 1:4],\n                                               downsample_times=downsample_factor_first,\n                                               voxel_size=voxel_size,\n                                               point_cloud_range=point_cloud_range)   # torch.Size([22795, 3])这些点属于哪个voxel\n    # Add batch_idx\n    voxel_idxs = torch.cat((points[:,0:1].long(), voxel_idxs), dim=-1)      # 加入batch idx\n    # Filter out points that are outside the valid point cloud range (invalid indices have -1)\n    voxel_idxs_valid_mask = (voxel_idxs != -1).all(-1)\n    voxel_idxs_valid = voxel_idxs[voxel_idxs_valid_mask]                    # torch.Size([22187, 4])\n    # Convert voxel_indices from (bxyz) to (bzyx) format for properly indexing voxelization layer\n    voxel_idxs_valid = voxel_idxs_valid[:, [0,3,2,1]]                       # torch.Size([22187, 4])\n    points_valid = points[voxel_idxs_valid_mask]                            # torch.Size([22187, 5])\n    centroids_first, centroid_voxel_idxs_first, num_points_in_centroids_first = `get_centroid_per_voxel`(points_valid, voxel_idxs_valid)\n    centroids_all[feature_location_first] = centroids_first                            # torch.Size([7732, 5])\n    centroid_voxel_idxs_all[feature_location_first] = centroid_voxel_idxs_first        # torch.Size([7732, 4])\n    for feature_location in feature_locations[1:]:        # [&amp;#39;x_conv3&amp;#39;, &amp;#39;x_conv4&amp;#39;]\n        grid_scaling = int(multi_scale_3d_strides[feature_location] / downsample_factor_first)     # 2=8/4\n        voxel_idxs = centroid_voxel_idxs_first.clone()\n        voxel_idxs[:, 1:] = centroid_voxel_idxs_first[:, 1:] // grid_scaling     # [  0,   1, 179, 149]->[ 0,  0, 89, 74]\n        centroids, centroid_voxel_idxs, _ = `get_centroid_per_voxel`(centroids_first, voxel_idxs, num_points_in_centroids_first)   # 每个大voxel所有点云求平均，对应的B,Z,Y,Z;\n        centroids_all[feature_location] = centroids\n        centroid_voxel_idxs_all[feature_location] = centroid_voxel_idxs\n    return centroids_all, centroid_voxel_idxs_all\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><span class=\'hidden-code\' data-code=\'def get_overlapping_voxel_indices(point_coords, downsample_times, voxel_size, point_cloud_range):\n    assert point_coords.shape[1] == 3\n    voxel_size = torch.tensor(voxel_size, device=point_coords.device).float() * downsample_times  # [0.05, 0.05, 0.1]->[0.2, 0.2, 0.4]\n    pc_range = torch.tensor(point_cloud_range, device=point_coords.device).float()                # tensor([  0, -40,  -3,  70.4,  40,   1],\n    voxel_indices = ((point_coords - pc_range[0:3]) / voxel_size)                                 # torch.Size([22795, 3]) 每个点在xyz上面的索引\n    # Calculate number of voxels in each dimension\n    grid_size = ((pc_range[3:6] - pc_range[0:3]) / voxel_size).long()                            # tensor([352, 400,  10], device=&amp;#39;cuda:0&amp;#39;) 有多少个voxels\n    # Check which points are in and which points are outside the point cloud range and set to -1\n    points_out_of_range = ((voxel_indices `<` 0) | (voxel_indices `>`= grid_size)).sum(dim=-1) `>` 0   # 大于的为-1\n    voxel_indices[points_out_of_range] = -1\n    return voxel_indices.long() # (xyz)\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><span class=\'hidden-code\' data-code=\'def get_centroid_per_voxel(points, voxel_idxs, num_points_in_voxel=None):   # torch.Size([22187, 5])；torch.Size([22187, 4])；\n    assert points.shape[0] == voxel_idxs.shape[0]\n    # torch.Size([7732, 4]) 7732个非0唯一voxel；torch.Size([22187])属于哪个voxle， torch.Size([7732])告诉哪个voxel有多少个\n    centroid_voxel_idxs, unique_idxs, labels_count = voxel_idxs.unique(dim=0, return_inverse=True, return_counts=True)  \n    unique_idxs = unique_idxs.view(unique_idxs.size(0), 1).expand(-1, points.size(-1)) # torch.Size([22187, 5]) unique_idxs[0]=[4242, 4242, 4242, 4242, 4242]\n    # Scatter add points based on unique voxel idxs\n    if num_points_in_voxel is not None:\n        ......\n    else:\n        centroids = torch.zeros((centroid_voxel_idxs.shape[0], points.shape[-1]), device=points.device, dtype=torch.float).scatter_add_(0, unique_idxs, points)   # torch.Size([7732, 5])将点云相加求平均\n        centroids = centroids / labels_count.float().unsqueeze(-1)\n    return centroids, centroid_voxel_idxs, labels_count       # 每个大voxel所有点云求平均，对应的B,Z,Y,Z; 每个大voxel的点云数量\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><span class=\'hidden-code\' data-code=\'def get_centroid_per_voxel(points, voxel_idxs, num_points_in_voxel=None):   # torch.Size([7732, 5])；torch.Size([7732, 4])； torch.Size([7732])\n    assert points.shape[0] == voxel_idxs.shape[0]\n    # torch.Size([3623, 4]) 3623个非0唯一voxel；torch.Size([7732])属于哪个voxle， torch.Size([3623])告诉哪个voxel有多少个\n    centroid_voxel_idxs, unique_idxs, labels_count = voxel_idxs.unique(dim=0, return_inverse=True, return_counts=True)  \n    unique_idxs = unique_idxs.view(unique_idxs.size(0), 1).expand(-1, points.size(-1)) # torch.Size([7732, 5]) unique_idxs[0]=[0, 0, 0, 0, 0]\n    # Scatter add points based on unique voxel idxs\n    if num_points_in_voxel is not None:\n        centroids = torch.zeros((centroid_voxel_idxs.shape[0], points.shape[-1]), device=points.device, dtype=torch.float).scatter_add_(0, unique_idxs, points * num_points_in_voxel.unsqueeze(-1))\n        num_points_in_centroids = torch.zeros((centroid_voxel_idxs.shape[0]), device=points.device, dtype=torch.int64).scatter_add_(0, unique_idxs[:,0], num_points_in_voxel)   # torch.Size([7732])->torch.Size([3623])\n        centroids = centroids / num_points_in_centroids.float().unsqueeze(-1)\n    else:\n        ......\n    return centroids, centroid_voxel_idxs, labels_count       # 每个大voxel所有点云求平均，对应的B,Z,Y,Z; 每个大voxel的点云数量\n\'> </span>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><span class=\'hidden-code\' data-code=\'def get_nonempty_voxel_feature_indices(voxel_indices, x_conv):\n    x_conv_hash_table = `get_voxel_indices_to_voxel_list_index`(x_conv)       # [11, 400, 352]-->torch.Size([1, 11, 400, 352])\n    # Get corresponding voxel feature indices\n    overlapping_voxel_feature_indices = torch.zeros(voxel_indices.shape[0], device=voxel_indices.device, dtype=torch.int64) # torch.Size([7732])\n    overlapping_voxel_feature_indices = x_conv_hash_table[voxel_indices[:,0], voxel_indices[:,1],\n                                                          voxel_indices[:,2], voxel_indices[:,3]]   # BZYX? torch.Size([7732])值从1->7732\n    # Remove empty voxels features\n    overlapping_voxel_feature_nonempty_mask = overlapping_voxel_feature_indices != 0      # torch.Size([7732])\n    # Filter and shift indices back by -1   没看懂，不能直接返回torch.arange(1, x_conv_indices.shape[0]+1, device=x_conv_indices.device)？因为有空的体素\n    overlapping_voxel_feature_indices_nonempty = overlapping_voxel_feature_indices[overlapping_voxel_feature_nonempty_mask] - 1\n    return overlapping_voxel_feature_indices_nonempty, overlapping_voxel_feature_nonempty_mask     # torch.Size([7512]);torch.Size([7732])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/voxel_aggregation_utils.py</p><span class=\'hidden-code\' data-code=\'def get_voxel_indices_to_voxel_list_index(x_conv):\n    x_conv_indices = x_conv.indices      # [11, 400, 352]->torch.Size([21177, 4]) [:,0]的范围(0-10),[:,1]的范围(1-10),[:,2]的范围(179-399),[:,3]的范围(11-351)\n    # Note that we need to offset the values by 1 since the dense representation has &amp;#39;0&amp;#39; to indicate an empty location\n    x_conv_values = torch.arange(1, x_conv_indices.shape[0]+1, device=x_conv_indices.device)      # torch.Size([21177])从1-21177\n    x_conv_shape = [x_conv.batch_size] + list(x_conv.spatial_shape)                               # [1, 11, 400, 352]\n    # x_conv_indices.T->(4,21177)  x_conv_values->(21177)    x_conv_shape=[1, 11, 400, 352]  存放的索引，存放的值，要生成稀疏张量的shape\n    # TODO: Need to convert to_dense representation. Can we use rule table instead? Can try scatter_nd in spconv too\n    x_conv_hash_table = torch.sparse_coo_tensor(x_conv_indices.T, x_conv_values, x_conv_shape, device=x_conv_indices.device).to_dense()   # torch.Size([1, 11, 400, 352])\n    return x_conv_hash_table\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/roi_head_template.py</p><span class=\'hidden-code\' data-code=\'class RoIHeadTemplate(nn.Module):\n    def proposal_layer(self, batch_dict, nms_config):\n        if batch_dict.get(&amp;#39;rois&amp;#39;, None) is not None:\n            return batch_dict  \n        batch_size = batch_dict[&amp;#39;batch_size&amp;#39;]               # 1\n        batch_box_preds = batch_dict[&amp;#39;batch_box_preds&amp;#39;]     # torch.Size([1, 211200, 7])  第一阶段生成的预测box，是真的box\n        batch_cls_preds = batch_dict[&amp;#39;batch_cls_preds&amp;#39;]     # torch.Size([1, 211200, 3])  第一阶段模型预测的类别\n        rois = batch_box_preds.new_zeros((batch_size, nms_config.NMS_POST_MAXSIZE, batch_box_preds.shape[-1]))     # torch.Size([1, 512, 7])\n        roi_scores = batch_box_preds.new_zeros((batch_size, nms_config.NMS_POST_MAXSIZE))                          # torch.Size([1, 512])\n        roi_labels = batch_box_preds.new_zeros((batch_size, nms_config.NMS_POST_MAXSIZE), dtype=torch.long)        # torch.Size([1, 512])\n        for index in range(batch_size):                    # 1\n            if batch_dict.get(&amp;#39;batch_index&amp;#39;, None) is not None:\n                assert batch_cls_preds.shape.__len__() == 2\n                batch_mask = (batch_dict[&amp;#39;batch_index&amp;#39;] == index)\n            else:\n                assert batch_dict[&amp;#39;batch_cls_preds&amp;#39;].shape.__len__() == 3\n                batch_mask = index\n            box_preds = batch_box_preds[batch_mask]       # torch.Size([211200, 7])\n            cls_preds = batch_cls_preds[batch_mask]       # torch.Size([211200, 3])\n            cur_roi_scores, cur_roi_labels = torch.max(cls_preds, dim=1)  # torch.Size([211200]；3各类别，值范围为0->2\n            if nms_config.MULTI_CLASSES_NMS:\n                raise NotImplementedError\n            else:\n                selected, selected_scores = class_agnostic_nms(                       # 对box无视类别做nms\n                    box_scores=cur_roi_scores, box_preds=box_preds, nms_config=nms_config\n                )\n            rois[index, :len(selected), :] = box_preds[selected]\n            roi_scores[index, :len(selected)] = cur_roi_scores[selected]\n            roi_labels[index, :len(selected)] = cur_roi_labels[selected]\n        batch_dict[&amp;#39;rois&amp;#39;] = rois                         # torch.Size([1, 512, 7])\n        batch_dict[&amp;#39;roi_scores&amp;#39;] = roi_scores             # torch.Size([1, 512])\n        batch_dict[&amp;#39;roi_labels&amp;#39;] = roi_labels + 1         # torch.Size([1, 512])\n        batch_dict[&amp;#39;has_class_labels&amp;#39;] = True if batch_cls_preds.shape[-1] > 1 else False  # True，有类别预测\n        batch_dict.pop(&amp;#39;batch_index&amp;#39;, None)\n        return batch_dict\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/roi_head_template.py</p><span class=\'hidden-code\' data-code=\'class RoIHeadTemplate(nn.Module):\n    def assign_targets(self, batch_dict):\n        batch_size = batch_dict[&amp;#39;batch_size&amp;#39;]\n        with torch.no_grad():\n            targets_dict = self.proposal_target_layer.`forward`(batch_dict)       # pcdet/models/roi_heads/target_assigner/proposal_target_layer.py\n        # [(&amp;#39;rois&amp;#39;, torch.Size([1, 128, 7])), (&amp;#39;gt_of_rois&amp;#39;, torch.Size([1, 128, 8])), (&amp;#39;gt_iou_of_rois&amp;#39;, torch.Size([1, 128])), (&amp;#39;roi_scores&amp;#39;, torch.Size([1, 128])), (&amp;#39;roi_labels&amp;#39;, torch.Size([1, 128])), (&amp;#39;reg_valid_mask&amp;#39;, torch.Size([1, 128])), (&amp;#39;rcnn_cls_labels&amp;#39;, torch.Size([1, 128]))]\n        rois = targets_dict[&amp;#39;rois&amp;#39;]  # (B, N, 7 + C)                            # torch.Size([1, 128, 7])  预测的\n        gt_of_rois = targets_dict[&amp;#39;gt_of_rois&amp;#39;]  # (B, N, 7 + C + 1)            # torch.Size([1, 128, 8])  匹配到的gt\n        targets_dict[&amp;#39;gt_of_rois_src&amp;#39;] = gt_of_rois.clone().detach()            # torch.Size([1, 128, 8])\n        # canonical transformation\n        roi_center = rois[:, :, 0:3]                                  # torch.Size([1, 128, 3])\n        roi_ry = rois[:, :, 6] % (2 * np.pi)                          # torch.Size([1, 128])\n        gt_of_rois[:, :, 0:3] = gt_of_rois[:, :, 0:3] - roi_center    # 匹配到的gt-预测的gt\n        gt_of_rois[:, :, 6] = gt_of_rois[:, :, 6] - roi_ry\n        # transfer LiDAR coords to local coords    pcdet/utils/common_utils.py   torch.Size([1, 128, 8])3Dbox就与角度无关了\n        gt_of_rois = common_utils.`rotate_points_along_z`(\n            points=gt_of_rois.view(-1, 1, gt_of_rois.shape[-1]), angle=-roi_ry.view(-1)\n        ).view(batch_size, -1, gt_of_rois.shape[-1])\n        # flip orientation if rois have opposite orientation\n        heading_label = gt_of_rois[:, :, 6] % (2 * np.pi)  # 0 ~ 2pi\n        opposite_flag = (heading_label `>` np.pi * 0.5) &amp; (heading_label `<` np.pi * 1.5)         # 角度在pi/2-`>`3pi/2\n        heading_label[opposite_flag] = (heading_label[opposite_flag] + np.pi) % (2 * np.pi)  # (0 ~ pi/2, 3pi/2 ~ 2pi)\n        flag = heading_label > np.pi\n        heading_label[flag] = heading_label[flag] - np.pi * 2  # (-pi/2, pi/2)  后面部分变成了(-pi/2,0)\n        heading_label = torch.clamp(heading_label, min=-np.pi / 2, max=np.pi / 2)\n        gt_of_rois[:, :, 6] = heading_label\n        targets_dict[&amp;#39;gt_of_rois&amp;#39;] = gt_of_rois      \n        return targets_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><span class=\'hidden-code\' data-code=\'class ProposalTargetLayer(nn.Module):\n    def forward(self, batch_dict):\n        batch_rois, batch_gt_of_rois, batch_roi_ious, batch_roi_scores, batch_roi_labels = self.`sample_rois_for_rcnn`(batch_dict=batch_dict)\n        # regression valid mask\n        reg_valid_mask = (batch_roi_ious > self.roi_sampler_cfg.REG_FG_THRESH).long()        # roi匹配到0.55的才算有用的torch.Size([1, 128])+0.55->torch.Size([1, 128])\n        # classification label\n        if self.roi_sampler_cfg.CLS_SCORE_TYPE == &amp;#39;cls&amp;#39;:\n            batch_cls_labels = (batch_roi_ious > self.roi_sampler_cfg.CLS_FG_THRESH).long()\n            ignore_mask = (batch_roi_ious `>` self.roi_sampler_cfg.CLS_BG_THRESH) &amp; (batch_roi_ious `<` self.roi_sampler_cfg.CLS_FG_THRESH)\n            batch_cls_labels[ignore_mask > 0] = -1\n        elif self.roi_sampler_cfg.CLS_SCORE_TYPE == &amp;#39;roi_iou&amp;#39;:               # &amp;#39;roi_iou&amp;#39;\n            iou_bg_thresh = self.roi_sampler_cfg.CLS_BG_THRESH               # 0.25\n            iou_fg_thresh = self.roi_sampler_cfg.CLS_FG_THRESH               # 0.75\n            fg_mask = batch_roi_ious > iou_fg_thresh                         # torch.Size([1, 128])\n            bg_mask = batch_roi_ious < iou_bg_thresh\n            interval_mask = (fg_mask == 0) &amp; (bg_mask == 0)\n            batch_cls_labels = (fg_mask > 0).float()                         # torch.Size([1, 128])  处于两者中间的label搞到0-1之间\n            batch_cls_labels[interval_mask] = (batch_roi_ious[interval_mask] - iou_bg_thresh) / (iou_fg_thresh - iou_bg_thresh)\n        else:\n            raise NotImplementedError\n        targets_dict = {&amp;#39;rois&amp;#39;: batch_rois, &amp;#39;gt_of_rois&amp;#39;: batch_gt_of_rois, &amp;#39;gt_iou_of_rois&amp;#39;: batch_roi_ious,\n                        &amp;#39;roi_scores&amp;#39;: batch_roi_scores, &amp;#39;roi_labels&amp;#39;: batch_roi_labels,\n                        &amp;#39;reg_valid_mask&amp;#39;: reg_valid_mask,            # roi这里只有正负样本\n                        &amp;#39;rcnn_cls_labels&amp;#39;: batch_cls_labels}\n        return targets_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><span class=\'hidden-code\' data-code=\'class ProposalTargetLayer(nn.Module):\n    def sample_rois_for_rcnn(self, batch_dict):\n        batch_size = batch_dict[&amp;#39;batch_size&amp;#39;]      # 1\n        rois = batch_dict[&amp;#39;rois&amp;#39;]                  # torch.Size([1, 512, 7])\n        roi_scores = batch_dict[&amp;#39;roi_scores&amp;#39;]      # torch.Size([1, 512])\n        roi_labels = batch_dict[&amp;#39;roi_labels&amp;#39;]      # torch.Size([1, 512])\n        gt_boxes = batch_dict[&amp;#39;gt_boxes&amp;#39;]          # torch.Size([1, 39, 8]) 为啥是8，最后维度为label\n        code_size = rois.shape[-1]\n        batch_rois = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE, code_size)               # torch.Size([1, 128, 7])\n        batch_gt_of_rois = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE, code_size + 1)     # torch.Size([1, 128, 8])\n        batch_roi_ious = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE)                      # torch.Size([1, 128])\n        batch_roi_scores = rois.new_zeros(batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE)                    # torch.Size([1, 128])\n        batch_roi_labels = rois.new_zeros((batch_size, self.roi_sampler_cfg.ROI_PER_IMAGE), dtype=torch.long)  # torch.Size([1, 128])\n \n        for index in range(batch_size):\n            cur_roi, cur_gt, cur_roi_labels, cur_roi_scores = \\\n                rois[index], gt_boxes[index], roi_labels[index], roi_scores[index]       # torch.Size([512, 7])；torch.Size([39, 8])；torch.Size([512])范围1-3；torch.Size([512])\n            k = cur_gt.__len__() - 1\n            while k >= 0 and cur_gt[k].sum() == 0:\n                k -= 1\n            cur_gt = cur_gt[:k + 1]\n            cur_gt = cur_gt.new_zeros((1, cur_gt.shape[1])) if len(cur_gt) == 0 else cur_gt\n            if self.roi_sampler_cfg.get(&amp;#39;SAMPLE_ROI_BY_EACH_CLASS&amp;#39;, False):         # True\n                max_overlaps, gt_assignment = self.`get_max_iou_with_same_class`(rois=cur_roi, roi_labels=cur_roi_labels,gt_boxes=cur_gt[:, 0:7], gt_labels=cur_gt[:, -1].long())\n            else:\n                iou3d = iou3d_nms_utils.boxes_iou3d_gpu(cur_roi, cur_gt[:, 0:7])  # (M, N)\n                max_overlaps, gt_assignment = torch.max(iou3d, dim=1)\n            sampled_inds = self.`subsample_rois`(max_overlaps=max_overlaps)        # torch.Size([128])\n            batch_rois[index] = cur_roi[sampled_inds]\n            batch_roi_labels[index] = cur_roi_labels[sampled_inds]\n            batch_roi_ious[index] = max_overlaps[sampled_inds]\n            batch_roi_scores[index] = cur_roi_scores[sampled_inds]\n            batch_gt_of_rois[index] = cur_gt[gt_assignment[sampled_inds]]        # 对应采样到的gt\n        return batch_rois, batch_gt_of_rois, batch_roi_ious, batch_roi_scores, batch_roi_labels      # torch.Size([1, 128, 7])；torch.Size([1, 128, 8])；torch.Size([1, 128])；torch.Size([1, 128])；torch.Size([1, 128])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><span class=\'hidden-code\' data-code=\'class ProposalTargetLayer(nn.Module):\n    max_overlaps = rois.new_zeros(rois.shape[0])               # torch.Size([512])\n    gt_assignment = roi_labels.new_zeros(roi_labels.shape[0])  # torch.Size([512])\n    for k in range(gt_labels.min().item(), gt_labels.max().item() + 1):\n        roi_mask = (roi_labels == k)\n        gt_mask = (gt_labels == k)\n        if roi_mask.sum() > 0 and gt_mask.sum() > 0:\n            cur_roi = rois[roi_mask]                 # torch.Size([128, 7])\n            cur_gt = gt_boxes[gt_mask]               # torch.Size([11, 7])\n            original_gt_assignment = gt_mask.nonzero().view(-1)                     # torch.Size([11])\n            iou3d = iou3d_nms_utils.boxes_iou3d_gpu(cur_roi[:, :7], cur_gt[:, :7])  # (M, N) torch.Size([128, 11])\n            cur_max_overlaps, cur_gt_assignment = torch.max(iou3d, dim=1)           # torch.Size([128])；torch.Size([128]) roi匹配到的iou值和对应的GT\n            max_overlaps[roi_mask] = cur_max_overlaps\n            gt_assignment[roi_mask] = original_gt_assignment[cur_gt_assignment]\n    return max_overlaps, gt_assignment\n\'> </span>'}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/target_assigner/proposal_target_layer.py</p><span class=\'hidden-code\' data-code=\'class ProposalTargetLayer(nn.Module):\n    def subsample_rois(self, max_overlaps):\n        # sample fg, easy_bg, hard_bg    # torch.Size([512])是512个预测的roi与gt匹配的最大iou值\n        fg_rois_per_image = int(np.round(self.roi_sampler_cfg.FG_RATIO * self.roi_sampler_cfg.ROI_PER_IMAGE))    # 0.5*128=64个作为前景？ \n        fg_thresh = min(self.roi_sampler_cfg.REG_FG_THRESH, self.roi_sampler_cfg.CLS_FG_THRESH)                  # min(0.55,0.75)=0.55\n        fg_inds = ((max_overlaps >= fg_thresh)).nonzero().view(-1)                                       # iou>0.55的0\n        easy_bg_inds = ((max_overlaps `<` self.roi_sampler_cfg.CLS_BG_THRESH_LO)).nonzero().view(-1)       # iou在0-`>`0.1之间的     torch.Size([488])\n        hard_bg_inds = ((max_overlaps `<` self.roi_sampler_cfg.REG_FG_THRESH) &amp;                            # iou在0.1-`>`0.55之间的  torch.Size([24])\n                (max_overlaps >= self.roi_sampler_cfg.CLS_BG_THRESH_LO)).nonzero().view(-1)\n        fg_num_rois = fg_inds.numel()\n        bg_num_rois = hard_bg_inds.numel() + easy_bg_inds.numel()\n        if fg_num_rois > 0 and bg_num_rois > 0:                                     # 既有前景，又有背景\n            # sampling fg               \n            fg_rois_per_this_image = min(fg_rois_per_image, fg_num_rois)            # 64，0 -0，前景最多64个\n            rand_num = torch.from_numpy(np.random.permutation(fg_num_rois)).type_as(max_overlaps).long()   # 采样前景\n            fg_inds = fg_inds[rand_num[:fg_rois_per_this_image]]\n            # sampling bg\n            bg_rois_per_this_image = self.roi_sampler_cfg.ROI_PER_IMAGE - fg_rois_per_this_image     # 采样背景\n            bg_inds = self.sample_bg_inds(hard_bg_inds, easy_bg_inds, bg_rois_per_this_image, self.roi_sampler_cfg.HARD_BG_RATIO)\n        elif fg_num_rois > 0 and bg_num_rois == 0:\n            # sampling fg 只有前景\n            rand_num = np.floor(np.random.rand(self.roi_sampler_cfg.ROI_PER_IMAGE) * fg_num_rois)\n            rand_num = torch.from_numpy(rand_num).type_as(max_overlaps).long()\n            fg_inds = fg_inds[rand_num]\n            bg_inds = fg_inds[fg_inds < 0] # yield empty tensor\n        elif bg_num_rois > 0 and fg_num_rois == 0:\n            # sampling bg  # 只有背景，没有前景\n            bg_rois_per_this_image = self.roi_sampler_cfg.ROI_PER_IMAGE\n            bg_inds = self.sample_bg_inds(hard_bg_inds, easy_bg_inds, bg_rois_per_this_image, self.roi_sampler_cfg.HARD_BG_RATIO)\n        else:\n            print(&amp;#39;maxoverlaps:(min=%f, max=%f)&amp;#39; % (max_overlaps.min().item(), max_overlaps.max().item()))\n            print(&amp;#39;ERROR: FG=%d, BG=%d&amp;#39; % (fg_num_rois, bg_num_rois))\n            raise NotImplementedError\n        sampled_inds = torch.cat((fg_inds, bg_inds), dim=0)          # torch.Size([128])前景加上背景128个\n        return sampled_inds\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/common_utils.py</p><span class=\'hidden-code\' data-code=\'def rotate_points_along_z(points, angle):\n    points, is_numpy = check_numpy_to_torch(points)\n    angle, _ = check_numpy_to_torch(angle)\n    cosa = torch.cos(angle)\n    sina = torch.sin(angle)\n    zeros = angle.new_zeros(points.shape[0])\n    ones = angle.new_ones(points.shape[0])\n    rot_matrix = torch.stack((\n        cosa,  sina, zeros,\n        -sina, cosa, zeros,\n        zeros, zeros, ones\n    ), dim=1).view(-1, 3, 3).float()\n    points_rot = torch.matmul(points[:, :, 0:3], rot_matrix)\n    points_rot = torch.cat((points_rot, points[:, :, 3:]), dim=-1)\n    return points_rot.numpy() if is_numpy else points_rot\n\'> </span>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelAggregationHead(RoIHeadTemplate):\n    def roi_grid_pool(self, batch_dict):\n        batch_size = batch_dict[&amp;#39;batch_size&amp;#39;]\n        batch_rois = batch_dict[&amp;#39;rois&amp;#39;]\n        # 128个roi，每个roi里面给6x6x6的小格子  这里得到128个roi中6x6x6的每个小格子的中心点  ；以及没有旋转和中心大为原点的原始小格子中心点\n        global_roi_grid_points, local_roi_grid_points = self.`get_global_grid_points_of_roi`(   # torch.Size([128, 216, 3]) torch.Size([128, 216, 3])\n            batch_dict, grid_size=self.model_cfg.ROI_GRID_POOL.GRID_SIZE\n        )  # (BxN, 6x6x6, 3)\n        global_roi_grid_points = global_roi_grid_points.view(batch_size, -1, 3)  # (B, Nx6x6x6, 3)  torch.Size([1, 27648, 3])\n        new_xyz = global_roi_grid_points.view(-1, 3)                             # torch.Size([27648, 3])\n \n        pooled_features_list = []\n        ball_idxs_list = []\n        for k, src_name in enumerate(self.pool_cfg.FEATURE_LOCATIONS):         # [&amp;#39;x_conv3&amp;#39;, &amp;#39;x_conv4&amp;#39;]\n            point_coords = batch_dict[&amp;#39;point_coords&amp;#39;][src_name]                # torch.Size([7512, 4])\n            point_features = batch_dict[&amp;#39;point_features&amp;#39;][src_name]            # torch.Size([7512, 64])\n            pool_layer = self.roi_grid_pool_layers[k]                          # StackSAModuleMSGAttention\n            xyz = point_coords[:, 1:4]                               # torch.Size([7512, 3])\n            xyz_batch_cnt = xyz.new_zeros(batch_size).int()          # torch.Size([1])   统计该batch有多少个rois->tensor([7512])\n            batch_idx = point_coords[:, 0]\n            for k in range(batch_size):\n                xyz_batch_cnt[k] = (batch_idx == k).sum()\n            # 体素特征层中采样，采样的是以网格点为中心，半径为r的球形区域中的体素点质心，然后基于这些体素点质心得到新的点特征（包括体素点质心的特征、体素点质心与网格点的相对距离以及使用KDE生成的当前网格点下对于体素点质心的密度估计\n            new_xyz_batch_cnt = xyz.new_zeros(batch_size).int().fill_(global_roi_grid_points.shape[1]) # tensor([27648])长度为batch的值\n            pool_output = pool_layer(                     # [torch.Size([27648, 3]), torch.Size([27648, 64])=》pooled_features, torch.Size([27648, 32])]=》ball_idxs\n                xyz=xyz.contiguous(),                     # torch.Size([7512, 3]) \n                xyz_batch_cnt=xyz_batch_cnt,\n                new_xyz=new_xyz,                          # torch.Size([27648, 3])\n                new_xyz_batch_cnt=new_xyz_batch_cnt,\n                features=point_features.contiguous(),     # torch.Size([7512, 64])\n            )  # (M1 + M2 ..., C)\n            if self.pool_cfg.get(&amp;#39;ATTENTION&amp;#39;, {}).get(&amp;#39;ENABLED&amp;#39;):\n                _, pooled_features, ball_idxs = pool_output   # torch.Size([27648, 64]), torch.Size([27648, 32])\n            else:\n                _, pooled_features = pool_output\n            pooled_features = pooled_features.view(               # torch.Size([128, 216, 64])\n                -1, self.model_cfg.ROI_GRID_POOL.GRID_SIZE ** 3,\n                pooled_features.shape[-1]\n            )  # (BxN, 6x6x6, C)\n            pooled_features_list.append(pooled_features)\n            if self.pool_cfg.get(&amp;#39;ATTENTION&amp;#39;, {}).get(&amp;#39;ENABLED&amp;#39;):        # True\n                ball_idxs = ball_idxs.view(                              # torch.Size([128, 216, 32])\n                    -1, self.model_cfg.ROI_GRID_POOL.GRID_SIZE **3,\n                    ball_idxs.shape[-1]\n                )\n                ball_idxs_list.append(ball_idxs)\n        all_pooled_features = torch.cat(pooled_features_list, dim=-1)        # torch.Size([128, 216, 128])\n        if self.pool_cfg.get(&amp;#39;ATTENTION&amp;#39;, {}).get(&amp;#39;ENABLED&amp;#39;):\n            all_ball_idxs = torch.cat(ball_idxs_list, dim=-1)                # torch.Size([128, 216, 64])\n        else:\n            all_ball_idxs = []\n        return all_pooled_features, global_roi_grid_points, local_roi_grid_points, all_ball_idxs  # torch.Size([128, 216, 128]),torch.Size([1, 27648, 3]),torch.Size([128, 216, 3]),torch.Size([128, 216, 64])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelAggregationHead(RoIHeadTemplate):\n    def get_global_grid_points_of_roi(self, batch_dict, grid_size):   # 6\n        rois = batch_dict[&amp;#39;rois&amp;#39;]              # torch.Size([1, 128, 7])预测的roi\n        rois = rois.view(-1, rois.shape[-1])   # torch.Size([128, 7])\n        batch_size_rcnn = rois.shape[0]        # 128\n        local_roi_grid_points = self.`get_dense_grid_points`(rois, batch_size_rcnn, grid_size)  # torch.Size([128, 7])+128+6->(B, 6x6x6, 3)\n        global_roi_grid_points = common_utils.`rotate_points_along_z`(         # torch.Size([128, 216, 3]) 所有的点沿着角度旋转\n            local_roi_grid_points.clone(), rois[:, 6]\n        ).squeeze(dim=1)\n        global_center = rois[:, 0:3].clone()\n        global_roi_grid_points += global_center.unsqueeze(dim=1)     # 再加上中心点  \n        return global_roi_grid_points, local_roi_grid_points\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelAggregationHead(RoIHeadTemplate):\n    def get_dense_grid_points(rois, batch_size_rcnn, grid_size):\n        faked_features = rois.new_ones((grid_size, grid_size, grid_size))       # torch.Size([6, 6, 6])\n        dense_idx = faked_features.nonzero()  # (N, 3) [x_idx, y_idx, z_idx]    # torch.Size([216, 3]) dense_idx[0]=[0,0,0],dense_idx[-1]=[5,5,5]\n        dense_idx = dense_idx.repeat(batch_size_rcnn, 1, 1).float()             # (B, 6x6x6, 3)\n        # torch.Size([128, 3])长宽高将设对一个(1,2,3)的做计算：roi_grid_points[0]=(-0.4167,-0.8333,-1.25) roi_grid_points[-1]=(0.4167,0.8333,1.25) \n        local_roi_size = rois.view(batch_size_rcnn, -1)[:, 3:6]                 \n        roi_grid_points = (dense_idx + 0.5) / grid_size * local_roi_size.unsqueeze(dim=1) - (local_roi_size.unsqueeze(dim=1) / 2)  # (B, 6x6x6, 3)  # 根据长宽高把roi3Dbox分成6x6x6分\n        return roi_grid_points\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/common_utils.py</p><span class=\'hidden-code\' data-code=\'def rotate_points_along_z(points, angle):\n    points, is_numpy = check_numpy_to_torch(points)\n    angle, _ = check_numpy_to_torch(angle)\n    cosa = torch.cos(angle)\n    sina = torch.sin(angle)\n    zeros = angle.new_zeros(points.shape[0])\n    ones = angle.new_ones(points.shape[0])\n    rot_matrix = torch.stack((\n        cosa,  sina, zeros,\n        -sina, cosa, zeros,\n        zeros, zeros, ones\n    ), dim=1).view(-1, 3, 3).float()\n    points_rot = torch.matmul(points[:, :, 0:3], rot_matrix)\n    points_rot = torch.cat((points_rot, points[:, :, 3:]), dim=-1)\n    return points_rot.numpy() if is_numpy else points_rot\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/pdv_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelAggregationHead(RoIHeadTemplate):\n    def get_positional_input(self, points, rois, local_roi_grid_points):     # torch.Size([22969, 5]); torch.Size([1, 128, 7]); torch.Size([128, 216, 3])\n        points_per_part = density_utils.`find_num_points_per_part_multi`(points,                                       # torch.Size([1, 128, 6, 6, 6])\n                                                                       rois,\n                                                                       self.model_cfg.ROI_GRID_POOL.GRID_SIZE,         # 6\n                                                                       self.pool_cfg.ATTENTION.MAX_NUM_BOXES,          # 20\n                                                                       return_centroid=self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == &amp;#39;density_centroid&amp;#39;)\n        points_per_part_num_features = 1 if len(points_per_part.shape) <= 5 else points_per_part.shape[-1]          # 1\n        points_per_part = points_per_part.view(points_per_part.shape[0]*points_per_part.shape[1], -1, points_per_part_num_features).float()  # torch.Size([128, 216, 1])\n        # First feature is density, other potential features are xyz\n        points_per_part[..., 0] = torch.log10(points_per_part[..., 0] + 0.5) - (math.log10(0.5) if self.model_cfg.get(&amp;#39;DENSITY_LOG_SHIFT&amp;#39;) else 0)\n        if self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == &amp;#39;grid_points&amp;#39;:\n            positional_input = local_roi_grid_points\n        elif self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == &amp;#39;density&amp;#39;:\n            positional_input = points_per_part\n        elif self.pool_cfg.ATTENTION.POSITIONAL_ENCODER == &amp;#39;density_grid_points&amp;#39;:\n            positional_input = torch.cat((local_roi_grid_points, points_per_part), dim=-1)  # torch.Size([128, 216, 4])\n        else:\n            positional_input = None\n        return positional_input\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/density_utils.py</p><span class=\'hidden-code\' data-code=\'def find_num_points_per_part_multi(batch_points, batch_boxes, grid_size, max_num_boxes, return_centroid=False): # torch.Size([22969, 5]),torch.Size([1, 128, 7]),6,20,False\n    batch_idx = batch_points[:, 0]\n    batch_points = batch_points[:, 1:4]\n    points_per_parts = []\n    for i in range(batch_boxes.shape[0]):\n        boxes = batch_boxes[i]                   # torch.Size([128, 7])\n        bs_mask = (batch_idx == i)               # torch.Size([128, 7])\n        points = batch_points[bs_mask]           # torch.Size([22969, 3])\n        box_idxs_of_pts = roiaware_pool3d_utils.`points_in_multi_boxes_gpu`(points.unsqueeze(0), boxes.unsqueeze(0), max_num_boxes).squeeze(0)  # torch.Size([22969, 20])\n        box_for_each_point = boxes[box_idxs_of_pts.long()]                 # torch.Size([22969, 20, 7])\n        xyz_local = points.unsqueeze(1) - box_for_each_point[..., 0:3]     # torch.Size([22969, 20, 3])\n        xyz_local_original_shape = xyz_local.shape\n        xyz_local = xyz_local.reshape(-1, 1, 3)                            # torch.Size([459380, 1, 3])\n        # Flatten for rotating points            # 为什么翻转？ torch.Size([459380, 1, 3])\n        xyz_local = common_utils.`rotate_points_along_z`(\n            xyz_local, -box_for_each_point.reshape(-1, 7)[:, 6]\n        )\n        # Change coordinate frame to corner instead of center of box\n        xyz_local_corner = xyz_local.reshape(xyz_local_original_shape) + box_for_each_point[..., 3:6] / 2      # torch.Size([22969, 20, 3])\n        # points_in_boxes_gpu gets points slightly outside of box, clamp values to make sure no out of index values\n        xyz_local_grid = (xyz_local_corner / (box_for_each_point[..., 3:6] / grid_size))                       # torch.Size([22969, 20, 3])\n        points_out_of_range = ((xyz_local_grid `<` 0) | (xyz_local_grid `>`= grid_size) | (xyz_local_grid.isnan())).any(-1).flatten()   # torch.Size([459380])=22969x20\n        xyz_local_grid = torch.cat((box_idxs_of_pts.unsqueeze(-1),xyz_local_grid), dim=-1).long()              # torch.Size([22969, 20, 4])\n        xyz_local_grid = xyz_local_grid.reshape(-1, xyz_local_grid.shape[-1])      # torch.Size([459380, 4])\n        # Filter based on valid box_idxs\n        valid_points_mask = (xyz_local_grid[:, 0] != -1) &amp; (~points_out_of_range)  # torch.Size([459380])\n        xyz_local_grid = xyz_local_grid[valid_points_mask]                         # torch.Size([18946, 4])\n        if return_centroid:\n            ......\n        else:\n            part_idxs, points_per_part = xyz_local_grid.unique(dim=0, return_counts=True)      # torch.Size([4526, 4]);torch.Size([4526])\n            # Sometimes no points in boxes, usually in the first few iterations. Return empty tensor in that case\n            if part_idxs.shape[0] == 0:\n                points_per_part_dense = torch.zeros((boxes.shape[0], grid_size, grid_size, grid_size), dtype=points_per_part.dtype, device=points.device)\n            else:\n                points_per_part_dense = torch.sparse_coo_tensor(part_idxs.T, points_per_part, size=(boxes.shape[0], grid_size, grid_size, grid_size)).to_dense()  # torch.Size([128, 6, 6, 6])\n        points_per_parts.append(points_per_part_dense)     # [torch.Size([128, 6, 6, 6])]\n    return torch.stack(points_per_parts)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py</p><span class=\'hidden-code\' data-code=\'def points_in_multi_boxes_gpu(points, boxes, max_num_boxes):\n    assert boxes.shape[0] == points.shape[0]\n    assert boxes.shape[2] == 7 and points.shape[2] == 3\n    batch_size, num_points, _ = points.shape       # 1,22969\n    box_idxs_of_pts = points.new_zeros((batch_size, num_points, max_num_boxes), dtype=torch.int).fill_(-1)   # (1,22969,20)\n    roiaware_pool3d_cuda.points_in_multi_boxes_gpu(boxes.contiguous(), points.contiguous(), box_idxs_of_pts, max_num_boxes)\n    return box_idxs_of_pts\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/attention_utils.py</p><span class=\'hidden-code\' data-code=\'class TransformerEncoder(nn.Module):\n    def forward(self, point_features, positional_input, src_key_padding_mask=None): # torch.Size([128, 216, 128]),torch.Size([128, 216, 4]),torch.Size([128, 216])\n        # Clone point features to prevent mutating input arguments\n        attended_features = torch.clone(point_features)\n        if src_key_padding_mask is not None:\n            empty_rois_mask = src_key_padding_mask.all(-1)                              # torch.Size([128])\n            attended_features_filtered = attended_features[~empty_rois_mask]            # torch.Size([128, 216, 128])\n            if self.pos_encoder is not None:                                            # FeedForwardPositionalEncoding\n                src_key_padding_mask_filtered = src_key_padding_mask[~empty_rois_mask]  # torch.Size([128, 216])\n                attended_features_filtered[~src_key_padding_mask_filtered] = self.pos_encoder(attended_features_filtered,\n                                                                                              positional_input[~empty_rois_mask] if positional_input is not None else None)[~src_key_padding_mask_filtered]\n            # (b, xyz, f) -> (xyz, b, f)\n            attended_features_filtered = attended_features_filtered.permute(1, 0, 2)    # torch.Size([128, 216, 128])->torch.Size([216, 128, 128])\n            # (xyz, b, f) -> (b, xyz, f)\n            attended_features[~empty_rois_mask] = self.transformer_encoder(attended_features_filtered,\n                                                                           src_key_padding_mask=src_key_padding_mask[~empty_rois_mask]).permute(1, 0, 2).contiguous()\n        else:\n            ......\n        return attended_features\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/roi_heads/roi_head_template.py</p><span class=\'hidden-code\' data-code=\'class RoIHeadTemplate(nn.Module):\n    def generate_predicted_boxes(self, batch_size, rois, cls_preds, box_preds):  # 1,torch.Size([1, 128, 7]),torch.Size([1, 128, 7]),None,torch.Size([128, 7])\n        code_size = self.box_coder.code_size    # 7\n        # batch_cls_preds: (B, N, num_class or 1)\n        if cls_preds is None:\n            batch_cls_preds = None\n        else:\n            batch_cls_preds = cls_preds.view(batch_size, -1, cls_preds.shape[-1])\n        batch_box_preds = box_preds.view(batch_size, -1, code_size)         # torch.Size([1, 128, 7])\n        roi_ry = rois[:, :, 6].view(-1)                     # torch.Size([128])\n        roi_xyz = rois[:, :, 0:3].view(-1, 3)               # torch.Size([128,7])\n        local_rois = rois.clone().detach()\n        local_rois[:, :, 0:3] = 0\n        batch_box_preds = self.box_coder.decode_torch(batch_box_preds, local_rois).view(-1, code_size)  # torch.Size([128, 7])\n        batch_box_preds = common_utils.rotate_points_along_z(batch_box_preds.unsqueeze(dim=1), roi_ry).squeeze(dim=1)\n        batch_box_preds[:, 0:3] += roi_xyz                 # torch.Size([128, 7])\n        batch_box_preds = batch_box_preds.view(batch_size, -1, code_size)\n        return batch_cls_preds, batch_box_preds            # None,torch.Size([1,128, 7])\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/density_utils.py</p><span class=\'hidden-code\' data-code=\'def find_num_points_per_part_multi(batch_points, batch_boxes, grid_size, max_num_boxes, return_centroid=False): # torch.Size([22969, 5]),torch.Size([1, 128, 7]),1,20,False\n    batch_idx = batch_points[:, 0]\n    batch_points = batch_points[:, 1:4]\n    points_per_parts = []\n    for i in range(batch_boxes.shape[0]):\n        boxes = batch_boxes[i]                   # torch.Size([128, 7])\n        bs_mask = (batch_idx == i)               # torch.Size([22969])\n        points = batch_points[bs_mask]           # torch.Size([22969, 3])\n        box_idxs_of_pts = roiaware_pool3d_utils.`points_in_multi_boxes_gpu`(points.unsqueeze(0), boxes.unsqueeze(0), max_num_boxes).squeeze(0)  # torch.Size([22969, 20])  22969最多在20个box里面，这里记录box的索引\n        box_for_each_point = boxes[box_idxs_of_pts.long()]                 # torch.Size([22969, 20, 7])       就是每个点给其配20个box\n        xyz_local = points.unsqueeze(1) - box_for_each_point[..., 0:3]     # torch.Size([22969, 20, 3])\n        xyz_local_original_shape = xyz_local.shape\n        xyz_local = xyz_local.reshape(-1, 1, 3)                            # torch.Size([459380, 1, 3])       以box为中心的点\n        # Flatten for rotating points            # 为什么翻转？ torch.Size([459380, 1, 3])\n        xyz_local = common_utils.rotate_points_along_z(\n            xyz_local, -box_for_each_point.reshape(-1, 7)[:, 6]\n        )\n        # Change coordinate frame to corner instead of center of box\n        xyz_local_corner = xyz_local.reshape(xyz_local_original_shape) + box_for_each_point[..., 3:6] / 2      # torch.Size([22969, 20, 3])   中心点从 box中心点为中心点 改成了 长宽高一半为中心点\n        # points_in_boxes_gpu gets points slightly outside of box, clamp values to make sure no out of index values\n        xyz_local_grid = (xyz_local_corner / (box_for_each_point[..., 3:6] / grid_size))                       # torch.Size([22969, 20, 3])   归一化\n        points_out_of_range = ((xyz_local_grid `<` 0) | (xyz_local_grid `>`= grid_size) | (xyz_local_grid.isnan())).any(-1).flatten()   # torch.Size([459380])=22969x20\n        xyz_local_grid = torch.cat((box_idxs_of_pts.unsqueeze(-1),xyz_local_grid), dim=-1).long()              # torch.Size([22969, 20, 4])   第0维是哪个box\n        xyz_local_grid = xyz_local_grid.reshape(-1, xyz_local_grid.shape[-1])      # torch.Size([19572, 4])\n        # Filter based on valid box_idxs\n        valid_points_mask = (xyz_local_grid[:, 0] != -1) &amp; (~points_out_of_range)  # torch.Size([459380])\n        xyz_local_grid = xyz_local_grid[valid_points_mask]                         # torch.Size([19572, 4])     # 去掉-1不是box的点\n        if return_centroid:\n            ......\n        else:\n            part_idxs, points_per_part = xyz_local_grid.unique(dim=0, return_counts=True)      # torch.Size([127, 4]);torch.Size([127])\n            # Sometimes no points in boxes, usually in the first few iterations. Return empty tensor in that case\n            if part_idxs.shape[0] == 0:\n                points_per_part_dense = torch.zeros((boxes.shape[0], grid_size, grid_size, grid_size), dtype=points_per_part.dtype, device=points.device)\n            else:\n                points_per_part_dense = torch.sparse_coo_tensor(part_idxs.T, points_per_part, size=(boxes.shape[0], grid_size, grid_size, grid_size)).to_dense()  # torch.Size([128, 1, 1, 1])\n        points_per_parts.append(points_per_part_dense)     # [torch.Size([128, 6, 6, 6])]\n    return torch.stack(points_per_parts)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py</p><span class=\'hidden-code\' data-code=\'def points_in_multi_boxes_gpu(points, boxes, max_num_boxes):\n    assert boxes.shape[0] == points.shape[0]\n    assert boxes.shape[2] == 7 and points.shape[2] == 3\n    batch_size, num_points, _ = points.shape       # 1,22969\n    box_idxs_of_pts = points.new_zeros((batch_size, num_points, max_num_boxes), dtype=torch.int).fill_(-1)   # (1,22969,20)   最后得到的结果\n    roiaware_pool3d_cuda.points_in_multi_boxes_gpu(boxes.contiguous(), points.contiguous(), box_idxs_of_pts, max_num_boxes)\n    return box_idxs_of_pts\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/roiaware_pool3d/src/roiaware_pool3d_kernel.cu</p><span class=\'hidden-code\' data-code=\'__global__ void points_in_boxes_kernel(int batch_size, int boxes_num, int pts_num, const float *boxes,const float *pts, int *box_idx_of_points){\n    // params boxes: (B, N, 7) [x, y, z, dx, dy, dz, heading] (x, y, z) is the box center\n    // params pts: (B, npoints, 3) [x, y, z] in LiDAR coordinate\n    // params boxes_idx_of_points: (B, npoints), default -1\n    int bs_idx = blockIdx.y;\n    int pt_idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (bs_idx >= batch_size || pt_idx >= pts_num) return;\n    boxes += bs_idx * boxes_num * 7;\n    pts += bs_idx * pts_num * 3 + pt_idx * 3;\n    box_idx_of_points += bs_idx * pts_num + pt_idx;\n    float local_x = 0, local_y = 0;\n    int cur_in_flag = 0;\n    for (int k = 0; k < boxes_num; k++){\n        cur_in_flag = check_pt_in_box3d(pts, boxes + k * 7, local_x, local_y);   // 判断该点云是不是在box里面\n        if (cur_in_flag){\n            box_idx_of_points[0] = k;                                            // 点云在box里面的话，值为哪个box\n            break;\n        }\n    }\n}\n\'> </span>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/pdv.py：loss计算</p><span class=\'hidden-code\' data-code=\'class PDV(Detector3DTemplate):\n    def __init__(self, model_cfg, num_class, dataset):\n        super().__init__(model_cfg=model_cfg, num_class=num_class, dataset=dataset)\n        self.module_list = self.build_networks()\n    def forward(self, batch_dict):\n        for cur_module in self.module_list:\n            batch_dict = cur_module(batch_dict)\n        if self.training:\n            loss, tb_dict, disp_dict = self.get_training_loss()\n            ret_dict = {\n                &amp;#39;loss&amp;#39;: loss\n            }\n            return ret_dict, tb_dict, disp_dict\n        else:\n            pred_dicts, recall_dicts = self.post_processing(batch_dict)\n            return pred_dicts, recall_dicts\n    def get_training_loss(self):\n        disp_dict = {}\n        loss_rpn, tb_dict = self.dense_head.`get_loss`()\n        loss_rcnn, tb_dict = self.roi_head.`get_loss`(tb_dict)\n        loss = loss_rpn + loss_rcnn\n        return loss, tb_dict, disp_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><span class=\'hidden-code\' data-code=\'class AnchorHeadTemplate(nn.Module):\n    def get_loss(self):\n        cls_loss, tb_dict = self.`get_cls_layer_loss`()\n        box_loss, tb_dict_box = self.`get_box_reg_layer_loss`()\n        tb_dict.update(tb_dict_box)\n        rpn_loss = cls_loss + box_loss\n        tb_dict[&amp;#39;rpn_loss&amp;#39;] = rpn_loss.item()\n        return rpn_loss, tb_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/anchor_head_template.py</p><span class=\'hidden-code\' data-code=\'class AnchorHeadTemplate(nn.Module):\n\'> </span>'}]}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
