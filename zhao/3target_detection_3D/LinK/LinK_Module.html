<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>LinK_Module</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">TSELKBlock</p><font size="0"><pre class="language-python"><code class="language-python">class TSELKBlock(nn.Module):\n    def forward(self, sct: spconv.SparseConvTensor, stride):\n        st, sct_save = <span style=\'color: green;font-weight: bold;\'>spconv2ts</span>(sct)            <span style=\'color: red\'>[41, 1440, 1440]</span>\n        new_st = self.<span style=\'color: green;font-weight: bold;\'>forward_</span>(st, stride)\n        new_sct = <span style=\'color: green;font-weight: bold;\'>ts2spconv</span>(new_st, sct_save)\n        return new_sct\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">spconv2ts</p><font size="0"><pre class="language-python"><code class="language-python">def spconv2ts(sct: spconv.SparseConvTensor):\n    feats = sct.features                                        <span style=\'color: red\'># torch.Size([137566, 16])</span>\n    coords = torch.index_select(sct.indices, 1,                 <span style=\'color: red\'># torch.Size([137566, 4])->(B,Z,Y,Z)=>(X,Y,Z,B)?</span>\n             torch.LongTensor([3,2,1,0]).to(sct.indices.device)).contiguous()\n    st = SparseTensor(feats, coords, 1)                         <span style=\'color: red\'># 这里将自带的tensor转变到torchsparse的tensor</span>\n    sct_save = dict()\n    sct_save[\'batch_size\'] = sct.batch_size                     <span style=\'color: red\'># 2</span>\n    sct_save[\'benchmark\'] = sct.benchmark                       <span style=\'color: red\'># False</span>\n    sct_save[\'benchmark_record\'] = sct.benchmark_record         <span style=\'color: red\'># {}</span>\n    sct_save[\'grid\'] = sct.grid                                 <span style=\'color: red\'># tensor([])</span>\n    sct_save[\'indice_dict\'] = sct.indice_dict                   <span style=\'color: red\'># {\'res0\': <spconv.pytorch.core...8910bc4f0>}</span>\n    sct_save[\'spatial_shape\'] = sct.spatial_shape               <span style=\'color: red\'># [41, 1440, 1440]</span>\n    sct_save[\'voxel_num\'] = sct.voxel_num                       <span style=\'color: red\'># None</span>\n    return st, sct_save\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">TSELKBlock-forward_</p><font size="0"><pre class="language-python"><code class="language-python">class TSELKBlock(nn.Module):\n    def forward_(self, st: SparseTensor, stride):\n        F_input = self.pre_mix(st.F)       <span style=\'color: red\'># Linear+LayerNorm => st.F=torch.Size([137566, 16]) -> torch.Size([137566, 16])</span>\n        local_mix = self.local_mix(st)     <span style=\'color: red\'># spnn.Conv3d(self.inc, self.inc, kernel_size=3, dilation=1,stride=1)</span>\n        if self.baseop == \'sin\':\n            ......\n        elif self.baseop == \'cos\':\n            pos_weight = self.pos_weight(st.C[:,:3].float())              <span style=\'color: red\'># torch.Size([137566, 4])  坐标用3维变成16维--》torch.Size([137566, 16])</span>\n            pos_weight = pos_weight[:,:self.inc//2].repeat([1,2])         <span style=\'color: red\'># channel grouping  torch.Size([137566, 8])->torch.Size([137566, 16])沿着第二维重复</span>\n            pos_weight_sin = torch.sin(pos_weight)                        <span style=\'color: red\'># torch.Size([137566, 16])</span>\n            pos_weight_cos = torch.cos(pos_weight)                        <span style=\'color: red\'># torch.Size([137566, 16])</span>\n            F_weighted_sin = F_input*pos_weight_sin                       <span style=\'color: red\'># torch.Size([137566, 16])</span>\n            F_weighted_cos = F_input*pos_weight_cos\n            st.F = torch.cat([F_weighted_cos, F_weighted_sin], dim=1).contiguous()     <span style=\'color: red\'># torch.Size([137566, 32])     K^(0)(a)*f_a+k^(1)(a)*f_a</span>\n            small_st, idx, counts = <span style=\'color: green;font-weight: bold;\'>large_to_small</span>(st, stride=stride)    <span style=\'color: red\'># 应该是7x7下采样得到新的tensor</span>\n            large_st = <span style=\'color: green;font-weight: bold;\'>small_to_large_v2</span>(small_st, st, idx, counts)      <span style=\'color: red\'># torch.Size([137566, 32])</span>\n            new_st_F = large_st.F[:,:self.inc]*pos_weight_cos + large_st.F[:,self.inc:]*pos_weight_sin  <span style=\'color: red\'># self.inc=16; -->torch.Size([137566, 16])</span>\n        elif self.baseop == \'cos_x_alpha\':\n            ......\n        elif self.baseop == \'cos_sin\':\n            ......\n        elif self.baseop == \'x\':\n            ......\n        new_st_F = self.norm(new_st_F)\n        local_F = self.norm_local(local_mix.F)\n        new_st_F = self.activate(new_st_F+local_F)\n        large_st.F = new_st_F\n        return large_st\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">large_to_small</p><font size="0"><pre class="language-python"><code class="language-python"><span style=\'color: red\'># x: SparseTensor->large, stride: scale of kernel </span>\n<span style=\'color: red\'># return : SparseTensor->small</span>\ndef large_to_small(large_x, stride):              <span style=\'color: red\'># torch.Size([137566, 32])，7  分成7快大小s</span>\n    x_C = torch.cat([torch.div(large_x.C[:,:3], stride, rounding_mode=\'floor\').int(), large_x.C[:,3:]], dim=1)   <span style=\'color: red\'># 相当于把x,y,z的位置除以7，可能有不同的点下采样到同一个点  torch.Size([137566, 4])</span>\n    large_x_hash = F.sphash(x_C.to(large_x.F.device))                      <span style=\'color: red\'># torch.Size([137566])</span>\n    small_x_C = torch.unique(x_C, dim=0)                                   <span style=\'color: red\'># torch.Size([13740, 4])</span>\n    small_x_hash = F.sphash(small_x_C.to(large_x.F.device))                <span style=\'color: red\'># torch.Size([13740])</span>\n    idx_query = F.sphashquery(large_x_hash, small_x_hash)                  <span style=\'color: red\'># torch.Size([137566])</span>\n    counts = F.spcount(idx_query.int(), len(small_x_hash))                 <span style=\'color: red\'># torch.Size([13740])</span>\n    inserted_feat = F.spvoxelize(large_x.F, idx_query, counts)\n    small_x = SparseTensor(inserted_feat, small_x_C, stride)\n    small_x.cmaps = large_x.cmaps\n    small_x.kmaps = large_x.kmaps\n    return small_x, idx_query, counts\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">small_to_large_v2</p><font size="0"><pre class="language-python"><code class="language-python"><span style=\'color: red\'># F.sphash()是一个函数，用于将一个点云的坐标和特征编码成一个哈希表。这个哈希表存储了点云中每个点的坐标和特征信息，以及这些点在原始点云中的索引。它使用了点云的体素化方法，将空间分成了许多小的体素，每个体素内部存储其内包含的点的信息。</span>\n<span style=\'color: red\'># 这种压缩方式可以大大减少点云的存储空间，并且可以加速点云的相关计算，如点云分割和物体检测。</span>\ndef small_to_large_v2(small_x, large_x, idx, counts):\n    <span style=\'color: red\'># local offsets to index neighbors</span>\n    ## [2^3,3]\n    kernel_size = 3\n    offsets = get_kernel_offsets(kernel_size, 1, 1, device=large_x.F.device)   <span style=\'color: red\'># torch.Size([27, 3])</span>\n    neighbor_hash = F.sphash(                                                  <span style=\'color: red\'># torch.Size([13740, 4]) + torch.Size([27, 3])  torch.Size([27, 13740])</span>\n        small_x.C, offsets \n    )                          \n    small_hash = F.sphash(small_x.C.to(large_x.F.device))                      <span style=\'color: red\'># torch.Size([13740])</span>\n    idx_query = F.sphashquery(neighbor_hash, small_hash)                       <span style=\'color: red\'># torch.Size([27, 13740])    </span>\n    idx_query = idx_query.transpose(0,1).contiguous()                          <span style=\'color: red\'># torch.Size([13740, 27])</span>\n    idx_query_flat = idx_query.view(-1)\n    f = torch.cat([small_x.F, torch.ones_like(small_x.F[:,:1]).to(small_x.F.device)], dim=1)   <span style=\'color: red\'># torch.Size([13740, 32])+torch.Size([13740, 1])->torch.Size([13740, 33])</span>\n    f = f*counts.unsqueeze(dim=-1)                                                             <span style=\'color: red\'># torch.Size([13740, 33])</span>\n    weights = torch.ones(small_x.F.shape[0], kernel_size**3).to(small_x.F.device).float()      <span style=\'color: red\'># torch.Size([13740, 27])</span>\n    weights[idx_query == -1] = 0\n    new_feat = F.spdevoxelize(f, idx_query, weights, kernel_size)              <span style=\'color: red\'># torch.Size([13740, 33])</span>\n    new_feat = new_feat[:,:-1] / new_feat[:,-1:]                               <span style=\'color: red\'># torch.Size([13740, 32])</span>\n    large_x.F = new_feat[idx]                                                  <span style=\'color: red\'># large_x.F.shape = torch.Size([137566, 32])   idx.shape=torch.Size([137566])</span>\n    return large_x\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">ts2spconv</p><font size="0"><pre class="language-python"><code class="language-python">def ts2spconv(st: SparseTensor, sct_save: dict):\n    features = st.feats                                       <span style=\'color: red\'># torch.Size([137566, 16])</span>\n    indices = torch.index_select(st.coords, 1, torch.LongTensor([3,2,1,0]).to(st.coords.device)).contiguous()\n    sct = spconv.SparseConvTensor(features,indices,\n                spatial_shape=sct_save[\'spatial_shape\'],      <span style=\'color: red\'># [41, 1440, 1440]</span>\n                batch_size=sct_save[\'batch_size\'],\n                grid=sct_save[\'grid\'],\n                voxel_num=sct_save[\'voxel_num\'],\n                indice_dict=sct_save[\'indice_dict\'],\n                benchmark=sct_save[\'benchmark\']\n    )\n    sct.benchmark_record = sct_save[\'benchmark_record\']\n    return sct\n</code></pre></font>'}]}]})</script></body>
</html>
