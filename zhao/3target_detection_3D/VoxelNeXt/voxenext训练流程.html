<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>voxenext训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py-训练流程</p><span class=\'hidden-code\' data-code=\'class VoxelNeXt(Detector3DTemplate):\n    def forward(self, batch_dict):      dict_keys([&amp;#39;points&amp;#39;, &amp;#39;frame_id&amp;#39;, &amp;#39;metadata&amp;#39;, &amp;#39;gt_boxes&amp;#39;, &amp;#39;flip_x&amp;#39;, &amp;#39;flip_y&amp;#39;, &amp;#39;noise_rot&amp;#39;, \n                                    &amp;#39;noise_scale&amp;#39;, &amp;#39;use_lead_xyz&amp;#39;, &amp;#39;voxels&amp;#39;, &amp;#39;voxel_coords&amp;#39;, &amp;#39;voxel_num_points&amp;#39;, &amp;#39;batch_size&amp;#39;])\n        for cur_module in self.module_list:           MeanVFE();VoxelResBackBone8xVoxelNeXt();VoxelNeXtHead\n            batch_dict = cur_module(batch_dict)\n        if self.training:\n            loss, tb_dict, disp_dict = self.`get_training_loss`()\n            ret_dict = {&amp;#39;loss&amp;#39;: loss}\n            return ret_dict, tb_dict, disp_dict\n        else:\n            pred_dicts, recall_dicts = self.post_processing(batch_dict)\n            return pred_dicts, recall_dicts\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/vfe/mean_vfe.py</p><span class=\'hidden-code\' data-code=\'class MeanVFE(VFETemplate):\n    def forward(self, batch_dict, **kwargs):\n        voxel_features, voxel_num_points = batch_dict[&amp;#39;voxels&amp;#39;], batch_dict[&amp;#39;voxel_num_points&amp;#39;]  # torch.Size([386474, 10, 5]);torch.Size([386474])\n        points_mean = voxel_features[:, :, :].sum(dim=1, keepdim=False)        \n        normalizer = torch.clamp_min(voxel_num_points.view(-1, 1), min=1.0).type_as(voxel_features)\n        points_mean = points_mean / normalizer\n        batch_dict[&amp;#39;voxel_features&amp;#39;] = points_mean.contiguous()       # torch.Size([386474, 5])\n        return batch_dict\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/spconv_backbone_voxelnext.py</p><span class=\'hidden-code\' data-code=\'class VoxelResBackBone8xVoxelNeXt(nn.Module):\n    def forward(self, batch_dict):\n        voxel_features, voxel_coords = batch_dict[&amp;#39;voxel_features&amp;#39;], batch_dict[&amp;#39;voxel_coords&amp;#39;]  # torch.Size([386474, 5]),torch.Size([386474, 4])\n        batch_size = batch_dict[&amp;#39;batch_size&amp;#39;]\n        input_sp_tensor = spconv.SparseConvTensor(\n            features=voxel_features,\n            indices=voxel_coords.int(),\n            spatial_shape=self.sparse_shape,        # [41, 1440, 1440]\n            batch_size=batch_size\n        )\n        x = self.conv_input(input_sp_tensor)     # [41, 1440, 1440]   torch.Size([386474, 4]),B,z,x,y\n        x_conv1 = self.conv1(x)              # [41, 1440, 1440] \n        x_conv2 = self.conv2(x_conv1)        # [21, 720, 720]    [(torch.min(x_conv3.indices[:,i]).item(),torch.max(x_conv3.indices[:,i]).item()) for i in range(4)]\n        x_conv3 = self.conv3(x_conv2)        # [11, 360, 360]      [(0, 3), (1, 10), (0, 359), (0, 359)]\n        x_conv4 = self.conv4(x_conv3)        # [6, 180, 180]       [(0, 3), (0, 5), (0, 179), (0, 179)]\n        x_conv5 = self.conv5(x_conv4)        # [3, 90, 90]\n        x_conv6 = self.conv6(x_conv5)        # [2, 45, 45]\n        x_conv5.indices[:, 1:] *= 2\n        x_conv6.indices[:, 1:] *= 4\n        # cat结果为(95490,128)的维度特征; x_conv4为(68725,128)的维度特征；\n        x_conv4 = x_conv4.replace_feature(torch.cat([x_conv4.features, x_conv5.features, x_conv6.features]))     # torch.Size([95490, 128])\n        x_conv4.indices = torch.cat([x_conv4.indices, x_conv5.indices, x_conv6.indices])      # 相当于把x_conv5和x_conv6的特征上采样到x_conv4\n        out = self.`bev_out`(x_conv4)       # [180, 180]\n        out = self.conv_out(out)         # [180, 180] + torch.Size([48666, 128])\n        out = self.shared_conv(out)      # [180, 180] + torch.Size([48666, 128])\n        batch_dict.update({\n            &amp;#39;encoded_spconv_tensor&amp;#39;: out,\n            &amp;#39;encoded_spconv_tensor_stride&amp;#39;: 8      # 8*180=1440\n        })\n        batch_dict.update({\n            &amp;#39;multi_scale_3d_features&amp;#39;: {&amp;#39;x_conv1&amp;#39;: x_conv1,&amp;#39;x_conv2&amp;#39;: x_conv2,&amp;#39;x_conv3&amp;#39;: x_conv3,&amp;#39;x_conv4&amp;#39;: x_conv4,}\n        })\n        batch_dict.update({\n            &amp;#39;multi_scale_3d_strides&amp;#39;: {&amp;#39;x_conv1&amp;#39;: 1,&amp;#39;x_conv2&amp;#39;: 2,&amp;#39;x_conv3&amp;#39;: 4,&amp;#39;x_conv4&amp;#39;: 8,}\n        })\n        return batch_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/spconv_backbone_voxelnext.py</p><span class=\'hidden-code\' data-code=\'class VoxelResBackBone8xVoxelNeXt(nn.Module):\n    def bev_out(self, x_conv):\n        features_cat = x_conv.features                      # torch.Size([95490, 128])\n        indices_cat = x_conv.indices[:, [0, 2, 3]]          # B,X,Y   torch.Size([95490, 3])\n        spatial_shape = x_conv.spatial_shape[1:]            # [6, 180, 180]->[180, 180]\n        # indices_cat为[95490, 3]；假设95489和95488的值都为(0,20,11)，且indices_unique的第10个值为(0,20,11)则_inv[95488]=10,_inv[95499]=10\n        indices_unique, _inv = torch.unique(indices_cat, dim=0, return_inverse=True)                  # torch.Size([29914, 3])  torch.Size([95490])范围为0-29914\n        features_unique = features_cat.new_zeros((indices_unique.shape[0], features_cat.shape[1]))    # torch.Size([29914, 128])\n        features_unique.index_add_(0, _inv, features_cat)    # 对相同索引下的特征进行相加\n        x_out = spconv.SparseConvTensor(\n            features=features_unique,\n            indices=indices_unique,                # torch.Size([29914, 3])\n            spatial_shape=spatial_shape,           # [180, 180]\n            batch_size=x_conv.batch_size           # 4\n        )\n        return x_out\n\'> </span>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def forward(self, data_dict):\n        x = data_dict[&amp;#39;encoded_spconv_tensor&amp;#39;]                  # [180, 180]\n        spatial_shape, batch_index, voxel_indices, spatial_indices, num_voxels = self.`_get_voxel_infos`(x)\n        self.forward_ret_dict[&amp;#39;batch_index&amp;#39;] = batch_index      # 范围为0-3\n        \n        pred_dicts = []\n        for head in self.heads_list:\n            pred_dicts.append(`head`(x))  # [{&amp;#39;center&amp;#39;:, &amp;#39;center_z&amp;#39;:, &amp;#39;dim&amp;#39;:, &amp;#39;rot&amp;#39;:, &amp;#39;vel&amp;#39;:},{},{},{},{},{}]  pred_dicts[0][&amp;#39;center&amp;#39;].shape=torch.Size([12154, 2])  这里12154是voxel的数量，对应voxel_indices     \n        if self.training:\n            target_dict = self.`assign_targets`(data_dict[&amp;#39;gt_boxes&amp;#39;], num_voxels, spatial_indices, spatial_shape)     \n            # 每个格子里面有多少个点，这些点在那个格子里面，[180, 180]大小的格子\n            self.forward_ret_dict[&amp;#39;target_dicts&amp;#39;] = target_dict    # [(key,i.shape) for key,value in target_dict.items() for i in value if torch.is_tensor(i)]\n        &amp;#39;&amp;#39;&amp;#39;\n        00:(&amp;#39;heatmaps&amp;#39;, torch.Size([12154, 1]))\n        05:(&amp;#39;heatmaps&amp;#39;, torch.Size([12154, 2]))\n        06:(&amp;#39;target_boxes&amp;#39;, torch.Size([1, 500, 10]))\n        12:(&amp;#39;inds&amp;#39;, torch.Size([1, 500]))\n        23:(&amp;#39;masks&amp;#39;, torch.Size([1, 500]))\n        &amp;#39;&amp;#39;&amp;#39;\n        self.forward_ret_dict[&amp;#39;pred_dicts&amp;#39;] = pred_dicts\n        self.forward_ret_dict[&amp;#39;voxel_indices&amp;#39;] = voxel_indices     # torch.Size([12154, 3]) type为int，范围为(0->B-1,0->180-1,0->180-1)\n        return data_dict \n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def _get_voxel_infos(self, x):\n        spatial_shape = x.spatial_shape      # [180, 180]\n        voxel_indices = x.indices            # torch.Size([48666, 3])\n        spatial_indices = []\n        num_voxels = []\n        batch_size = x.batch_size\n        batch_index = voxel_indices[:, 0]\n        for bs_idx in range(batch_size):\n            batch_inds = batch_index==bs_idx\n            spatial_indices.append(voxel_indices[batch_inds][:, [2, 1]])\n            num_voxels.append(batch_inds.sum())\n        # [180, 180], torch.Size([48666]), torch.Size([48666, 3]), [[12154, 2],[12196, 2],[12132, 2],[12184, 2]],  [12154,12196,12132,12184]\n        return spatial_shape, batch_index, voxel_indices, spatial_indices, num_voxels\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def assign_targets(self, gt_boxes, num_voxels, spatial_indices, spatial_shape):\n        target_assigner_cfg = self.model_cfg.TARGET_ASSIGNER_CONFIG\n        batch_size = gt_boxes.shape[0]        # 1\n        ret_dict = {&amp;#39;heatmaps&amp;#39;: [],&amp;#39;target_boxes&amp;#39;: [],&amp;#39;inds&amp;#39;: [],&amp;#39;masks&amp;#39;: [],&amp;#39;heatmap_masks&amp;#39;: [],&amp;#39;gt_boxes&amp;#39;: []}\n        all_names = np.array([&amp;#39;bg&amp;#39;, *self.class_names])                          # 11\n        for idx, cur_class_names in enumerate(self.class_names_each_head):       # [&amp;#39;car&amp;#39;]\n            heatmap_list, target_boxes_list, inds_list, masks_list, gt_boxes_list = [], [], [], [], []\n            for bs_idx in range(batch_size):     #\n                cur_gt_boxes = gt_boxes[bs_idx]\n                gt_class_names = all_names[cur_gt_boxes[:, -1].cpu().long().numpy()]\n                gt_boxes_single_head = []\n                for idx, name in enumerate(gt_class_names):\n                    if name not in cur_class_names:\n                        continue\n                    temp_box = cur_gt_boxes[idx]\n                    temp_box[-1] = cur_class_names.index(name) + 1\n                    gt_boxes_single_head.append(temp_box[None, :])\n                if len(gt_boxes_single_head) == 0:\n                    gt_boxes_single_head = cur_gt_boxes[:0, :]\n                else:\n                    gt_boxes_single_head = torch.cat(gt_boxes_single_head, dim=0)    # torch.Size([2, 10])\n                heatmap, ret_boxes, inds, mask = self.`assign_target_of_single_head`(\n                    num_classes=len(cur_class_names), gt_boxes=gt_boxes_single_head,        # 1，torch.Size([2, 10])\n                    num_voxels=num_voxels[bs_idx], spatial_indices=spatial_indices[bs_idx], # 12154，torch.Size([12154, 2])\n                    spatial_shape=spatial_shape, \n                    feature_map_stride=target_assigner_cfg.FEATURE_MAP_STRIDE,    # 8\n                    num_max_objs=target_assigner_cfg.NUM_MAX_OBJS,                # 500\n                    gaussian_overlap=target_assigner_cfg.GAUSSIAN_OVERLAP,        # 0.1\n                    min_radius=target_assigner_cfg.MIN_RADIUS,                    # 2\n                )\n                heatmap_list.append(heatmap.to(gt_boxes_single_head.device))\n                target_boxes_list.append(ret_boxes.to(gt_boxes_single_head.device))\n                inds_list.append(inds.to(gt_boxes_single_head.device))\n                masks_list.append(mask.to(gt_boxes_single_head.device))\n                gt_boxes_list.append(gt_boxes_single_head[:, :-1])\n            ret_dict[&amp;#39;heatmaps&amp;#39;].append(torch.cat(heatmap_list, dim=1).permute(1, 0))\n            ret_dict[&amp;#39;target_boxes&amp;#39;].append(torch.stack(target_boxes_list, dim=0))\n            ret_dict[&amp;#39;inds&amp;#39;].append(torch.stack(inds_list, dim=0))\n            ret_dict[&amp;#39;masks&amp;#39;].append(torch.stack(masks_list, dim=0))\n            ret_dict[&amp;#39;gt_boxes&amp;#39;].append(gt_boxes_list)\n        return ret_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def assign_target_of_single_head(self, num_classes, gt_boxes, num_voxels, spatial_indices, spatial_shape, feature_map_stride, num_max_objs=500,\n                gaussian_overlap=0.1, min_radius=2):\n        heatmap = gt_boxes.new_zeros(num_classes, num_voxels)     # torch.Size([1, 12154])\n        ret_boxes = gt_boxes.new_zeros((num_max_objs, gt_boxes.shape[-1] - 1 + 1))\n        inds = gt_boxes.new_zeros(num_max_objs).long()\n        mask = gt_boxes.new_zeros(num_max_objs).long()\n        x, y, z = gt_boxes[:, 0], gt_boxes[:, 1], gt_boxes[:, 2]\n        coord_x = (x - self.point_cloud_range[0]) / self.voxel_size[0] / feature_map_stride\n        coord_y = (y - self.point_cloud_range[1]) / self.voxel_size[1] / feature_map_stride\n        coord_x = torch.clamp(coord_x, min=0, max=spatial_shape[1] - 0.5)  # bugfixed: 1e-6 does not work for center.int()\n        coord_y = torch.clamp(coord_y, min=0, max=spatial_shape[0] - 0.5)  # 范围变到0-(180-0.5=179.5)\n        center = torch.cat((coord_x[:, None], coord_y[:, None]), dim=-1)\n        center_int = center.int()\n        center_int_float = center_int.float()     # 0-179\n        dx, dy, dz = gt_boxes[:, 3], gt_boxes[:, 4], gt_boxes[:, 5]       # 长宽高\n        dx = dx / self.voxel_size[0] / feature_map_stride\n        dy = dy / self.voxel_size[1] / feature_map_stride\n        radius = centernet_utils.gaussian_radius(dx, dy, min_overlap=gaussian_overlap)\n        radius = torch.clamp_min(radius.int(), min=min_radius)\n        for k in range(min(num_max_objs, gt_boxes.shape[0])):  # 0-2\n            if dx[k] <= 0 or dy[k] <= 0:\n                continue\n            if not (0 <= center_int[k][0] <= spatial_shape[1] and 0 <= center_int[k][1] <= spatial_shape[0]):\n                continue\n            cur_class_id = (gt_boxes[k, -1] - 1).long()     # id从0开始，类别从car开始\n            distance = self.distance(spatial_indices, center[k])    # 距离最短的那个作为box响应\n            inds[k] = distance.argmin()\n            mask[k] = 1\n            if &amp;#39;gt_center&amp;#39; in self.gaussian_type:        # True pcdet/models/model_utils/centernet_utils.py\n                centernet_utils.`draw_gaussian_to_heatmap_voxels`(heatmap[cur_class_id], distance, radius[k].item() * self.gaussian_ratio)\n            if &amp;#39;nearst&amp;#39; in self.gaussian_type:\n                centernet_utils.draw_gaussian_to_heatmap_voxels(heatmap[cur_class_id], self.distance(spatial_indices, spatial_indices[inds[k]]), radius[k].item() * self.gaussian_ratio)\n            ret_boxes[k, 0:2] = center[k] - spatial_indices[inds[k]][:2]  # 相应的距离与该格子的距离\n            ret_boxes[k, 2] = z[k]\n            ret_boxes[k, 3:6] = gt_boxes[k, 3:6].log()\n            ret_boxes[k, 6] = torch.cos(gt_boxes[k, 6])\n            ret_boxes[k, 7] = torch.sin(gt_boxes[k, 6])\n            if gt_boxes.shape[1] > 8:\n                ret_boxes[k, 8:] = gt_boxes[k, 7:-1]\n        return heatmap, ret_boxes, inds, mask    # torch.Size([1, 12154])； torch.Size([500, 10]) torch.Size([500])； torch.Size([500])\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/centernet_utils.py</p><span class=\'hidden-code\' data-code=\'def draw_gaussian_to_heatmap_voxels(heatmap, distances, radius, k=1):\n    diameter = 2 * radius + 1       # 2*2+1=5\n    sigma = diameter / 6            # 5/6\n    masked_gaussian = torch.exp(- distances / (2 * sigma * sigma))     # torch.Size([12154])--距离越大，值越小\n    torch.max(heatmap, masked_gaussian, out=heatmap)\n    return heatmap\n\'> </span>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXt(Detector3DTemplate):\n    def get_training_loss(self):\n        disp_dict = {}\n        loss, tb_dict = self.dense_head.`get_loss`()\n        return loss, tb_dict, disp_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def get_loss(self):                                            # 新的一段\n        pred_dicts = self.forward_ret_dict[&amp;#39;pred_dicts&amp;#39;]\n        target_dicts = self.forward_ret_dict[&amp;#39;target_dicts&amp;#39;]\n        batch_index = self.forward_ret_dict[&amp;#39;batch_index&amp;#39;]         # torch.Size([64265])\n        tb_dict = {}\n        loss = 0\n        batch_indices = self.forward_ret_dict[&amp;#39;voxel_indices&amp;#39;][:, 0]\n        spatial_indices = self.forward_ret_dict[&amp;#39;voxel_indices&amp;#39;][:, 1:]\n        for idx, pred_dict in enumerate(pred_dicts):\n            pred_dict[&amp;#39;hm&amp;#39;] = self.sigmoid(pred_dict[&amp;#39;hm&amp;#39;])          # torch.Size([64265, 1])\n            hm_loss = self.hm_loss_func(pred_dict[&amp;#39;hm&amp;#39;], target_dicts[&amp;#39;heatmaps&amp;#39;][idx])    # torch.Size([64265, 1]);torch.Size([64265, 1])   FocalLossSparse()\n            hm_loss *= self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[&amp;#39;cls_weight&amp;#39;]      # *1.0\n            target_boxes = target_dicts[&amp;#39;target_boxes&amp;#39;][idx]                      # torch.Size([4, 500, 10])\n            pred_boxes = torch.cat([pred_dict[head_name] for head_name in self.separate_head_cfg.HEAD_ORDER], dim=1)  # torch.Size([64265, 10])\n            reg_loss = self.reg_loss_func(                                        # RegLossSparse()\n                pred_boxes, target_dicts[&amp;#39;masks&amp;#39;][idx], target_dicts[&amp;#39;inds&amp;#39;][idx], target_boxes, batch_index\n            )  # torch.Size([64265, 10]) + torch.Size([4, 500]) + torch.Size([4, 500]) + torch.Size([4, 500, 10]) + torch.Size([64265])->torch.Size([10])\n            loc_loss = (reg_loss * reg_loss.new_tensor(self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[&amp;#39;code_weights&amp;#39;])).sum() # [1,1,1,1,1,1,0.2,0.2,1,1]\n            loc_loss = loc_loss * self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[&amp;#39;loc_weight&amp;#39;]\n            tb_dict[&amp;#39;hm_loss_head_%d&amp;#39; % idx] = hm_loss.item()\n            tb_dict[&amp;#39;loc_loss_head_%d&amp;#39; % idx] = loc_loss.item()\n            if self.iou_branch:\n                batch_box_preds = self.`_get_predicted_boxes`(pred_dict, spatial_indices)\n                pred_boxes_for_iou = batch_box_preds.detach()\n                iou_loss = self.crit_iou(pred_dict[&amp;#39;iou&amp;#39;], target_dicts[&amp;#39;masks&amp;#39;][idx], target_dicts[&amp;#39;inds&amp;#39;][idx],\n                                            pred_boxes_for_iou, target_dicts[&amp;#39;gt_boxes&amp;#39;][idx], batch_indices)\n                iou_reg_loss = self.crit_iou_reg(batch_box_preds, target_dicts[&amp;#39;masks&amp;#39;][idx], target_dicts[&amp;#39;inds&amp;#39;][idx],\n                                                    target_dicts[&amp;#39;gt_boxes&amp;#39;][idx], batch_indices)\n                iou_weight = self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[&amp;#39;iou_weight&amp;#39;] if &amp;#39;iou_weight&amp;#39; in self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS else self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[&amp;#39;loc_weight&amp;#39;]\n                iou_reg_loss = iou_reg_loss * iou_weight #self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[&amp;#39;loc_weight&amp;#39;]\n                loss += (hm_loss + loc_loss + iou_loss + iou_reg_loss)\n                tb_dict[&amp;#39;iou_loss_head_%d&amp;#39; % idx] = iou_loss.item()\n                tb_dict[&amp;#39;iou_reg_loss_head_%d&amp;#39; % idx] = iou_reg_loss.item()\n            else:\n                loss += hm_loss + loc_loss\n        tb_dict[&amp;#39;rpn_loss&amp;#39;] = loss.item()\n        return loss, tb_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def _get_predicted_boxes(self, pred_dict, spatial_indices):\n        center = pred_dict[&amp;#39;center&amp;#39;]\n        center_z = pred_dict[&amp;#39;center_z&amp;#39;]\n        #dim = pred_dict[&amp;#39;dim&amp;#39;].exp()\n        dim = torch.exp(torch.clamp(pred_dict[&amp;#39;dim&amp;#39;], min=-5, max=5))\n        rot_cos = pred_dict[&amp;#39;rot&amp;#39;][:, 0].unsqueeze(dim=1)\n        rot_sin = pred_dict[&amp;#39;rot&amp;#39;][:, 1].unsqueeze(dim=1)\n        angle = torch.atan2(rot_sin, rot_cos)\n        xs = (spatial_indices[:, 1:2] + center[:, 0:1]) * self.feature_map_stride * self.voxel_size[0] + self.point_cloud_range[0]\n        ys = (spatial_indices[:, 0:1] + center[:, 1:2]) * self.feature_map_stride * self.voxel_size[1] + self.point_cloud_range[1]\n        box_part_list = [xs, ys, center_z, dim, angle]\n        pred_box = torch.cat((box_part_list), dim=-1)\n        return pred_box\n\'> </span>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py-预测流程</p><span class=\'hidden-code\' data-code=\'class VoxelNeXt(Detector3DTemplate):\n    def forward(self, batch_dict):      dict_keys([&amp;#39;points&amp;#39;, &amp;#39;frame_id&amp;#39;, &amp;#39;metadata&amp;#39;, &amp;#39;gt_boxes&amp;#39;, &amp;#39;flip_x&amp;#39;, &amp;#39;flip_y&amp;#39;, &amp;#39;noise_rot&amp;#39;, \n                                    &amp;#39;noise_scale&amp;#39;, &amp;#39;use_lead_xyz&amp;#39;, &amp;#39;voxels&amp;#39;, &amp;#39;voxel_coords&amp;#39;, &amp;#39;voxel_num_points&amp;#39;, &amp;#39;batch_size&amp;#39;])\n        for cur_module in self.module_list:           MeanVFE();VoxelResBackBone8xVoxelNeXt();VoxelNeXtHead\n            batch_dict = `cur_module`(batch_dict)\n        if self.training:\n            loss, tb_dict, disp_dict = self.get_training_loss()\n            ret_dict = {&amp;#39;loss&amp;#39;: loss}\n            return ret_dict, tb_dict, disp_dict\n        else:\n            pred_dicts, recall_dicts = self.`post_processing`(batch_dict)\n            return pred_dicts, recall_dicts\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def forward(self, data_dict):\n        x = data_dict[&amp;#39;encoded_spconv_tensor&amp;#39;]        # [180, 180]\n        spatial_shape, batch_index, voxel_indices, spatial_indices, num_voxels = self._get_voxel_infos(x)\n        self.forward_ret_dict[&amp;#39;batch_index&amp;#39;] = batch_index # 范围为0-3\n        \n        pred_dicts = []\n        for head in self.heads_list:\n            pred_dicts.append(head(x))  # [{&amp;#39;center&amp;#39;:, &amp;#39;center_z&amp;#39;:, &amp;#39;dim&amp;#39;:, &amp;#39;rot&amp;#39;:, &amp;#39;vel&amp;#39;:},{},{},{},{},{}]\n        if self.training:\n            target_dict = self.assign_targets(\n                data_dict[&amp;#39;gt_boxes&amp;#39;], num_voxels, spatial_indices, spatial_shape\n            )     # 每个格子里面有多少个点，这些点在那个格子里面，[180, 180]大小的格子\n            self.forward_ret_dict[&amp;#39;target_dicts&amp;#39;] = target_dict    # [(key,i.shape) for key,value in target_dict.items() for i in value if torch.is_tensor(i)]\n        &amp;#39;&amp;#39;&amp;#39;\n        00:(&amp;#39;heatmaps&amp;#39;, torch.Size([12154, 1]))\n        05:(&amp;#39;heatmaps&amp;#39;, torch.Size([12154, 2]))\n        06:(&amp;#39;target_boxes&amp;#39;, torch.Size([1, 500, 10]))\n        12:(&amp;#39;inds&amp;#39;, torch.Size([1, 500]))\n        23:(&amp;#39;masks&amp;#39;, torch.Size([1, 500]))\n        &amp;#39;&amp;#39;&amp;#39;\n        self.forward_ret_dict[&amp;#39;pred_dicts&amp;#39;] = pred_dicts\n        self.forward_ret_dict[&amp;#39;voxel_indices&amp;#39;] = voxel_indices\n        if not self.training or self.predict_boxes_when_training:\n            if self.double_flip:\n                data_dict[&amp;#39;batch_size&amp;#39;] = data_dict[&amp;#39;batch_size&amp;#39;] // 4\n            pred_dicts = self.`generate_predicted_boxes`(data_dict[&amp;#39;batch_size&amp;#39;], pred_dicts, voxel_indices, spatial_shape)\n            if self.predict_boxes_when_training:\n                rois, roi_scores, roi_labels = self.reorder_rois_for_refining(data_dict[&amp;#39;batch_size&amp;#39;], pred_dicts)\n                data_dict[&amp;#39;rois&amp;#39;] = rois\n                data_dict[&amp;#39;roi_scores&amp;#39;] = roi_scores\n                data_dict[&amp;#39;roi_labels&amp;#39;] = roi_labels\n                data_dict[&amp;#39;has_class_labels&amp;#39;] = True\n            else:\n                data_dict[&amp;#39;final_box_dicts&amp;#39;] = pred_dicts\n        return data_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def generate_predicted_boxes(self, batch_size, pred_dicts, voxel_indices, spatial_shape):\n        post_process_cfg = self.model_cfg.POST_PROCESSING\n        post_center_limit_range = torch.tensor(post_process_cfg.POST_CENTER_LIMIT_RANGE).cuda().float()     # [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]\n        ret_dict = [{&amp;#39;pred_boxes&amp;#39;: [], &amp;#39;pred_scores&amp;#39;: [], &amp;#39;pred_labels&amp;#39;: [], &amp;#39;pred_ious&amp;#39;: []} for k in range(batch_size)]\n        for idx, pred_dict in enumerate(pred_dicts):\n            if self.double_flip:                # False\n                batch_hm, batch_center, batch_center_z, batch_dim, batch_rot_cos, batch_rot_sin, batch_vel, batch_iou, voxel_indices_ = self.`merge_double_flip`( )\n            else:       # [(key,value.shape) for key,value in pred_dict.items()]\n                batch_hm = pred_dict[&amp;#39;hm&amp;#39;].sigmoid()  # [(&amp;#39;center&amp;#39;, torch.Size([44223, 2])), (&amp;#39;center_z&amp;#39;, torch.Size([44223, 1])), (&amp;#39;dim&amp;#39;, torch.Size([44223, 3])), (&amp;#39;rot&amp;#39;, torch.Size([44223, 2])), (&amp;#39;vel&amp;#39;, torch.Size([44223, 2])), (&amp;#39;hm&amp;#39;, torch.Size([44223, 1]))]\n                batch_center = pred_dict[&amp;#39;center&amp;#39;]\n                batch_center_z = pred_dict[&amp;#39;center_z&amp;#39;]\n                batch_dim = pred_dict[&amp;#39;dim&amp;#39;].exp()\n                batch_rot_cos = pred_dict[&amp;#39;rot&amp;#39;][:, 0].unsqueeze(dim=1)\n                batch_rot_sin = pred_dict[&amp;#39;rot&amp;#39;][:, 1].unsqueeze(dim=1)\n                batch_iou = (pred_dict[&amp;#39;iou&amp;#39;] + 1) * 0.5 if self.iou_branch else None\n                batch_vel = pred_dict[&amp;#39;vel&amp;#39;] if &amp;#39;vel&amp;#39; in self.separate_head_cfg.HEAD_ORDER else None\n                voxel_indices_ = voxel_indices         # torch.Size([44223, 3]),B,X,Y\n            final_pred_dicts = centernet_utils.`decode_bbox_from_voxels_nuscenes`(\n                batch_size=batch_size, indices=voxel_indices_,\n                obj=batch_hm, \n                rot_cos=batch_rot_cos,\n                rot_sin=batch_rot_sin,\n                center=batch_center, center_z=batch_center_z,\n                dim=batch_dim, vel=batch_vel, iou=batch_iou,\n                point_cloud_range=self.point_cloud_range, voxel_size=self.voxel_size,\n                feature_map_stride=self.feature_map_stride,                                # 8\n                K=post_process_cfg.MAX_OBJ_PER_SAMPLE,                                     # 500\n                #circle_nms=(post_process_cfg.NMS_CONFIG.NMS_TYPE == &amp;#39;circle_nms&amp;#39;),\n                score_thresh=post_process_cfg.SCORE_THRESH,\n                post_center_limit_range=post_center_limit_range\n            )\n            for k, final_dict in enumerate(final_pred_dicts):\n                final_dict[&amp;#39;pred_labels&amp;#39;] = self.class_id_mapping_each_head[idx][final_dict[&amp;#39;pred_labels&amp;#39;].long()]   # [[0],[1, 2],[3, 4],[5],[6, 7],[8, 9]]\n                if not self.iou_branch:      # True\n                    selected, selected_scores = model_nms_utils.`class_agnostic_nms`(\n                        box_scores=final_dict[&amp;#39;pred_scores&amp;#39;], box_preds=final_dict[&amp;#39;pred_boxes&amp;#39;],\n                        nms_config=post_process_cfg.NMS_CONFIG,\n                        score_thresh=None\n                    )\n                    final_dict[&amp;#39;pred_boxes&amp;#39;] = final_dict[&amp;#39;pred_boxes&amp;#39;][selected]\n                    final_dict[&amp;#39;pred_scores&amp;#39;] = selected_scores\n                    final_dict[&amp;#39;pred_labels&amp;#39;] = final_dict[&amp;#39;pred_labels&amp;#39;][selected]\n                ret_dict[k][&amp;#39;pred_boxes&amp;#39;].append(final_dict[&amp;#39;pred_boxes&amp;#39;])\n                ret_dict[k][&amp;#39;pred_scores&amp;#39;].append(final_dict[&amp;#39;pred_scores&amp;#39;])\n                ret_dict[k][&amp;#39;pred_labels&amp;#39;].append(final_dict[&amp;#39;pred_labels&amp;#39;])\n                ret_dict[k][&amp;#39;pred_ious&amp;#39;].append(final_dict[&amp;#39;pred_ious&amp;#39;])\n        for k in range(batch_size):\n            pred_boxes = torch.cat(ret_dict[k][&amp;#39;pred_boxes&amp;#39;], dim=0)\n            pred_scores = torch.cat(ret_dict[k][&amp;#39;pred_scores&amp;#39;], dim=0)\n            pred_labels = torch.cat(ret_dict[k][&amp;#39;pred_labels&amp;#39;], dim=0)\n            if self.iou_branch:\n                pred_ious = torch.cat(ret_dict[k][&amp;#39;pred_ious&amp;#39;], dim=0)\n                pred_boxes, pred_scores, pred_labels = self.rotate_class_specific_nms_iou(pred_boxes, pred_scores, pred_ious, pred_labels, self.rectifier, self.nms_configs)\n            ret_dict[k][&amp;#39;pred_boxes&amp;#39;] = pred_boxes\n            ret_dict[k][&amp;#39;pred_scores&amp;#39;] = pred_scores\n            ret_dict[k][&amp;#39;pred_labels&amp;#39;] = pred_labels + 1\n        return ret_dict\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXtHead(nn.Module):\n    def merge_double_flip(self, pred_dict, batch_size, voxel_indices, spatial_shape):\n        # spatial_shape (Z, Y, X)     [334, 334]  - y,x\n        pred_dict[&amp;#39;hm&amp;#39;] = pred_dict[&amp;#39;hm&amp;#39;].sigmoid()          # torch.Size([257894, 1])\n        pred_dict[&amp;#39;dim&amp;#39;] = pred_dict[&amp;#39;dim&amp;#39;].exp()            # torch.Size([257894, 3])\n        batch_indices = voxel_indices[:, 0]                  # torch.Size([257894])  范围0-7，真实batch size为2\n        spatial_indices = voxel_indices[:, 1:]               # torch.Size([257894, 2])对应y-x\n        pred_dict_ = {k: [] for k in pred_dict.keys()}\n        counts = []\n        spatial_indices_ = []\n        for bs_idx in range(batch_size):                     # 2\n            spatial_indices_batch = []\n            pred_dict_batch = {k: [] for k in pred_dict.keys()}\n            for i in range(4):                               # &amp;#39;org&amp;#39;,&amp;#39;yflip&amp;#39;, &amp;#39;xflip&amp;#39;, &amp;#39;xyflip&amp;#39;\n                bs_indices = batch_indices == (bs_idx * 4 + i)\n                if i in [1, 3]:\n                    spatial_indices[bs_indices, 0] = spatial_shape[0] - spatial_indices[bs_indices, 0]  # 处理y值\n                if i in [2, 3]:\n                    spatial_indices[bs_indices, 1] = spatial_shape[1] - spatial_indices[bs_indices, 1]  # 处理x值\n                if i == 1:\n                    pred_dict[&amp;#39;center&amp;#39;][bs_indices, 1] = - pred_dict[&amp;#39;center&amp;#39;][bs_indices, 1]\n                    pred_dict[&amp;#39;rot&amp;#39;][bs_indices, 1] *= -1           # y翻转\n                    if &amp;#39;vel&amp;#39; in pred_dict:\n                        pred_dict[&amp;#39;vel&amp;#39;][bs_indices, 1] *= -1\n                if i == 2:\n                    pred_dict[&amp;#39;center&amp;#39;][bs_indices, 0] = - pred_dict[&amp;#39;center&amp;#39;][bs_indices, 0]\n                    pred_dict[&amp;#39;rot&amp;#39;][bs_indices, 0] *= -1           # x翻转\n                    if &amp;#39;vel&amp;#39; in pred_dict:\n                        pred_dict[&amp;#39;vel&amp;#39;][bs_indices, 0] *= -1\n                if i == 3:\n                    pred_dict[&amp;#39;center&amp;#39;][bs_indices, 0] = - pred_dict[&amp;#39;center&amp;#39;][bs_indices, 0]\n                    pred_dict[&amp;#39;center&amp;#39;][bs_indices, 1] = - pred_dict[&amp;#39;center&amp;#39;][bs_indices, 1]\n                    pred_dict[&amp;#39;rot&amp;#39;][bs_indices, 1] *= -1\n                    pred_dict[&amp;#39;rot&amp;#39;][bs_indices, 0] *= -1\n                    if &amp;#39;vel&amp;#39; in pred_dict:\n                        pred_dict[&amp;#39;vel&amp;#39;][bs_indices] *= -1\n                spatial_indices_batch.append(spatial_indices[bs_indices])\n                for k in pred_dict.keys():\n                    pred_dict_batch[k].append(pred_dict[k][bs_indices])\n            spatial_indices_batch = torch.cat(spatial_indices_batch)        # [,,,]四个合成一个torch.Size([128697, 2])\n            spatial_indices_unique, _inv, count = torch.unique(spatial_indices_batch, dim=0, return_inverse=True,return_counts=True)  # torch.Size([37359, 2])有3万7千多个唯一值，torch.Size([128697])值范围在0-37359，torch.Size([37359])\n            spatial_indices_.append(spatial_indices_unique)\n            counts.append(count)\n            for k in pred_dict.keys():\n                pred_dict_batch[k] = torch.cat(pred_dict_batch[k])                         # k=&amp;#39;center&amp;#39; 合并后 pred_dict_batch[k].shape=torch.Size([128697, 2])\n                features_unique = pred_dict_batch[k].new_zeros((spatial_indices_unique.shape[0], pred_dict_batch[k].shape[1]))   # 初始化0值的 torch.Size([37359, 2])\n                features_unique.index_add_(0, _inv, pred_dict_batch[k])                    # 这里把相同预测的加起来\n                pred_dict_[k].append(features_unique)\n        for k in pred_dict.keys():\n            pred_dict_[k] = torch.cat(pred_dict_[k])                  # 长度为2，拼起来\n        counts = torch.cat(counts).unsqueeze(-1).float()\n        voxel_indices_ = torch.cat([torch.cat(\n            [torch.full((indices.shape[0], 1), i, device=indices.device, dtype=indices.dtype), indices], dim=1\n        ) for i, indices in enumerate(spatial_indices_)])\n        batch_hm = pred_dict_[&amp;#39;hm&amp;#39;]\n        batch_center = pred_dict_[&amp;#39;center&amp;#39;]\n        batch_center_z = pred_dict_[&amp;#39;center_z&amp;#39;]\n        batch_dim = pred_dict_[&amp;#39;dim&amp;#39;]\n        batch_rot_cos = pred_dict_[&amp;#39;rot&amp;#39;][:, 0].unsqueeze(dim=1)\n        batch_rot_sin = pred_dict_[&amp;#39;rot&amp;#39;][:, 1].unsqueeze(dim=1)\n        batch_vel = pred_dict_[&amp;#39;vel&amp;#39;] if &amp;#39;vel&amp;#39; in self.separate_head_cfg.HEAD_ORDER else None\n        batch_hm /= counts                                        # 相当于相同位置预测的box求平均了\n        batch_center /= counts\n        batch_center_z /= counts\n        batch_dim /= counts\n        batch_rot_cos /= counts\n        batch_rot_sin /= counts\n        if not batch_vel is None:\n            batch_vel /= counts\n        return batch_hm, batch_center, batch_center_z, batch_dim, batch_rot_cos, batch_rot_sin, batch_vel, None, voxel_indices_\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/centernet_utils.py</p><span class=\'hidden-code\' data-code=\'def decode_bbox_from_voxels_nuscenes(batch_size, indices, obj, rot_cos, rot_sin,\n                            center, center_z, dim, vel=None, iou=None, point_cloud_range=None, voxel_size=None, voxels_3d=None,\n                            feature_map_stride=None, K=100, score_thresh=None, post_center_limit_range=None, add_features=None):\n    batch_idx = indices[:, 0]\n    spatial_indices = indices[:, 1:]\n    scores, inds, class_ids = _topk_1d(None, batch_size, batch_idx, obj, K=K, nuscenes=True)   # obj->batch_hm\n    center = gather_feat_idx(center, inds, batch_size, batch_idx)       # torch.Size([4, 500]),4,torch.Size([44223])\n    rot_sin = gather_feat_idx(rot_sin, inds, batch_size, batch_idx)\n    rot_cos = gather_feat_idx(rot_cos, inds, batch_size, batch_idx)\n    center_z = gather_feat_idx(center_z, inds, batch_size, batch_idx)\n    dim = gather_feat_idx(dim, inds, batch_size, batch_idx)\n    spatial_indices = gather_feat_idx(spatial_indices, inds, batch_size, batch_idx)\n    if not add_features is None:\n        add_features = [gather_feat_idx(add_feature, inds, batch_size, batch_idx) for add_feature in add_features]\n    if not isinstance(feature_map_stride, int):\n        feature_map_stride = gather_feat_idx(feature_map_stride.unsqueeze(-1), inds, batch_size, batch_idx)\n    angle = torch.atan2(rot_sin, rot_cos)\n    # (indices(voxel的索引)+pred_dict[&amp;#39;center&amp;#39;])*8*0.075+(-51.2) 乘以8之前的范围是0->180\n    xs = (spatial_indices[:, :, -1:] + center[:, :, 0:1]) * feature_map_stride * voxel_size[0] + point_cloud_range[0]\n    ys = (spatial_indices[:, :, -2:-1] + center[:, :, 1:2]) * feature_map_stride * voxel_size[1] + point_cloud_range[1]\n    # zs = (spatial_indices[:, :, 0:1]) * feature_map_stride * voxel_size[2] + point_cloud_range[2] + center_z\n    box_part_list = [xs, ys, center_z, dim, angle]\n    if not vel is None:\n        vel = gather_feat_idx(vel, inds, batch_size, batch_idx)\n        box_part_list.append(vel)\n    if not iou is None:\n        iou = gather_feat_idx(iou, inds, batch_size, batch_idx)\n        iou = torch.clamp(iou, min=0, max=1.)\n    final_box_preds = torch.cat((box_part_list), dim=-1)           # torch.Size([4, 500, 9])\n    final_scores = scores.view(batch_size, K)                      # torch.Size([4, 500])\n    final_class_ids = class_ids.view(batch_size, K)                # torch.Size([4, 500])\n    if not add_features is None:                                   # False\n        add_features = [add_feature.view(batch_size, K, add_feature.shape[-1]) for add_feature in add_features]\n    assert post_center_limit_range is not None\n    mask = (final_box_preds[..., :3] >= post_center_limit_range[:3]).all(2)\n    mask &amp;= (final_box_preds[..., :3] <= post_center_limit_range[3:]).all(2)\n    if score_thresh is not None:\n        mask &amp;= (final_scores > score_thresh)\n    ret_pred_dicts = []\n    for k in range(batch_size):\n        cur_mask = mask[k]\n        cur_boxes = final_box_preds[k, cur_mask]\n        cur_scores = final_scores[k, cur_mask]\n        cur_labels = final_class_ids[k, cur_mask]\n        cur_add_features = [add_feature[k, cur_mask] for add_feature in add_features] if not add_features is None else None\n        cur_iou = iou[k, cur_mask] if not iou is None else None\n        ret_pred_dicts.append({\n            &amp;#39;pred_boxes&amp;#39;: cur_boxes,\n            &amp;#39;pred_scores&amp;#39;: cur_scores,\n            &amp;#39;pred_labels&amp;#39;: cur_labels,\n            &amp;#39;pred_ious&amp;#39;: cur_iou,\n            &amp;#39;add_features&amp;#39;: cur_add_features,\n        })\n    return ret_pred_dicts\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/model_nms_utils.py</p><span class=\'hidden-code\' data-code=\'def class_agnostic_nms(box_scores, box_preds, nms_config, score_thresh=None):\n    src_box_scores = box_scores\n    if score_thresh is not None:\n        scores_mask = (box_scores >= score_thresh)\n        box_scores = box_scores[scores_mask]\n        box_preds = box_preds[scores_mask]\n    selected = []\n    if box_scores.shape[0] > 0:\n        box_scores_nms, indices = torch.topk(box_scores, k=min(nms_config.NMS_PRE_MAXSIZE, box_scores.shape[0]))\n        boxes_for_nms = box_preds[indices]\n        keep_idx, selected_scores = getattr(iou3d_nms_utils, nms_config.NMS_TYPE)(\n                boxes_for_nms[:, 0:7], box_scores_nms, nms_config.NMS_THRESH, **nms_config\n        )\n        selected = indices[keep_idx[:nms_config.NMS_POST_MAXSIZE]]\n    if score_thresh is not None:\n        original_idxs = scores_mask.nonzero().view(-1)\n        selected = original_idxs[selected]\n    return selected, src_box_scores[selected]\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py</p><span class=\'hidden-code\' data-code=\'class VoxelNeXt(Detector3DTemplate):\n    def post_processing(self, batch_dict):\n        post_process_cfg = self.model_cfg.POST_PROCESSING # {&amp;#39;RECALL_THRESH_LIST&amp;#39;: [0.3, 0.5, 0.7], &amp;#39;EVAL_METRIC&amp;#39;: &amp;#39;kitti&amp;#39;}\n        batch_size = batch_dict[&amp;#39;batch_size&amp;#39;]\n        final_pred_dict = batch_dict[&amp;#39;final_box_dicts&amp;#39;]\n        recall_dict = {}\n        for index in range(batch_size):\n            pred_boxes = final_pred_dict[index][&amp;#39;pred_boxes&amp;#39;]\n            recall_dict = self.`generate_recall_record`(\n                box_preds=pred_boxes,\n                recall_dict=recall_dict, batch_index=index, data_dict=batch_dict,\n                thresh_list=post_process_cfg.RECALL_THRESH_LIST\n            )\n        return final_pred_dict, recall_dict\n\'> </span>'}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
