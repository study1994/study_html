<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>voxenext训练流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py-训练流程</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXt(Detector3DTemplate):\n    def forward(self, batch_dict):      <span style=\'color: red\'>dict_keys([\'points\', \'frame_id\', \'metadata\', \'gt_boxes\', \'flip_x\', \'flip_y\', \'noise_rot\', </span>\n                                    <span style=\'color: red\'>\'noise_scale\', \'use_lead_xyz\', \'voxels\', \'voxel_coords\', \'voxel_num_points\', \'batch_size\'])</span>\n        for cur_module in self.module_list:           <span style=\'color: red\'>MeanVFE();VoxelResBackBone8xVoxelNeXt();VoxelNeXtHead</span>\n            batch_dict = cur_module(batch_dict)\n        if self.training:\n            loss, tb_dict, disp_dict = self.<span style=\'color: green;font-weight: bold;\'>get_training_loss</span>()\n            ret_dict = {\'loss\': loss}\n            return ret_dict, tb_dict, disp_dict\n        else:\n            pred_dicts, recall_dicts = self.post_processing(batch_dict)\n            return pred_dicts, recall_dicts\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/vfe/mean_vfe.py</p><font size="0"><pre class="language-python"><code class="language-python">class MeanVFE(VFETemplate):\n    def forward(self, batch_dict, **kwargs):\n        voxel_features, voxel_num_points = batch_dict[\'voxels\'], batch_dict[\'voxel_num_points\']  <span style=\'color: red\'># torch.Size([386474, 10, 5]);torch.Size([386474])</span>\n        points_mean = voxel_features[:, :, :].sum(dim=1, keepdim=False)        \n        normalizer = torch.clamp_min(voxel_num_points.view(-1, 1), min=1.0).type_as(voxel_features)\n        points_mean = points_mean / normalizer\n        batch_dict[\'voxel_features\'] = points_mean.contiguous()       <span style=\'color: red\'># torch.Size([386474, 5])</span>\n        return batch_dict\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/spconv_backbone_voxelnext.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelResBackBone8xVoxelNeXt(nn.Module):\n    def forward(self, batch_dict):\n        voxel_features, voxel_coords = batch_dict[\'voxel_features\'], batch_dict[\'voxel_coords\']  <span style=\'color: red\'># torch.Size([386474, 5]),torch.Size([386474, 4])</span>\n        batch_size = batch_dict[\'batch_size\']\n        input_sp_tensor = spconv.SparseConvTensor(\n            features=voxel_features,\n            indices=voxel_coords.int(),\n            spatial_shape=self.sparse_shape,        <span style=\'color: red\'># [41, 1440, 1440]</span>\n            batch_size=batch_size\n        )\n        x = self.conv_input(input_sp_tensor)     <span style=\'color: red\'># [41, 1440, 1440]   torch.Size([386474, 4]),B,z,x,y</span>\n        x_conv1 = self.conv1(x)              <span style=\'color: red\'># [41, 1440, 1440] </span>\n        x_conv2 = self.conv2(x_conv1)        <span style=\'color: red\'># [21, 720, 720]    [(torch.min(x_conv3.indices[:,i]).item(),torch.max(x_conv3.indices[:,i]).item()) for i in range(4)]</span>\n        x_conv3 = self.conv3(x_conv2)        <span style=\'color: red\'># [11, 360, 360]      [(0, 3), (1, 10), (0, 359), (0, 359)]</span>\n        x_conv4 = self.conv4(x_conv3)        <span style=\'color: red\'># [6, 180, 180]       [(0, 3), (0, 5), (0, 179), (0, 179)]</span>\n        x_conv5 = self.conv5(x_conv4)        <span style=\'color: red\'># [3, 90, 90]</span>\n        x_conv6 = self.conv6(x_conv5)        <span style=\'color: red\'># [2, 45, 45]</span>\n        x_conv5.indices[:, 1:] *= 2\n        x_conv6.indices[:, 1:] *= 4\n        <span style=\'color: red\'># cat结果为(95490,128)的维度特征; x_conv4为(68725,128)的维度特征；</span>\n        x_conv4 = x_conv4.replace_feature(torch.cat([x_conv4.features, x_conv5.features, x_conv6.features]))     <span style=\'color: red\'># torch.Size([95490, 128])</span>\n        x_conv4.indices = torch.cat([x_conv4.indices, x_conv5.indices, x_conv6.indices])      <span style=\'color: red\'># 相当于把x_conv5和x_conv6的特征上采样到x_conv4</span>\n        out = self.<span style=\'color: green;font-weight: bold;\'>bev_out</span>(x_conv4)       <span style=\'color: red\'># [180, 180]</span>\n        out = self.conv_out(out)         <span style=\'color: red\'># [180, 180] + torch.Size([48666, 128])</span>\n        out = self.shared_conv(out)      <span style=\'color: red\'># [180, 180] + torch.Size([48666, 128])</span>\n        batch_dict.update({\n            \'encoded_spconv_tensor\': out,\n            \'encoded_spconv_tensor_stride\': 8      <span style=\'color: red\'># 8*180=1440</span>\n        })\n        batch_dict.update({\n            \'multi_scale_3d_features\': {\'x_conv1\': x_conv1,\'x_conv2\': x_conv2,\'x_conv3\': x_conv3,\'x_conv4\': x_conv4,}\n        })\n        batch_dict.update({\n            \'multi_scale_3d_strides\': {\'x_conv1\': 1,\'x_conv2\': 2,\'x_conv3\': 4,\'x_conv4\': 8,}\n        })\n        return batch_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/spconv_backbone_voxelnext.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelResBackBone8xVoxelNeXt(nn.Module):\n    def bev_out(self, x_conv):\n        features_cat = x_conv.features                      <span style=\'color: red\'># torch.Size([95490, 128])</span>\n        indices_cat = x_conv.indices[:, [0, 2, 3]]          <span style=\'color: red\'># B,X,Y   torch.Size([95490, 3])</span>\n        spatial_shape = x_conv.spatial_shape[1:]            <span style=\'color: red\'># [6, 180, 180]->[180, 180]</span>\n        <span style=\'color: red\'># indices_cat为[95490, 3]；假设95489和95488的值都为(0,20,11)，且indices_unique的第10个值为(0,20,11)则_inv[95488]=10,_inv[95499]=10</span>\n        indices_unique, _inv = torch.unique(indices_cat, dim=0, return_inverse=True)                  <span style=\'color: red\'># torch.Size([29914, 3])  torch.Size([95490])范围为0-29914</span>\n        features_unique = features_cat.new_zeros((indices_unique.shape[0], features_cat.shape[1]))    <span style=\'color: red\'># torch.Size([29914, 128])</span>\n        features_unique.index_add_(0, _inv, features_cat)    <span style=\'color: red\'># 对相同索引下的特征进行相加</span>\n        x_out = spconv.SparseConvTensor(\n            features=features_unique,\n            indices=indices_unique,                <span style=\'color: red\'># torch.Size([29914, 3])</span>\n            spatial_shape=spatial_shape,           <span style=\'color: red\'># [180, 180]</span>\n            batch_size=x_conv.batch_size           <span style=\'color: red\'># 4</span>\n        )\n        return x_out\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def forward(self, data_dict):\n        x = data_dict[\'encoded_spconv_tensor\']                  <span style=\'color: red\'># [180, 180]</span>\n        spatial_shape, batch_index, voxel_indices, spatial_indices, num_voxels = self.<span style=\'color: green;font-weight: bold;\'>_get_voxel_infos</span>(x)\n        self.forward_ret_dict[\'batch_index\'] = batch_index      <span style=\'color: red\'># 范围为0-3</span>\n        \n        pred_dicts = []\n        for head in self.heads_list:\n            pred_dicts.append(<span style=\'color: green;font-weight: bold;\'>head</span>(x))  <span style=\'color: red\'># [{\'center\':, \'center_z\':, \'dim\':, \'rot\':, \'vel\':},{},{},{},{},{}]</span>\n        if self.training:\n            target_dict = self.<span style=\'color: green;font-weight: bold;\'>assign_targets</span>(data_dict[\'gt_boxes\'], num_voxels, spatial_indices, spatial_shape)     \n            <span style=\'color: red\'># 每个格子里面有多少个点，这些点在那个格子里面，[180, 180]大小的格子</span>\n            self.forward_ret_dict[\'target_dicts\'] = target_dict    <span style=\'color: red\'># [(key,i.shape) for key,value in target_dict.items() for i in value if torch.is_tensor(i)]</span>\n        """\n        00:(\'heatmaps\', torch.Size([12154, 1]))\n        05:(\'heatmaps\', torch.Size([12154, 2]))\n        06:(\'target_boxes\', torch.Size([1, 500, 10]))\n        12:(\'inds\', torch.Size([1, 500]))\n        23:(\'masks\', torch.Size([1, 500]))\n        """\n        self.forward_ret_dict[\'pred_dicts\'] = pred_dicts\n        self.forward_ret_dict[\'voxel_indices\'] = voxel_indices     <span style=\'color: red\'># torch.Size([12154, 3]) type为int，范围为(0->B-1,0->180-1,0->180-1)</span>\n        return data_dict \n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def _get_voxel_infos(self, x):\n        spatial_shape = x.spatial_shape      <span style=\'color: red\'># [180, 180]</span>\n        voxel_indices = x.indices            <span style=\'color: red\'># torch.Size([48666, 3])</span>\n        spatial_indices = []\n        num_voxels = []\n        batch_size = x.batch_size\n        batch_index = voxel_indices[:, 0]\n        for bs_idx in range(batch_size):\n            batch_inds = batch_index==bs_idx\n            spatial_indices.append(voxel_indices[batch_inds][:, [2, 1]])\n            num_voxels.append(batch_inds.sum())\n        <span style=\'color: red\'># [180, 180], torch.Size([48666]), torch.Size([48666, 3]), [[12154, 2],[12196, 2],[12132, 2],[12184, 2]],  [12154,12196,12132,12184]</span>\n        return spatial_shape, batch_index, voxel_indices, spatial_indices, num_voxels\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def assign_targets(self, gt_boxes, num_voxels, spatial_indices, spatial_shape):\n        target_assigner_cfg = self.model_cfg.TARGET_ASSIGNER_CONFIG\n        batch_size = gt_boxes.shape[0]        <span style=\'color: red\'># 1</span>\n        ret_dict = {\'heatmaps\': [],\'target_boxes\': [],\'inds\': [],\'masks\': [],\'heatmap_masks\': [],\'gt_boxes\': []}\n        all_names = np.array([\'bg\', *self.class_names])                          <span style=\'color: red\'># 11</span>\n        for idx, cur_class_names in enumerate(self.class_names_each_head):       <span style=\'color: red\'># [\'car\']</span>\n            heatmap_list, target_boxes_list, inds_list, masks_list, gt_boxes_list = [], [], [], [], []\n            for bs_idx in range(batch_size):     #\n                cur_gt_boxes = gt_boxes[bs_idx]\n                gt_class_names = all_names[cur_gt_boxes[:, -1].cpu().long().numpy()]\n                gt_boxes_single_head = []\n                for idx, name in enumerate(gt_class_names):\n                    if name not in cur_class_names:\n                        continue\n                    temp_box = cur_gt_boxes[idx]\n                    temp_box[-1] = cur_class_names.index(name) + 1\n                    gt_boxes_single_head.append(temp_box[None, :])\n                if len(gt_boxes_single_head) == 0:\n                    gt_boxes_single_head = cur_gt_boxes[:0, :]\n                else:\n                    gt_boxes_single_head = torch.cat(gt_boxes_single_head, dim=0)    <span style=\'color: red\'># torch.Size([2, 10])</span>\n                heatmap, ret_boxes, inds, mask = self.<span style=\'color: green;font-weight: bold;\'>assign_target_of_single_head</span>(\n                    num_classes=len(cur_class_names), gt_boxes=gt_boxes_single_head,        <span style=\'color: red\'># 1，torch.Size([2, 10])</span>\n                    num_voxels=num_voxels[bs_idx], spatial_indices=spatial_indices[bs_idx], <span style=\'color: red\'># 12154，torch.Size([12154, 2])</span>\n                    spatial_shape=spatial_shape, \n                    feature_map_stride=target_assigner_cfg.FEATURE_MAP_STRIDE,    <span style=\'color: red\'># 8</span>\n                    num_max_objs=target_assigner_cfg.NUM_MAX_OBJS,                <span style=\'color: red\'># 500</span>\n                    gaussian_overlap=target_assigner_cfg.GAUSSIAN_OVERLAP,        <span style=\'color: red\'># 0.1</span>\n                    min_radius=target_assigner_cfg.MIN_RADIUS,                    <span style=\'color: red\'># 2</span>\n                )\n                heatmap_list.append(heatmap.to(gt_boxes_single_head.device))\n                target_boxes_list.append(ret_boxes.to(gt_boxes_single_head.device))\n                inds_list.append(inds.to(gt_boxes_single_head.device))\n                masks_list.append(mask.to(gt_boxes_single_head.device))\n                gt_boxes_list.append(gt_boxes_single_head[:, :-1])\n            ret_dict[\'heatmaps\'].append(torch.cat(heatmap_list, dim=1).permute(1, 0))\n            ret_dict[\'target_boxes\'].append(torch.stack(target_boxes_list, dim=0))\n            ret_dict[\'inds\'].append(torch.stack(inds_list, dim=0))\n            ret_dict[\'masks\'].append(torch.stack(masks_list, dim=0))\n            ret_dict[\'gt_boxes\'].append(gt_boxes_list)\n        return ret_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def assign_target_of_single_head(self, num_classes, gt_boxes, num_voxels, spatial_indices, spatial_shape, feature_map_stride, num_max_objs=500,\n                gaussian_overlap=0.1, min_radius=2):\n        heatmap = gt_boxes.new_zeros(num_classes, num_voxels)     <span style=\'color: red\'># torch.Size([1, 12154])</span>\n        ret_boxes = gt_boxes.new_zeros((num_max_objs, gt_boxes.shape[-1] - 1 + 1))\n        inds = gt_boxes.new_zeros(num_max_objs).long()\n        mask = gt_boxes.new_zeros(num_max_objs).long()\n        x, y, z = gt_boxes[:, 0], gt_boxes[:, 1], gt_boxes[:, 2]\n        coord_x = (x - self.point_cloud_range[0]) / self.voxel_size[0] / feature_map_stride\n        coord_y = (y - self.point_cloud_range[1]) / self.voxel_size[1] / feature_map_stride\n        coord_x = torch.clamp(coord_x, min=0, max=spatial_shape[1] - 0.5)  <span style=\'color: red\'># bugfixed: 1e-6 does not work for center.int()</span>\n        coord_y = torch.clamp(coord_y, min=0, max=spatial_shape[0] - 0.5)  <span style=\'color: red\'># 范围变到0-(180-0.5=179.5)</span>\n        center = torch.cat((coord_x[:, None], coord_y[:, None]), dim=-1)\n        center_int = center.int()\n        center_int_float = center_int.float()     <span style=\'color: red\'># 0-179</span>\n        dx, dy, dz = gt_boxes[:, 3], gt_boxes[:, 4], gt_boxes[:, 5]       <span style=\'color: red\'># 长宽高</span>\n        dx = dx / self.voxel_size[0] / feature_map_stride\n        dy = dy / self.voxel_size[1] / feature_map_stride\n        radius = centernet_utils.gaussian_radius(dx, dy, min_overlap=gaussian_overlap)\n        radius = torch.clamp_min(radius.int(), min=min_radius)\n        for k in range(min(num_max_objs, gt_boxes.shape[0])):  <span style=\'color: red\'># 0-2</span>\n            if dx[k] <= 0 or dy[k] <= 0:\n                continue\n            if not (0 <= center_int[k][0] <= spatial_shape[1] and 0 <= center_int[k][1] <= spatial_shape[0]):\n                continue\n            cur_class_id = (gt_boxes[k, -1] - 1).long()     <span style=\'color: red\'># id从0开始，类别从car开始</span>\n            distance = self.distance(spatial_indices, center[k])    <span style=\'color: red\'># 距离最短的那个作为box响应</span>\n            inds[k] = distance.argmin()\n            mask[k] = 1\n            if \'gt_center\' in self.gaussian_type:        <span style=\'color: red\'># True pcdet/models/model_utils/centernet_utils.py</span>\n                centernet_utils.<span style=\'color: green;font-weight: bold;\'>draw_gaussian_to_heatmap_voxels</span>(heatmap[cur_class_id], distance, radius[k].item() * self.gaussian_ratio)\n            if \'nearst\' in self.gaussian_type:\n                centernet_utils.draw_gaussian_to_heatmap_voxels(heatmap[cur_class_id], self.distance(spatial_indices, spatial_indices[inds[k]]), radius[k].item() * self.gaussian_ratio)\n            ret_boxes[k, 0:2] = center[k] - spatial_indices[inds[k]][:2]  <span style=\'color: red\'># 相应的距离与该格子的距离</span>\n            ret_boxes[k, 2] = z[k]\n            ret_boxes[k, 3:6] = gt_boxes[k, 3:6].log()\n            ret_boxes[k, 6] = torch.cos(gt_boxes[k, 6])\n            ret_boxes[k, 7] = torch.sin(gt_boxes[k, 6])\n            if gt_boxes.shape[1] > 8:\n                ret_boxes[k, 8:] = gt_boxes[k, 7:-1]\n        return heatmap, ret_boxes, inds, mask    <span style=\'color: red\'># torch.Size([1, 12154])； torch.Size([500, 10]) torch.Size([500])； torch.Size([500])</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/centernet_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def draw_gaussian_to_heatmap_voxels(heatmap, distances, radius, k=1):\n    diameter = 2 * radius + 1       <span style=\'color: red\'># 2*2+1=5</span>\n    sigma = diameter / 6            <span style=\'color: red\'># 5/6</span>\n    masked_gaussian = torch.exp(- distances / (2 * sigma * sigma))     <span style=\'color: red\'># torch.Size([12154])--距离越大，值越小</span>\n    torch.max(heatmap, masked_gaussian, out=heatmap)\n    return heatmap\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXt(Detector3DTemplate):\n    def get_training_loss(self):\n        disp_dict = {}\n        loss, tb_dict = self.dense_head.<span style=\'color: green;font-weight: bold;\'>get_loss</span>()\n        return loss, tb_dict, disp_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def get_loss(self):                                            <span style=\'color: red\'># 新的一段</span>\n        pred_dicts = self.forward_ret_dict[\'pred_dicts\']\n        target_dicts = self.forward_ret_dict[\'target_dicts\']\n        batch_index = self.forward_ret_dict[\'batch_index\']         <span style=\'color: red\'># torch.Size([64265])</span>\n        tb_dict = {}\n        loss = 0\n        batch_indices = self.forward_ret_dict[\'voxel_indices\'][:, 0]\n        spatial_indices = self.forward_ret_dict[\'voxel_indices\'][:, 1:]\n        for idx, pred_dict in enumerate(pred_dicts):\n            pred_dict[\'hm\'] = self.sigmoid(pred_dict[\'hm\'])          <span style=\'color: red\'># torch.Size([64265, 1])</span>\n            hm_loss = self.hm_loss_func(pred_dict[\'hm\'], target_dicts[\'heatmaps\'][idx])    <span style=\'color: red\'># torch.Size([64265, 1]);torch.Size([64265, 1])   FocalLossSparse()</span>\n            hm_loss *= self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[\'cls_weight\']      <span style=\'color: red\'># *1.0</span>\n            target_boxes = target_dicts[\'target_boxes\'][idx]                      <span style=\'color: red\'># torch.Size([4, 500, 10])</span>\n            pred_boxes = torch.cat([pred_dict[head_name] for head_name in self.separate_head_cfg.HEAD_ORDER], dim=1)  <span style=\'color: red\'># torch.Size([64265, 10])</span>\n            reg_loss = self.reg_loss_func(                                        <span style=\'color: red\'># RegLossSparse()</span>\n                pred_boxes, target_dicts[\'masks\'][idx], target_dicts[\'inds\'][idx], target_boxes, batch_index\n            )  <span style=\'color: red\'># torch.Size([64265, 10]) + torch.Size([4, 500]) + torch.Size([4, 500]) + torch.Size([4, 500, 10]) + torch.Size([64265])->torch.Size([10])</span>\n            loc_loss = (reg_loss * reg_loss.new_tensor(self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[\'code_weights\'])).sum() <span style=\'color: red\'># [1,1,1,1,1,1,0.2,0.2,1,1]</span>\n            loc_loss = loc_loss * self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[\'loc_weight\']\n            tb_dict[\'hm_loss_head_%d\' % idx] = hm_loss.item()\n            tb_dict[\'loc_loss_head_%d\' % idx] = loc_loss.item()\n            if self.iou_branch:\n                batch_box_preds = self.<span style=\'color: green;font-weight: bold;\'>_get_predicted_boxes</span>(pred_dict, spatial_indices)\n                pred_boxes_for_iou = batch_box_preds.detach()\n                iou_loss = self.crit_iou(pred_dict[\'iou\'], target_dicts[\'masks\'][idx], target_dicts[\'inds\'][idx],\n                                            pred_boxes_for_iou, target_dicts[\'gt_boxes\'][idx], batch_indices)\n                iou_reg_loss = self.crit_iou_reg(batch_box_preds, target_dicts[\'masks\'][idx], target_dicts[\'inds\'][idx],\n                                                    target_dicts[\'gt_boxes\'][idx], batch_indices)\n                iou_weight = self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[\'iou_weight\'] if \'iou_weight\' in self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS else self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[\'loc_weight\']\n                iou_reg_loss = iou_reg_loss * iou_weight #self.model_cfg.LOSS_CONFIG.LOSS_WEIGHTS[\'loc_weight\']\n                loss += (hm_loss + loc_loss + iou_loss + iou_reg_loss)\n                tb_dict[\'iou_loss_head_%d\' % idx] = iou_loss.item()\n                tb_dict[\'iou_reg_loss_head_%d\' % idx] = iou_reg_loss.item()\n            else:\n                loss += hm_loss + loc_loss\n        tb_dict[\'rpn_loss\'] = loss.item()\n        return loss, tb_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def _get_predicted_boxes(self, pred_dict, spatial_indices):\n        center = pred_dict[\'center\']\n        center_z = pred_dict[\'center_z\']\n        #dim = pred_dict[\'dim\'].exp()\n        dim = torch.exp(torch.clamp(pred_dict[\'dim\'], min=-5, max=5))\n        rot_cos = pred_dict[\'rot\'][:, 0].unsqueeze(dim=1)\n        rot_sin = pred_dict[\'rot\'][:, 1].unsqueeze(dim=1)\n        angle = torch.atan2(rot_sin, rot_cos)\n        xs = (spatial_indices[:, 1:2] + center[:, 0:1]) * self.feature_map_stride * self.voxel_size[0] + self.point_cloud_range[0]\n        ys = (spatial_indices[:, 0:1] + center[:, 1:2]) * self.feature_map_stride * self.voxel_size[1] + self.point_cloud_range[1]\n        box_part_list = [xs, ys, center_z, dim, angle]\n        pred_box = torch.cat((box_part_list), dim=-1)\n        return pred_box\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py-预测流程</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXt(Detector3DTemplate):\n    def forward(self, batch_dict):      <span style=\'color: red\'>dict_keys([\'points\', \'frame_id\', \'metadata\', \'gt_boxes\', \'flip_x\', \'flip_y\', \'noise_rot\', </span>\n                                    <span style=\'color: red\'>\'noise_scale\', \'use_lead_xyz\', \'voxels\', \'voxel_coords\', \'voxel_num_points\', \'batch_size\'])</span>\n        for cur_module in self.module_list:           <span style=\'color: red\'>MeanVFE();VoxelResBackBone8xVoxelNeXt();VoxelNeXtHead</span>\n            batch_dict = <span style=\'color: green;font-weight: bold;\'>cur_module</span>(batch_dict)\n        if self.training:\n            loss, tb_dict, disp_dict = self.get_training_loss()\n            ret_dict = {\'loss\': loss}\n            return ret_dict, tb_dict, disp_dict\n        else:\n            pred_dicts, recall_dicts = self.<span style=\'color: green;font-weight: bold;\'>post_processing</span>(batch_dict)\n            return pred_dicts, recall_dicts\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def forward(self, data_dict):\n        x = data_dict[\'encoded_spconv_tensor\']        <span style=\'color: red\'># [180, 180]</span>\n        spatial_shape, batch_index, voxel_indices, spatial_indices, num_voxels = self._get_voxel_infos(x)\n        self.forward_ret_dict[\'batch_index\'] = batch_index <span style=\'color: red\'># 范围为0-3</span>\n        \n        pred_dicts = []\n        for head in self.heads_list:\n            pred_dicts.append(head(x))  <span style=\'color: red\'># [{\'center\':, \'center_z\':, \'dim\':, \'rot\':, \'vel\':},{},{},{},{},{}]</span>\n        if self.training:\n            target_dict = self.assign_targets(\n                data_dict[\'gt_boxes\'], num_voxels, spatial_indices, spatial_shape\n            )     <span style=\'color: red\'># 每个格子里面有多少个点，这些点在那个格子里面，[180, 180]大小的格子</span>\n            self.forward_ret_dict[\'target_dicts\'] = target_dict    <span style=\'color: red\'># [(key,i.shape) for key,value in target_dict.items() for i in value if torch.is_tensor(i)]</span>\n        """\n        00:(\'heatmaps\', torch.Size([12154, 1]))\n        05:(\'heatmaps\', torch.Size([12154, 2]))\n        06:(\'target_boxes\', torch.Size([1, 500, 10]))\n        12:(\'inds\', torch.Size([1, 500]))\n        23:(\'masks\', torch.Size([1, 500]))\n        """\n        self.forward_ret_dict[\'pred_dicts\'] = pred_dicts\n        self.forward_ret_dict[\'voxel_indices\'] = voxel_indices\n        if not self.training or self.predict_boxes_when_training:\n            if self.double_flip:\n                data_dict[\'batch_size\'] = data_dict[\'batch_size\'] <span style=\'color: red\'>// 4</span>\n            pred_dicts = self.<span style=\'color: green;font-weight: bold;\'>generate_predicted_boxes</span>(data_dict[\'batch_size\'], pred_dicts, voxel_indices, spatial_shape)\n            if self.predict_boxes_when_training:\n                rois, roi_scores, roi_labels = self.reorder_rois_for_refining(data_dict[\'batch_size\'], pred_dicts)\n                data_dict[\'rois\'] = rois\n                data_dict[\'roi_scores\'] = roi_scores\n                data_dict[\'roi_labels\'] = roi_labels\n                data_dict[\'has_class_labels\'] = True\n            else:\n                data_dict[\'final_box_dicts\'] = pred_dicts\n        return data_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def generate_predicted_boxes(self, batch_size, pred_dicts, voxel_indices, spatial_shape):\n        post_process_cfg = self.model_cfg.POST_PROCESSING\n        post_center_limit_range = torch.tensor(post_process_cfg.POST_CENTER_LIMIT_RANGE).cuda().float()     <span style=\'color: red\'># [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]</span>\n        ret_dict = [{\'pred_boxes\': [], \'pred_scores\': [], \'pred_labels\': [], \'pred_ious\': []} for k in range(batch_size)]\n        for idx, pred_dict in enumerate(pred_dicts):\n            if self.double_flip:                <span style=\'color: red\'># False</span>\n                batch_hm, batch_center, batch_center_z, batch_dim, batch_rot_cos, batch_rot_sin, batch_vel, batch_iou, voxel_indices_ = self.<span style=\'color: green;font-weight: bold;\'>merge_double_flip</span>( )\n            else:       <span style=\'color: red\'># [(key,value.shape) for key,value in pred_dict.items()]</span>\n                batch_hm = pred_dict[\'hm\'].sigmoid()  <span style=\'color: red\'># [(\'center\', torch.Size([44223, 2])), (\'center_z\', torch.Size([44223, 1])), (\'dim\', torch.Size([44223, 3])), (\'rot\', torch.Size([44223, 2])), (\'vel\', torch.Size([44223, 2])), (\'hm\', torch.Size([44223, 1]))]</span>\n                batch_center = pred_dict[\'center\']\n                batch_center_z = pred_dict[\'center_z\']\n                batch_dim = pred_dict[\'dim\'].exp()\n                batch_rot_cos = pred_dict[\'rot\'][:, 0].unsqueeze(dim=1)\n                batch_rot_sin = pred_dict[\'rot\'][:, 1].unsqueeze(dim=1)\n                batch_iou = (pred_dict[\'iou\'] + 1) * 0.5 if self.iou_branch else None\n                batch_vel = pred_dict[\'vel\'] if \'vel\' in self.separate_head_cfg.HEAD_ORDER else None\n                voxel_indices_ = voxel_indices         <span style=\'color: red\'># torch.Size([44223, 3]),B,X,Y</span>\n            final_pred_dicts = centernet_utils.<span style=\'color: green;font-weight: bold;\'>decode_bbox_from_voxels_nuscenes</span>(\n                batch_size=batch_size, indices=voxel_indices_,\n                obj=batch_hm, \n                rot_cos=batch_rot_cos,\n                rot_sin=batch_rot_sin,\n                center=batch_center, center_z=batch_center_z,\n                dim=batch_dim, vel=batch_vel, iou=batch_iou,\n                point_cloud_range=self.point_cloud_range, voxel_size=self.voxel_size,\n                feature_map_stride=self.feature_map_stride,                                <span style=\'color: red\'># 8</span>\n                K=post_process_cfg.MAX_OBJ_PER_SAMPLE,                                     <span style=\'color: red\'># 500</span>\n                #circle_nms=(post_process_cfg.NMS_CONFIG.NMS_TYPE == \'circle_nms\'),\n                score_thresh=post_process_cfg.SCORE_THRESH,\n                post_center_limit_range=post_center_limit_range\n            )\n            for k, final_dict in enumerate(final_pred_dicts):\n                final_dict[\'pred_labels\'] = self.class_id_mapping_each_head[idx][final_dict[\'pred_labels\'].long()]   <span style=\'color: red\'># [[0],[1, 2],[3, 4],[5],[6, 7],[8, 9]]</span>\n                if not self.iou_branch:      <span style=\'color: red\'># True</span>\n                    selected, selected_scores = model_nms_utils.<span style=\'color: green;font-weight: bold;\'>class_agnostic_nms</span>(\n                        box_scores=final_dict[\'pred_scores\'], box_preds=final_dict[\'pred_boxes\'],\n                        nms_config=post_process_cfg.NMS_CONFIG,\n                        score_thresh=None\n                    )\n                    final_dict[\'pred_boxes\'] = final_dict[\'pred_boxes\'][selected]\n                    final_dict[\'pred_scores\'] = selected_scores\n                    final_dict[\'pred_labels\'] = final_dict[\'pred_labels\'][selected]\n                ret_dict[k][\'pred_boxes\'].append(final_dict[\'pred_boxes\'])\n                ret_dict[k][\'pred_scores\'].append(final_dict[\'pred_scores\'])\n                ret_dict[k][\'pred_labels\'].append(final_dict[\'pred_labels\'])\n                ret_dict[k][\'pred_ious\'].append(final_dict[\'pred_ious\'])\n        for k in range(batch_size):\n            pred_boxes = torch.cat(ret_dict[k][\'pred_boxes\'], dim=0)\n            pred_scores = torch.cat(ret_dict[k][\'pred_scores\'], dim=0)\n            pred_labels = torch.cat(ret_dict[k][\'pred_labels\'], dim=0)\n            if self.iou_branch:\n                pred_ious = torch.cat(ret_dict[k][\'pred_ious\'], dim=0)\n                pred_boxes, pred_scores, pred_labels = self.rotate_class_specific_nms_iou(pred_boxes, pred_scores, pred_ious, pred_labels, self.rectifier, self.nms_configs)\n            ret_dict[k][\'pred_boxes\'] = pred_boxes\n            ret_dict[k][\'pred_scores\'] = pred_scores\n            ret_dict[k][\'pred_labels\'] = pred_labels + 1\n        return ret_dict\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/voxelnext_head.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXtHead(nn.Module):\n    def merge_double_flip(self, pred_dict, batch_size, voxel_indices, spatial_shape):\n        <span style=\'color: red\'># spatial_shape (Z, Y, X)     [334, 334]  - y,x</span>\n        pred_dict[\'hm\'] = pred_dict[\'hm\'].sigmoid()          <span style=\'color: red\'># torch.Size([257894, 1])</span>\n        pred_dict[\'dim\'] = pred_dict[\'dim\'].exp()            <span style=\'color: red\'># torch.Size([257894, 3])</span>\n        batch_indices = voxel_indices[:, 0]                  <span style=\'color: red\'># torch.Size([257894])  范围0-7，真实batch size为2</span>\n        spatial_indices = voxel_indices[:, 1:]               <span style=\'color: red\'># torch.Size([257894, 2])对应y-x</span>\n        pred_dict_ = {k: [] for k in pred_dict.keys()}\n        counts = []\n        spatial_indices_ = []\n        for bs_idx in range(batch_size):                     <span style=\'color: red\'># 2</span>\n            spatial_indices_batch = []\n            pred_dict_batch = {k: [] for k in pred_dict.keys()}\n            for i in range(4):                               <span style=\'color: red\'># \'org\',\'yflip\', \'xflip\', \'xyflip\'</span>\n                bs_indices = batch_indices == (bs_idx * 4 + i)\n                if i in [1, 3]:\n                    spatial_indices[bs_indices, 0] = spatial_shape[0] - spatial_indices[bs_indices, 0]  <span style=\'color: red\'># 处理y值</span>\n                if i in [2, 3]:\n                    spatial_indices[bs_indices, 1] = spatial_shape[1] - spatial_indices[bs_indices, 1]  <span style=\'color: red\'># 处理x值</span>\n                if i == 1:\n                    pred_dict[\'center\'][bs_indices, 1] = - pred_dict[\'center\'][bs_indices, 1]\n                    pred_dict[\'rot\'][bs_indices, 1] *= -1           <span style=\'color: red\'># y翻转</span>\n                    if \'vel\' in pred_dict:\n                        pred_dict[\'vel\'][bs_indices, 1] *= -1\n                if i == 2:\n                    pred_dict[\'center\'][bs_indices, 0] = - pred_dict[\'center\'][bs_indices, 0]\n                    pred_dict[\'rot\'][bs_indices, 0] *= -1           <span style=\'color: red\'># x翻转</span>\n                    if \'vel\' in pred_dict:\n                        pred_dict[\'vel\'][bs_indices, 0] *= -1\n                if i == 3:\n                    pred_dict[\'center\'][bs_indices, 0] = - pred_dict[\'center\'][bs_indices, 0]\n                    pred_dict[\'center\'][bs_indices, 1] = - pred_dict[\'center\'][bs_indices, 1]\n                    pred_dict[\'rot\'][bs_indices, 1] *= -1\n                    pred_dict[\'rot\'][bs_indices, 0] *= -1\n                    if \'vel\' in pred_dict:\n                        pred_dict[\'vel\'][bs_indices] *= -1\n                spatial_indices_batch.append(spatial_indices[bs_indices])\n                for k in pred_dict.keys():\n                    pred_dict_batch[k].append(pred_dict[k][bs_indices])\n            spatial_indices_batch = torch.cat(spatial_indices_batch)        <span style=\'color: red\'># [,,,]四个合成一个torch.Size([128697, 2])</span>\n            spatial_indices_unique, _inv, count = torch.unique(spatial_indices_batch, dim=0, return_inverse=True,return_counts=True)  <span style=\'color: red\'># torch.Size([37359, 2])有3万7千多个唯一值，torch.Size([128697])值范围在0-37359，torch.Size([37359])</span>\n            spatial_indices_.append(spatial_indices_unique)\n            counts.append(count)\n            for k in pred_dict.keys():\n                pred_dict_batch[k] = torch.cat(pred_dict_batch[k])                         <span style=\'color: red\'># k=\'center\' 合并后 pred_dict_batch[k].shape=torch.Size([128697, 2])</span>\n                features_unique = pred_dict_batch[k].new_zeros((spatial_indices_unique.shape[0], pred_dict_batch[k].shape[1]))   <span style=\'color: red\'># 初始化0值的 torch.Size([37359, 2])</span>\n                features_unique.index_add_(0, _inv, pred_dict_batch[k])                    <span style=\'color: red\'># 这里把相同预测的加起来</span>\n                pred_dict_[k].append(features_unique)\n        for k in pred_dict.keys():\n            pred_dict_[k] = torch.cat(pred_dict_[k])                  <span style=\'color: red\'># 长度为2，拼起来</span>\n        counts = torch.cat(counts).unsqueeze(-1).float()\n        voxel_indices_ = torch.cat([torch.cat(\n            [torch.full((indices.shape[0], 1), i, device=indices.device, dtype=indices.dtype), indices], dim=1\n        ) for i, indices in enumerate(spatial_indices_)])\n        batch_hm = pred_dict_[\'hm\']\n        batch_center = pred_dict_[\'center\']\n        batch_center_z = pred_dict_[\'center_z\']\n        batch_dim = pred_dict_[\'dim\']\n        batch_rot_cos = pred_dict_[\'rot\'][:, 0].unsqueeze(dim=1)\n        batch_rot_sin = pred_dict_[\'rot\'][:, 1].unsqueeze(dim=1)\n        batch_vel = pred_dict_[\'vel\'] if \'vel\' in self.separate_head_cfg.HEAD_ORDER else None\n        batch_hm /= counts                                        <span style=\'color: red\'># 相当于相同位置预测的box求平均了</span>\n        batch_center /= counts\n        batch_center_z /= counts\n        batch_dim /= counts\n        batch_rot_cos /= counts\n        batch_rot_sin /= counts\n        if not batch_vel is None:\n            batch_vel /= counts\n        return batch_hm, batch_center, batch_center_z, batch_dim, batch_rot_cos, batch_rot_sin, batch_vel, None, voxel_indices_\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/centernet_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def decode_bbox_from_voxels_nuscenes(batch_size, indices, obj, rot_cos, rot_sin,\n                            center, center_z, dim, vel=None, iou=None, point_cloud_range=None, voxel_size=None, voxels_3d=None,\n                            feature_map_stride=None, K=100, score_thresh=None, post_center_limit_range=None, add_features=None):\n    batch_idx = indices[:, 0]\n    spatial_indices = indices[:, 1:]\n    scores, inds, class_ids = _topk_1d(None, batch_size, batch_idx, obj, K=K, nuscenes=True)   <span style=\'color: red\'># obj->batch_hm</span>\n    center = gather_feat_idx(center, inds, batch_size, batch_idx)       <span style=\'color: red\'># torch.Size([4, 500]),4,torch.Size([44223])</span>\n    rot_sin = gather_feat_idx(rot_sin, inds, batch_size, batch_idx)\n    rot_cos = gather_feat_idx(rot_cos, inds, batch_size, batch_idx)\n    center_z = gather_feat_idx(center_z, inds, batch_size, batch_idx)\n    dim = gather_feat_idx(dim, inds, batch_size, batch_idx)\n    spatial_indices = gather_feat_idx(spatial_indices, inds, batch_size, batch_idx)\n    if not add_features is None:\n        add_features = [gather_feat_idx(add_feature, inds, batch_size, batch_idx) for add_feature in add_features]\n    if not isinstance(feature_map_stride, int):\n        feature_map_stride = gather_feat_idx(feature_map_stride.unsqueeze(-1), inds, batch_size, batch_idx)\n    angle = torch.atan2(rot_sin, rot_cos)\n    xs = (spatial_indices[:, :, -1:] + center[:, :, 0:1]) * feature_map_stride * voxel_size[0] + point_cloud_range[0]\n    ys = (spatial_indices[:, :, -2:-1] + center[:, :, 1:2]) * feature_map_stride * voxel_size[1] + point_cloud_range[1]\n    #zs = (spatial_indices[:, :, 0:1]) * feature_map_stride * voxel_size[2] + point_cloud_range[2] + center_z\n    box_part_list = [xs, ys, center_z, dim, angle]\n    if not vel is None:\n        vel = gather_feat_idx(vel, inds, batch_size, batch_idx)\n        box_part_list.append(vel)\n    if not iou is None:\n        iou = gather_feat_idx(iou, inds, batch_size, batch_idx)\n        iou = torch.clamp(iou, min=0, max=1.)\n    final_box_preds = torch.cat((box_part_list), dim=-1)           <span style=\'color: red\'># torch.Size([4, 500, 9])</span>\n    final_scores = scores.view(batch_size, K)                      <span style=\'color: red\'># torch.Size([4, 500])</span>\n    final_class_ids = class_ids.view(batch_size, K)                <span style=\'color: red\'># torch.Size([4, 500])</span>\n    if not add_features is None:                                   <span style=\'color: red\'># False</span>\n        add_features = [add_feature.view(batch_size, K, add_feature.shape[-1]) for add_feature in add_features]\n    assert post_center_limit_range is not None\n    mask = (final_box_preds[..., :3] >= post_center_limit_range[:3]).all(2)\n    mask &= (final_box_preds[..., :3] <= post_center_limit_range[3:]).all(2)\n    if score_thresh is not None:\n        mask &= (final_scores > score_thresh)\n    ret_pred_dicts = []\n    for k in range(batch_size):\n        cur_mask = mask[k]\n        cur_boxes = final_box_preds[k, cur_mask]\n        cur_scores = final_scores[k, cur_mask]\n        cur_labels = final_class_ids[k, cur_mask]\n        cur_add_features = [add_feature[k, cur_mask] for add_feature in add_features] if not add_features is None else None\n        cur_iou = iou[k, cur_mask] if not iou is None else None\n        ret_pred_dicts.append({\n            \'pred_boxes\': cur_boxes,\n            \'pred_scores\': cur_scores,\n            \'pred_labels\': cur_labels,\n            \'pred_ious\': cur_iou,\n            \'add_features\': cur_add_features,\n        })\n    return ret_pred_dicts\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/model_utils/model_nms_utils.py</p><font size="0"><pre class="language-python"><code class="language-python">def class_agnostic_nms(box_scores, box_preds, nms_config, score_thresh=None):\n    src_box_scores = box_scores\n    if score_thresh is not None:\n        scores_mask = (box_scores >= score_thresh)\n        box_scores = box_scores[scores_mask]\n        box_preds = box_preds[scores_mask]\n    selected = []\n    if box_scores.shape[0] > 0:\n        box_scores_nms, indices = torch.topk(box_scores, k=min(nms_config.NMS_PRE_MAXSIZE, box_scores.shape[0]))\n        boxes_for_nms = box_preds[indices]\n        keep_idx, selected_scores = getattr(iou3d_nms_utils, nms_config.NMS_TYPE)(\n                boxes_for_nms[:, 0:7], box_scores_nms, nms_config.NMS_THRESH, **nms_config\n        )\n        selected = indices[keep_idx[:nms_config.NMS_POST_MAXSIZE]]\n    if score_thresh is not None:\n        original_idxs = scores_mask.nonzero().view(-1)\n        selected = original_idxs[selected]\n    return selected, src_box_scores[selected]\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/voxelnext.py</p><font size="0"><pre class="language-python"><code class="language-python">class VoxelNeXt(Detector3DTemplate):\n    def post_processing(self, batch_dict):\n        post_process_cfg = self.model_cfg.POST_PROCESSING <span style=\'color: red\'># {\'RECALL_THRESH_LIST\': [0.3, 0.5, 0.7], \'EVAL_METRIC\': \'kitti\'}</span>\n        batch_size = batch_dict[\'batch_size\']\n        final_pred_dict = batch_dict[\'final_box_dicts\']\n        recall_dict = {}\n        for index in range(batch_size):\n            pred_boxes = final_pred_dict[index][\'pred_boxes\']\n            recall_dict = self.<span style=\'color: green;font-weight: bold;\'>generate_recall_record</span>(\n                box_preds=pred_boxes,\n                recall_dict=recall_dict, batch_index=index, data_dict=batch_dict,\n                thresh_list=post_process_cfg.RECALL_THRESH_LIST\n            )\n        return final_pred_dict, recall_dict\n</code></pre></font>'}]}]})</script></body>
</html>
