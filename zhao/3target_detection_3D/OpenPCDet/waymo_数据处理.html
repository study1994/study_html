<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>waymo_数据处理</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p>单帧数据处理<a href="">tools/cfgs/dataset_configs/waymo_dataset.yaml</a></p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def create_waymo_infos():\n    dataset = WaymoDataset()\n    waymo_infos_train = dataset.<span style=\'color: green;font-weight: bold;\'>get_infos</span>(raw_data_path,save_path,num_workers,has_label,sampled_interval=1)\n    with open(train_filename, \'wb\') as f:\n        pickle.dump(waymo_infos_train, f)\n    dataset.<span style=\'color: green;font-weight: bold;\'>create_groundtruth_database</span>(info_path,save_path,split,sampled_interval,used_classes,processed_data_tag)\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def get_infos(): <span style=\'color: red\'># sampled_interval=1，update_info_only=False,不是处理序列</span>\n        <span style=\'color: red\'># self.sample_sequence_list=[segment*.tfrecord,...]->sample_sequence_file_list=[PosixPath(\'/sdb/*.tfrecord\'),...]</span>\n        print(\'The waymo sample interval is %d, total sequecnes is %d\'% (sampled_interval, len(self.sample_sequence_list)))\n        process_single_sequence = partial(waymo_utils.process_single_sequence,save_path, sampled_interval,has_label)\n        sample_sequence_file_list = [self.check_sequence_name_with_all_version(raw_data_path / sequence_file)\n            for sequence_file in self.sample_sequence_list]\n        with multiprocessing.Pool(num_workers) as p:\n            sequence_infos = list(tqdm(p.imap(<span style=\'color: green;font-weight: bold;\'>process_single_sequence</span>, sample_sequence_file_list),total=len(sample_sequence_file_list)))\n        all_sequences_infos = [item for infos in sequence_infos for item in infos]\n        return all_sequences_infos\n</code></pre><p></font>\nsequence_infos=[,..,]长24，也就是有24个tfrecord，每个tfrecord里面有159帧数据，每帧数据格式为<a href="https://gitee.com/zhao-study/data_code/blob/master/3target_detection_3D/project/OpenPCDet/pcdet/datasets/waymo/waymo_dataset.log">waymo_dataset.log</a><br></p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_utils.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def process_single_sequence(sequence_file, save_path, sampled_interval, has_label=True, use_two_returns=True, update_info_only=False):\n    sequence_name = os.path.splitext(os.path.basename(sequence_file))[0]  <span style=\'color: red\'># sequence_name=\'segment-10017090168044687777_6380_000_6400_000_with_camera_labels\'</span>\n    if pkl_file.exists():        <span style=\'color: red\'># data/waymo/waymo_processed_data_v0_5_0/segment-*_with_camera_labels/segment-*_with_camera_labels.pkl</span>\n        sequence_infos = pickle.load(open(pkl_file, \'rb\'))        <span style=\'color: red\'># </span>\n        if not update_info_only:\n            return sequence_infos\n</code></pre><p></font>\n要是不存在读取tfrecord保存的格式如下<a href="https://gitee.com/zhao-study/data_code/blob/master/3target_detection_3D/project/OpenPCDet/pcdet/datasets/waymo/waymo_dataset.log">waymo_dataset.log</a><br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n      def create_groundtruth_database(self, info_path, save_path, used_classes=None, split=\'train\', sampled_interval=10,processed_data_tag=None):\n        use_sequence_data = self.dataset_cfg.get(\'SEQUENCE_CONFIG\', None) is not None and self.dataset_cfg.SEQUENCE_CONFIG.ENABLED\n        <span style=\'color: red\'># use_sequence_data=False,sampled_interval=1</span>\n        if use_sequence_data:\n            ......\n        else:\n            database_save_path = "data/waymo/waymo_processed_data_v0_5_0_gt_database_train_sampled_1" \n            db_info_save_path = "data/waymo/waymo_processed_data_v0_5_0_waymo_dbinfos_train_sampled_1.pkl"\n            db_data_save_path = "data/waymo/waymo_processed_data_v0_5_0_gt_database_train_sampled_1_global.npy"\n        database_save_path.mkdir(parents=True, exist_ok=True)\n        all_db_infos = {}\n        with open(info_path, \'rb\') as f:\n            infos = pickle.load(f)\n        point_offset_cnt = 0\n        stacked_gt_points = []\n        for k in tqdm(range(0, len(infos), sampled_interval)):      <span style=\'color: red\'># k=0</span>\n            info = infos[k]\n            pc_info = info[\'point_cloud\']\n            sequence_name = pc_info[\'lidar_sequence\']      <span style=\'color: red\'># \'segment-10017090168044687777_6380_000_6400_000_with_camera_labels\'</span>\n            sample_idx = pc_info[\'sample_idx\']             <span style=\'color: red\'># sample_idx=0</span>\n            points = self.<span style=\'color: green;font-weight: bold;\'>get_lidar</span>(sequence_name, sample_idx)   <span style=\'color: red\'># ######################################################</span>\n            if use_sequence_data:\n                ......\n            annos = info[\'annos\']\n            names = annos[\'name\']\n            difficulty = annos[\'difficulty\']\n            gt_boxes = annos[\'gt_boxes_lidar\']\n            <span style=\'color: red\'># 这些类别太多，减少这些数据增强</span>\n            if k % 4 != 0 and len(names) > 0:       <span style=\'color: red\'># 1,2,3,5,6,7这些帧去掉有Vehicle的3D box？</span>\n                mask = (names == \'Vehicle\')\n                names = names[~mask]\n                difficulty = difficulty[~mask]\n                gt_boxes = gt_boxes[~mask]\n            if k % 2 != 0 and len(names) > 0:      <span style=\'color: red\'># 1,3,5,7这些帧去掉有Pedestrian的3D box？</span>\n                mask = (names == \'Pedestrian\')\n                names = names[~mask]\n                difficulty = difficulty[~mask]\n                gt_boxes = gt_boxes[~mask]\n            db_info[\'global_data_offset\'] = [point_offset_cnt, point_offset_cnt + gt_points.shape[0]]  <span style=\'color: red\'># 注意global_data_offset干嘛的</span>\n            point_offset_cnt += gt_points.shape[0]\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def get_lidar(self, sequence_name, sample_idx):\n        lidar_file = self.data_path / sequence_name / (\'%04d.npy\' % sample_idx)  <span style=\'color: red\'># data/waymo/waymo_processed_data_v0_5_0/segment-*_with_camera_labels/0000.npy</span>\n        point_features = np.load(lidar_file)  <span style=\'color: red\'># (N, 7): point_features=(n,6)->[x, y, z, intensity, elongation, NLZ_flag]</span>\n        points_all, NLZ_flag = point_features[:, 0:5], point_features[:, 5]\n        points_all[:, 3] = np.tanh(points_all[:, 3])\n        return points_all\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">对单帧数据进行处理得到3D box</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(<span style=\'color: green;font-weight: bold;\'>DatasetTemplate</span>):\n    def __init__(self, dataset_cfg, class_names, training=True, root_path=None, logger=None):\n        self.seq_name_to_infos = self.<span style=\'color: green;font-weight: bold;\'>include_waymo_data</span>(self.mode)\n        self.use_shared_memory=False\n        self.pred_boxes_dict = {}\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class DatasetTemplate(torch_data.Dataset):\n    def __init__(self, dataset_cfg=None, class_names=None, training=True, root_path=None, logger=None):\n        self.point_feature_encoder = <span style=\'color: green;font-weight: bold;\'>PointFeatureEncoder</span>()\n        self.data_augmentor = <span style=\'color: green;font-weight: bold;\'>DataAugmentor</span>() if self.training else None\n        self.data_processor = DataProcessor()\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/processor/point_feature_encoder.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class PointFeatureEncoder(object):\n    def __init__(self, config, point_cloud_range=None):\n        super().__init__()\n        self.point_encoding_config = config\n        assert list(self.point_encoding_config.src_feature_list[0:3]) == [\'x\', \'y\', \'z\'] <span style=\'color: red\'># self.used_feature_list=[\'x\', \'y\', \'z\', \'intensity\', \'elongation\']</span>\n        self.used_feature_list = self.point_encoding_config.used_feature_list            <span style=\'color: red\'># self.src_feature_list=[\'x\', \'y\', \'z\', \'intensity\', \'elongation\']</span>\n        self.src_feature_list = self.point_encoding_config.src_feature_list\n        self.point_cloud_range = point_cloud_range\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/augmentor/data_augmentor.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class DataAugmentor(object):\n    def __init__(self, root_path, augmentor_configs, class_names, logger=None):\n        for cur_cfg in aug_config_list:\n            cur_augmentor = getattr(self, cur_cfg.NAME)(config=cur_cfg)\n            self.data_augmentor_queue.append(cur_augmentor)         <span style=\'color: red\'># self.data_augmentor_queue=[...]</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def include_waymo_data(self, mode):\n</code></pre><p></font>\nself.infos=[{},...]长度4761，里面格式如<a href="https://gitee.com/zhao-study/data_code/blob/master/3target_detection_3D/project/OpenPCDet/pcdet/datasets/waymo/waymo_dataset.log">waymo_dataset.log</a>；self.infos=953每5次取一帧？<br></p>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def __getitem__(self, index):\n        info = copy.deepcopy(self.infos[index])        <span style=\'color: red\'># len(self.infos)=953      len(self.infos)=4761所有frame都用到了</span>\n</code></pre></font>\npoints = self.get_lidar(sequence_name, sample_idx)->\'segment-*_labels\',sample_idx=95<br>\npoints.shape=(180977, 5)<br>\ngt_boxes_lidar = annos[\'gt_boxes_lidar\']->np.shape=(17, 9)->(17,7)<br>\nfilter empty boxes->(16,7)<br>\ndata_dict.keys()=[\'sample_idx\', \'points\', \'frame_id\', \'gt_boxes\', \'flip_x\', \'flip_y\', \'noise_rot\', \'noise_scale\', \'use_lead_xyz\', \'voxels\', \'voxel_coords\', \'voxel_num_points\', \'metadata\']<br>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p>多帧数据处理<a href="">tools/cfgs/dataset_configs/waymo_dataset_multiframe.yaml</a></p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">def create_waymo_infos():\n    dataset = WaymoDataset()\n    waymo_infos_train = dataset.<span style=\'color: green;font-weight: bold;\'>get_infos</span>(raw_data_path,save_path,num_workers,has_label,sampled_interval=1)\n    with open(train_filename, \'wb\') as f:\n        pickle.dump(waymo_infos_train, f)\n    dataset.<span style=\'color: green;font-weight: bold;\'>create_groundtruth_database</span>(info_path,save_path,split,sampled_interval,used_classes,processed_data_tag)\n    <span style=\'color: red\'># 这个里面的点云是多帧融合的点云；每个box里面的点云数目增多了。</span>\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def get_infos(): <span style=\'color: red\'># sampled_interval=1，update_info_only=True,处理序列</span>\n        <span style=\'color: red\'># self.sample_sequence_list=[segment*.tfrecord,...]->sample_sequence_file_list=[PosixPath(\'/sdb/*.tfrecord\'),...]</span>\n        print(\'The waymo sample interval is %d, total sequecnes is %d\'% (sampled_interval, len(self.sample_sequence_list)))\n        process_single_sequence = partial(waymo_utils.process_single_sequence,save_path, sampled_interval,has_label)\n        sample_sequence_file_list = [self.check_sequence_name_with_all_version(raw_data_path / sequence_file)\n            for sequence_file in self.sample_sequence_list]\n        with multiprocessing.Pool(num_workers) as p:\n            sequence_infos = list(tqdm(p.imap(<span style=\'color: green;font-weight: bold;\'>process_single_sequence</span>, sample_sequence_file_list),total=len(sample_sequence_file_list)))\n        all_sequences_infos = [item for infos in sequence_infos for item in infos]\n        return all_sequences_infos\n        <span style=\'color: red\'># 都是存储在data/waymo/waymo_processed_data_v0_5_0/segment-*/segment-*_with_camera_labels.pkl</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def create_groundtruth_database(self, info_path, save_path, used_classes=None, split=\'train\', sampled_interval=10,processed_data_tag=None):\n        use_sequence_data = self.dataset_cfg.get(\'SEQUENCE_CONFIG\', None) is not None and self.dataset_cfg.SEQUENCE_CONFIG.ENABLED\n        <span style=\'color: red\'># use_sequence_data=False,sampled_interval=1</span>\n        if use_sequence_data:\n            database_save_path = "data/waymo/waymo_processed_data_v0_5_0_gt_database_train_sampled_1_multiframe_-4_to_0" \n            db_info_save_path = "data/waymo/waymo_processed_data_v0_5_0_waymo_dbinfos_train_sampled_1_multiframe_-4_to_0.pkl"\n            db_data_save_path = "data/waymo/waymo_processed_data_v0_5_0_gt_database_train_sampled_1_multiframe_-4_to_0_global.npy"\n        else:\n            ......\n        for k in tqdm(range(0, len(infos), sampled_interval)):\n            info = infos[k]\n            pc_info = info[\'point_cloud\']\n            sequence_name = pc_info[\'lidar_sequence\']\n            sample_idx = pc_info[\'sample_idx\']\n            points = self.get_lidar(sequence_name, sample_idx)   <span style=\'color: red\'># ######################################################</span>\n            if use_sequence_data:\n                if use_sequence_data:\n                points, num_points_all, sample_idx_pre_list, _, _, _, _ = self.<span style=\'color: green;font-weight: bold;\'>get_sequence_data</span>(  <span style=\'color: red\'># 只用到points</span>\n                    info, points, sequence_name, sample_idx, self.dataset_cfg.SEQUENCE_CONFIG        <span style=\'color: red\'># {\'ENABLED\': True, \'SAMPLE_OFFSET\': [-4,0]}</span>\n                )\n            db_info[\'global_data_offset\'] = [point_offset_cnt, point_offset_cnt + gt_points.shape[0]]  <span style=\'color: red\'># 注意global_data_offset干嘛的</span>\n            point_offset_cnt += gt_points.shape[0]\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def get_sequence_data(self, info, points, sequence_name, sample_idx, sequence_cfg, load_pred_boxes=False):        <span style=\'color: red\'># 新加</span>\n        def remove_ego_points(points, center_radius=1.0):\n            mask = ~((np.abs(points[:, 0]) < center_radius) & (np.abs(points[:, 1]) < center_radius))    <span style=\'color: red\'># 移除掉中间的点</span>\n            return points[mask]\n        pose_cur = info[\'pose\'].reshape((4, 4))         <span style=\'color: red\'># (4, 4)</span>\n        num_pts_cur = points.shape[0]                   <span style=\'color: red\'># 184307</span>\n        sample_idx_pre_list = np.clip(sample_idx + np.arange(sequence_cfg.SAMPLE_OFFSET[0], sequence_cfg.SAMPLE_OFFSET[1]), 0, 0x7FFFFFFF)   \n        <span style=\'color: red\'># 0-array([0, 0, 0, 0])；1array([0, 0, 0, 1])；2array([0, 0, 1, 2])；5</span>\n        sample_idx_pre_list = sample_idx_pre_list[::-1]\n        if sequence_cfg.get(\'ONEHOT_TIMESTAMP\', False):\n            ......\n        else:\n            points = np.hstack([points, np.zeros((points.shape[0], 1)).astype(points.dtype)])        <span style=\'color: red\'># (184307, 6=5+1)</span>\n        sequence_info = self.seq_name_to_infos[sequence_name]      <span style=\'color: red\'># \'segment-10017090168044687777_6380_000_6400_000_with_camera_labels\'有159帧序列信息</span>\n        for idx, sample_idx_pre in enumerate(sample_idx_pre_list):\n            points_pre = self.get_lidar(sequence_name, sample_idx_pre)         <span style=\'color: red\'># 前面的点云(183651, 5)</span>\n            pose_pre = sequence_info[sample_idx_pre][\'pose\'].reshape((4, 4))   <span style=\'color: red\'># 前面的姿态(4, 4)</span>\n            expand_points_pre = np.concatenate([points_pre[:, :3], np.ones((points_pre.shape[0], 1))], axis=-1)   <span style=\'color: red\'># (183651, 4)</span>\n            points_pre_global = np.dot(expand_points_pre, pose_pre.T)[:, :3]     <span style=\'color: red\'># 前面的点云@姿态的转置->(183651, 3)</span>\n            expand_points_pre_global = np.concatenate([points_pre_global, np.ones((points_pre_global.shape[0], 1))], axis=-1)\n            points_pre2cur = np.dot(expand_points_pre_global, np.linalg.inv(pose_cur.T))[:, :3]     <span style=\'color: red\'># 得到当前姿态的点云+原来的属性</span>\n            points_pre = np.concatenate([points_pre2cur, points_pre[:, 3:]], axis=-1)               <span style=\'color: red\'># (183651, 5)</span>\n            if sequence_cfg.get(\'ONEHOT_TIMESTAMP\', False):\n                ......\n            else:\n                <span style=\'color: red\'># add timestamp</span>\n                points_pre = np.hstack([points_pre, 0.1 * (sample_idx - sample_idx_pre) * np.ones((points_pre.shape[0], 1)).astype(points_pre.dtype)])  <span style=\'color: red\'># one frame 0.1s (183651, 6)当前帧尾0，往前0.1</span>\n            points_pre = remove_ego_points(points_pre, 1.0)     <span style=\'color: red\'># (183651, 6)</span>\n            points_pre_all.append(points_pre)\n        return points, num_points_all, sample_idx_pre_list, poses, pred_boxes, pred_scores, pred_labels  <span style=\'color: red\'># 只用到points</span>\n</code></pre></font>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p>读取多帧处理数据用于训练<a href="test_data.py">test_data-centerpoint_4frames</a></p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(<span style=\'color: green;font-weight: bold;\'>DatasetTemplate</span>):\n    def __init__(self, dataset_cfg, class_names, training=True, root_path=None, logger=None):\n        self.seq_name_to_infos = self.<span style=\'color: green;font-weight: bold;\'>include_waymo_data</span>(self.mode)  <span style=\'color: red\'># 不需要序列为False，返回None，需要返回self.seq_name_to_infos[\'segment-*_with_camera_labels\']={...} </span>\n        self.use_shared_memory=False\n        self.pred_boxes_dict = {}\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class DatasetTemplate(torch_data.Dataset):\n    def __init__(self, dataset_cfg=None, class_names=None, training=True, root_path=None, logger=None):\n        self.point_feature_encoder = <span style=\'color: green;font-weight: bold;\'>PointFeatureEncoder</span>()\n        self.data_augmentor = <span style=\'color: green;font-weight: bold;\'>DataAugmentor</span>() if self.training else None\n        self.data_processor = DataProcessor()\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/processor/point_feature_encoder.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class PointFeatureEncoder(object):\n    def __init__(self, config, point_cloud_range=None):\n        super().__init__()\n        self.point_encoding_config = config\n        assert list(self.point_encoding_config.src_feature_list[0:3]) == [\'x\', \'y\', \'z\'] <span style=\'color: red\'># self.used_feature_list=[\'x\', \'y\', \'z\', \'intensity\', \'elongation\', \'timestamp\']</span>\n        self.used_feature_list = self.point_encoding_config.used_feature_list            <span style=\'color: red\'># self.src_feature_list=[\'x\', \'y\', \'z\', \'intensity\', \'elongation\', \'timestamp\']</span>\n        self.src_feature_list = self.point_encoding_config.src_feature_list\n        self.point_cloud_range = point_cloud_range                                       <span style=\'color: red\'># -75.2, -75.2,  -2. ,  75.2,  75.2,   4.</span>\n</code></pre></font>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/augmentor/data_augmentor.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class DataAugmentor(object):\n    def __init__(self, root_path, augmentor_configs, class_names, logger=None):\n        for cur_cfg in aug_config_list:\n            cur_augmentor = getattr(self, cur_cfg.NAME)(config=cur_cfg)\n            self.data_augmentor_queue.append(cur_augmentor)         <span style=\'color: red\'># self.data_augmentor_queue=[...]</span>\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def include_waymo_data(self, mode):\n</code></pre><p></font>\nself.infos=[{},...]长度4761，里面格式如<a href="https://gitee.com/zhao-study/data_code/blob/master/3target_detection_3D/project/OpenPCDet/pcdet/datasets/waymo/waymo_dataset.log">waymo_dataset.log</a>；self.infos=953每5次取一帧？<br></p>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/waymo/waymo_dataset.py</p><font size="0"><pre class="language-python" style="line-height: 0.01; "><code class="language-python">class WaymoDataset(DatasetTemplate):\n    def __getitem__(self, index):\n        info = copy.deepcopy(self.infos[index])        <span style=\'color: red\'># len(self.infos)=953      len(self.infos)=4761所有frame都用到了</span>\n        if self.use_shared_memory and index < self.shared_memory_file_limit:\n            ......\n        else:\n            points = self.get_lidar(sequence_name, sample_idx)         <span style=\'color: red\'># (177097, 5)</span>\n        if self.dataset_cfg.get(\'SEQUENCE_CONFIG\', None) is not None and self.dataset_cfg.SEQUENCE_CONFIG.ENABLED:           <span style=\'color: red\'># True--融合前后帧点云</span>\n            points, num_points_all, sample_idx_pre_list, poses, pred_boxes, pred_scores, pred_labels = self.<span style=\'color: green;font-weight: bold;\'>get_sequence_data</span>(\n                info, points, sequence_name, sample_idx, self.dataset_cfg.SEQUENCE_CONFIG,load_pred_boxes=self.dataset_cfg.get(\'USE_PREDBOX\', False)  <span style=\'color: red\'># {\'ENABLED\': True, \'SAMPLE_OFFSET\': [-3, 0]} 跟create_groundtruth_database一样</span>\n            )             <span style=\'color: red\'># (721060, 6)</span>\n            input_dict[\'poses\'] = poses\n            if self.dataset_cfg.get(\'USE_PREDBOX\', False):        <span style=\'color: red\'># False，如果为True--# (4, 177, 9)  ；融合四帧，177是4帧检测结果最多的数量</span>\n                ......\n        ##########################################\n        if \'annos\' in info:\n            if self.dataset_cfg.get(\'INFO_WITH_FAKELIDAR\', False):\n                ......\n            else:\n                gt_boxes_lidar = annos[\'gt_boxes_lidar\']                #(35, 9)-标注的box，上面是预测的box\n            if self.dataset_cfg.get(\'TRAIN_WITH_SPEED\', False):          <span style=\'color: red\'># 新加</span>\n                assert gt_boxes_lidar.shape[-1] == 9\n            else:\n                ......\n            if self.training and self.dataset_cfg.get(\'FILTER_EMPTY_BOXES_FOR_TRAIN\', False):\n                mask = (annos[\'num_points_in_gt\'] > 0)  <span style=\'color: red\'># filter empty boxes</span>\n                annos[\'name\'] = annos[\'name\'][mask]\n                gt_boxes_lidar = gt_boxes_lidar[mask]               <span style=\'color: red\'># 过滤空的之后只有(32,7)了</span>\n                annos[\'num_points_in_gt\'] = annos[\'num_points_in_gt\'][mask]\n            input_dict.update({\n                \'gt_names\': annos[\'name\'],\n                \'gt_boxes\': gt_boxes_lidar,\n                \'num_points_in_gt\': annos.get(\'num_points_in_gt\', None)\n            })\n        data_dict = self.prepare_data(data_dict=input_dict)\n        data_dict[\'metadata\'] = info.get(\'metadata\', info[\'frame_id\'])\n        data_dict.pop(\'num_points_in_gt\', None)\n        return data_dict\n</code></pre></font>'}]}]})</script></body>
</html>
