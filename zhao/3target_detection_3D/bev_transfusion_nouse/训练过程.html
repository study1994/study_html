<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>训练过程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">初始化</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py:def gen_dx_bx</p>dx, bx, nx = gen_dx_bx(self.grid_conf[\'xbound\'],               # [-54, 54, 0.6]<br>\nself.grid_conf[\'ybound\'],               # [-54, 54, 0.6]<br>\nself.grid_conf[\'zbound\'], )             # [-5, 3, 0.6]<br>\ndxtensor([0.5000, 0.5000, 0.5000]);bx=tensor([-49.7500, -49.7500,  -4.7500]); nx=tensor([180, 180,  13])<br>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py:class LiftSplatShoot:def create_frustum</p>\n<p><code>============pandaset=====================</code><br>\n<code>============nuscenes=====================</code><br>\n先生成在3D坐标系的堆体，这里的D就是到像素坐标系要除以的z，恢复相机坐标系就是torch.cat((points[...,:2]*points[...,2:3],points[...,2:3])<br>\n参数：self.final_dim=(900, 1600)；self.fH, self.fW=(112, 200)；self.grid_conf[\'dbound\']=[4.0, 45.0, 1.0]<br>\nfinal_dim=(900, 1600)，fH,fW=(112,200)，下采样8倍<br>\nself.grid_conf[\'dbound\']=[4.0, 45.0, 1.0]-》ds.shape=(41, 112, 200)<br>\nfrustum=(41,112,200,3)<br></p>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">训练图片</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevf_faster_rcnn.py:class BEVF_FasterRCNN:def extract_feat</p>\n<p>img_feats=[torch.Size([12, 256, 112, 200])]<br>\npts_feats=None<br>\n<code>------------------if self.lift:----------------------------</code><br>\nimg_feats_view.shape=torch.Size([2, 6, 256, 112, 200])<br>\nrots.shape=torch.Size([2, 6, 3, 3])<br>\ntrans.shape=torch.Size([2, 6, 3])<br>\nlidar2img_rt[0].shape=(4, 4);len(lidar2img_rt)=6<br>\n输入self.lift_splat_shot_vis(img_feats_view, rots, trans, lidar2img_rt=lidar2img_rt, img_metas=img_metas)<br></p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def forward</p>输入self.get_voxels：x, rots, trans, post_rots, post_trans<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def get_voxels</p>输入self.get_geometry：rots, trans, post_rots, post_trans<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：self.get_geometry</p>\n<p>geom.shape=torch.Size([2, 6, 41, 112, 200, 3])映射雷达坐坐标系上<code>cam_to_ego</code><br>\npoints.shape=torch.Size([2, 6, 41, 112, 200, 3])<br></p>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def get_voxels</p>输入self.get_cam_feats图片特征x，也就是上面的img_feats_view.shape=torch.Size([2, 6, 256, 112, 200])<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def get_cam_feats</p>\n<p>只是针对特征操作<br>\n上面输入图片特征torch.Size([12, 256, 112, 200])经过CamEncode<br>\n参数self.D=41；self.C=64,inputC=256,得到x.shape=torch.Size([12, 64, 41, 112, 200]);depth.shape=torch.Size([12, 41, 112, 200])<br>\n过程<code>def get_depth_feat(self, x)</code>:x-&gt;torch.Size([12, 105, 112, 200])前41维度代表深度，后64维度代表像素点特征.<br>\ndepth.unsqueeze(1).shape=torch.Size([12, 1, 41, 112, 200])+x[:, self.D:(self.D + self.C)].unsqueeze(2).shape=torch.Size([12, 64, 1, 112, 200])<br>\n相乘得到new_x，与depth返回<br></p>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def get_voxels</p>\n<p>经过函数<code>def get_cam_feats(self, x)</code>得到x.shape=torch.Size([2, 6, 41, 112, 200, 64]);depth.shape=;torch.Size([2, 6, 41, 112, 200])<br>\n输入self.voxel_pooling：geom.shape=torch.Size([2, 6, 41, 112, 200, 3])和x.shape=torch.Size([2, 6, 41, 112, 200, 64])<br></p>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：voxel_pooling</p>视锥点云和图像特征的空间尺度是等大的，也就是位置有着一一对应的关系，视锥点云转换到bev下后，每个点都会被分配到bev的柱子里面，<br>\n这个柱子就是bev空间每个grid都对应一个[dx,dy,无限高]的立方体，这样每一个grid的特征就是在里面所有点对应的图像特征求和来表示的<br>\n(B,N,D,H,W,C)=(2, 6, 41, 112, 200, 64); Nprime=11020800<br>\ngeom_feats.shape=torch.Size([2, 6, 41, 112, 200, 3])->torch.Size([2, 6, 41, 112, 200, 3])<br>\n要把原先的范围假如-100->100;映射到范围180-180；<br>\n->torch.Size([11020800, 3])<br>\nbatch_ix->torch.Size([11020800, 1])<br>\nself.nx=tensor([180, 180,  13], device=\'cuda:0\')<br>\nsort之后：<br>\nx.shape=torch.Size([5918319, 64]); geom_feats.shape=torch.Size([5918319, 4]); ranks.shape=torch.Size([5918319]);<br>\n输入到QuickCumsum得到x.shape=torch.Size([5918319, 64])->geom_feats.shape=torch.Size([5918319, 4]);<br>\nfinal->torch.Size([2, 64, 13, 180, 180])<br>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def get_voxels</p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/cam_stream_lss.py：class LiftSplatShoot：def forward</p>x.shape=torch.Size([2, 64, 13, 180, 180])->bev.shape=bev.shape=torch.Size([2, 832, 180, 180])<br>\n->X=torch.Size([2, 256, 180, 180])<br>\ndepth.shape=torch.Size([2, 6, 41, 112, 200])<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/bevf_faster_rcnn.py:class BEVF_FasterRCNN:def extract_feat</p>\n<p>img_bev_feat.shape=torch.Size([2, 256, 180, 180])+depth.shape=torch.Size([2, 6, 41, 112, 200])<br>\n<code>----------------------光图片融合--------------------------------------</code><br>\npts_feats=[img_bev_feat]<br>\n<code>----------------------图片点云融合--------------------------------------</code><br>\npts_feats=[self.reduc_conv(torch.cat([img_bev_feat, pts_feats[0]], dim=1))]<br></p>'}]}]})</script></body>
</html>
