<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>kitti训练pointpillars流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 150vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">训练命令</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-"><code class="language-">{\n    "name": "Python:train.py",\n    "type": "python",\n    "request": "launch",\n    "program": "/sdb/zzhu/open_code/mmdetection3d/tools/train.py",\n    "console": "integratedTerminal",\n    "args": [\n        "--config", "configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py"\n    ],\n    "env": {\n        "CUDA_VISIBLE_DEVICES": "4"\n    },\n},\n</code></pre>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">数据处理过程</p>\n<p><a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py">hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class</a><br></p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p><a href="configs/_base_/datasets/kitti-3d-3class.py#L102">RepeatDataset:configs/<em>base</em>/datasets/kitti-3d-3class.py</a></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p><a href="configs/_base_/datasets/kitti-3d-3class.py#L105">KittiDataset:configs/<em>base</em>/datasets/kitti-3d-3class.py</a></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p><a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L24">LoadPointsFromFile:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p><a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L25">LoadAnnotations3D:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p><a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L26">ObjectSample:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p><a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L12">DataBaseSampler:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a></p>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型运行过程</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def forward_train</p>对应配置文件：type=\'VoxelNet\'<br>\n输入数据：len(points)=6；points[0].shape=torch.Size([18574, 4])<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def extract_feat</p>voxels, num_points, coors = self.voxelize(points)<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/voxel/voxelize.py：class Voxelization：def forward</p>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">【Voxelization】mmdet3d/ops/voxel/voxelize.py：class _Voxelization：def forward</p>voxels.shape=torch.Size([16000, 32, 4])其中16000有配置文件设置<br>\ncoors.shape=torch.Size([16000, 3])<br>\nnum_points_per_voxel.shape=torch.Size([16000])<br>\n经过voxel_num = hard_voxelize(......)<br>\nvoxels.shape=torch.Size([34978, 32, 4])=34978个体素，里面32个点云<br>\nnum_points.shape=torch.Size([34978]);num_points[0]=tensor(7, device=\'cuda:0\', dtype=torch.int32)=第一个体素只有7个点云<br>\ncoors.shape=torch.Size([34978，4]);coors[:,0]为某个体素属于那个batch;coors[:,2]y=(0,495);coors[:,3]x=(0,431)<br>'}]}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def extract_feat</p>voxel_features = self.voxel_encoder(voxels, num_points, coors)<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">【pts_voxel_encoder-HardVFE】mmdet3d/models/voxel_encoders/pillar_encoder.py:class PillarFeatureNet:def forward</p>features.shape=torch.Size([34978, 32, 9])<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def extract_feat</p>voxel_features.shape=torch.Size([34978, 64])<br>\nx = self.middle_encoder(voxel_features, coors, batch_size)<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">【pts_middle_encoder】mmdet3d/models/middle_encoders/pillar_scatter.py: class PointPillarsScatter: def forward</p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def extract_feat</p>x.shape=torch.Size([6, 64, 496, 432])<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">【SECOND】mmdet3d/models/backbones/second.py:class SECOND:def forward</p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def extract_feat</p>len(x)=3;<br>\nx[0].shape=torch.Size([6, 64, 248, 216]);x[1].shape=torch.Size([6, 128, 124, 108]);x[2].shape=torch.Size([6, 256, 62, 54]);<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">【SECONDFPN】mmdet3d/models/necks/second_fpn.py:class SECONDFPN: def forward</p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def extract_feat</p>len(x)=1;<br>\nx[0].shape=torch.Size([6, 384, 248, 216])384=128x3<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def forward_train</p>outs = self.bbox_head(x)<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/anchor3d_head.py:class Anchor3DHead:def forward_single</p>len(x)=1;x[0].shape=torch.Size([6, 384, 248, 216])384=128x3<br>\nanchor有6个<br>\ncls_score.shape=torch.Size([6, 18, 248, 216])=>12=6x3<br>\nbbox_pred.shape=torch.Size([6, 42, 248, 216])=>12=6x7<br>\ndir_cls_preds.shape=torch.Size([6, 12, 248, 216])=>12=6x2<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py：class VoxelNet：def forward_train</p>outs=[cls_score、bbox_pred、dir_cls_preds]<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/core/anchor/anchor_3d_generator.py#L177</p>\n<p>anchor数量：<code>len(sizes)*len(rotations)=6</code><br>\nanchor_range[2]=-0.6,anchor_range[5]=-0.6,feature_size[0]=1,=》z_centers=0.6<br>\nanchor_range[1]=-39.68, anchor_range[4]=39.68, feature_size[1]=248=&gt;y_centers=&gt;(-39.68,39.68)共248个值<br>\nret=torch.Size([1, 248, 216, 1, 2, 7])<br></p>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">软件测试流程</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-"><code class="language-">{\n    "name": "Python: test.py",\n    "type": "python",\n    "request": "launch",\n    "program": "tools/test.py",\n    "console": "integratedTerminal",\n    "args": [\n        "configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car.py",\n        "pretrain/PointPillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20200620_230614-77663cd6.pth",\n        // "--out","/sdb/zzhu/open_code/mmdetection3d/tools/test_res/kitti/",\n        "--format_only"\n    ],\n    "env": {\n        "CUDA_VISIBLE_DEVICES": "0"\n    },\n},\n</code></pre>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">软件测试流程</p>\n<p>outputs[0].keys()=dict_keys([\'boxes_3d\', \'scores_3d\', \'labels_3d\'])<br>\n<code>dataset.format_results(outputs, **kwargs)</code><br></p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/datasets/kitti_dataset.py</p>\n<p>pklfile_prefix=\'/tmp/tmpxz04yh7l/results\'<br>\n<code>result_files = self.bbox2result_kitti(outputs, self.CLASSES,pklfile_prefix,submission_prefix)</code><br>\n先将检测结果转为kitti格式<br>\nimage_shape=array([ 375, 1242], dtype=int32)<br>\n<code>box_dict = self.convert_valid_bboxes(pred_dicts, info)</code><br>\nbox_preds[:2]=LiDARInstance3DBoxes(tensor([[19.7917, 12.8699, -1.5022,  1.6375,  4.2081,  1.4549,  2.7211],[31.9988,  2.7463, -1.2208,  1.6501,  4.2425,  1.4678,  1.8600]]))<br>\nbox_preds[:2]角度限制了<br>\nLiDARInstance3DBoxes(tensor([[19.7917, 12.8699, -1.5022,  1.6375,  4.2081,  1.4549, -0.4204],[31.9988,  2.7463, -1.2208,  1.6501,  4.2425,  1.4678, -1.2816]]))<br>\nbox_preds_camera[:2]=CameraInstance3DBoxes(tensor([[-12.8514,   1.7697,  19.5044,   4.2081,   1.4549,   1.6375,  -0.4204],[ -2.7285,   1.5089,  31.7125,   4.2425,   1.4678,   1.6501,  -1.2816]]))<br>\nbox_corners.shape=torch.Size([8, 8, 3])<br>\nbox_corners_in_image.shape=torch.Size([8, 8, 2])<br>\nbox_2d_preds.shape=torch.Size([8, 4])<br>\nbox_2d_preds[:2]=tensor([[ 30.0130, 183.5995, 226.6361, 244.1719], [511.5352, 173.7185, 582.1530, 209.8180]])<br></p>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">def format_results</p>result_files[0].keys()=dict_keys([\'name\', \'truncated\', \'occluded\', \'alpha\', \'bbox\', \'dimensions\', \'location\', \'rotation_y\', \'score\', \'sample_idx\'])<br>\ntmp_dir=<TemporaryDirectory \'/tmp/tmpxz04yh7l\'><br>'}]}]})</script></body>
</html>
