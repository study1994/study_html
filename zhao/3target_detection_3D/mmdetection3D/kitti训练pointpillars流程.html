<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>kitti训练pointpillars流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">训练命令</p><span class=\'hidden-code\' data-code=\'{\n    &amp;#39;name&amp;#39;: &amp;#39;Python:train.py&amp;#39;,\n    &amp;#39;type&amp;#39;: &amp;#39;python&amp;#39;,\n    &amp;#39;request&amp;#39;: &amp;#39;launch&amp;#39;,\n    &amp;#39;program&amp;#39;: &amp;#39;/sdb/zzhu/open_code/mmdetection3d/tools/train.py&amp;#39;,\n    &amp;#39;console&amp;#39;: &amp;#39;integratedTerminal&amp;#39;,\n    &amp;#39;args&amp;#39;: [\n        &amp;#39;--config&amp;#39;, &amp;#39;configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py&amp;#39;\n    ],\n    &amp;#39;env&amp;#39;: {\n        &amp;#39;CUDA_VISIBLE_DEVICES&amp;#39;: &amp;#39;4&amp;#39;\n    },\n},\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">数据处理过程</p>\n<p><a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py">hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class</a><br>\n<a href="configs/_base_/datasets/kitti-3d-3class.py#L102">RepeatDataset:configs/<em>base</em>/datasets/kitti-3d-3class.py</a><br>\n<a href="configs/_base_/datasets/kitti-3d-3class.py#L105">KittiDataset:configs/<em>base</em>/datasets/kitti-3d-3class.py</a><br>\n<a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L24">LoadPointsFromFile:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a><br>\n<a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L25">LoadAnnotations3D:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a><br>\n<a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L26">ObjectSample:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a><br>\n<a href="configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py#L12">DataBaseSampler:configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class.py</a><br></p>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型运行过程</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py</p><span class=\'hidden-code\' data-code=\'class VoxelNet(SingleStage3DDetector):\n    def forward_train(self,points,img_metas,gt_bboxes_3d,gt_labels_3d,gt_bboxes_ignore=None):\n        x = self.`extract_feat`(points, img_metas)                 # len(points)=6；points[0].shape=torch.Size([18574, 4])\n        outs = self.`bbox_head`(x)\n        loss_inputs = outs + (gt_bboxes_3d, gt_labels_3d, img_metas)\n        losses = self.bbox_head.`loss`(*loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)\n        return losses\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py</p><span class=\'hidden-code\' data-code=\'class VoxelNet(SingleStage3DDetector):\n    def extract_feat(self, points, img_metas=None):\n        &amp;#39;&amp;#39;&amp;#39;Extract features from points.&amp;#39;&amp;#39;&amp;#39;\n        voxels, num_points, coors = self.`voxelize`(points)\n        voxel_features = self.`voxel_encoder`(voxels, num_points, coors)    # torch.Size([34978, 64])\n        batch_size = coors[-1, 0].item() + 1\n        x = self.`middle_encoder`(voxel_features, coors, batch_size)        # torch.Size([6, 64, 496, 432]\n        x = self.`backbone`(x)\n        if self.with_neck:\n            x = self.`neck`(x)\n        return x\n\'> </span>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/detectors/voxelnet.py</p><span class=\'hidden-code\' data-code=\'class VoxelNet(SingleStage3DDetector):\n    def voxelize(self, points):\n        &amp;#39;&amp;#39;&amp;#39;Apply hard voxelization to points.&amp;#39;&amp;#39;&amp;#39;\n        voxels, coors, num_points = [], [], []\n        for res in points:\n            res_voxels, res_coors, res_num_points = self.`voxel_layer`(res)\n            voxels.append(res_voxels)\n            coors.append(res_coors)\n            num_points.append(res_num_points)\n        voxels = torch.cat(voxels, dim=0)                    # voxels.shape=torch.Size([34978, 32, 4])=34978个体素，里面32个点云\n        num_points = torch.cat(num_points, dim=0)            # num_points.shape=torch.Size([34978]);num_points[0]=tensor(7, device=&amp;#39;cuda:0&amp;#39;, dtype=torch.int32)=第一个体素只有7个点云\n        coors_batch = []\n        for i, coor in enumerate(coors):\n            coor_pad = F.pad(coor, (1, 0), mode=&amp;#39;constant&amp;#39;, value=i)\n            coors_batch.append(coor_pad)\n        coors_batch = torch.cat(coors_batch, dim=0)          # coors.shape=torch.Size([34978，4]);coors[:,0]为某个体素属于那个batch;coors[:,2]y=(0,495);coors[:,3]x=(0,431)\n        return voxels, num_points, coors_batch\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/voxel/voxelize.py</p><span class=\'hidden-code\' data-code=\'class Voxelization(nn.Module):\n    def forward(self, input):\n        if self.training:\n            max_voxels = self.max_voxels[0]\n        else:\n            max_voxels = self.max_voxels[1]\n        return `voxelization`(input, self.voxel_size, self.point_cloud_range,self.max_num_points, max_voxels,self.deterministic)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/ops/voxel/voxelize.py</p><span class=\'hidden-code\' data-code=\'class _Voxelization(Function):\n    @staticmethod\n    def forward(ctx,points,voxel_size,coors_range,max_points=35,max_voxels=20000,deterministic=True):\n        if max_points == -1 or max_voxels == -1:\n            coors = points.new_zeros(size=(points.size(0), 3), dtype=torch.int)\n            dynamic_voxelize(points, coors, voxel_size, coors_range, 3)\n            return coors\n        else:\n            voxels = points.new_zeros(size=(max_voxels, max_points, points.size(1)))  # voxels.shape=torch.Size([16000, 32, 4])其中16000有配置文件设置  \n            coors = points.new_zeros(size=(max_voxels, 3), dtype=torch.int)           # coors.shape=torch.Size([16000, 3]) \n            num_points_per_voxel = points.new_zeros(size=(max_voxels, ), dtype=torch.int)   # num_points_per_voxel.shape=torch.Size([16000])\n            voxel_num = `hard_voxelize`(points, voxels, coors,num_points_per_voxel, voxel_size,coors_range, max_points, max_voxels, 3,deterministic)\n            # select the valid voxels\n            voxels_out = voxels[:voxel_num]           # voxels.shape=torch.Size([34978, 32, 4])=34978个体素，里面32个点云\n            coors_out = coors[:voxel_num]             # num_points.shape=torch.Size([34978]);num_points[0]=tensor(7, device=&amp;#39;cuda:0&amp;#39;, dtype=torch.int32)=第一个体素只有7个点云\n            num_points_per_voxel_out = num_points_per_voxel[:voxel_num]        # coors.shape=torch.Size([34978，4]);coors[:,0]为某个体素属于那个batch;coors[:,2]y=(0,495);coors[:,3]x=(0,431)\n            return voxels_out, coors_out, num_points_per_voxel_out\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/voxel_encoders/pillar_encoder.py</p><span class=\'hidden-code\' data-code=\'class PillarFeatureNet(nn.Module):\n    def forward(self, features, num_points, coors):\n        features_ls = [features]\n        # Find distance of x, y, and z from cluster center\n        if self._with_cluster_center:\n            points_mean = features[:, :, :3].sum(dim=1, keepdim=True) / num_points.type_as(features).view(-1, 1, 1)\n            f_cluster = features[:, :, :3] - points_mean\n            features_ls.append(f_cluster)\n        # Find distance of x, y, and z from pillar center\n        dtype = features.dtype\n        if self._with_voxel_center:\n            if not self.legacy:\n                f_center = torch.zeros_like(features[:, :, :2])\n                f_center[:, :, 0] = features[:, :, 0] - (coors[:, 3].to(dtype).unsqueeze(1) * self.vx + self.x_offset)\n                f_center[:, :, 1] = features[:, :, 1] - (coors[:, 2].to(dtype).unsqueeze(1) * self.vy + self.y_offset)\n            else:\n                f_center = features[:, :, :2]\n                f_center[:, :, 0] = f_center[:, :, 0] - (coors[:, 3].type_as(features).unsqueeze(1) * self.vx + self.x_offset)\n                f_center[:, :, 1] = f_center[:, :, 1] - (coors[:, 2].type_as(features).unsqueeze(1) * self.vy + self.y_offset)\n            features_ls.append(f_center)\n        if self._with_distance:\n            points_dist = torch.norm(features[:, :, :3], 2, 2, keepdim=True)\n            features_ls.append(points_dist)\n        # Combine together feature decorations\n        features = torch.cat(features_ls, dim=-1)                           # torch.Size([35245, 32, 9])\n        # The feature decorations were calculated without regard to whether pillar was empty. \n        # Need to ensure that empty pillars remain set to zeros.\n        voxel_count = features.shape[1]     \n        mask = get_paddings_indicator(num_points, voxel_count, axis=0)       # torch.Size([35245, 32])\n        mask = torch.unsqueeze(mask, -1).type_as(features)\n        features *= mask                                                     # torch.Size([35245, 32, 9])\n        for pfn in self.pfn_layers:\n            features = `pfn`(features, num_points)                           \n        return features.squeeze(1)                                           # torch.Size([34978, 64])\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/middle_encoders/pillar_scatter.py</p><span class=\'hidden-code\' data-code=\'class PointPillarsScatter(nn.Module):\n    def forward(self, voxel_features, coors, batch_size=None):\n        &amp;#39;&amp;#39;&amp;#39;Foraward function to scatter features.&amp;#39;&amp;#39;&amp;#39;\n        # TODO: rewrite the function in a batch manner no need to deal with different batch cases\n        if batch_size is not None:\n            return self.`forward_batch`(voxel_features, coors, batch_size)\n        else:\n            return self.forward_single(voxel_features, coors)\n\'> </span>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/middle_encoders/pillar_scatter.py</p><span class=\'hidden-code\' data-code=\'class PointPillarsScatter(nn.Module):\n    def forward_batch(self, voxel_features, coors, batch_size):     # (N, M, C)、(N, 4).\n        # batch_canvas will be the final output.\n        batch_canvas = []        # batch_canvas will be the final output.\n        for batch_itt in range(batch_size):\n            # Create the canvas for this sample\n            canvas = torch.zeros(self.in_channels,self.nx * self.ny,dtype=voxel_features.dtype,device=voxel_features.device)\n            # Only include non-empty pillars\n            batch_mask = coors[:, 0] == batch_itt\n            this_coors = coors[batch_mask, :]\n            indices = this_coors[:, 2] * self.nx + this_coors[:, 3]\n            indices = indices.type(torch.long)\n            voxels = voxel_features[batch_mask, :]\n            voxels = voxels.t()\n            # Now scatter the blob back to the canvas.\n            canvas[:, indices] = voxels\n            # Append to a list for later stacking.\n            batch_canvas.append(canvas)\n        # Stack to 3-dim tensor (batch-size, in_channels, nrows*ncols)\n        batch_canvas = torch.stack(batch_canvas, 0)\n        # Undo the column stacking to final 4-dim tensor\n        batch_canvas = batch_canvas.view(batch_size, self.in_channels, self.ny,self.nx)     # x.shape=torch.Size([6, 64, 496, 432]\n        return batch_canvas\n\'> </span>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/backbones/second.py</p><span class=\'hidden-code\' data-code=\'class SECOND(BaseModule):\n    def forward(self, x):          # (N, C, H, W).\n        outs = []\n        for i in range(len(self.blocks)):\n            x = self.blocks[i](x)\n            outs.append(x)         # torch.Size([6, 64, 496, 432]->[[6, 64, 248, 216]x2,[6, 128, 124, 108]x4,[6, 256, 62, 54]x8]\n        return tuple(outs)\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/necks/second_fpn.py</p><span class=\'hidden-code\' data-code=\'class SECONDFPN(BaseModule):\n    def forward(self, x):\n        assert len(x) == len(self.in_channels)\n        ups = [deblock(x[i]) for i, deblock in enumerate(self.deblocks)]\n        if len(ups) > 1:\n            out = torch.cat(ups, dim=1)     # torch.Size([6, 384, 248, 216])384=128x3\n        else:\n            out = ups[0]\n        return [out]\n\'> </span>'}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/anchor3d_head.py</p><span class=\'hidden-code\' data-code=\'class Anchor3DHead(BaseModule, AnchorTrainMixin):\n    def forward_single(self, x):                # anchor有6个\n        cls_score = self.conv_cls(x)            # torch.Size([6, 18, 248, 216])=>18=6x3\n        bbox_pred = self.conv_reg(x)            # torch.Size([6, 42, 248, 216])=>42=6x8\n        dir_cls_preds = None                    # torch.Size([6, 12, 248, 216])=>12=6x2\n        if self.use_direction_classifier: \n            dir_cls_preds = self.conv_dir_cls(x)\n        return cls_score, bbox_pred, dir_cls_preds\n\'> </span>'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">软件测试流程</p><span class=\'hidden-code\' data-code=\'{\n    &amp;#39;name&amp;#39;: &amp;#39;Python: test.py&amp;#39;,\n    &amp;#39;type&amp;#39;: &amp;#39;python&amp;#39;,\n    &amp;#39;request&amp;#39;: &amp;#39;launch&amp;#39;,\n    &amp;#39;program&amp;#39;: &amp;#39;tools/test.py&amp;#39;,\n    &amp;#39;console&amp;#39;: &amp;#39;integratedTerminal&amp;#39;,\n    &amp;#39;args&amp;#39;: [\n        &amp;#39;configs/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car.py&amp;#39;,\n        &amp;#39;pretrain/PointPillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20200620_230614-77663cd6.pth&amp;#39;,\n        // &amp;#39;--out&amp;#39;,&amp;#39;/sdb/zzhu/open_code/mmdetection3d/tools/test_res/kitti/&amp;#39;,\n        &amp;#39;--format_only&amp;#39;\n    ],\n    &amp;#39;env&amp;#39;: {\n        &amp;#39;CUDA_VISIBLE_DEVICES&amp;#39;: &amp;#39;0&amp;#39;\n    },\n},\n\'> </span>'}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
