<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>训练fcos3d_nuscenes流程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">相关资料</p>\n<p><a href="https://gitee.com/zhao-study/data_code/blob/master/3target_detection_3D/project/Mono3D_fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d.py">fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d.py</a><br></p>'}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">读取数据流程</p>init_初始化<br>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">site-packages/mmdet/datasets/coco.py:def load_annotations</p>len(data_infos)=168780; data_infos[0].keys()=dict_keys([\'file_name\', \'id\', \'token\', \'cam2ego_rotation\', \'cam2ego_translation\', \'ego2global_rotation\', \'ego2global_translation\', \'cam_intrinsic\', \'width\', \'height\', \'filename\'])<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">site-packages/mmdet/datasets/custom.py:def __getitem__:</p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">site-packages/mmdet/datasets/custom.py:def prepare_train_img:</p>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">site-packages/mmdet/datasets/coco.py:def get_ann_info:</p>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/datasets/nuscenes_mono_dataset.py:def _parse_ann_info:需要写的代码</p>ann_info[0]<br>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-python"><code class="language-python">\'file_name\':\'samples/CAM_FRONT_RIGHT/n008-2018-08-30-15-16-55-0400__CAM_FRONT_RIGHT__1535656619770482.jpg\'\n\'image_id\':\'39016ec655864188a592c6d571a2bace\'\n\'area\':14319.15253166274\n\'category_name\':\'car\'\n\'category_id\':0\n\'bbox\':[1423.8459064796646, 359.9941725586372, 176.15409352033544, 81.2876513142723]\n\'iscrowd\':0\n\'bbox_cam3d\':[17.917394889231144, -1.2885081395237552, 31.393943046675236, 4.761, 1.9, 1.946, 2.9612160312161246]\n\'velo_cam3d\':[0.0, 0.0]\n\'center2d\':[1535.0500238983427, 400.373187237498, 31.393943046675236]\n\'attribute_name\':\'vehicle.parked\'\n\'attribute_id\':6\n\'segmentation\':[]\n\'id\':902923\nlen():14\n</code></pre>'}]}, {'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/datasets/nuscenes_mono_dataset.py:def _parse_ann_info:需要写的代码</p>img_info<br>', 'children': [{'type': 'heading', 'depth': 7, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-python"><code class="language-python">\'file_name\':\'samples/CAM_FRONT_RIGHT/n008-2018-08-30-15-16-55-0400__CAM_FRONT_RIGHT__1535656619770482.jpg\'\n\'id\':\'39016ec655864188a592c6d571a2bace\'\n\'token\':\'e1d1e1806a7f4263ba59af7f749ef326\'\n\'cam2ego_rotation\':[0.20335173766558642, -0.19146333228946724, 0.6785710044972951, -0.6793609166212989]\n\'cam2ego_translation\':[1.58082565783, -0.499078711449, 1.51749368405]\n\'ego2global_rotation\':[0.9422984872595677, 0.017476920676708387, 0.0017391228598700533, -0.3343128678403938]\n\'ego2global_translation\':[1337.007196856983, 867.4962688666, 0.0]\n\'cam_intrinsic\':[[1256.7485116440405, 0.0, 817.7887570959712], [0.0, 1256.7485116440403, 451.9541780095127], [0.0, 0.0, 1.0]]\n\'width\':1600\n\'height\':900\n\'filename\':\'samples/CAM_FRONT_RIGHT/n008-2018-08-30-15-16-55-0400__CAM_FRONT_RIGHT__1535656619770482.jpg\'\nlen():11\n</code></pre>'}]}]}]}]}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">输入网络</p>\n<p>图片大小800x480;<code>gt_bboxes</code>是在该分辨率下的2Dbox框<br>\n<code>gt_bboxes_3d</code>相机坐标系的gt，通过内参cam_intrinsic，得到图片1600x900大小下的八个顶点<br>\n<code>centers2d</code>在像素坐标系下的中心点，对应图片大小为1600x900,<code>depth</code>深度是相机坐标系的那个point_2d[..., 2:3]<br></p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-python"><code class="language-python">point_2d_res = point_2d[..., :2] / point_2d[..., 2:3]\nif with_depth:\n    points_2d_depth = np.concatenate([point_2d_res, point_2d[..., 2:3]],axis=-1)\n    return points_2d_depth\n</code></pre>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">head流程</p>提取特征后<br>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def forward</p>len(feats)==5;torch.Size([2, 256, 128, 232])->torch.Size([2, 256, 8, 15]);self.strides=[8, 16, 32, 64, 128];<br>\n下降范围[8, 16, 32, 64, 128],regress_ranges=((-1, 48), (48, 96), (96, 192), (192, 384), (384, INF)),<br>\n1600：200，100<br>\n900：<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def forward_single</p>super().forward_single(x)<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/anchor_free_mono3d_head.py:class AnchorFreeMono3DHead:def forward_single</p>cls_score=(bs,n_class,h,w), bbox_pred=(bs,7,h,w)中心偏移+深度+WHL, dir_cls_pred=(bs,2,h,w), attr_pred=None,<br>\ncls_feat=(bs,256,h,w), reg_feat=(bs,256,h,w)<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def forward_single</p>\n<p>if self.centerness_on_reg-&gt;reg_feat-&gt;torch.Size([2, 64, 60, 100])-&gt;centerness=(bs,1,h,w)-&gt;2, 1, 60, 100<br>\nscale_offset, scale_depth, scale_size = Scale()<br>\n深度和长宽高经过exp处理：<code>bbox_pred[:, 2] = bbox_pred[:, 2].exp()</code>+<code>bbox_pred[:, 3:6] = bbox_pred[:, 3:6].exp() + 1e-6</code><br>\nself.norm_on_bbox=True<br>\n返回cls_score-[2, 10, 60, 100]10类, bbox_pred-[2, 9, 60, 100]-中心点/深度偏移/长宽高/, dir_cls_pred-[2, 2, 60, 100], attr_pred-[2, 9, 60, 100], centerness-[2, 1, 60, 100]<br></p>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">损失流程</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def loss</p>featmap_sizes=[[torch.Size([60, 100]), torch.Size([30, 50]), torch.Size([15, 25]), torch.Size([8, 13]), torch.Size([4, 7])]]<br>\npoints范围-映射到了800x480：<br>\n6000x2【(4,12,...,796),(4,4,...,476)】,<br>\n1500x2【(8,24,...,792),(8,8,...,472)】,<br>\n375x2【16...】, 104【32...】, 28【64....】<br>\nself.get_points<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/anchor_free_mono3d_head.py:class AnchorFreeMono3DHead:def get_points</p>dtype=torch.float32,strides=[8, 16, 32, 64, 128]<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/anchor_free_mono3d_head.py:class AnchorFreeMono3DHead:def _get_points_single</p>h,w= 60,100,flatten=False<br>\ny-torch.Size([60, 100]),x-torch.Size([60, 100])<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/anchor_free_mono3d_head.py:class AnchorFreeMono3DHead:def get_points</p>len(mlvl_points)=5; [torch.Size([6000, 2]),]<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def loss</p>len(all_level_points)=5;[torch.Size([6000, 2]),torch.Size([1500, 2]),torch.Size([375, 2]),torch.Size([104, 2]),torch.Size([28, 2])]<br>\nself.get_targets-输入真值<br>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py：class FCOSMono3DHead:def get_targets</p>len(expanded_regress_ranges)=5;regress_ranges=((-1, 48), (48, 96), (96, 192), (192, 384), (384, 100000000.0))<br>\nconcat_regress_ranges-torch.Size([8007, 2]); concat_points-torch.Size([8007, 2])；6000+1500+375+104+28=8007<br>\nnum_points=[[6000, 1500, 375, 104, 28]]根据feature map得到而来-->没有映射回原图<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py：class FCOSMono3DHead:def _get_target_single</p>\n<p><code>对于每张图片</code><br>\nnum_points=8007,gt_bboxes=(2,4), gt_bboxes_3d-CameraInstance3DBoxes-(2,9), points-torch.Size([8007, 2]), num_points_per_lvl-[6000, 1500, 375, 104, 28]<br>\n<code>注意：change orientation to local yaw</code><br>\ngt_bboxes_3d[..., 6] = -torch.atan2(gt_bboxes_3d[..., 0], gt_bboxes_3d[..., 2]) + gt_bboxes_3d[..., 6]-》前面范围-pi-&gt;pi;<br>\nareas-torch.Size([8007, 2]);后面2是2个box,  regress_ranges-torch.Size([8007, 2, 2])第2个2是两个box<br>\nbbox_targets_3d-&gt;(8007, 2, 9); feature map每个点（到原图）与真实中心点(原图)距离2，深度1，长宽高3,角度1+属性2【这里面gt_bboxes_3d的z没有用到】<br>\nbbox_targets-&gt;torch.Size([8007, 2, 4])feature map每个点（到原图）与2Dbox（不是原图）上下左右的距离<br>\n<code>------------------------condition1: inside a "center bbox"---------------------------------</code><br>\n这个点在原始图片上要在box扩展之内<br>\nradius=self.center_sample_radius=1.5,  self.strides=[8, 16, 32, 64, 128],  center_gts-torch.Size([8007, 2, 4]),2是box数目，4是上下左右<br>\ncenter_bbox-&gt;torch.Size([8007, 2, 4])每个feature的点距真实中心映射到feature的位置的距离,   inside_gt_bbox_mask-torch.Size([8007, 2])<br>\n<code>------------------------condition2: limit the regression range for each location----------</code><br>\n这一步将真实box放到不到的feature map，不同feature map不能放相同的3Dbox<br>\nbbox_targets-&gt;feature map每个点与2Dbox上下左右的距离的最大值，在不同feature【stride-8,16,32,64,128】的范围<br>\n超参数regress_ranges=((-1, 48), (48, 96), (96, 192), (192, 384), (384, 100000000.0)) 设置<br>\nmax_regress_distance-&gt;torch.Size([8007, 2]);  inside_regress_range-&gt;torch.Size([8007, 2])<br>\n<code>=========================================================================================</code><br>\ndists=torch.Size([8007, 2]);---&gt;min_dist_inds=torch.Size([8007])<br>\nbbox_targets-(8007,2);  bbox_targets_3d-(8007,9)前两个点是feature map上的点与真实x,y的距离<br>\nrelative_dists-8007+-self.centerness_alpha(2.5)=centerness_targets-8007<br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py：class FCOSMono3DHead:def get_targets</p>len(labels_3d_list)=2,  bbox_targets_3d_list-[torch.Size([8007, 9]),torch.Size([8007, 9])],   centerness_targets_list-[torch.Size([8007]),torch.Size([8007])]<br>\nconcat_lvl_labels_3d=>【】,<br>\nconcat_lvl_bbox_targets_3d=>,<br>\nconcat_lvl_centerness_targets=>,<br>\nconcat_lvl_attr_targets=>，<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def loss</p>\n<p>flatten_cls_scores = torch.cat(flatten_cls_scores)-torch.Size([16014, 10])10个类别【min=-5.0552, max=-3.9641】<br>\nflatten_bbox_preds = torch.cat(flatten_bbox_preds)-torch.Size([16014, 9])--&gt;pos_bbox_preds=torch.Size([14, 9])<br>\nflatten_dir_cls_preds = torch.cat(flatten_dir_cls_preds)-torch.Size([16014, 2])--&gt;pos_dir_cls_preds=torch.Size([14, 2])<br>\nflatten_centerness = torch.cat(flatten_centerness)-torch.Size([16014])--&gt;pos_centerness=torch.Size([14])<br>\n<code>------------------------</code><br>\nflatten_labels_3d = torch.cat(labels_3d)-torch.Size([16014])----torch.int64+【min=0,max=10】===FocalLoss()<br>\nflatten_bbox_targets_3d = torch.cat(bbox_targets_3d)-torch.Size([16014, 9])--&gt;pos_bbox_targets_3d=torch.Size([14, 9])<br>\nflatten_centerness_targets = torch.cat(centerness_targets)-torch.Size([16014])--&gt;pos_centerness_targets=torch.Size([14])<br>\nif self.use_direction_classifier=True;self.dir_offset=0.7854;<br></p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def get_direction_target</p>rot_gt-torch.Size([19])看到的角度<br>\nnum_bins=2，dir_cls_targets-torch.Size([19])，值要么0要么1<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">mmdet3d/models/dense_heads/fcos_mono3d_head.py:class FCOSMono3DHead:def loss</p>loss_rotsin-算的是sin(yaw)cos(yaw)的差值<br>\nCrossEntropyLoss()-><br>'}]}]})</script></body>
</html>
