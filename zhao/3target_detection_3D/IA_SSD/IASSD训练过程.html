<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>IASSD训练过程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 150vw;
  height: 200vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">数据处理</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/kitti/kitti_dataset.py:class KittiDataset:def __getitem__</p>\n<p>info.keys()=dict_keys([\'point_cloud\', \'image\', \'calib\', \'annos\'])<br>\nsample_idx=\'006736\'<br>\nimg_shape=array([ 375, 1242])<br>\ncalib=<pcdet.utils.calibration_kitti.Calibration object at 0x7fcd5f42ddd8><br>\nget_item_list=[\'points\']<br>\n相机坐标系转到雷达坐标系：8个目标<br>\ngt_boxes_camera.shape=(8,7)&lt;-&gt;gt_boxes_lidar;<code>pcdet/utils/box_utils.py:def boxes3d_kitti_camera_to_lidar</code> gt_names.shape=(8,)<br>\n下载road planes，这对于训练中的数据增强是可选的？<br>\nroad_plane=array([-0.0154115,-0.99985959,0.00657865,1.63900299])<br>\npoints=(115922,4); FOV_POINTS_ONLY=True;<br></p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/calibration_kitti.py:def lidar_to_rect保留正前方的点云</p>pts_lidar=(115922,3)->(115922,4);<br>\npts_rect=(115922,3);这里相当于映射到图片上过滤掉一些点<br>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/kitti/kitti_dataset.py,class KittiDataset:def __getitem__</p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/dataset.py:def prepare_data</p>data_dict.get(\'gt_boxes\', None) is not None:True<br>\n把类别合到gt_boxes里面:data_dict[\'gt_boxes\'].shape=(39,8)<br>\ndata_dict[\'points\'][0]=array([28.520061  , 16.495598  , -0.36022797,  0.], dtype=float32)<br>\ndata_dict = self.point_feature_encoder.forward(data_dict)<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/processor/point_feature_encoder.py:class PointFeatureEncoder:def forward</p>data_dict[\'points\'].shape=(22307, 4); use_lead_xyz=True;后面是false<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/dataset.py:def prepare_data</p>data_dict = self.data_processor.forward【数据增强处理】<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/datasets/processor/data_processor.py:class DataProcessor:def forward</p>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': "<p>pcdet/datasets/dataset.py<code>:</code>class DatasetTemplate:def collate_batch<br>\nbatch_list[0].keys()=dict_keys(['frame_id', 'gt_boxes', 'points', 'use_lead_xyz', 'image_shape'])<br></p>"}]}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/IASSD.py:class IASSD:def forward</p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/IASSD_backbone.py:class IASSD_Backbone:def forward</p>\n<p><a href="https://gitee.com/zhao-study/data_code/blob/master/3target_detection_3D/project/IA_SSD/model.log">model.log</a><br>\nbatch_idx.shape=(32768); xyz.shape=(32768,3)-&gt;(2,16384,3); features.shape=(32768,1)-&gt;(2,1,16384);<br>\nencoder_coords.shape=(2,16384,4);<br>\nself.layer_types=[\'SA_Layer\', \'SA_Layer\', \'SA_Layer\', \'SA_Layer\', \'Vote_Layer\', \'SA_Layer\'];<br>\nself.layer_inputs=[0, 1, 2, 3, 4, 3];<br>\nself.ctr_idx_list=[-1, -1, -1, -1, -1, 5];<br>\ni=0:<br>\nxyz_input.shape=(2,16384,3); feature_input=(2,1,16384); li_cls_pred=None; ctr_xyz=None;<br></p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/pointnet2/pointnet2_batch/pointnet2_modules.py:class PointnetSAModuleMSG_WithSampling:def forward</p>\n<p><code>---------------------------------if ctr_xyz is None:---------------------------------------------</code><br>\nself.sample_type_list=[\'D-FPS\'];<br>\n<code>================================  for i in range(len(self.sample_type_list)):============================</code><br>\nself.sample_range_list=[-1];self.npoint_list=[4096],npoint=4096<br>\n<code>---------------------------------if sample_range==-1:--------------------------------------------</code><br>\nxyz_tmp.shape=(2,16384,3); feature_tmp.shape=(2,16384,1); cls_features_tmp=None;<br>\n<code>-------------------------------------------------------------------------------------------------</code><br>\n<code>------------------------elif \'D-FPS\' in sample_type or \'DFS\' in sample_type:---------------------</code><br>\nsample_idx.shape=(2,4096); new_xyz=(2,4096,3);<br>\n<code>-------------------------------------------------------------------------------------------------</code><br>\nself.groupers=ModuleList((0): QueryAndGroup() (1): QueryAndGroup())<br>\n<code>--------------------------------if len(self.groupers) &gt; 0:-----------------------------------</code> groupers-&gt;mlps-&gt;aggregation_layer<br>\ni=0<br>\nxyz.shape=(2,16384,3),new_xyz.shpae=(2,4096,3),features.shape=(2,1,16384)--&gt;new_features.shape=(2,4,4096,16)-&gt;(2,32,4096,16)-&gt;(2,32,4096,1)-&gt;(2,32,4096)<br>\ni=1<br>\nxyz.shape=(2,16384,3),new_xyz.shpae=(2,4096,3),features.shape=(2,1,16384)--&gt;new_features.shape=(2,4,4096,32)-&gt;(2,64,4096,32)-&gt;(2,64,4096,1)-&gt;(2,64,4096)-&gt;(2,96,4096)<br>\n<code>----------------------------if self.aggregation_layer is not None-------------------------------</code><br>\nself.aggregation_layer-&gt;CBR:new_features.shape=(2,64,4096);<br>\n<code>--------------------------------------------------------------------------------------------------</code><br>\nnew_xyz=(2,4096,3); cls_features=None<br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/IASSD_backbone.py:class IASSD_Backbone:def forward</p>encoder_xyz=[(2,16384,3),(2,4096,3)]<br>\nencoder_coords=[(2,16384,4),(2,4096,4)]->batch_size+ xyz<br>\nencoder_features=[(2,1,16384),(2,64,4096)]<br>\nself.ctr_idx_list: [-1, -1, -1, -1, -1, 5]<br>\nsa_ins_preds=[[]]<br>\ni=1:<br>\nxyz_input.shape=(2,4096,3); feature_input=(2,64,4096); li_cls_pred=None; ctr_xyz=None;<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/pointnet2/pointnet2_batch/pointnet2_modules.py:class PointnetSAModuleMSG_WithSampling:def forward</p>self.sample_type_list=[\'D-FPS\'];self.sample_range_list=[-1];self.npoint_list=[1024]<br>\nif sample_range==-1:xyz_tmp.shape=(2,4096,3); feature_tmp.shape=(2,4096,64); cls_features_tmp=None; npoint=1024<br>\nsample_idx.shape=(2,1024); new_xyz=(2,1024,3);<br>\nself.groupers=ModuleList((0): QueryAndGroup() (1): QueryAndGroup())<br>\nxyz.shape=(2,4096,3),new_xyz.shpae=(2,1024,3),features.shape=(2,64,4096)-->new_features.shape=(2,67,1024,16)->(2,128,1024,16)->(2,128,1024,1)->(2,128,1024)<br>\nxyz.shape=(2,4096,3),new_xyz.shpae=(2,1024,3),features.shape=(2,64,4096)-->new_features.shape=(2,67,1024,32)->(2,128,1024,32)->(2,128,1024,1)->(2,128,1024)->(2,256,4096)<br>\nself.aggregation_layer->CBR:new_features.shape=(2,128,1024); cls_features.shape=(2,1024,3)#用于ctr_aware选取前景点的<br>\nnew_xyz=(2,4096,3); cls_features=None<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/IASSD_backbone.py:class IASSD_Backbone:def forward</p>encoder_xyz=[(2,16384,3),(2,4096,3),(2,1024,3)]<br>\nencoder_coords=[(2,16384,4),(2,4096,4),(2,1024,4)]<br>\nencoder_features=[(2,1,16384),(2,64,4096),(2,128,1024)]<br>\nsa_ins_preds=[[],(2,1024,4)]<br>\ni=2:<br>\nxyz_input.shape=(2,1024,3); feature_input=(2,128,1024); li_cls_pred.shape=(2,1024,3); ctr_xyz=None;<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/pointnet2/pointnet2_batch/pointnet2_modules.py:class PointnetSAModuleMSG_WithSampling:def forward</p>self.sample_type_list=[\'ctr_aware\'];self.sample_range_list=[-1];self.npoint_list=[512]<br>\nif sample_range==-1:xyz_tmp.shape=(2,1024,3); feature_tmp.shape=(2,1024,128); cls_features_tmp=(2,1024,3); npoint=512<br>\ncls_features_max.shape=(2,1024);->score_pred.shape=(2,1024);<br>\nsample_idx.shape=(2,512); new_xyz=(2,512,3);<br>\nself.groupers=ModuleList((0): QueryAndGroup() (1): QueryAndGroup())<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/IASSD_backbone.py:class IASSD_Backbone:def forward</p>encoder_xyz=[(2,16384,3),(2,4096,3),(2,1024,3),(2,512,3)]<br>\nencoder_coords=[(2,16384,4),(2,4096,4),(2,1024,4),(2,512,4)]<br>\nencoder_features=[(2,1,16384),(2,64,4096),(2,128,1024),(2,256,512)]<br>\nsa_ins_preds=[[],(2,1024,4),(2,512，4)]<br>\ni=3:<br>\nencoder_xyz=[(2,16384,3),(2,4096,3),(2,1024,3),(2,512,3),(2,256,3)]<br>\nencoder_coords=[(2,16384,4),(2,4096,4),(2,1024,4),(2,512,4),(2,256,4)]<br>\nencoder_features=[(2,1,16384),(2,64,4096),(2,128,1024),(2,256,512),(2,256,256)]<br>\nsa_ins_preds=[[],(2,1024,4),(2,512,4)，[]]<br>\n<br>\ni=4:\'Vote_Layer\'<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/ops/pointnet2/pointnet2_batch/pointnet2_modules.py:class Vote_layer:def forward</p>xyz_select=torch.Size([2, 256, 3]); features_select=torch.Size([2, 256, 256])<br>\nnew_features:([2, 128, 256])-->ctr_offsets:([2, 3, 256]->[2, 256, 3]<br>\nnew_features=[]<br>\nself.max_offset_limit=tensor([3., 3., 2.])<br>\nvote_xyz, new_features, xyz_select, ctr_offsets->torch.Size([2, 256, 3]),torch.Size([2, 256, 0]),torch.Size([2, 256, 3]),torch.Size([2, 256, 3])<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/backbones_3d/IASSD_backbone.py:class IASSD_Backbone:def forward</p>encoder_xyz=[(2,16384,3),(2,4096,3),(2,1024,3),(2,512,3),(2,256,3),(2,256,3)]<br>\nencoder_coords=[(2,16384,4),(2,4096,4),(2,1024,4),(2,512,4),(2,256,4),(2,256,4),(2,256,4)]<br>\nencoder_features=[(2,1,16384),(2,64,4096),(2,128,1024),(2,256,512),(2,256,256),[]]<br>\nsa_ins_preds=[[],(2,1024,4),(2,512,4),[],[]]<br>\nctr_offsets.shape=(2,256,3);->(512,4)<br>\ncenters.shape=(2,256,3);;->(512,4)<br>\ncenters_origin.shape=(2,256,3);;->(512,4)<br>\ni=5:<br>\nencoder_xyz=[(2,16384,3),(2,4096,3),(2,1024,3),(2,512,3),(2,256,3),(2,256,3),(2,256,3)]<br>\nencoder_coords=[(2,16384,4),(2,4096,4),(2,1024,4),(2,512,4),(2,256,4),(2,256,4),(2,256,4),(2,256,4)]<br>\nencoder_features=[(2,1,16384),(2,64,4096),(2,128,1024),(2,256,512),(2,256,256),[],(2,512,256)]<br>\nsa_ins_preds=[[],(2,1024,4),(2,512,4),[],[],[]]<br>\nctr_batch_idx.shape=(2,256)->(512)<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-python"><code class="language-python">'}]}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">batch_dict</p>frame_id:array([\'006209\', \'005966\'], dtype=\'<U6\')<br>\ngt_boxes:torch.Size([2, 36, 8])<br>\npoints:torch.Size([32768, 5])<br>\nuse_lead_xyztensor([1., 1.], device=\'cuda:0\')<br>\nimage_shape:tensor([[ 375, 1242],[ 375, 1242]],torch.int32)<br>\nbatch_size:2<br>\nctr_offsets:torch.Size([512, 4])<br>\ncenters:torch.Size([512, 4])<br>\ncenters_origin:torch.Size([512, 4])<br>\ncenters_features:torch.Size([512, 512])<br>\nctr_batch_idxtorch.Size([512])值在0->batch_size-1之间<br>\nencoder_xyz：len()=7     [(2,16384,3), (2,4096,3),(2,1024,3),  (2,512,3),  (2,256,3),  (2,256,3),          (2,256,3)]<br>\nencoder_coords：len()=8  [(2,16384,4), (2,4096,4),(2,1024,4),  (2,512,4),  (2,256,4),  (2,256,4),(2,256,4),(2,256,4)]  vote_;ayer层的时候加了两次<br>\nsa_ins_preds：len()=6    [             [],        (2,1024,4),  (2,512,4),   [],        [],                 []]<br>\nencoder_features:len()=7 [(2,1,16384),(2,64,4096),(2,128,1024),(2,256,512),(2,256,256),[],                 (2,512,256)]<br>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<pre class="language-"><code class="language-">'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/IASSD.py:class IASSD:def forward</p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def forward</p>center_features.shape=(512,512)<br>\ncenter_features.shape=(512,512); center_coords.shape=(512,4);<br>\ncenter_cls_preds.shape=(total_centers,num_class)=(512,3);<br>\ncenter_box_preds.shape=(total_centers,box_code_size)=(512,30);box_iou3d_preds=None,<br>\n30为6+12*2（12个bin以及每个bin的迁移）<br>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def assign_targets</p>gt_boxes.shape=(2,34,8)<br>\nbatch_size=2<br>\nextend_gt=gt_boxes;extra_width=[0.2,0.2,0.2]->extend_gt_boxes.shape(2,34,8)<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def assign_stack_targets_IASSD</p>\n<p>bs_idx=512它的值是第几个batch_id<br>\n<code>--------------------for k in range(batch_size)-------------------------</code><br>\npoints_single.shape=(256,3)某个batch的那些点; point_cls_labels_single.shape=(256);<br>\nbox_idxs_of_pts.shape=(256);256个点是不是在3Dbox里面<br>\nbox_fg_flag=42表示该batch有42个点在3D box里面<br>\nuse_query_assign=False; use_ex_gt_assign=False; set_ignore_flag=True; use_ball_constraint=True;<br>\n<code>--------------------elif set_ignore_flag:-------------------------</code><br>\n(extend_box_idxs_of_pts &gt;= 0).sum()=54个点在扩充box里面，这样不在里面但是在扩充的范围之内的有12个(54-42)<br>\npoint_cls_labels_single[ignore_flag]=-1，不在里面但是在扩充的范围之内的<br>\n<code>----------------------------------------------------------------</code><br>\ngt_box_of_fg_points.shape=(44,8)有44个点在box里面(不包括扩充部分)，这里bbox有重复；<br>\nbg_flag为背景的是True<br>\nbox_idxs_labels.shape=（512，）；里面的值表示在哪个box3D里面<br>\ngt_box_of_points.shape=(512,8) 512个点含有box3D的队对应值<br>\n<code>--------------------if ret_box_labels and gt_box_of_fg_points.shape[0] &gt; 0------------------------</code><br>\nbs_mask.sum()=256-&gt;point_box_labels_single.shape=(256,8)<br></p>', 'children': [{'type': 'heading', 'depth': 6, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/utils/box_coder_utils.py:class PointResidual_BinOri_Coder:def encode_torch</p>\n<p>gt_boxes.shape=(44,7); points.shape=(44,3);<br>\n<code>---------------------if self.use_mean_size:------------------------------------------------</code><br>\ngt_classes.shape=(44)上面44个box的真实标签<br>\nself.mean_size=tensor([[3.9000,1.6000,1.5600],[0.8000,0.6000,1.7300],[1.7600,0.6000,1.7300]],device=\'cuda:0\')<br>\nself.bin_inter=0.5235987755982988【0/self.bin_inter=0.0； 2*np.pi/self.bin_inter=12.0】<br></p>'}]}, {'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def assign_stack_targets_IASSD</p>fg_point_box_labels.shape=(256,8)<br>\n\'point_cls_labels\':torch.Size([512]);0是背景的label；-1是ignore，1-n_class是类别的值<br>\n\'point_box_labels\':torch.Size([512, 8])；经过encode的结果；有重复的，最后两维为bin_id和bin_res<br>\n\'gt_box_of_fg_points\': torch.Size([67, 8])；原始的3D box有重复的<br>\n\'box_idxs_labels\': torch.Size([512]); torch.sum(box_idxs_labels>=0)=67; 值为是哪个3D box<br>\n\'gt_box_of_points\': torch.Size([512, 8]);背景和-1的box为0，其它为该点对应的GTbox<br>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def assign_targets</p>\n<p><code>------------------------if target_cfg.get(\'INS_AWARE_ASSIGN\', False)--------------------------------</code><br>\nsa_ins_preds=[[],(2,1024,4),(2,512,4),[],[],[]]<br>\nfor i in range(1, len(sa_ins_preds)):<br>\ni=1<br>\nsa_xyz=torch.Size([2, 4096, 4])<br>\nextend_gt_boxes.shape=torch.Size([2, 39, 8])<br>\n<code>---------------------------------------------------------------------------------------------------</code><br>\n<code>===========================================================================</code><br>\npoint_cls_labels-&gt;sa_ins_labels=            [torch.Size([8192]),       torch.Size([2048]),       torch.Size([1024]),      torch.Size([512]),       torch.Size([512])]<br>\ngt_box_of_fg_points-&gt;sa_gt_box_of_fg_points=[torch.Size([1969, 8]),    torch.Size([519, 8]),     torch.Size([296, 8]),    torch.Size([146, 8]),    torch.Size([146, 8])]<br>\ngt_box_of_points-&gt;sa_gt_box_of_points=      [torch.Size([8192, 8]),    torch.Size([2048, 8]),    torch.Size([1024, 8]),   torch.Size([512, 8]),    torch.Size([512, 8])]<br>\nbox_idxs_labels-&gt;sa_box_idxs_labels=        [torch.Size([8192]),       torch.Size([2048]),       torch.Size([1024]),      torch.Size([512]),       torch.Size([512])]<br>\nsa_xyz_coords=                              [torch.Size([2, 4096, 4]), torch.Size([2, 1024, 4]), torch.Size([2, 512, 4]), torch.Size([2, 256, 4]), torch.Size([2, 256, 4])]<br>\n<code>===========================================================================</code><br>\n<code>------------------------if extra_method is not None and extra_method.NAME == \'extend_gt\':-----</code><br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def forward</p>\n<p><code>------------if not self.training or self.predict_boxes_when_training----------------------------</code><br>\ncenter_coords[:, 1:4]=(512,3),,center_cls_preds=(512,3)主要三个类，center_box_preds=torch.Size([512, 30])<br></p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/point_head_template.py：class PointHeadTemplate：def generate_predicted_boxes</p>pred_classes.shape=torch.Size([512]);point_box_preds=(512,7)<br>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def forward</p>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/detectors/IASSD.py:class IASSD:def get_training_loss</p>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def get_loss</p>\n<p><code>--------center_loss_reg, tb_dict_3 = self.get_contextual_vote_loss()---------------------</code><br></p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def get_contextual_vote_loss</p>\n<p>pos_mask.shape=torch.Size([512]),在box点的索引<br>\n<code>------------for i in self.forward_ret_dict[\'center_origin_cls_labels\'].unique():--------</code><br>\n对于每个label，i=1是第一个label，小于等于0是背景和ignore，continue<br>\ncenter_box_labels为box的中心点，torch.Size([84, 3])表示84个label对应box的中心点，有重复<br>\ncenters_origin.shape=ctr_offsets=torch.Size([512, 4])<br>\ncenters_pred.shape=torch.Size([84, 3])<br>\n这里计算中心点的距离loss<br></p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def get_loss</p>\n<p><code>------if self.model_cfg.LOSS_CONFIG.get(\'LOSS_INS\', None) is not None-------------</code><br></p>', 'children': [{'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def get_sa_ins_layer_loss</p>[i.shape for i in sa_ins_labels]=[torch.Size([8192]), torch.Size([2048]), torch.Size([1024]), torch.Size([512]), torch.Size([512])]。。。这些点对应在box里面的label<br>\nsa_ins_preds=[[],(2, 1024, 4),(2, 512, 4),[],[],[]]4后面的3个值是类别<br>\ni=1,  point_cls_preds.shape=torch.Size([2048, 3])  point_cls_labels.shape=torch.Size([2048]),对应所在box的label<br>', 'children': [{'type': 'heading', 'depth': 5, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def generate_sa_center_ness_mask</p>[i.shape for i in sa_pos_mask]=[torch.Size([8192]), torch.Size([2048]), torch.Size([1024]), torch.Size([512]), torch.Size([512])]里面对应的label-1负样本，0背景，大于0正样本<br>\n[i.shape for i in sa_gt_boxes]=[torch.Size([1436, 8]), torch.Size([433, 8]), torch.Size([264, 8]), torch.Size([142, 8]), torch.Size([142, 8])]点对应得3Dbox<br>\n[i.shape for i in sa_xyz_coords]=[torch.Size([2, 4096, 4]), torch.Size([2, 1024, 4]), torch.Size([2, 512, 4]), torch.Size([2, 256, 4]), torch.Size([2, 256, 4])]对应点的坐标<br>\n[i.shape for i in sa_centerness_mask]=[torch.Size([8192]), torch.Size([2048]), torch.Size([1024]), torch.Size([512]), torch.Size([512])]<br>'}]}, {'type': 'heading', 'depth': 4, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def get_sa_ins_layer_loss</p>'}]}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">pcdet/models/dense_heads/IASSD_head.py:class IASSD_Head:def get_loss</p>\n<p><code>------if self.model_cfg.LOSS_CONFIG.get(\'LOSS_INS\', None) is not None-------------</code><br></p>'}]}]}]})</script></body>
</html>
