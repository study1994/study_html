<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>cuda_pointpillars_demo</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">main.cpp</p><span class=\'hidden-code\' data-code=\'int main(int argc, const char **argv){\n  `Getinfo`();\n  cudaEvent_t start, stop;           // 0x7fffde347792,0x7fffffffd800\n  float elapsedTime = 0.0f;\n  cudaStream_t stream = NULL;        // 0x0\n  checkCudaErrors(cudaEventCreate(&amp;start));\n  checkCudaErrors(cudaEventCreate(&amp;stop));\n  checkCudaErrors(cudaStreamCreate(&amp;stream));\n  Params `params_`;\n  std::vector`<``Bndbox``>` nms_pred;\n  nms_pred.reserve(100);              // 在需要对大量数据进行处理的时候就要使用reserve主动分配内存以提升程序执行效率\n  PointPillar `pointpillar`(Model_File, stream);\n  for (int i = 0; i < 10; i++){\n    std::string dataFile = Data_File;      // &amp;#39;../data/&amp;#39;\n    std::stringstream ss;\n    ss<< i;\n    int n_zero = 6;\n    std::string _str = ss.str();           // &amp;#39;0&amp;#39;\n    std::string index_str = std::string(n_zero - _str.length(), &amp;#39;0&amp;#39;) + _str;\n    dataFile += index_str;\n    dataFile +=&amp;#39;.bin&amp;#39;;                    // &amp;#39;../data/000000.bin&amp;#39;\n    // load points cloud\n    unsigned int length = 0;\n    void *data = NULL;\n    std::shared_ptr`<`char`>` buffer((char *)data, std::default_delete`<`char[]`>`());\n    `loadData`(dataFile.data(), &amp;data, &amp;length);\n    buffer.reset((char *)data);\n    float* points = (float*)buffer.get();\n    size_t points_size = length/sizeof(float)/4;    // 20285\n    float *points_data = nullptr;\n    unsigned int points_data_size = points_size * 4 * sizeof(float);\n    checkCudaErrors(cudaMallocManaged((void **)&amp;points_data, points_data_size));\n    checkCudaErrors(cudaMemcpy(points_data, points, points_data_size, cudaMemcpyDefault));\n    checkCudaErrors(cudaDeviceSynchronize());\n    cudaEventRecord(start, stream);\n    `pointpillar.doinfer`(points_data, points_size, nms_pred);\n    cudaEventRecord(stop, stream);\n    cudaEventSynchronize(stop);\n    cudaEventElapsedTime(&amp;elapsedTime, start, stop);\n    checkCudaErrors(cudaFree(points_data));\n    std::string save_file_name = Save_Dir + index_str + &amp;#39;.txt&amp;#39;;\n    SaveBoxPred(nms_pred, save_file_name);\n    nms_pred.clear();\n  }\n  checkCudaErrors(cudaEventDestroy(start));\n  checkCudaErrors(cudaEventDestroy(stop));\n  checkCudaErrors(cudaStreamDestroy(stream));\n  return 0;\n}\n\'> </span>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">main.cpp</p><span class=\'hidden-code\' data-code=\'void Getinfo(void){\n  cudaDeviceProp prop;       //\n  int count = 0;\n  cudaGetDeviceCount(&amp;count);     // count=8  &amp;count=0x7fffffffd4b8\n  printf(&amp;#39;\\nGPU has cuda devices: %d\\n&amp;#39;, count);      // GPU has cuda devices: 8\n  for (int i = 0; i < count; ++i) {\n    cudaGetDeviceProperties(&amp;prop, i);\n    printf(&amp;#39;----device id: %d info----\\n&amp;#39;, i);\n    printf(&amp;#39;  GPU : %s \\n&amp;#39;, prop.name);                                // GPU : NVIDIA GeForce RTX 3090\n    printf(&amp;#39;  Capbility: %d.%d\\n&amp;#39;, prop.major, prop.minor);            // Capbility: 8.6\n    printf(&amp;#39;  Global memory: %luMB\\n&amp;#39;, prop.totalGlobalMem >> 20);     // Global memory: 24268MB\n    printf(&amp;#39;  Const memory: %luKB\\n&amp;#39;, prop.totalConstMem  >> 10);      // Const memory: 64KB\n    printf(&amp;#39;  SM in a block: %luKB\\n&amp;#39;, prop.sharedMemPerBlock >> 10);  // SM in a block: 48KB\n    printf(&amp;#39;  warp size: %d\\n&amp;#39;, prop.warpSize);                        // warp size: 32\n    printf(&amp;#39;  threads in a block: %d\\n&amp;#39;, prop.maxThreadsPerBlock);     // threads in a block: 1024\n    printf(&amp;#39;  block dim: (%d,%d,%d)\\n&amp;#39;, prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);  // block dim: (1024,1024,64)\n    printf(&amp;#39;  grid dim: (%d,%d,%d)\\n&amp;#39;, prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);         // grid dim: (2147483647,65535,65535)\n  }\n  printf(&amp;#39;\\n&amp;#39;);\n}\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">include/params.h</p><span class=\'hidden-code\' data-code=\'const int MAX_VOXELS = 40000;\nclass Params{\n  public:\n    static const int num_classes = 3;\n    const char *class_name [num_classes] = { &amp;#39;Car&amp;#39;,&amp;#39;Pedestrian&amp;#39;,&amp;#39;Cyclist&amp;#39;,};\n    const float min_x_range = 0.0;\n    const float max_x_range = 69.12;\n    const float min_y_range = -39.68;\n    const float max_y_range = 39.68;\n    const float min_z_range = -3.0;\n    const float max_z_range = 1.0;\n    // the size of a pillar\n    const float pillar_x_size = 0.16;   // 432\n    const float pillar_y_size = 0.16;   // 496\n    const float pillar_z_size = 4.0;\n    const int max_num_points_per_pillar = 32;\n    const int num_point_values = 4;\n    // the number of feature maps for pillar scatter\n    const int num_feature_scatter = 64;\n    const float dir_offset = 0.78539;\n    const float dir_limit_offset = 0.0;\n    // the num of direction classes(bins)\n    const int num_dir_bins = 2;\n    // anchors decode by (x, y, z, dir)\n    static const int num_anchors = num_classes * 2;  // 6\n    static const int len_per_anchor = 4;             // 长宽高+角度\n    const float anchors[num_anchors * len_per_anchor] = {\n      3.9,1.6,1.56,0.0,\n      3.9,1.6,1.56,1.57,\n      0.8,0.6,1.73,0.0,\n      0.8,0.6,1.73,1.57,\n      1.76,0.6,1.73,0.0,\n      1.76,0.6,1.73,1.57,\n      };       // 6x4\n    const float anchor_bottom_heights[num_classes] = {-1.78,-0.6,-0.6,};\n    // the score threshold for classification\n    const float score_thresh = 0.1;\n    const float nms_thresh = 0.01;\n    const int max_num_pillars = MAX_VOXELS;       // 40000\n    const int pillarPoints_bev = max_num_points_per_pillar * max_num_pillars;  // 32*40000\n    // the detected boxes result decode by (x, y, z, w, l, h, yaw)\n    const int num_box_values = 7;\n    // the input size of the 2D backbone network\n    const int grid_x_size = (max_x_range - min_x_range) / pillar_x_size;   // 432\n    const int grid_y_size = (max_y_range - min_y_range) / pillar_y_size;   // 496\n    const int grid_z_size = (max_z_range - min_z_range) / pillar_z_size;   // 1\n    // the output size of the 2D backbone network\n    const int feature_x_size = grid_x_size / 2;       \n    const int feature_y_size = grid_y_size / 2;\n    Params() {};\n};\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">include/postprocess.h</p><span class=\'hidden-code\' data-code=\'struct Bndbox {float x;float y;float z;float w;float l;float h;float rt;int id;float score;\n    Bndbox(){};\n    Bndbox(float x_, float y_, float z_, float w_, float l_, float h_, float rt_, int id_, float score_)\n        : x(x_), y(y_), z(z_), w(w_), l(l_), h(h_), rt(rt_), id(id_), score(score_) {}\n};\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">src/pointpillar.cpp</p><span class=\'hidden-code\' data-code=\'class PointPillar {\n  private:\n    Params params_;\n    cudaEvent_t start_, stop_;\n    cudaStream_t stream_;\n    std::shared_ptr`<`PreProcessCuda`>` pre_;\n    std::shared_ptr`<`TRT`>` trt_;\n    std::shared_ptr`<`PostProcessCuda`>` post_;\n    //input of pre-process\n    float *voxel_features_ = nullptr;       // 网络输入\n    unsigned int *voxel_num_ = nullptr;\n    unsigned int *voxel_idxs_ = nullptr;\n    unsigned int *pillar_num_ = nullptr;\n    unsigned int voxel_features_size_ = 0;\n    unsigned int voxel_num_size_ = 0;\n    unsigned int voxel_idxs_size_ = 0;\n    //TRT-input\n    float *features_input_ = nullptr;         // TRT输入\n    unsigned int *params_input_ = nullptr;\n    unsigned int features_input_size_ = 0;\n    //output of TRT -- input of post-process\n    float *cls_output_ = nullptr;             // TRT输出\n    float *box_output_ = nullptr;\n    float *dir_cls_output_ = nullptr;\n    unsigned int cls_size_;\n    unsigned int box_size_;\n    unsigned int dir_cls_size_;\n    //output of post-process\n    float *bndbox_output_ = nullptr;          // 后处理的结果\n    unsigned int bndbox_size_ = 0;\n    std::vector`<`Bndbox`>` res_;\n  public:\n    PointPillar(std::string modelFile, cudaStream_t stream = 0);\n    ~PointPillar(void);\n    int doinfer(void*points, unsigned int point_size, std::vector`<`Bndbox`>` &amp;res);\n};\n// ----------------------------------------------------------------------------------------\nPointPillar::PointPillar(std::string modelFile, cudaStream_t stream):stream_(stream){  // &amp;#39;../model/pointpillar.onnx&amp;#39;;  0x5555567d9fd0  后面初始化变量：cudaStream_t PointPillar::stream_=stream\n  checkCudaErrors(cudaEventCreate(&amp;start_));       \n  checkCudaErrors(cudaEventCreate(&amp;stop_));\n  pre_.reset(new `PreProcessCuda`(stream_));   // 设置变量值 std::shared_ptr`<`PreProcessCuda`>` pre_ = new PreProcessCuda(stream_)\n  trt_.reset(new `TRT`(modelFile, stream_));\n  post_.reset(new `PostProcessCuda`(stream_));\n  //point cloud to voxels\n  voxel_features_size_ = MAX_VOXELS * params_.max_num_points_per_pillar * 4 * sizeof(float);      // 40000*32*4*4 倒数第二个4为(x,y,z,r)\n  voxel_num_size_ = MAX_VOXELS * sizeof(unsigned int);                                            // sizeof(unsigned int)=4\n  voxel_idxs_size_ = MAX_VOXELS* 4 * sizeof(unsigned int);\n  checkCudaErrors(cudaMallocManaged((void **)&amp;voxel_features_, voxel_features_size_));\n  checkCudaErrors(cudaMallocManaged((void **)&amp;voxel_num_, voxel_num_size_));\n  checkCudaErrors(cudaMallocManaged((void **)&amp;voxel_idxs_, voxel_idxs_size_));\n  checkCudaErrors(cudaMemsetAsync(voxel_features_, 0, voxel_features_size_, stream_));\n  checkCudaErrors(cudaMemsetAsync(voxel_num_, 0, voxel_num_size_, stream_));\n  checkCudaErrors(cudaMemsetAsync(voxel_idxs_, 0, voxel_idxs_size_, stream_));\n  //TRT-input\n  features_input_size_ = MAX_VOXELS * params_.max_num_points_per_pillar * 10 * sizeof(float);    // 40000x32x10\n  checkCudaErrors(cudaMallocManaged((void **)&amp;features_input_, features_input_size_));\n  checkCudaErrors(cudaMallocManaged((void **)&amp;params_input_, sizeof(unsigned int)));\n  checkCudaErrors(cudaMemsetAsync(features_input_, 0, features_input_size_, stream_));\n  checkCudaErrors(cudaMemsetAsync(params_input_, 0, sizeof(unsigned int), stream_));\n  //output of TRT -- input of post-process\n  cls_size_ = params_.feature_x_size * params_.feature_y_size * params_.num_classes * params_.num_anchors * sizeof(float);      // 216x248x3x6\n  box_size_ = params_.feature_x_size * params_.feature_y_size * params_.num_box_values * params_.num_anchors * sizeof(float);   // 216x248x7x6\n  dir_cls_size_ = params_.feature_x_size * params_.feature_y_size * params_.num_dir_bins * params_.num_anchors * sizeof(float); // 216x248x2x6\n  checkCudaErrors(cudaMallocManaged((void **)&amp;cls_output_, cls_size_));\n  checkCudaErrors(cudaMallocManaged((void **)&amp;box_output_, box_size_));\n  checkCudaErrors(cudaMallocManaged((void **)&amp;dir_cls_output_, dir_cls_size_));\n  //output of post-process 【这里9为x、y、z、w、l、h、rt、id、score】\n  bndbox_size_ = (params_.feature_x_size * params_.feature_y_size * params_.num_anchors * 9 + 1) * sizeof(float);     // 216x248x6x9+1\n  checkCudaErrors(cudaMallocManaged((void **)&amp;bndbox_output_, bndbox_size_));\n  res_.reserve(100);\n  return;\n}\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">include/preprocess.h</p><span class=\'hidden-code\' data-code=\'class PreProcessCuda {\n  private:\n    Params params_;\n    unsigned int *mask_;\n    float *voxels_;\n    int *voxelsList_;\n    float *params_cuda_;\n    cudaStream_t stream_ = 0;\n  public:\n    PreProcessCuda(cudaStream_t stream_ = 0);\n    ~PreProcessCuda();\n    //points cloud -> voxels (BEV) -> feature*4 \n    int generateVoxels(float *points, size_t points_size, unsigned int *pillar_num, float *voxel_features, unsigned int *voxel_num, unsigned int *voxel_idxs);\n    //feature*4 -> feature * 10 \n    int generateFeatures(float* voxel_features, unsigned int *voxel_num, unsigned int* voxel_idxs, unsigned int *params, float* features);\n};\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">src/pointpillar.cpp</p><span class=\'hidden-code\' data-code=\'TRT::TRT(std::string modelFile, cudaStream_t stream):stream_(stream){\n  std::string modelCache = modelFile + &amp;#39;.cache&amp;#39;;        // &amp;#39;../model/pointpillar.onnx.cache&amp;#39;\n  std::fstream trtCache(modelCache, std::ifstream::in);\n  checkCudaErrors(cudaEventCreate(&amp;start_));\n  checkCudaErrors(cudaEventCreate(&amp;stop_));\n  if (!trtCache.is_open())            // False\n  {.....} else {\n\tstd::cout << &amp;#39;load TRT cache.&amp;#39;<<std::endl;\n    char *data;\n    unsigned int length;\n    // get length of file:\n    trtCache.seekg(0, trtCache.end);\n    length = trtCache.tellg();           // 20242750\n    trtCache.seekg(0, trtCache.beg);\n    data = (char *)malloc(length);\n    if (data == NULL ) {\n       std::cout << &amp;#39;Can&amp;#39;t malloc data.\\n&amp;#39;;\n       exit(-1);\n    }\n    trtCache.read(data, length);\n    // create context\n    auto runtime = nvinfer1::createInferRuntime(gLogger_);\n    if (runtime == nullptr) {\t  std::cout << &amp;#39;load TRT cache0.&amp;#39;<<std::endl;\n        std::cerr << &amp;#39;: runtime null!&amp;#39; << std::endl;\n        exit(-1);\n    }\n    //plugin_ = nvonnxparser::createPluginFactory(gLogger_);\n    engine_ = (runtime->deserializeCudaEngine(data, length, 0));\n    if (engine_ == nullptr) {\n        std::cerr << &amp;#39;: engine null!&amp;#39; << std::endl;\n        exit(-1);\n    }\n    free(data);\n    trtCache.close();\n  }\n  context_ = engine_->createExecutionContext();   // runtime->engine_->context_\n  return;\n}\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">src/postprocess.cpp</p><span class=\'hidden-code\' data-code=\'PostProcessCuda::PostProcessCuda(cudaStream_t stream){\n  stream_ = stream;\n  checkCudaErrors(cudaMalloc((void **)&amp;anchors_, params_.num_anchors * params_.len_per_anchor * sizeof(float)));      // 6,4,sizeof(float)=4\n  checkCudaErrors(cudaMalloc((void **)&amp;anchor_bottom_heights_, params_.num_classes * sizeof(float)));\n  checkCudaErrors(cudaMalloc((void **)&amp;object_counter_, sizeof(int)));\n  checkCudaErrors(cudaMemcpyAsync(anchors_, params_.anchors,params_.num_anchors * params_.len_per_anchor * sizeof(float), cudaMemcpyDefault, stream_));\n  checkCudaErrors(cudaMemcpyAsync(anchor_bottom_heights_, params_.anchor_bottom_heights,params_.num_classes * sizeof(float), cudaMemcpyDefault, stream_));\n  checkCudaErrors(cudaMemsetAsync(object_counter_, 0, sizeof(int), stream_));\n  return;\n}\n\'> </span>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">main.cpp</p><span class=\'hidden-code\' data-code=\'int loadData(const char *file, void **data, unsigned int *length){\n  std::fstream dataFile(file, std::ifstream::in);\n  if (!dataFile.is_open()){\n\t  std::cout << &amp;#39;Can&amp;#39;t open files: &amp;#39;<< file<<std::endl;\n\t  return -1;\n  }\n  //get length of file:\n  unsigned int len = 0;\n  dataFile.seekg (0, dataFile.end);\n  len = dataFile.tellg();\n  dataFile.seekg (0, dataFile.beg);\n  //allocate memory:\n  char *buffer = new char[len];\n  if(buffer==NULL) {\n\t  std::cout << &amp;#39;Can&amp;#39;t malloc buffer.&amp;#39;<<std::endl;\n      dataFile.close();\n\t  exit(-1);\n  }\n  //read data as a block:\n  dataFile.read(buffer, len);\n  dataFile.close();\n  *data = (void*)buffer;\n  *length = len;       // 324560\n  return 0;  \n}\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">src/pointpillar.cpp</p><span class=\'hidden-code\' data-code=\'int PointPillar::doinfer(void*points_data, unsigned int points_size, std::vector`<`Bndbox`>` &amp;nms_pred){\n  pre_->`generateVoxels`((float*)points_data, points_size,\n        params_input_,\n        voxel_features_, \n        voxel_num_,\n        voxel_idxs_);\n  pre_->`generateFeatures`(voxel_features_,\n      voxel_num_,\n      voxel_idxs_,\n      params_input_,\n      features_input_);\n  void *buffers[] = {features_input_, voxel_idxs_, params_input_, cls_output_, box_output_, dir_cls_output_};\n  trt_->`doinfer`(buffers);\n  checkCudaErrors(cudaMemsetAsync(params_input_, 0, sizeof(unsigned int), stream_));\n  post_->`doPostprocessCuda`(cls_output_, box_output_, dir_cls_output_, bndbox_output_);\n  checkCudaErrors(cudaDeviceSynchronize());\n  float obj_count = bndbox_output_[0];\n  int num_obj = static_cast`<`int`>`(obj_count);\n  auto output = bndbox_output_ + 1;\n  for (int i = 0; i < num_obj; i++) {\n    auto Bb = Bndbox(output[i * 9],\n                    output[i * 9 + 1], output[i * 9 + 2], output[i * 9 + 3],\n                    output[i * 9 + 4], output[i * 9 + 5], output[i * 9 + 6],\n                    static_cast`<`int`>`(output[i * 9 + 7]),\n                    output[i * 9 + 8]);\n    res_.push_back(Bb);\n  }\n  `nms_cpu`(res_, params_.nms_thresh, nms_pred);\n  res_.clear();\n  return 0;\n}\n\'> </span>'}]}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
