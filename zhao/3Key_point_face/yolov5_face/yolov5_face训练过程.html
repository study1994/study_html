<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov5_face训练过程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/prism.css"><link rel="stylesheet" href="https://study1994.github.io/study_html/npm/markmap-toolbar@0.13.5/dist/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/d3@6.7.0"></script>
    <script src="https://study1994.github.io/study_html/npm/markmap-view@0.13.5"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">数据处理</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><font size="0"><pre class="language-python"><code class="language-python">class LoadFaceImagesAndLabels(Dataset):  <span style=\'color: red\'># for training/testing</span>\n    def __init__(self,......):\n        ...\n        self.img_files = list(cache.keys())               <span style=\'color: red\'># len(self.img_files)=12880</span>\n        self.label_files = img2label_paths(cache.keys())  <span style=\'color: red\'># self.img_files[0]=\'....../widerface/train/0_Parade_Parade_0_1014.jpg\'</span>\n        ...\n</code></pre></font>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><font size="0"><pre class="language-python"><code class="language-python">class LoadFaceImagesAndLabels(Dataset):\n    def __getitem__(self, index):\n        index = self.indices[index]  <span style=\'color: red\'># linear, shuffled, or image_weights</span>\n         hyp = self.hyp\n        mosaic = self.mosaic and random.random() < hyp[\'mosaic\']\n        if mosaic:\n            img, labels = <span style=\'color: green;font-weight: bold;\'>load_mosaic_face</span>(self, index)\n            shapes = None\n        else:\n            img, (h0, w0), (h, w) = load_image(self, index)\n            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  <span style=\'color: red\'># final letterboxed shape</span>\n            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n            shapes = (h0, w0), ((h / h0, w / w0), pad)                                    <span style=\'color: red\'># for COCO mAP rescaling</span>\n            labels = []                       <span style=\'color: red\'># Load labels</span>\n            x = self.labels[index]\n            if x.size > 0:                    <span style=\'color: red\'># Normalized xywh to pixel xyxy format</span>\n                labels = x.copy()\n                labels[:, 1] = ratio[0] * w * (x[:, 1] - x[:, 3] / 2) + pad[0]  <span style=\'color: red\'># pad width</span>\n                labels[:, 2] = ratio[1] * h * (x[:, 2] - x[:, 4] / 2) + pad[1]  <span style=\'color: red\'># pad height</span>\n                labels[:, 3] = ratio[0] * w * (x[:, 1] + x[:, 3] / 2) + pad[0]\n                labels[:, 4] = ratio[1] * h * (x[:, 2] + x[:, 4] / 2) + pad[1]\n                labels[:, 5] = np.array(x[:, 5] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 5] + pad[0]) + (np.array(x[:, 5] > 0, dtype=np.int32) - 1)\n                labels[:, 6] = np.array(x[:, 6] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 6] + pad[1]) + (np.array(x[:, 6] > 0, dtype=np.int32) - 1)\n                labels[:, 7] = np.array(x[:, 7] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 7] + pad[0]) + (np.array(x[:, 7] > 0, dtype=np.int32) - 1)\n                labels[:, 8] = np.array(x[:, 8] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 8] + pad[1]) + (np.array(x[:, 8] > 0, dtype=np.int32) - 1)\n                labels[:, 9] = np.array(x[:, 5] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 9] + pad[0]) + (np.array(x[:, 9] > 0, dtype=np.int32) - 1)\n                labels[:, 10] = np.array(x[:, 5] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 10] + pad[1]) + (np.array(x[:, 10] > 0, dtype=np.int32) - 1)\n                labels[:, 11] = np.array(x[:, 11] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 11] + pad[0]) + (np.array(x[:, 11] > 0, dtype=np.int32) - 1)\n                labels[:, 12] = np.array(x[:, 12] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 12] + pad[1]) + (np.array(x[:, 12] > 0, dtype=np.int32) - 1)\n                labels[:, 13] = np.array(x[:, 13] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 13] + pad[0]) + (np.array(x[:, 13] > 0, dtype=np.int32) - 1)\n                labels[:, 14] = np.array(x[:, 14] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 14] + pad[1]) + (np.array(x[:, 14] > 0, dtype=np.int32) - 1)\n        if self.augment:           <span style=\'color: red\'># Augment imagespace</span>\n            if not mosaic:\n                img, labels = <span style=\'color: green;font-weight: bold;\'>random_perspective</span>(img, labels,degrees=hyp[\'degrees\'],translate=hyp[\'translate\'],scale=hyp[\'scale\'],shear=hyp[\'shear\'],perspective=hyp[\'perspective\'])\n            augment_hsv(img, hgain=hyp[\'hsv_h\'], sgain=hyp[\'hsv_s\'], vgain=hyp[\'hsv_v\'])    <span style=\'color: red\'># Augment colorspace</span>\n        nL = len(labels)  <span style=\'color: red\'># number of labels</span>\n        if nL:\n            labels[:, 1:5] = xyxy2xywh(labels[:, 1:5])    <span style=\'color: red\'># convert xyxy to xywh</span>\n            labels[:, [2, 4]] /= img.shape[0]             <span style=\'color: red\'># normalized height 0-1         归一化到0-1</span>\n            labels[:, [1, 3]] /= img.shape[1]             <span style=\'color: red\'># normalized width 0-1</span>\n            labels[:, [5, 7, 9, 11, 13]] /= img.shape[1]  <span style=\'color: red\'># normalized landmark x 0-1</span>\n            labels[:, [5, 7, 9, 11, 13]] = np.where(labels[:, [5, 7, 9, 11, 13]] < 0, -1, labels[:, [5, 7, 9, 11, 13]])\n            labels[:, [6, 8, 10, 12, 14]] /= img.shape[0] <span style=\'color: red\'># normalized landmark y 0-1</span>\n            labels[:, [6, 8, 10, 12, 14]] = np.where(labels[:, [6, 8, 10, 12, 14]] < 0, -1, labels[:, [6, 8, 10, 12, 14]])\n        if self.augment:\n            if random.random() < hyp[\'fliplr\']:\n                img = np.fliplr(img)\n                if nL:\n                    labels[:, 1] = 1 - labels[:, 1]\n                    labels[:, 5] = np.where(labels[:, 5] < 0, -1, 1 - labels[:, 5])\n                    labels[:, 7] = np.where(labels[:, 7] < 0, -1, 1 - labels[:, 7])\n                    labels[:, 9] = np.where(labels[:, 9] < 0, -1, 1 - labels[:, 9])\n                    labels[:, 11] = np.where(labels[:, 11] < 0, -1, 1 - labels[:, 11])\n                    labels[:, 13] = np.where(labels[:, 13] < 0, -1, 1 - labels[:, 13])\n                    eye_left = np.copy(labels[:, [5, 6]])       <span style=\'color: red\'># 左右镜像的时候，左眼、右眼，\u3000左嘴角、右嘴角无法区分, 应该交换位置，便于网络学习</span>\n                    mouth_left = np.copy(labels[:, [11, 12]])\n                    labels[:, [5, 6]] = labels[:, [7, 8]]\n                    labels[:, [7, 8]] = eye_left\n                    labels[:, [11, 12]] = labels[:, [13, 14]]\n                    labels[:, [13, 14]] = mouth_left\n        labels_out = torch.zeros((nL, 16))\n        if nL:\n            labels_out[:, 1:] = torch.from_numpy(labels)\n        img = img[:, :, ::-1].transpose(2, 0, 1)  <span style=\'color: red\'># BGR to RGB, to 3x416x416</span>\n        img = np.ascontiguousarray(img)\n        return torch.from_numpy(img), labels_out, self.img_files[index], shapes\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><font size="0"><pre class="language-python"><code class="language-python">def load_mosaic_face(self, index):\n    labels4 = []\n    s = self.img_size                                                                    <span style=\'color: red\'># 先建立一个大图，(<span style=\'color: green;font-weight: bold;\'>2*s</span>，<span style=\'color: green;font-weight: bold;\'>2*s</span>)</span>\n    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]            <span style=\'color: red\'># mosaic center x, y</span>\n    indices = [index] + [self.indices[random.randint(0, self.n - 1)] for _ in range(3)]  <span style=\'color: red\'># 3 additional image indices</span>\n    for i, index in enumerate(indices):\n        img, _, (h, w) = load_image(self, index)                               <span style=\'color: red\'># Load image            place img in img4</span>\n        if i == 0:    <span style=\'color: red\'># top left</span>\n            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  <span style=\'color: red\'># base image with 4 tiles</span>\n            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc        <span style=\'color: red\'># xmin, ymin, xmax, ymax (large image)</span>\n            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h        <span style=\'color: red\'># xmin, ymin, xmax, ymax (small image)</span>\n        elif i == 1:  <span style=\'color: red\'># top right</span>\n            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n        elif i == 2:  <span style=\'color: red\'># bottom left</span>\n            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)\n        elif i == 3:  <span style=\'color: red\'># bottom right</span>\n            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  <span style=\'color: red\'># img4[ymin:ymax, xmin:xmax]  y1a:y2a,x1a:x2a是在大图的位置，y1b:y2b, x1b:x2b小图位置</span>\n        padw = x1a - x1b                                <span style=\'color: red\'># padw<span style=\'color: green;font-weight: bold;\'>></span>0说明x方向没被切，padh<span style=\'color: green;font-weight: bold;\'><</span>0说明x方向被切</span>\n        padh = y1a - y1b\n        x = self.labels[index]\n        labels = x.copy()\n        if x.size > 0:  <span style=\'color: red\'># Normalized xywh to pixel xyxy format</span>\n            labels[:, 1] = w * (x[:, 1] - x[:, 3] / 2) + padw      <span style=\'color: red\'># box, x1,y1,x2,y2</span>\n            labels[:, 2] = h * (x[:, 2] - x[:, 4] / 2) + padh\n            labels[:, 3] = w * (x[:, 1] + x[:, 3] / 2) + padw\n            labels[:, 4] = h * (x[:, 2] + x[:, 4] / 2) + padh\n            labels[:, 5] = np.array(x[:, 5] > 0, dtype=np.int32) * (w * x[:, 5] + padw) + (np.array(x[:, 5] > 0, dtype=np.int32) - 1)  <span style=\'color: red\'># 10 landmarks</span>\n            labels[:, 6] = np.array(x[:, 6] > 0, dtype=np.int32) * (h * x[:, 6] + padh) + (np.array(x[:, 6] > 0, dtype=np.int32) - 1)  <span style=\'color: red\'># 相当于遮挡的为-1没遮挡的都会计算</span>\n            labels[:, 7] = np.array(x[:, 7] > 0, dtype=np.int32) * (w * x[:, 7] + padw) + (np.array(x[:, 7] > 0, dtype=np.int32) - 1)\n            labels[:, 8] = np.array(x[:, 8] > 0, dtype=np.int32) * (h * x[:, 8] + padh) + (np.array(x[:, 8] > 0, dtype=np.int32) - 1)\n            labels[:, 9] = np.array(x[:, 9] > 0, dtype=np.int32) * (w * x[:, 9] + padw) + (np.array(x[:, 9] > 0, dtype=np.int32) - 1)\n            labels[:, 10] = np.array(x[:, 10] > 0, dtype=np.int32) * (h * x[:, 10] + padh) + (np.array(x[:, 10] > 0, dtype=np.int32) - 1)\n            labels[:, 11] = np.array(x[:, 11] > 0, dtype=np.int32) * (w * x[:, 11] + padw) + (np.array(x[:, 11] > 0, dtype=np.int32) - 1)\n            labels[:, 12] = np.array(x[:, 12] > 0, dtype=np.int32) * (h * x[:, 12] + padh) + (np.array(x[:, 12] > 0, dtype=np.int32) - 1)\n            labels[:, 13] = np.array(x[:, 13] > 0, dtype=np.int32) * (w * x[:, 13] + padw) + (np.array(x[:, 13] > 0, dtype=np.int32) - 1)\n            labels[:, 14] = np.array(x[:, 14] > 0, dtype=np.int32) * (h * x[:, 14] + padh) + (np.array(x[:, 14] > 0, dtype=np.int32) - 1)\n        labels4.append(labels)\n    if len(labels4):                                                         <span style=\'color: red\'># Concat/clip labels</span>\n        labels4 = np.concatenate(labels4, 0)\n        np.clip(labels4[:, 1:5], 0, 2 * s, out=labels4[:, 1:5])              <span style=\'color: red\'># use with random_perspective</span>\n        labels4[:, 5:] = np.where(labels4[:, 5:] < 0, -1, labels4[:, 5:])    <span style=\'color: red\'># landmarks</span>\n        labels4[:, 5:] = np.where(labels4[:, 5:] > 2 * s, -1, labels4[:, 5:])\n        labels4[:, 5] = np.where(labels4[:, 6] == -1, -1, labels4[:, 5])\n        labels4[:, 6] = np.where(labels4[:, 5] == -1, -1, labels4[:, 6])\n        labels4[:, 7] = np.where(labels4[:, 8] == -1, -1, labels4[:, 7])\n        labels4[:, 8] = np.where(labels4[:, 7] == -1, -1, labels4[:, 8])\n        labels4[:, 9] = np.where(labels4[:, 10] == -1, -1, labels4[:, 9])\n        labels4[:, 10] = np.where(labels4[:, 9] == -1, -1, labels4[:, 10])\n        labels4[:, 11] = np.where(labels4[:, 12] == -1, -1, labels4[:, 11])\n        labels4[:, 12] = np.where(labels4[:, 11] == -1, -1, labels4[:, 12])\n        labels4[:, 13] = np.where(labels4[:, 14] == -1, -1, labels4[:, 13])\n        labels4[:, 14] = np.where(labels4[:, 13] == -1, -1, labels4[:, 14])\n    img4, labels4 = random_perspective(img4, labels4,degrees=self.hyp[\'degrees\'],translate=self.hyp[\'translate\'],scale=self.hyp[\'scale\'],  <span style=\'color: red\'># Augment</span>\n                                       shear=self.hyp[\'shear\'],perspective=self.hyp[\'perspective\'],border=self.mosaic_border)              <span style=\'color: red\'># border to remove</span>\n    return img4, labels4\n</code></pre></font>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><font size="0"><pre class="language-python"><code class="language-python">def random_perspective(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0, border=(0, 0)):\n    height = img.shape[0] + border[0] * 2  <span style=\'color: red\'># shape(h,w,c)</span>\n    width = img.shape[1] + border[1] * 2\n    C = np.eye(3)                <span style=\'color: red\'># Center</span>\n    C[0, 2] = -img.shape[1] / 2  <span style=\'color: red\'># x translation (pixels)</span>\n    C[1, 2] = -img.shape[0] / 2  <span style=\'color: red\'># y translation (pixels)</span>\n    P = np.eye(3)                <span style=\'color: red\'># Perspective</span>\n    P[2, 0] = random.uniform(-perspective, perspective)  <span style=\'color: red\'># x perspective (about y)</span>\n    P[2, 1] = random.uniform(-perspective, perspective)  <span style=\'color: red\'># y perspective (about x)</span>\n    R = np.eye(3)                          <span style=\'color: red\'># Rotation and Scale</span>\n    a = random.uniform(-degrees, degrees)\n    s = random.uniform(1 - scale, 1 + scale)\n    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)\n    S = np.eye(3)                          <span style=\'color: red\'># Shear</span>\n    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  <span style=\'color: red\'># x shear (deg)</span>\n    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  <span style=\'color: red\'># y shear (deg)</span>\n    T = np.eye(3)                <span style=\'color: red\'># Translation</span>\n    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  <span style=\'color: red\'># x translation (pixels)</span>\n    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  <span style=\'color: red\'># y translation (pixels)</span>\n    <span style=\'color: red\'># Combined rotation matrix</span>\n    M = T @ S @ R @ P @ C        <span style=\'color: red\'># order of operations (right to left) is IMPORTANT</span>\n    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  <span style=\'color: red\'># image changed</span>\n        if perspective:\n            img = cv2.warpPerspective(img, M, dsize=(width, height), borderValue=(114, 114, 114))\n        else:                    <span style=\'color: red\'># affine</span>\n            img = cv2.warpAffine(img, M[:2], dsize=(width, height), borderValue=(114, 114, 114))\n    <span style=\'color: red\'># Visualize</span>\n    <span style=\'color: red\'># import matplotlib.pyplot as plt</span>\n    <span style=\'color: red\'># ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()</span>\n    <span style=\'color: red\'># ax[0].imshow(img[:, :, ::-1])  </span>\n    <span style=\'color: red\'># ax[1].imshow(img2[:, :, ::-1]) </span>\n    n = len(targets)               <span style=\'color: red\'># Transform label coordinates</span>\n    if n:\n        xy = np.ones((n * 9, 3))   <span style=\'color: red\'># xy = np.ones((n * 4, 3))   多5个关键点</span>\n        xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]].reshape(n * 9, 2)  <span style=\'color: red\'># x1y1, x2y2, x1y2, x2y1</span>\n        xy = xy @ M.T              <span style=\'color: red\'># transform   <span style=\'color: green;font-weight: bold;\'>1,2,3,4,1,4,3,2</span>表示x1y1,x2y2,x1y2,x2y1;<span style=\'color: green;font-weight: bold;\'>5,6,7,8,9,10,11,12,13,14</span>表示5个点xp1yp1,xp2yp2,xp3yp3,xp4yp4,xp5yp5</span>\n        if perspective:\n            xy = (xy[:, :2] / xy[:, 2:3]).reshape(n, 18)  <span style=\'color: red\'># rescale   .reshape(n, 18)中18表示9个点</span>\n        else:                                             <span style=\'color: red\'># affine</span>\n            xy = xy[:, :2].reshape(n, 18)\n        x = xy[:, [0, 2, 4, 6]]    <span style=\'color: red\'># create new boxes</span>\n        y = xy[:, [1, 3, 5, 7]]\n        landmarks = xy[:, [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n        mask = np.array(targets[:, 5:] > 0, dtype=np.int32)\n        landmarks = landmarks * mask\n        landmarks = landmarks + mask - 1\n        landmarks = np.where(landmarks < 0, -1, landmarks)\n        landmarks[:, [0, 2, 4, 6, 8]] = np.where(landmarks[:, [0, 2, 4, 6, 8]] > width, -1, landmarks[:, [0, 2, 4, 6, 8]])\n        landmarks[:, [1, 3, 5, 7, 9]] = np.where(landmarks[:, [1, 3, 5, 7, 9]] > height, -1,landmarks[:, [1, 3, 5, 7, 9]])\n        landmarks[:, 0] = np.where(landmarks[:, 1] == -1, -1, landmarks[:, 0])   <span style=\'color: red\'># landmarks的操作是只要其中一个点的x出去了，点的y也变成-1</span>\n        landmarks[:, 1] = np.where(landmarks[:, 0] == -1, -1, landmarks[:, 1])\n        landmarks[:, 2] = np.where(landmarks[:, 3] == -1, -1, landmarks[:, 2])\n        landmarks[:, 3] = np.where(landmarks[:, 2] == -1, -1, landmarks[:, 3])\n        landmarks[:, 4] = np.where(landmarks[:, 5] == -1, -1, landmarks[:, 4])\n        landmarks[:, 5] = np.where(landmarks[:, 4] == -1, -1, landmarks[:, 5])\n        landmarks[:, 6] = np.where(landmarks[:, 7] == -1, -1, landmarks[:, 6])\n        landmarks[:, 7] = np.where(landmarks[:, 6] == -1, -1, landmarks[:, 7])\n        landmarks[:, 8] = np.where(landmarks[:, 9] == -1, -1, landmarks[:, 8])\n        landmarks[:, 9] = np.where(landmarks[:, 8] == -1, -1, landmarks[:, 9])\n        targets[:,5:] = landmarks\n        xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n        xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)               <span style=\'color: red\'># clip boxes</span>\n        xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\n        i = box_candidates(box1=targets[:, 1:5].T * s, box2=xy.T)  <span style=\'color: red\'># filter candidates</span>\n        targets = targets[i]\n        targets[:, 1:5] = xy[i]\n    return img, targets\n</code></pre></font>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/loss.py</p><font size="0"><pre class="language-python"><code class="language-python">def compute_loss(p, targets, model):                      <span style=\'color: red\'>#  类别1人脸  其中0-3(xywh);4置信度；5-14 10个关键点x1y1->x5y5;15类别</span>\n    device = targets.device   <span style=\'color: red\'># p=>[torch.Size([16,3,100,100,16]), torch.Size([16,3,50,50,16]), torch.Size([16,3,25,25,16])]  16=4+1+10+1  </span>\n    lcls, lbox, lobj, lmark = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)\n    tcls, tbox, indices, anchors, tlandmarks, lmks_mask = <span style=\'color: green;font-weight: bold;\'>build_targets</span>(p, targets, model)    <span style=\'color: red\'># targets  多了tlandmarks和lmks_mask结果</span>\n    h = model.hyp                                         <span style=\'color: red\'># hyperparameters</span>\n    <span style=\'color: red\'># Define criteria</span>\n    BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[\'cls_pw\']], device=device))        <span style=\'color: red\'># weight=model.class_weights)</span>\n    BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[\'obj_pw\']], device=device))\n    landmarks_loss = LandmarksLoss(1.0)\n    cp, cn = smooth_BCE(eps=0.0)                          <span style=\'color: red\'># Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3</span>\n    g = h[\'fl_gamma\']                                     <span style=\'color: red\'># focal loss gamma</span>\n    if g > 0:\n        BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)\n    <span style=\'color: red\'># Losses</span>\n    nt = 0                                                          <span style=\'color: red\'># number of targets</span>\n    no = len(p)                                                     <span style=\'color: red\'># number of outputs</span>\n    balance = [4.0, 1.0, 0.4] if no == 3 else [4.0, 1.0, 0.4, 0.1]  <span style=\'color: red\'># P3-5 or P3-6</span>\n    for i, pi in enumerate(p):                                      <span style=\'color: red\'># layer index, layer predictions</span>\n        b, a, gj, gi = indices[i]                                   <span style=\'color: red\'># image, anchor, gridy, gridx</span>\n        tobj = torch.zeros_like(pi[..., 0], device=device)          <span style=\'color: red\'># target obj</span>\n        n = b.shape[0]                                              <span style=\'color: red\'># number of targets</span>\n        if n:\n            nt += n                                     <span style=\'color: red\'># cumulative targets</span>\n            ps = pi[b, a, gj, gi]                       <span style=\'color: red\'># prediction subset corresponding to targets</span>\n            <span style=\'color: red\'># Regression</span>\n            pxy = ps[:, :2].sigmoid() * 2. - 0.5\n            pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]\n            pbox = torch.cat((pxy, pwh), 1)             <span style=\'color: red\'># predicted box</span>\n            iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  <span style=\'color: red\'># iou(prediction, target)</span>\n            lbox += (1.0 - iou).mean()                  <span style=\'color: red\'># iou loss</span>\n            <span style=\'color: red\'># Objectness</span>\n            tobj[b, a, gj, gi] = (1.0 - model.gr) + model.gr * iou.detach().clamp(0).type(tobj.dtype)  <span style=\'color: red\'># iou ratio</span>\n            <span style=\'color: red\'># Classification</span>\n            if model.nc > 1:                            <span style=\'color: red\'># cls loss (only if multiple classes)</span>\n                t = torch.full_like(ps[:, 15:], cn, device=device)      <span style=\'color: red\'># targets</span>\n                t[range(n), tcls[i]] = cp\n                lcls += BCEcls(ps[:, 15:], t)           <span style=\'color: red\'># BCE</span>\n            <span style=\'color: red\'># landmarks loss</span>\n            <span style=\'color: red\'># plandmarks = ps[:,5:15].sigmoid() * 8. - 4.</span>\n            plandmarks = ps[:,5:15]\n            plandmarks[:, 0:2] = plandmarks[:, 0:2] * anchors[i]\n            plandmarks[:, 2:4] = plandmarks[:, 2:4] * anchors[i]\n            plandmarks[:, 4:6] = plandmarks[:, 4:6] * anchors[i]\n            plandmarks[:, 6:8] = plandmarks[:, 6:8] * anchors[i]\n            plandmarks[:, 8:10] = plandmarks[:,8:10] * anchors[i]\n            lmark += landmarks_loss(plandmarks, tlandmarks[i], lmks_mask[i])\n        lobj += BCEobj(pi[..., 4], tobj) * balance[i]  <span style=\'color: red\'># obj loss</span>\n    s = 3 / no                                         <span style=\'color: red\'># output count scaling</span>\n    lbox *= h[\'box\'] * s\n    lobj *= h[\'obj\'] * s * (1.4 if no == 4 else 1.)\n    lcls *= h[\'cls\'] * s\n    lmark *= h[\'landmark\'] * s\n    bs = tobj.shape[0]                                 <span style=\'color: red\'># batch size</span>\n    loss = lbox + lobj + lcls + lmark\n    return loss * bs, torch.cat((lbox, lobj, lcls, lmark, loss)).detach()\n</code></pre></font>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/loss.py：def build_targets</p><font size="0"><pre class="language-python"><code class="language-python">def build_targets(p, targets, model):                                        <span style=\'color: red\'># torch.Size([518, 16])</span>\n    det = model.module.model[-1] if is_parallel(model) else model.model[-1]  <span style=\'color: red\'># Detect() module</span>\n    na, nt = det.na, targets.shape[0]                                        <span style=\'color: red\'># number of anchors, targets   3,518</span>\n    tcls, tbox, indices, anch, landmarks, lmks_mask = [], [], [], [], [], []\n    gain = torch.ones(17, device=targets.device)                             <span style=\'color: red\'># 原先7对应(image,class,x,y,w,h)与合并的anchor，多了10</span>\n    ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  <span style=\'color: red\'># same as .repeat_interleave(nt)  ai=(3,518)</span>\n    targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)       <span style=\'color: red\'># append anchor indices  （3, 518, 17）</span>\n    g = 0.5                                                                  <span style=\'color: red\'># bias</span>\n    off = torch.tensor([[0, 0],\n                        [1, 0], [0, 1], [-1, 0], [0, -1],      <span style=\'color: red\'># j,k,l,m</span>\n                        <span style=\'color: red\'># [1, 1], [1, -1], [-1, 1], [-1, -1], </span>\n                        ], device=targets.device).float() * g  <span style=\'color: red\'># offsets</span>\n    for i in range(det.nl):\n        anchors = det.anchors[i]                            <span style=\'color: red\'># torch.Size([3, 2]),就是给3个长宽不一样的anchor</span>\n        gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  <span style=\'color: red\'># xyxy gain</span>\n        gain[6:16] = torch.tensor(p[i].shape)[[3, 2, 3, 2, 3, 2, 3, 2, 3, 2]]  <span style=\'color: red\'># xyxy gain   landmarks 10</span>\n        t = targets * gain                                  <span style=\'color: red\'># Match targets to anchors   将归一化的点恢复到feature map的大小  torch.Size([3, 518, 17])</span>\n        if nt:                                              <span style=\'color: red\'># Matches</span>\n            r = t[:, :, 4:6] / anchors[:, None]             <span style=\'color: red\'># wh ratio torch.Size([3, 518, 2]);有最大的宽或者高与anchor的宽高比小于4= model.hyp[\'anchor_t\']</span>\n            j = torch.max(r, 1. / r).max(2)[0] < model.hyp[\'anchor_t\']         <span style=\'color: red\'># compare</span>\n            <span style=\'color: red\'># j = wh_iou(anchors, t[:, 4:6]) > model.hyp[\'iou_t\'] </span>\n            t = t[j]                                        <span style=\'color: red\'># filter             t->torch.Size([3, 518, 17])->t为torch.Size([1303, 17])匹配上的</span>\n            <span style=\'color: red\'># Offsets</span>\n            gxy = t[:, 2:4]           <span style=\'color: red\'># grid xy             torch.Size([1303, 2]),假设第0个=(19.53795, 75.11905)</span>\n            gxi = gain[[2, 3]] - gxy  <span style=\'color: red\'># inverse             gxi第0个为（80.46205, 24.88095）</span>\n            j, k = ((gxy % 1. <span style=\'color: green;font-weight: bold;\'><</span> g) & (gxy <span style=\'color: green;font-weight: bold;\'>></span> 1.)).T          <span style=\'color: red\'># j,k,l,m为torch.Size([1303])的bool数据</span>\n            l, m = ((gxi % 1. <span style=\'color: green;font-weight: bold;\'><</span> g) & (gxi <span style=\'color: green;font-weight: bold;\'>></span> 1.)).T\n            j = torch.stack((torch.ones_like(j), j, k, l, m))  <span style=\'color: red\'># j.shape=torch.Size([5, 1303])   该点的响应，上下左右响应</span>\n            t = t.repeat((5, 1, 1))[j]                         <span style=\'color: red\'># t.repeat((5, 1, 1))=(5,1303,17)->t.shape=torch.Size([3903, 17])</span>\n            offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]\n        else:\n            t = targets[0]\n            offsets = 0\n        <span style=\'color: red\'># Define</span>\n        b, c = t[:, :2].long().T  <span style=\'color: red\'># image, class</span>\n        gxy = t[:, 2:4]           <span style=\'color: red\'># grid xy</span>\n        gwh = t[:, 4:6]           <span style=\'color: red\'># grid wh</span>\n        gij = (gxy - offsets).long()\n        gi, gj = gij.T            <span style=\'color: red\'># grid xy indices</span>\n        <span style=\'color: red\'># Append</span>\n        a = t[:, 16].long()       <span style=\'color: red\'># anchor indices</span>\n        indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  <span style=\'color: red\'># image, anchor, grid indices</span>\n        tbox.append(torch.cat((gxy - gij, gwh), 1))  <span style=\'color: red\'># box</span>\n        anch.append(anchors[a])  <span style=\'color: red\'># anchors</span>\n        tcls.append(c)           <span style=\'color: red\'># class</span>\n        <span style=\'color: red\'># landmarks</span>\n        lks = t[:,6:16]          <span style=\'color: red\'># 关键点lks.shape=torch.Size([3903, 10])</span>\n        <span style=\'color: red\'># lks_mask = lks > 0</span>\n        <span style=\'color: red\'># lks_mask = lks_mask.float()</span>\n        lks_mask = torch.where(lks < 0, torch.full_like(lks, 0.), torch.full_like(lks, 1.0))\n        <span style=\'color: red\'># 应该是关键点的坐标除以anch的宽高才对，便于模型学习。使用gwh会导致不同关键点的编码不同，没有统一的参考标准</span>\n        lks[:, [0, 1]] = (lks[:, [0, 1]] - gij)\n        lks[:, [2, 3]] = (lks[:, [2, 3]] - gij)\n        lks[:, [4, 5]] = (lks[:, [4, 5]] - gij)\n        lks[:, [6, 7]] = (lks[:, [6, 7]] - gij)\n        lks[:, [8, 9]] = (lks[:, [8, 9]] - gij)\n        lks_mask_new = lks_mask\n        lmks_mask.append(lks_mask_new)\n        landmarks.append(lks)\n    return tcls, tbox, indices, anch, landmarks, lmks_mask\n</code></pre></font>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/loss.py</p>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">anchor</p>'}]})</script></body>
</html>
