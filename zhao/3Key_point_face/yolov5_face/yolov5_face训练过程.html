<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>yolov5_face训练过程</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.hidden-code {
  display: none !important;
}
</style>
<link rel="stylesheet" href="https://study1994.github.io/study_html/npm/mycss/style.css">
</head>
<body>
    <svg id="mindmap"></svg>
    <script src="https://study1994.github.io/study_html/npm/myjs/d3@6.7.0.js"></script>
    <script src="https://study1994.github.io/study_html/npm/myjs/markmap-view@0.13.5.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        (r => {
            setTimeout(r);
        })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{'type': 'root', 'depth': 0, 'content': '', 'children': [{'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">数据处理</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><span class=\'hidden-code\' data-code=\'class LoadFaceImagesAndLabels(Dataset):  # for training/testing\n    def __init__(self,......):\n        ...\n        self.img_files = list(cache.keys())               # len(self.img_files)=12880\n        self.label_files = img2label_paths(cache.keys())  # self.img_files[0]=&amp;#39;....../widerface/train/0_Parade_Parade_0_1014.jpg&amp;#39;\n        ...\n\'> </span>'}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><span class=\'hidden-code\' data-code=\'class LoadFaceImagesAndLabels(Dataset):\n    def __getitem__(self, index):\n        index = self.indices[index]  # linear, shuffled, or image_weights\n         hyp = self.hyp\n        mosaic = self.mosaic and random.random() < hyp[&amp;#39;mosaic&amp;#39;]\n        if mosaic:\n            img, labels = `load_mosaic_face`(self, index)\n            shapes = None\n        else:\n            img, (h0, w0), (h, w) = load_image(self, index)\n            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape\n            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n            shapes = (h0, w0), ((h / h0, w / w0), pad)                                    # for COCO mAP rescaling\n            labels = []                       # Load labels\n            x = self.labels[index]\n            if x.size > 0:                    # Normalized xywh to pixel xyxy format\n                labels = x.copy()\n                labels[:, 1] = ratio[0] * w * (x[:, 1] - x[:, 3] / 2) + pad[0]  # pad width\n                labels[:, 2] = ratio[1] * h * (x[:, 2] - x[:, 4] / 2) + pad[1]  # pad height\n                labels[:, 3] = ratio[0] * w * (x[:, 1] + x[:, 3] / 2) + pad[0]\n                labels[:, 4] = ratio[1] * h * (x[:, 2] + x[:, 4] / 2) + pad[1]\n                labels[:, 5] = np.array(x[:, 5] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 5] + pad[0]) + (np.array(x[:, 5] > 0, dtype=np.int32) - 1)\n                labels[:, 6] = np.array(x[:, 6] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 6] + pad[1]) + (np.array(x[:, 6] > 0, dtype=np.int32) - 1)\n                labels[:, 7] = np.array(x[:, 7] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 7] + pad[0]) + (np.array(x[:, 7] > 0, dtype=np.int32) - 1)\n                labels[:, 8] = np.array(x[:, 8] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 8] + pad[1]) + (np.array(x[:, 8] > 0, dtype=np.int32) - 1)\n                labels[:, 9] = np.array(x[:, 5] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 9] + pad[0]) + (np.array(x[:, 9] > 0, dtype=np.int32) - 1)\n                labels[:, 10] = np.array(x[:, 5] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 10] + pad[1]) + (np.array(x[:, 10] > 0, dtype=np.int32) - 1)\n                labels[:, 11] = np.array(x[:, 11] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 11] + pad[0]) + (np.array(x[:, 11] > 0, dtype=np.int32) - 1)\n                labels[:, 12] = np.array(x[:, 12] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 12] + pad[1]) + (np.array(x[:, 12] > 0, dtype=np.int32) - 1)\n                labels[:, 13] = np.array(x[:, 13] > 0, dtype=np.int32) * (ratio[0] * w * x[:, 13] + pad[0]) + (np.array(x[:, 13] > 0, dtype=np.int32) - 1)\n                labels[:, 14] = np.array(x[:, 14] > 0, dtype=np.int32) * (ratio[1] * h * x[:, 14] + pad[1]) + (np.array(x[:, 14] > 0, dtype=np.int32) - 1)\n        if self.augment:           # Augment imagespace\n            if not mosaic:\n                img, labels = `random_perspective`(img, labels,degrees=hyp[&amp;#39;degrees&amp;#39;],translate=hyp[&amp;#39;translate&amp;#39;],scale=hyp[&amp;#39;scale&amp;#39;],shear=hyp[&amp;#39;shear&amp;#39;],perspective=hyp[&amp;#39;perspective&amp;#39;])\n            augment_hsv(img, hgain=hyp[&amp;#39;hsv_h&amp;#39;], sgain=hyp[&amp;#39;hsv_s&amp;#39;], vgain=hyp[&amp;#39;hsv_v&amp;#39;])    # Augment colorspace\n        nL = len(labels)  # number of labels\n        if nL:\n            labels[:, 1:5] = xyxy2xywh(labels[:, 1:5])    # convert xyxy to xywh\n            labels[:, [2, 4]] /= img.shape[0]             # normalized height 0-1         归一化到0-1\n            labels[:, [1, 3]] /= img.shape[1]             # normalized width 0-1\n            labels[:, [5, 7, 9, 11, 13]] /= img.shape[1]  # normalized landmark x 0-1\n            labels[:, [5, 7, 9, 11, 13]] = np.where(labels[:, [5, 7, 9, 11, 13]] < 0, -1, labels[:, [5, 7, 9, 11, 13]])\n            labels[:, [6, 8, 10, 12, 14]] /= img.shape[0] # normalized landmark y 0-1\n            labels[:, [6, 8, 10, 12, 14]] = np.where(labels[:, [6, 8, 10, 12, 14]] < 0, -1, labels[:, [6, 8, 10, 12, 14]])\n        if self.augment:\n            if random.random() < hyp[&amp;#39;fliplr&amp;#39;]:\n                img = np.fliplr(img)\n                if nL:\n                    labels[:, 1] = 1 - labels[:, 1]\n                    labels[:, 5] = np.where(labels[:, 5] < 0, -1, 1 - labels[:, 5])\n                    labels[:, 7] = np.where(labels[:, 7] < 0, -1, 1 - labels[:, 7])\n                    labels[:, 9] = np.where(labels[:, 9] < 0, -1, 1 - labels[:, 9])\n                    labels[:, 11] = np.where(labels[:, 11] < 0, -1, 1 - labels[:, 11])\n                    labels[:, 13] = np.where(labels[:, 13] < 0, -1, 1 - labels[:, 13])\n                    eye_left = np.copy(labels[:, [5, 6]])       # 左右镜像的时候，左眼、右眼，\u3000左嘴角、右嘴角无法区分, 应该交换位置，便于网络学习\n                    mouth_left = np.copy(labels[:, [11, 12]])\n                    labels[:, [5, 6]] = labels[:, [7, 8]]\n                    labels[:, [7, 8]] = eye_left\n                    labels[:, [11, 12]] = labels[:, [13, 14]]\n                    labels[:, [13, 14]] = mouth_left\n        labels_out = torch.zeros((nL, 16))\n        if nL:\n            labels_out[:, 1:] = torch.from_numpy(labels)\n        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n        img = np.ascontiguousarray(img)\n        return torch.from_numpy(img), labels_out, self.img_files[index], shapes\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><span class=\'hidden-code\' data-code=\'def load_mosaic_face(self, index):\n    labels4 = []\n    s = self.img_size                                                                    # 先建立一个大图，(`2*s`，`2*s`)\n    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]            # mosaic center x, y\n    indices = [index] + [self.indices[random.randint(0, self.n - 1)] for _ in range(3)]  # 3 additional image indices\n    for i, index in enumerate(indices):\n        img, _, (h, w) = load_image(self, index)                               # Load image            place img in img4\n        if i == 0:    # top left\n            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles\n            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc        # xmin, ymin, xmax, ymax (large image)\n            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h        # xmin, ymin, xmax, ymax (small image)\n        elif i == 1:  # top right\n            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n        elif i == 2:  # bottom left\n            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)\n        elif i == 3:  # bottom right\n            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]  y1a:y2a,x1a:x2a是在大图的位置，y1b:y2b, x1b:x2b小图位置\n        padw = x1a - x1b                                # padw`>`0说明x方向没被切，padh`<`0说明x方向被切\n        padh = y1a - y1b\n        x = self.labels[index]\n        labels = x.copy()\n        if x.size > 0:  # Normalized xywh to pixel xyxy format\n            labels[:, 1] = w * (x[:, 1] - x[:, 3] / 2) + padw      # box, x1,y1,x2,y2\n            labels[:, 2] = h * (x[:, 2] - x[:, 4] / 2) + padh\n            labels[:, 3] = w * (x[:, 1] + x[:, 3] / 2) + padw\n            labels[:, 4] = h * (x[:, 2] + x[:, 4] / 2) + padh\n            labels[:, 5] = np.array(x[:, 5] > 0, dtype=np.int32) * (w * x[:, 5] + padw) + (np.array(x[:, 5] > 0, dtype=np.int32) - 1)  # 10 landmarks\n            labels[:, 6] = np.array(x[:, 6] > 0, dtype=np.int32) * (h * x[:, 6] + padh) + (np.array(x[:, 6] > 0, dtype=np.int32) - 1)  # 相当于遮挡的为-1没遮挡的都会计算\n            labels[:, 7] = np.array(x[:, 7] > 0, dtype=np.int32) * (w * x[:, 7] + padw) + (np.array(x[:, 7] > 0, dtype=np.int32) - 1)\n            labels[:, 8] = np.array(x[:, 8] > 0, dtype=np.int32) * (h * x[:, 8] + padh) + (np.array(x[:, 8] > 0, dtype=np.int32) - 1)\n            labels[:, 9] = np.array(x[:, 9] > 0, dtype=np.int32) * (w * x[:, 9] + padw) + (np.array(x[:, 9] > 0, dtype=np.int32) - 1)\n            labels[:, 10] = np.array(x[:, 10] > 0, dtype=np.int32) * (h * x[:, 10] + padh) + (np.array(x[:, 10] > 0, dtype=np.int32) - 1)\n            labels[:, 11] = np.array(x[:, 11] > 0, dtype=np.int32) * (w * x[:, 11] + padw) + (np.array(x[:, 11] > 0, dtype=np.int32) - 1)\n            labels[:, 12] = np.array(x[:, 12] > 0, dtype=np.int32) * (h * x[:, 12] + padh) + (np.array(x[:, 12] > 0, dtype=np.int32) - 1)\n            labels[:, 13] = np.array(x[:, 13] > 0, dtype=np.int32) * (w * x[:, 13] + padw) + (np.array(x[:, 13] > 0, dtype=np.int32) - 1)\n            labels[:, 14] = np.array(x[:, 14] > 0, dtype=np.int32) * (h * x[:, 14] + padh) + (np.array(x[:, 14] > 0, dtype=np.int32) - 1)\n        labels4.append(labels)\n    if len(labels4):                                                         # Concat/clip labels\n        labels4 = np.concatenate(labels4, 0)\n        np.clip(labels4[:, 1:5], 0, 2 * s, out=labels4[:, 1:5])              # use with random_perspective\n        labels4[:, 5:] = np.where(labels4[:, 5:] < 0, -1, labels4[:, 5:])    # landmarks\n        labels4[:, 5:] = np.where(labels4[:, 5:] > 2 * s, -1, labels4[:, 5:])\n        labels4[:, 5] = np.where(labels4[:, 6] == -1, -1, labels4[:, 5])\n        labels4[:, 6] = np.where(labels4[:, 5] == -1, -1, labels4[:, 6])\n        labels4[:, 7] = np.where(labels4[:, 8] == -1, -1, labels4[:, 7])\n        labels4[:, 8] = np.where(labels4[:, 7] == -1, -1, labels4[:, 8])\n        labels4[:, 9] = np.where(labels4[:, 10] == -1, -1, labels4[:, 9])\n        labels4[:, 10] = np.where(labels4[:, 9] == -1, -1, labels4[:, 10])\n        labels4[:, 11] = np.where(labels4[:, 12] == -1, -1, labels4[:, 11])\n        labels4[:, 12] = np.where(labels4[:, 11] == -1, -1, labels4[:, 12])\n        labels4[:, 13] = np.where(labels4[:, 14] == -1, -1, labels4[:, 13])\n        labels4[:, 14] = np.where(labels4[:, 13] == -1, -1, labels4[:, 14])\n    img4, labels4 = random_perspective(img4, labels4,degrees=self.hyp[&amp;#39;degrees&amp;#39;],translate=self.hyp[&amp;#39;translate&amp;#39;],scale=self.hyp[&amp;#39;scale&amp;#39;],  # Augment\n                                       shear=self.hyp[&amp;#39;shear&amp;#39;],perspective=self.hyp[&amp;#39;perspective&amp;#39;],border=self.mosaic_border)              # border to remove\n    return img4, labels4\n\'> </span>'}, {'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/face_datasets.py</p><span class=\'hidden-code\' data-code=\'def random_perspective(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0, border=(0, 0)):\n    height = img.shape[0] + border[0] * 2  # shape(h,w,c)\n    width = img.shape[1] + border[1] * 2\n    C = np.eye(3)                # Center\n    C[0, 2] = -img.shape[1] / 2  # x translation (pixels)\n    C[1, 2] = -img.shape[0] / 2  # y translation (pixels)\n    P = np.eye(3)                # Perspective\n    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)\n    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)\n    R = np.eye(3)                          # Rotation and Scale\n    a = random.uniform(-degrees, degrees)\n    s = random.uniform(1 - scale, 1 + scale)\n    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)\n    S = np.eye(3)                          # Shear\n    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)\n    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)\n    T = np.eye(3)                # Translation\n    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation (pixels)\n    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation (pixels)\n    # Combined rotation matrix\n    M = T @ S @ R @ P @ C        # order of operations (right to left) is IMPORTANT\n    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed\n        if perspective:\n            img = cv2.warpPerspective(img, M, dsize=(width, height), borderValue=(114, 114, 114))\n        else:                    # affine\n            img = cv2.warpAffine(img, M[:2], dsize=(width, height), borderValue=(114, 114, 114))\n    # Visualize\n    # import matplotlib.pyplot as plt\n    # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()\n    # ax[0].imshow(img[:, :, ::-1])   # base\n    # ax[1].imshow(img2[:, :, ::-1])  # warped\n    n = len(targets)               # Transform label coordinates\n    if n:\n        xy = np.ones((n * 9, 3))   # xy = np.ones((n * 4, 3))   多5个关键点\n        xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]].reshape(n * 9, 2)  # x1y1, x2y2, x1y2, x2y1\n        xy = xy @ M.T              # transform   `1,2,3,4,1,4,3,2`表示x1y1,x2y2,x1y2,x2y1;`5,6,7,8,9,10,11,12,13,14`表示5个点xp1yp1,xp2yp2,xp3yp3,xp4yp4,xp5yp5\n        if perspective:\n            xy = (xy[:, :2] / xy[:, 2:3]).reshape(n, 18)  # rescale   .reshape(n, 18)中18表示9个点\n        else:                                             # affine\n            xy = xy[:, :2].reshape(n, 18)\n        x = xy[:, [0, 2, 4, 6]]    # create new boxes\n        y = xy[:, [1, 3, 5, 7]]\n        landmarks = xy[:, [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n        mask = np.array(targets[:, 5:] > 0, dtype=np.int32)\n        landmarks = landmarks * mask\n        landmarks = landmarks + mask - 1\n        landmarks = np.where(landmarks < 0, -1, landmarks)\n        landmarks[:, [0, 2, 4, 6, 8]] = np.where(landmarks[:, [0, 2, 4, 6, 8]] > width, -1, landmarks[:, [0, 2, 4, 6, 8]])\n        landmarks[:, [1, 3, 5, 7, 9]] = np.where(landmarks[:, [1, 3, 5, 7, 9]] > height, -1,landmarks[:, [1, 3, 5, 7, 9]])\n        landmarks[:, 0] = np.where(landmarks[:, 1] == -1, -1, landmarks[:, 0])   # landmarks的操作是只要其中一个点的x出去了，点的y也变成-1\n        landmarks[:, 1] = np.where(landmarks[:, 0] == -1, -1, landmarks[:, 1])\n        landmarks[:, 2] = np.where(landmarks[:, 3] == -1, -1, landmarks[:, 2])\n        landmarks[:, 3] = np.where(landmarks[:, 2] == -1, -1, landmarks[:, 3])\n        landmarks[:, 4] = np.where(landmarks[:, 5] == -1, -1, landmarks[:, 4])\n        landmarks[:, 5] = np.where(landmarks[:, 4] == -1, -1, landmarks[:, 5])\n        landmarks[:, 6] = np.where(landmarks[:, 7] == -1, -1, landmarks[:, 6])\n        landmarks[:, 7] = np.where(landmarks[:, 6] == -1, -1, landmarks[:, 7])\n        landmarks[:, 8] = np.where(landmarks[:, 9] == -1, -1, landmarks[:, 8])\n        landmarks[:, 9] = np.where(landmarks[:, 8] == -1, -1, landmarks[:, 9])\n        targets[:,5:] = landmarks\n        xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n        xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)               # clip boxes\n        xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\n        i = box_candidates(box1=targets[:, 1:5].T * s, box2=xy.T)  # filter candidates\n        targets = targets[i]\n        targets[:, 1:5] = xy[i]\n    return img, targets\n\'> </span>'}]}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">模型训练</p>', 'children': [{'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/loss.py</p><span class=\'hidden-code\' data-code=\'def compute_loss(p, targets, model):                      #  类别1人脸  其中0-3(xywh);4置信度；5-14 10个关键点x1y1->x5y5;15类别\n    device = targets.device   # p=>[torch.Size([16,3,100,100,16]), torch.Size([16,3,50,50,16]), torch.Size([16,3,25,25,16])]  16=4+1+10+1  \n    lcls, lbox, lobj, lmark = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)\n    tcls, tbox, indices, anchors, tlandmarks, lmks_mask = `build_targets`(p, targets, model)    # targets  多了tlandmarks和lmks_mask结果\n    h = model.hyp                                         # hyperparameters\n    # Define criteria\n    BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[&amp;#39;cls_pw&amp;#39;]], device=device))        # weight=model.class_weights)\n    BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[&amp;#39;obj_pw&amp;#39;]], device=device))\n    landmarks_loss = LandmarksLoss(1.0)\n    cp, cn = smooth_BCE(eps=0.0)                          # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3\n    g = h[&amp;#39;fl_gamma&amp;#39;]                                     # focal loss gamma\n    if g > 0:\n        BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)\n    # Losses\n    nt = 0                                                          # number of targets\n    no = len(p)                                                     # number of outputs\n    balance = [4.0, 1.0, 0.4] if no == 3 else [4.0, 1.0, 0.4, 0.1]  # P3-5 or P3-6\n    for i, pi in enumerate(p):                                      # layer index, layer predictions\n        b, a, gj, gi = indices[i]                                   # image, anchor, gridy, gridx\n        tobj = torch.zeros_like(pi[..., 0], device=device)          # target obj\n        n = b.shape[0]                                              # number of targets\n        if n:\n            nt += n                                     # cumulative targets\n            ps = pi[b, a, gj, gi]                       # prediction subset corresponding to targets\n            # Regression\n            pxy = ps[:, :2].sigmoid() * 2. - 0.5\n            pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]\n            pbox = torch.cat((pxy, pwh), 1)             # predicted box\n            iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # iou(prediction, target)\n            lbox += (1.0 - iou).mean()                  # iou loss\n            # Objectness\n            tobj[b, a, gj, gi] = (1.0 - model.gr) + model.gr * iou.detach().clamp(0).type(tobj.dtype)  # iou ratio\n            # Classification\n            if model.nc > 1:                            # cls loss (only if multiple classes)\n                t = torch.full_like(ps[:, 15:], cn, device=device)      # targets\n                t[range(n), tcls[i]] = cp\n                lcls += BCEcls(ps[:, 15:], t)           # BCE\n            # landmarks loss\n            # plandmarks = ps[:,5:15].sigmoid() * 8. - 4.\n            plandmarks = ps[:,5:15]\n            plandmarks[:, 0:2] = plandmarks[:, 0:2] * anchors[i]\n            plandmarks[:, 2:4] = plandmarks[:, 2:4] * anchors[i]\n            plandmarks[:, 4:6] = plandmarks[:, 4:6] * anchors[i]\n            plandmarks[:, 6:8] = plandmarks[:, 6:8] * anchors[i]\n            plandmarks[:, 8:10] = plandmarks[:,8:10] * anchors[i]\n            lmark += landmarks_loss(plandmarks, tlandmarks[i], lmks_mask[i])\n        lobj += BCEobj(pi[..., 4], tobj) * balance[i]  # obj loss\n    s = 3 / no                                         # output count scaling\n    lbox *= h[&amp;#39;box&amp;#39;] * s\n    lobj *= h[&amp;#39;obj&amp;#39;] * s * (1.4 if no == 4 else 1.)\n    lcls *= h[&amp;#39;cls&amp;#39;] * s\n    lmark *= h[&amp;#39;landmark&amp;#39;] * s\n    bs = tobj.shape[0]                                 # batch size\n    loss = lbox + lobj + lcls + lmark\n    return loss * bs, torch.cat((lbox, lobj, lcls, lmark, loss)).detach()\n\'> </span>', 'children': [{'type': 'heading', 'depth': 3, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/loss.py：def build_targets</p><span class=\'hidden-code\' data-code=\'def build_targets(p, targets, model):                                        # torch.Size([518, 16])\n    det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module\n    na, nt = det.na, targets.shape[0]                                        # number of anchors, targets   3,518\n    tcls, tbox, indices, anch, landmarks, lmks_mask = [], [], [], [], [], []\n    gain = torch.ones(17, device=targets.device)                             # 原先7对应(image,class,x,y,w,h)与合并的anchor，多了10\n    ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)  ai=(3,518)\n    targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)       # append anchor indices  （3, 518, 17）\n    g = 0.5                                                                  # bias\n    off = torch.tensor([[0, 0],\n                        [1, 0], [0, 1], [-1, 0], [0, -1],      # j,k,l,m\n                        # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm\n                        ], device=targets.device).float() * g  # offsets\n    for i in range(det.nl):\n        anchors = det.anchors[i]                            # torch.Size([3, 2]),就是给3个长宽不一样的anchor\n        gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain\n        gain[6:16] = torch.tensor(p[i].shape)[[3, 2, 3, 2, 3, 2, 3, 2, 3, 2]]  # xyxy gain   landmarks 10\n        t = targets * gain                                  # Match targets to anchors   将归一化的点恢复到feature map的大小  torch.Size([3, 518, 17])\n        if nt:                                              # Matches\n            r = t[:, :, 4:6] / anchors[:, None]             # wh ratio torch.Size([3, 518, 2]);有最大的宽或者高与anchor的宽高比小于4= model.hyp[&amp;#39;anchor_t&amp;#39;]\n            j = torch.max(r, 1. / r).max(2)[0] < model.hyp[&amp;#39;anchor_t&amp;#39;]         # compare\n            # j = wh_iou(anchors, t[:, 4:6]) > model.hyp[&amp;#39;iou_t&amp;#39;]  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))\n            t = t[j]                                        # filter             t->torch.Size([3, 518, 17])->t为torch.Size([1303, 17])匹配上的\n            # Offsets\n            gxy = t[:, 2:4]           # grid xy             torch.Size([1303, 2]),假设第0个=(19.53795, 75.11905)\n            gxi = gain[[2, 3]] - gxy  # inverse             gxi第0个为（80.46205, 24.88095）\n            j, k = ((gxy % 1. `<` g) &amp; (gxy `>` 1.)).T          # j,k,l,m为torch.Size([1303])的bool数据\n            l, m = ((gxi % 1. `<` g) &amp; (gxi `>` 1.)).T\n            j = torch.stack((torch.ones_like(j), j, k, l, m))  # j.shape=torch.Size([5, 1303])   该点的响应，上下左右响应\n            t = t.repeat((5, 1, 1))[j]                         # t.repeat((5, 1, 1))=(5,1303,17)->t.shape=torch.Size([3903, 17])\n            offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]\n        else:\n            t = targets[0]\n            offsets = 0\n        # Define\n        b, c = t[:, :2].long().T  # image, class\n        gxy = t[:, 2:4]           # grid xy\n        gwh = t[:, 4:6]           # grid wh\n        gij = (gxy - offsets).long()\n        gi, gj = gij.T            # grid xy indices\n        # Append\n        a = t[:, 16].long()       # anchor indices\n        indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # image, anchor, grid indices\n        tbox.append(torch.cat((gxy - gij, gwh), 1))  # box\n        anch.append(anchors[a])  # anchors\n        tcls.append(c)           # class\n        # landmarks\n        lks = t[:,6:16]          # 关键点lks.shape=torch.Size([3903, 10])\n        # lks_mask = lks > 0\n        # lks_mask = lks_mask.float()\n        lks_mask = torch.where(lks < 0, torch.full_like(lks, 0.), torch.full_like(lks, 1.0))\n        # 应该是关键点的坐标除以anch的宽高才对，便于模型学习。使用gwh会导致不同关键点的编码不同，没有统一的参考标准\n        lks[:, [0, 1]] = (lks[:, [0, 1]] - gij)\n        lks[:, [2, 3]] = (lks[:, [2, 3]] - gij)\n        lks[:, [4, 5]] = (lks[:, [4, 5]] - gij)\n        lks[:, [6, 7]] = (lks[:, [6, 7]] - gij)\n        lks[:, [8, 9]] = (lks[:, [8, 9]] - gij)\n        lks_mask_new = lks_mask\n        lmks_mask.append(lks_mask_new)\n        landmarks.append(lks)\n    return tcls, tbox, indices, anch, landmarks, lmks_mask\n\'> </span>'}]}, {'type': 'heading', 'depth': 2, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">utils/loss.py</p>'}]}, {'type': 'heading', 'depth': 1, 'payload': {'lines': [0, 1]}, 'content': '<p style="color: blue;font-weight: bold;">anchor</p>'}]})</script><script src='https://study1994.github.io/study_html/npm/myjs/tooltip.js'></script>
</body>
</html>
