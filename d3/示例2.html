<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <title>pnp_det损失计算过程</title>
  <style>
    * {
      margin: 0;
      padding: 0;
    }

    #mindmap {
      display: block;
      width: 100vw;
      height: 100vh;
    }

    .hidden-code {
      display: none !important;
    }
  </style>
  <link rel="stylesheet" href="./npm/mycss/prism.css" />
  <link rel="stylesheet" href="./npm/mycss/style.css" />
</head>

<body>
  <svg id="mindmap"></svg>
  <script src="./npm/myjs/d3@6.7.0.js"></script>
  <script src="./npm/myjs/markmap-view@0.13.5.js"></script>
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
  <script>
    ((r) => {
      setTimeout(r);
    })(() => {
      const { markmap, mm } = window;
      const toolbar = new markmap.Toolbar();
      toolbar.attach(mm);
      const el = toolbar.render();
      el.setAttribute("style", "position:absolute;bottom:20px;right:20px");
      document.body.append(el);
    });
  </script>
  <script>
    ((getMarkmap, getOptions, root, jsonOptions) => {
      const markmap = getMarkmap();
      window.mm = markmap.Markmap.create(
        "svg#mindmap",
        (getOptions || markmap.deriveOptions)(jsonOptions),
        root
      );
    })(() => window.markmap, null, {
      type: "root",
      depth: 0,
      content: "",
      children: [
        {
          type: "heading",
          depth: 1,
          payload: { lines: [0, 1] },
          content:
            `<p style="color: blue;font-weight: bold;">损失计算过程</p>`,
          children: [
            {
              type: "heading",
              depth: 2,
              payload: { lines: [0, 1] },
              content:
                `<p style="color: blue;font-weight: bold;">epropnp_det/models/dense_heads/deform_pnp_head.py</p><span class="hidden-code" data-code="class DeformPnPHead(BaseDenseHead):
        def forward_train(self,
                      mlvl_feats,                # [i.shape for i in mlvl_feats](1600, 900) = [torch.Size([6, 256, 84, 200])x8, torch.Size([6, 256, 42, 100])x16, torch.Size([6, 256, 21, 50])x32, torch.Size([6, 256, 11, 25])x64, torch.Size([6, 256, 6, 13])x128]
                      img_metas,                 # 6张图片[,,...],img_metas[0]['ori_shape']=(900, 1600, 3);img_metas[0]['img_shape']=(672, 1600, 3);img_metas[0]['pad_shape']=(672, 1600, 3);img_metas[0]['flip']=True;img_metas[0]['flip_direction']='horizontal'
                      gt_bboxes,                 # 6个2D box[,,...],gt_bboxes[0].shape=torch.Size([3, 4])
                      gt_labels=None,            # 6个2D box[,,...],gt_labels[0].shape=torch.Size([3])
                      gt_bboxes_ignore=None,     
                      gt_bboxes_3d=None,         # 6个3D box[,,...],gt_bboxes_3d[0].shape=torch.Size([3, 7])-->对着的是原始图片
                      gt_x3d=None,               # 6个 box第一个box有n个值，gt_x3d[0][0].shape=torch.Size([2, 3])；gt_x3d[0][1].shape=torch.Size([1, 3])；...；gt_x3d[0][n].shape=torch.Size([433, 3])；
                      gt_x2d=None,               # 6个 box第一个box有n个值，gt_x2d[0][0].shape=torch.Size([2, 2])；gt_x2d[0][1].shape=torch.Size([1, 2])；...；gt_x2d[0][n].shape=torch.Size([433, 2])；
                      gt_attr=None,
                      gt_velo=None,
                      img_dense_x2d=None,        # img_dense_x2d.shape=torch.Size([6, 2, 672, 1600])       # img_dense_x2d这个是一样的吗？每个
                      img_dense_x2d_mask=None,   # img_dense_x2d_mask.shape=torch.Size([6, 1, 672, 1600])
                      cam_intrinsic=None):       # cam_intrinsic[0].shape=torch.Size([3, 3])
        # ===== prepare img metas and g.t. =====
"> </span>`,
              children: [
                {
                  type: "heading",
                  depth: 3,
                  payload: { lines: [0, 1] },
                  content:
                    `<p style="color: blue;font-weight: bold;">epropnp_det/core/bbox_3d/center_target.py</p><span class="hidden-code" data-code="class VolumeCenter(object):               # 体积中心
    def get_centers_2d(self, bboxes_2d, bboxes_3d, obj_img_inds, img_dense_x2d_small, img_dense_x2d_mask_small,cam_intrinsic, max_shape)
        num_obj = bboxes_3d.size(0)                    # 22
        num_img = cam_intrinsic.size(0)                # 6
        pad_shape = torch.ceil(max_shape / self.output_stride) * self.output_stride           # tensor([ 900., 1600.], device='cuda:0')->tensor([ 904., 1600.], device='cuda:0')8的倍数
        verts = self.base_mesh.verts_list()[0].to(device) * 0.5  # (vn, 3)     torch.Size([8, 3])值为-0.5或0.5，中心点为原点的长宽高为1的3D box
        faces = self.base_mesh.faces_list()[0].to(device)        # (fn, 3)     torch.Size([12, 3])
        vn = verts.size(0)
        fn = faces.size(0)
        verts = verts[None].expand(num_obj, -1, -1)  # (num_obj, vn, 3)  torch.Size([22, 8, 3])
        verts_oc = verts * bboxes_3d[:, None, :3]    # torch.Size([22, 8, 3]),长宽高乘以那8个顶点
        # =====transform to opencv camera space=====
        rot_mats = yaw_to_rot_mat(bboxes_3d[:, 6])  # (num_obj, 3, 3)          得到旋转矩阵
        # (num_obj, vn, 3) = ((num_obj, 3, 3) @ (num_obj, 3, vn)) -> (num_obj, vn, 3) + (num_obj, 1, 3)
        verts_cam = (rot_mats @ verts_oc.transpose(-1, -2)).transpose(-1, -2) + bboxes_3d[:, None, 3:6]    # torch.Size([22, 8, 3])得到22个3Dbox的8个顶点
        # =====join meshes as scenes=====
        verts_list = []  # list of scenes
        faces_list = []
        num_obj_per_img_list = []
        img_has_object_list = []
        for i in range(num_img):                        # 6张图片
            verts_scene = verts_cam[obj_img_inds == i]  # (num_obj_per_img, vn, 3)       # torch.Size([4, 8, 3])
            num_obj_per_img = verts_scene.size(0)
            img_has_object = num_obj_per_img > 0
            if img_has_object:                                                           # 该张图片有3D box
                faces_scene = faces.unsqueeze(0).expand(num_obj_per_img, -1, -1)         # (num_obj_per_img, fn, 3)  torch.Size([4, 12, 3])
                faces_scene = faces_scene + torch.arange(0, num_obj_per_img * vn, step=vn, device=device)[:, None, None]      # reindex  torch.Size([4, 12, 3]) / vn=8    tensor([[[ 0]],[[ 8]],[[16]],[[24]]], device='cuda:0')
                verts_list.append(verts_scene.reshape(num_obj_per_img * vn, 3))          # 顶点          第一个值的shape=torch.Size([32, 3])
                faces_list.append(faces_scene.reshape(num_obj_per_img * fn, 3))          # 对应顶点索引   第一个值的shape=torch.Size([48, 3])
            num_obj_per_img_list.append(num_obj_per_img)                                 # [4, 5, 2, 2, 3, 6]
            img_has_object_list.append(img_has_object)                                   # [True, True, True, True, True, True]
        scene_meshes = Meshes(verts=verts_list, faces=faces_list)      
        # =====select images with objects=====
        img_has_object_list = torch.tensor(img_has_object_list, dtype=torch.bool, device=device)    # tensor([True, True, True, True, True, True], device='cuda:0')
        img_dense_x2d_small = img_dense_x2d_small[img_has_object_list]                              # torch.Size([6, 2, 84, 200])
        img_dense_x2d_mask_small = img_dense_x2d_mask_small[img_has_object_list]                    # torch.Size([6, 1, 84, 200])
        cam_intrinsic = cam_intrinsic[img_has_object_list]
        obj_img_inds_new = (img_has_object_list.cumsum(dim=0) - 1)[obj_img_inds]                    # img_has_object_list.cumsum(dim=0) - 1--》 torch.Size([22])
        # =====camera conversion=====
        f = cam_intrinsic[:, [0, 1], [0, 1]]   # (num_img, 2) [fx, fy]    torch.Size([6, 2])
        p = cam_intrinsic[:, :2, 2]            # (num_img, 2) [px, py]
        half_shape = pad_shape / 2             # (2, ) [h, w]     tensor([ 904., 1600.], device='cuda:0')->tensor([452., 800.], device='cuda:0')
        denom = torch.min(half_shape)          # 452
        cameras = PerspectiveCameras(focal_length=-f / denom,principal_point=(half_shape[[1, 0]] - (p + 0.5)) / denom,device=device)
        # =====rasterize=====
        h_rend, w_rend = int(pad_shape[0]) // self.render_stride, int(pad_shape[1]) // self.render_stride    # self.render_stride=4 --->226,400
        raster_settings = RasterizationSettings(image_size=(h_rend, w_rend),blur_radius=0.0, faces_per_pixel=self.faces_per_pixel,z_clip_value=1e-2)
        frags = self.rasterizer(scene_meshes, cameras=cameras, raster_settings=raster_settings)
        pix_to_face = frags.pix_to_face  # (num_img, h_rend, w_rend, faces_per_pixel)      # torch.Size([6, 226, 400, 16])
        zbuf = frags.zbuf                # (num_img, h_rend, w_rend, faces_per_pixel)      # torch.Size([6, 226, 400, 16])
        # =====post proc=====
        if num_obj > self.max_gpu_obj > 0:      # num_obj > False > 0
            bboxes_2d = bboxes_2d.cpu()
            zbuf = zbuf.cpu()
            pix_to_face = pix_to_face.cpu()
            img_dense_x2d_small = img_dense_x2d_small.cpu()
            img_dense_x2d_mask_small = img_dense_x2d_mask_small.cpu()
            pad_shape = pad_shape.cpu()
            obj_img_inds_new = obj_img_inds_new.cpu()
        centers_2d, bboxes_2d, valid_mask = self.post_proc(zbuf, pix_to_face, img_dense_x2d_small, img_dense_x2d_mask_small,pad_shape, num_obj, obj_img_inds_new, bboxes_2d, fn)        
"> </span>
verts<br>
<span class="hidden-code" data-code="tensor([[-0.5000, -0.5000,  0.5000],
        [ 0.5000, -0.5000,  0.5000],
        [-0.5000,  0.5000,  0.5000],
        [ 0.5000,  0.5000,  0.5000],
        [-0.5000, -0.5000, -0.5000],
        [ 0.5000, -0.5000, -0.5000],
        [-0.5000,  0.5000, -0.5000],
        [ 0.5000,  0.5000, -0.5000]], device='cuda:0')
"> </span>
faces<br>
<span class="hidden-code" data-code="tensor([[0, 1, 2],
        [1, 3, 2],
        [2, 3, 7],
        [2, 7, 6],
        [1, 7, 3],
        [1, 5, 7],
        [6, 7, 4],
        [7, 5, 4],
        [0, 4, 1],
        [1, 4, 5],
        [2, 6, 4],
        [0, 2, 4]], device='cuda:0')
"> </span>`,
                  children: [
                    {
                      type: "heading",
                      depth: 4,
                      payload: { lines: [0, 1] },
                      content:
                        `<p style="color: blue;font-weight: bold;">epropnp_det/core/bbox_3d/center_target.py</p><span class="hidden-code" data-code="class VolumeCenter(object):               # 体积中心
    def post_proc(self, zbuf, pix_to_face, img_dense_x2d_small, img_dense_x2d_mask_small,pad_shape, num_obj, obj_img_inds, bboxes_2d, fn)
"> </span>`,
                    },
                  ],
                },
                {
                  type: "heading",
                  depth: 3,
                  payload: { lines: [0, 1] },
                  content:
                    `<p style="color: blue;font-weight: bold;">epropnp_det/core/bbox_3d/center_target.py</p><span class="hidden-code" data-code="class VolumeCenter(object):               # 体积中心
    def get_centers_2d(self, bboxes_2d, bboxes_3d, obj_img_inds, img_dense_x2d_small, img_dense_x2d_mask_small,cam_intrinsic, max_shape)
"> </span>`,
                },
              ],
            },
            {
              type: "heading",
              depth: 2,
              payload: { lines: [0, 1] },
              content:
                `<p style="color: blue;font-weight: bold;">epropnp_det/models/dense_heads/deform_pnp_head.py</p><span class="hidden-code" data-code="class DeformPnPHead(BaseDenseHead):
        def forward_train()
"> </span>`,
            },
          ],
        },
      ],
    });
  </script>
  <script>
    // 修改滚轮行为：从缩放改为上下移动画布
    (() => {
      function setupWheelPan() {
        if (!window.mm || !window.mm.svg) return;

        const svg = window.mm.svg.node();
        const zoom = window.mm.zoom;

        if (!svg || !zoom) return;

        // 获取 d3（d3 通过 script 标签加载，应该是全局可用的）
        const d3 = window.d3;
        if (!d3 || !d3.zoomIdentity) {
          console.warn('d3 not found, wheel pan may not work');
          return;
        }

        // 禁用滚轮缩放：修改 filter 函数，让滚轮事件不触发缩放
        const originalFilter = zoom.filter();
        zoom.filter(function (event) {
          // 如果是滚轮事件，不触发缩放
          if (event.type === 'wheel') {
            return false;
          }
          // 其他事件使用原来的 filter
          return originalFilter ? originalFilter.apply(this, arguments) : true;
        });

        // 添加自定义滚轮事件处理：上下移动画布
        svg.addEventListener('wheel', function (e) {
          // 如果鼠标在弹窗上，不处理
          const hoverTooltip = document.querySelector('div[style*="z-index: 999999"]');
          const modal = document.querySelector('div[style*="z-index: 99999"]');
          if (hoverTooltip && hoverTooltip.contains(e.target)) return;
          if (modal && modal.contains(e.target)) return;

          // 阻止默认行为
          e.preventDefault();
          e.stopPropagation();

          // 获取当前的 transform
          const gNode = window.mm.g.node();
          const transform = gNode.__zoom || { k: 1, x: 0, y: 0 };

          // 计算滚动的距离（垂直滚动）
          const deltaY = e.deltaY;
          const scrollSpeed = 1; // 滚动速度，可以根据需要调整

          // 更新 y 坐标（上下移动）
          const newY = transform.y + deltaY * scrollSpeed;

          // 使用 d3-zoom 的 API 来更新 transform
          const newTransform = d3.zoomIdentity
            .translate(transform.x, newY)
            .scale(transform.k);

          // 应用新的 transform
          window.mm.g.call(zoom.transform, newTransform);
        }, { passive: false });
      }

      // 等待 markmap 创建完成
      setTimeout(() => {
        setupWheelPan();
        // 如果 markmap 是延迟创建的，也需要监听
        const checkInterval = setInterval(() => {
          if (window.mm && window.mm.svg && window.mm.zoom) {
            setupWheelPan();
            clearInterval(checkInterval);
          }
        }, 100);

        // 10秒后停止检查
        setTimeout(() => clearInterval(checkInterval), 10000);
      }, 500);
    })();
  </script>
  <script src="./npm/myjs/tooltip.js"></script>
</body>

</html>